[{"chunk": " Continual Learning: Applications and the Road Forward\nEli Verwimp\u2217\nRahaf Aljundi\nShai Ben-David Matthias Bethge Andrea Cossu Alexander Gepperth Tyler L. Hayes\nEyke Hu\u0308llermeier Christopher Kanan Dhireesha Kudithipudi Christoph H. Lampert Martin Mundt\nRazvan Pascanu Adrian Popescu Andreas S. Tolias Joost van de Weijer Bing Liu\nVincenzo Lomonaco Tinne Tuytelaars Gido M. van de Ven\nKU Leuven, Belgium Toyota Motor Europe, Belgium University of Waterloo, and Vector Institute, Ontario, Canada University of Tu\u0308bingen, Germany University of Pisa, Italy University of Applied Sciences Fulda, Germany NAVER LABS Europe, France University of Munich (LMU), Germany University of Rochester, Rochester, NY, USA University of Texas at San Antonio, TX, USA Institute of Science and Technology Austria (ISTA) TU Darmstadt & hessian.AI, Germany Google DeepMind, UK Universite\u0301 Paris-Saclay, CEA, LIST, France Baylor College of Medicine, Houston, TX, USA Computer Vision Center, UAB, Barcelona, Spain University of Illinois at Chicago, USA University of Pisa, Italy KU Leuven, Belgium KU Leuven, Belgium\nAbstract\nContinual learning is a sub-field of machine learning, which aims to allow machine learning models to continuously learn on new data, by accumulating knowledge without forgetting what was learned in the past. In this work, we take a step back, and ask: \u201cWhy should one care about continual learning in the first place?\u201d. We set the stage by surveying recent continual learning papers published at three major machine learning conferences, and show that memory-constrained settings dominate the field. Then, we discuss five open problems in machine learning, and even though they seem unrelated to continual learning at first sight, we show that continual learning will inevitably be part of their solution. These problems are model-editing, personalization, on-device learning, faster (re-)training and reinforcement learning. Finally, by comparing the desiderata from these unsolved problems and the current assumptions in continual learning, we highlight and discuss four future directions for continual learning research. We hope that this work offers an interesting perspective on the future of continual learning, while displaying its potential value and the paths we have to pursue in order to make it successful. This work is the result of the many discussions the authors had at the Dagstuhl seminar on Deep Continual Learning, in March 2023.\n1 Introduction\nContinual learning, sometimes referred to as lifelong learning or incremental learning, is a sub-field of machine learning that focuses on the challenging problem of incrementally training models on a stream of data with the aim of accumulating knowledge over time. This setting calls for algorithms that can learn new skills with minimal forgetting of what they had learned previously, transfer knowledge across tasks, and smoothly adapt\n\u2217Corresponding author: eli.verwimp@kuleuven.be\n1\narXiv:2311.11908v2 [cs.LG] 21 Nov 2023\n "}, {"chunk": " to new circumstances when needed. This is in contrast with the traditional setting of machine learning, which typically builds on the premise that all data, both for training and testing, are sampled i.i.d. (independent and identically distributed) from a single, stationary data distribution.\nDeep learning models in particular are in need of continual learning capabilities. A first reason for this is their strong dependence on data. When trained on a stream of data whose underlying distribution changes over time, deep learning models tend to adapt to the most recent data, thereby \u201ccatastrophically\u201d forgetting the information that had been learned earlier (French, 1999). Secondly, continual learning capabilities could reduce the very long training times of deep learning models. When new data are available, current industry practice is to retrain a model fully from scratch on all, past and new, data (see Example 3.4). Such re- training is time inefficient, sub-optimal and unsustainable, with recent large models exceeding 10.000 GPU days of training (Radford et al., 2021). Simple solutions, like freezing feature extractor layers, are often not an option as the power of deep learning hinges on the representations learned by those layers (Bengio et al., 2013). To work well in challenging applications in e.g. computer vision and natural language processing, they often need to be changed.\nThe paragraph above describes two naive approaches to the continual learning problem. The first one, incrementally training \u2013 or finetuning \u2013 a model only on the new data, usually suffers from suboptimal performance when models adapt too strongly to the new data. The second approach, repeatedly retraining a model on all data used so far, is undesirable due to its high computational and memory costs. The goal of continual learning is to find approaches that have a better trade-off between performance and efficiency (e.g. compute and memory) than these two naive ones. In the contemporary continual learning literature, this trade-off typically manifests itself by limiting memory capacity and optimizing performance under this con- straint. Computational costs are not often considered in the current continual learning literature, although this is challenged in some recent works, which we discuss in Sections 2 and 4.1.\nIn this article, we highlight several practical problems in which there is an inevitable continual learning component, often because there is some form of new data that is available for a model to train on. We discuss how these problems require continual learning, and how in these problems that what is constrained and that what is optimized differs. Constraints are hard limits set by the environment of the problem (e.g. small devices have limited memory), under which other aspects, such as computational cost and performance, need to be optimized. Progress in the problems we discuss goes hand in hand with progress in continual learning, and we hope that they serve as a motivation to continue working on continual learning, and offer an alternative way to look at it and its benefits. Similarly, they can offer an opportunity to align currently common assumptions that stem from the benchmarks we use, with those derived from the problems we aim to solve. Section 3 describes some of these problems and in Section 4 we discuss some exciting future research directions in continual learning, by comparing the desiderata of the discussed problems and contemporary continual learning methods.\n2 Current continual learning\nBefore exploring different problem settings in which we foresee continual learning as a useful tool, we first wish to understand the current landscape. Our aim is to paint a clear picture of how memory and compu- tational cost are approached. To achieve this, we surveyed continual learning papers accepted at three top machine learning conferences (ECCV \u201922, NeurIPS \u201922 and CVPR \u201923). We considered all papers with either \u2018incremental\u2019, \u2018continual\u2019, \u2018forgetting\u2019, \u2018lifelong\u2019 or \u2018catastrophic\u2019 in their titles, disregarding false positives. See Appendix for the methodology. For our final set of 60 papers, we investigated how they balance the memory and compute cost trade-offs. We discern five categories:\nNot discussed: No clear mention of the impact of the proposed method/analysis on the cost Discussed: Cost is discussed in text, but not quantitatively compared between methods. Compared: Cost is qualitatively compared to other methods\nConstrained: Methods are compared using the same limited cost.\nOptimized: Cost is among the optimized metrics.\n2\n"}, {"chunk": " Optimized\nConstrained\nCompared\nDiscussed\nNot discussed\n34\n28\n22\n332\n2\nNone \u22641% 1-5% 5-10% 10-99% 100% Percentage of stored data\nFigure 1: Most papers strongly restrict memory use and do not discuss computational cost. The figure shows an overview of the surveyed papers in Section 2. Each dot represents one paper, illustrating what percentage of data their methods store (horizontal axis) and how computational cost is handled (vertical axis). The majority of surveyed papers are in the lower-left corner: those that strongly restrict memory use and do not quantitatively approach computational cost (i.e. it is at most discussed). For more details, see Appendix.\nMany continual learning papers use memory in a variety of ways, most often in the form of storing samples, but regularly model copies (e.g. for distillation) or class means and their variances are stored as well. We focus on the amount of stored data, as this is the most common use of memory, but discuss other memory costs in the Appendix. Of the surveyed papers, all but two constrain the amount of stored samples. So rather than reporting the category, in Figure 1, we report how strongly it is constrained, using the percentage of all data that is stored. It is apparent that the majority of these papers do not store any (raw) samples and many are using only a small fraction. Two notable exceptions that store all the raw data are a paper on continual reinforcement learning (RL) (Fu et al., 2022), something which is not uncommon in RL, see Section 3.5. The second one, by Prabhu et al. (2023a), studies common CL algorithms under a restricted computational cost.\nWhile memory costs (for raw samples) are almost always constrained, computational costs are much less so. Sometimes simply discussing that there is (almost) no additional computational cost can suffice, yet it is remarkable that in more than 50% of the papers there is no mention of the computational cost at all. When it is compared, it is often done in the appendix. There are a few notable exceptions in the survey, which focus explicitly on the influence of the computational cost, either by constraining (Prabhu et al., 2023a; Kumari et al., 2022; Ghunaim et al., 2023) or optimizing it (Wang et al., 2022b). For a more elaborate discussion of measuring the computational cost, see Section 4.1. Together, these results show that many continual learning methods are developed with a low memory constraint, and with limited attention to the computational cost. They are two among other relevant dimensions of continual learning in biological systems (Kudithipudi et al., 2022) and artificial variants (Mundt et al., 2022), yet with the naive solutions of the introduction in mind, they are two crucial components of any continual learning algorithm. In the next section, we introduce some problems for which continual learning is inevitable. They illustrate that methods with a low computational cost is just as well an important setting, yet it has not received the same level of attention.\n3 Continual learning is not a choice\nTo solve the problems described in this section, continual learning is necessary and not just a tool that one could use. We argue that in all of them, the problem can, at least partly, be recast as a continual learning\n3\n 1\n3\n10\n12\n      Computational cost\n"}, {"chunk": " problem. This means that the need for continual learning algorithms arises from the nature of the problem itself, and not just from the choice of a specific way for solving it. We start these subsections by explaining what the problem is and why it fundamentally requires continual learning. Next we briefly discuss current solutions and how they relate to established continual learning algorithms. We conclude each part by laying down what the constraints are and what metrics should be optimized.\n3.1 Adapting machine learning models locally\nIt is often necessary to correct wrongly learned predictions from past data. Real world practice shows us that models are often imperfect, e.g. models frequently learn various forms of decision shortcuts (Lapuschkin et al., 2019), or sometimes the original training data become outdated and are no longer aligned with current facts (e.g. a change in government leaders). Additionally, strictly accumulating knowledge may not always be compliant with present legal regulations and social desiderata. Overcoming existing biases, more accurately reflecting fairness criteria, or adhering to privacy protection regulations (e.g. the right to be forgotten of the GDPR in Europe (Union, 2016)), represent a second facet of the editing problem.\nWhen mistakes are exposed, it is desirable to selectively edit the model without forgetting other relevant knowledge and without re-training from scratch. The model editing pipeline (Mitchell et al., 2022) first identifies corner cases and failures, then prompts data collection over those cases, and subsequently re- trains/updates the model. Recently proposed methods are able to locally change models, yet this comes at a significant cost, or model draw-down, i.e. forgetting of knowledge that was correct (Santurkar et al., 2021). Often the goal of model editing is to change the output associated with a specific input from A to B, yet changing the output to something generic or undefined is an equally interesting case. Such changes can be important in privacy-sensitive applications, to e.g. forget learned faces or other personal attributes.\nNaively, one could retrain a model from scratch with an updated dataset, that no longer contains outdated facts and references to privacy-sensitive subjects, or includes more data on previously out-of-distribution data. To fully retrain on the new dataset, significant computational power and access to all previous training data is necessary. Instead, with effective continual learning, this naive approach can be improved by only changing what should be changed. An ideal solution would be able to continually fix mistakes, at a much lower computational cost than retraining from scratch, without forgetting previously learned and unaffected information. Such a solution would minimize computational cost, while maximizing performance. There is no inherent limitation on memory in this problem, although it can be limited if not all training data are freely accessible.\n3.2 Incorporation of user- and domain-specific knowledge\nSome of the most powerful machine learning models are trained on very large datasets, usually scraped from the Internet. The result is a model that is able to extract useful and diverse features from high-dimensional data. However, the vastness of the data they are trained on also has a downside. Internet data is generated by many different people, who all have their own preferences and interests. One model cannot fit these\n Example: 3.1\n Lazaridou et al. (2021) used the customnews benchmark to evaluate how well a lan- guage model trained on news data from 1969 \u2013 2017 performs on data from 2018 and 2019. They find that models perform worse on the newest data, mostly on proper nouns (e.g. \u201cArdern\u201d or \u201cKhashoggi\u201d), as well as words introduced because of soci- etal changes such as \u201cCovid-19\u201d and \u201cMeToo\u201d. They identify a set of 287 new words that were not used in any document prior to 2018. Such new words are inevitable in future texts too. To teach a model these changes they perform updates on the newly arriving data, which gradually improves the performance on the years 2018 and 2019 (a 10% decrease in perplexity), yet at the cost of performance on earlier years (a 5% increase on all previous years). When weighing all years equally, the final model thus got worse than before updating.\n 4\n"}, {"chunk": " conflicting preferences, and the best fit is close to the average internet user (Hu et al., 2022b). However, machine learning models are often used by individuals or small groups, or for highly specific applications. This contradiction makes any possessive references such as \u2018my car\u2019 or \u2018my favorite band\u2019 by construction ambiguous and impossible for the system to understand. Further, Internet scraped data often do not contain (enough) information to reach the best performance in specialized application domains like science and user sentiment analysis (Beltagy et al., 2019).\nDomain adaptation and personalization are thus often necessary. The topic has been investigated in the natural language processing (NLP) community for many different applications. Initially, fine-tuning on a supervised domain-specific dataset was the method of choice, but recently, with the success of very large language models (LLM), the focus has shifted towards changing only a small subset of parameters with adapters (Houlsby et al., 2019), low-rank updates (Hu et al., 2022a) or prompting (Jung et al., 2023). How- ever, these methods do not explicitly identify and preserve important knowledge in the original language model. This hampers the integration of general and domain-specific knowledge and produces weaker re- sults (Ke et al., 2022). To identify the parameters that are important for the general knowledge in the LLM in order to protect them is a challenging problem. Recent works (Ke et al., 2021) made some progress in balancing the trade-off between performance on in-domain and older data. In the computer vision field, similar work has also been done by adapting CLIP to different domains (Wortsman et al., 2022) and to include personal text and image pairs (Cohen et al., 2022).\nNo matter how large or sophisticated the pre-trained models become, there will always be data that they are not, or cannot be, trained on (e.g. tomorrow\u2019s data). It is impossible to acquire all the information in the world, and even if it were possible, that cannot result in personalized models. When specialized data are collected afterwards, models can be updated either on the original machine or on a smaller device. Again, the final goal is to train a specialized or personalized model, more compute-efficient than when trained from scratch. On the original training server, past data are usually available. When this is not the case, because training happens on a more restricted (e.g. personal) device, memory does become a constraint, which we elaborate on in the next subsection.\n Example: 3.2\n Dingliwal et al. (2023) personalize end-to-end speech recognition models with words that are personal to the user (e.g. family member names) or words that are very rare except in specialized environments (e.g. \u201cecchy- moses\u201d in medical settings). With an extra attention module and a pre- computed set of representations of the specialized vocabulary, they \u2018bias\u2019 the original model towards using the new rare and unknown words. The performance on the specialized words is remarkably improved, yet with a decrease in performance on non-specialist word recognition. In their exper- iments specialized tokens are less than 1% off all tokens, so even a relatively small decrease in performance on other tokens is non-negligible.\n... with ecchymosis as result ...\n  ... with echo Moses as result ...\n 3.3 On-device learning\nTo offer an experience aligned with a user\u2019s preferences, or adjusted to a new personal environment, many deep learning applications require updates on the deployed device. Cloud computing is often not available because of communication issues (e.g. in remote locations with restricted internet access, or when dealing with very large quantities of data), or to preserve the privacy of the user (e.g. for domestic robots, monitoring cameras). On such small devices, both memory and computational resources are typically constrained, and the primary goal is to maximize model efficacy under these constraints. These tight constraints often make storing all user data and retraining from scratch infeasible, necessitating continual learning whenever the pre-trained capabilities should not be lost during continued on-device training (see also Example 3.3).\nThese constraints, as well as increasingly complex computations for energy-accuracy trade-offs in real- time (Kudithipudi et al., 2023), limit the direct application of optimization typically used in cloud de-\n5\n"}, {"chunk": " ployments. For example, existing methods only update the final classification layer of a pre-trained feature extractor (Hayes & Kanan, 2022). Yet this relatively lightweight process becomes challenging when there is a large domain gap between the initial training set and the on-device data. The latter is often hard to collect, since labeling large amounts of data by the user is impractical, requiring few-shot solutions. When devices shrink even further, the communication costs become significant, and reading and writing to memory can be up to \u223c99% of the total energy budget (Dally, 2022). In addition to algorithmic optimizations for con- tinual learning, architectural optimizations offer interesting possibilities. These enhancements may include energy-efficient memory hierarchies, adaptable dataflow distribution, domain-specific compute optimizations like quantization and pruning, and hardware-software co-design techniques (Kudithipudi et al., 2022).\nOn-device learning from data that is collected locally almost certainly involves a distribution shift from the original (pre-)training data. This means the sampling process is no longer i.i.d., thus requiring continual learning to maintain good performance on the initial training set. If these devices operate on longer time scales, the data they sample themselves will not be i.i.d. either. To leverage the originally learned information as well as adapt to local distribution changes, such devices require continual learning to operate effectively. Importantly, they should be able to learn using only a limited amount of labeled information, while operating under the memory and compute constraints of the device.\n3.4 Faster retraining with warm starting\nIn many industrial settings, deep neural networks are periodically re-trained from scratch when new data are available, or when a distribution shift is detected. The newly gathered data is typically a lot smaller than the original dataset is, which makes starting from scratch a wasteful endeavor. As more and more data is collected, the computational requirements for retraining continue to grow over time. Instead, continual learning can start from the initial model and only update what is necessary to improve performance on the new dataset. Most continual learning methods are not designed for computational efficiency (Harun et al., 2023a), yet Harun et al. (2023b) show that reductions in training time by an order of magnitude are possible, while reaching similar performance. Successful continual learning would offer a way to drastically reduce the expenses and extraordinary carbon footprint associated with retraining from scratch (Amodei & Hernandez, 2018), without sacrificing accuracy.\nThe challenge is to achieve performance equal to or better than a solution that is trained from scratch, but with fewer additional resources. One could say that it is the performance that is constrained, and computational cost that must be optimized. Simple approaches, like warm-starting, i.e. from a previously trained network, can yield poorer generalization than models trained from scratch on small datasets (Ash & Adams, 2020), yet it is unclear whether this translates to larger datasets, and remains a debated question. Similar results were found in (Berariu et al., 2021; Dohare et al., 2023), which report a loss of plasticity, i.e. the ability to learn new knowledge after an initial training phase. In curriculum learning (Bengio et al., 2009), recent works have tried to make learning more efficient by cleverly selecting which samples to train on when (Hacohen et al., 2020). Similarly, active learning (Settles, 2009) studies which unlabeled samples could best be labeled (given a restricted budget) to most effectively learn. Today those fields have to balance\n Example: 3.3\n In a 2022 article by MIT Review (Guo, 2022), it was revealed how a robot vacuum\ncleaner had sent images, in some cases sensitive ones, back to the company, to\nbe labeled and used in further training on central servers. In response, an R&D\ndirector of the company stated: \u201cRoad systems are quite standard, so for makers\nof self-driving cars, you\u2019ll know how the lane looks [...], but each home interior is\nvastly different\u201d, acknowledging the need to adjust the robots to the environment\nthey are working in. Our homes are highly diverse, but also one of the most\nintimate and private places that exist. Images can reveal every detail about them\nand should thus remain private. Adapting to individual homes is necessary, but\nshould not come at the cost of initial smart abilities such as object recognition, collision prevention and planning, which are unlikely to be learned using only locally gathered data.\n 6\n"}, {"chunk": " learning new information with preventing forgetting, yet with successful continual learning they could focus more on learning new information as well and as quickly as possible.\nMinimizing computational cost could also be rephrased as maximizing learning efficiency. Not having to re-learn from scratch whenever new data is available, figuring out the best order to use data for learning, or the best samples to label can all contribute to this goal. Crucially, maximizing knowledge accumulation from the available data is part of this challenge. Previous work (Hadsell et al., 2020; Hacohen et al., 2020; Pliushch et al., 2022) suggested that even when all data is used together, features are learned in sequential order. Exploiting this order to make learning efficiently requires continual learning.\n Example: 3.4\n Continuous training is one of the six important building blocks in MLOps\n(Machine Learning Operations, similar to DevOps), according to a Google\nML\ndevelopment\nwhite paper on the subject (Salama et al., 2021). This step is consid-\nered necessary, in response to performance decays when incoming data\nContinuous\nTraining monitoring\noperationalization characteristics change. They describe in great detail how to optimize this\npipeline, from various ways to trigger retraining to automated approaches\nMLOps\nto deploy retrained models. However, retraining is implicitly considered to\nlifecycle\nbe from scratch, which makes most pipelines inherently inefficient. Simi-\nPrediction\nServing\nContinuous training larly, other resources stating the importance of retraining ML models and\nefficient MLOps, at most very briefly consider other options than retraining\nModel\ndeployment\nfrom scratch (Kreuzberger et al., 2023; Komolafe, 2023; Alla et al., 2021).\nThe efficiency that can be gained here represents an enormous opportunity\nfor the continual learning field, which is clearly illustrated by Huyen (2022) from an industry perspective.\n     3.5 Reinforcement learning\nIn reinforcement learning (RL), agents learn by interacting with an environment. This creates a loop, where the agent takes an action within the environment, and receives from the environment an observation and a reward. The goal of the learning process is to learn a policy, i.e. a strategy to choose the next action based on the observations and rewards seen so far, which maximizes the rewards (Sutton & Barto, 2018). Given that observations and rewards are conditioned on the policy, this leads to a natural non-stationarity, where each improvement step done on the policy can lead the agent to explore new parts of the environment. The implicit non-stationarity of RL can be relaxed to a piece-wise stationary setting in off policy RL settings Sutton & Barto (2018), however this still implies a continual learning problem. Offline RL (Levine et al., 2020) (e.g. imitation learning) completely decouples the policy used to collect data from the learning policy, leading to a static data distribution, though is not always applicable and can lead to suboptimal solutions due to the inability of the agent to explore. Lastly, for real-world problems, the environment itself may be non-stationary, either intrinsically so, or through the actions of the agent.\nThe presence of non-stationarities in reinforcement learning makes efficient learning difficult. To accelerate learning, experience replay has been an essential part of reinforcement learning (Lin, 1992; Mnih et al., 2015). While engaging in new observations, previously encountered states and action pairs are replayed to make training more i.i.d. In contrast to replay in supervised learning, in RL there is less focus on restricting the amount of stored examples, as the cost of obtaining them is considered very high. Instead the focus is how to select samples for replay (e.g. Schaul et al., 2016) and how to create new experiences from stored ones (Lin et al., 2021). Additionally, loss of plasticity (e.g. Dohare et al., 2023; Lyle et al., 2022) \u2014 inability of learning efficiently new tasks \u2014 and formalizing the concept of continual learning (e.g. Kumar et al., 2023; Abel et al., 2023) also take a much more central role in the RL community.\nFinally, besides the non-stationarities encountered while learning a single task, agents are often required to learn multiple tasks. This setting is an active area of research (Wo\u0142czyk et al., 2021; Kirkpatrick et al., 2017; Rolnick et al., 2019), particularly since the external imposed non-stationarity allows the experimenter to control it and probe different aspects of the learning process. RL has its own specific problems with continual learning, e.g. trivially applying rehearsal methods fails in the multi-task setting, and not all parts\n7\n"}, {"chunk": " of the network should be regularized equally (Wolczyk et al., 2022). Issues considering the inability to learn continually versus the inability to explore an environment efficiently, as well as dealing with concepts like episodic and non-episodic RL, makes the study of continual learning in RL more challenging. Further research promises agents that train faster, learn multiple different tasks sequentially and effectively re-use knowledge from previous tasks to work faster and towards more complex goals.\n4 Future directions for continual learning\nIn this section we discuss interesting future directions for continual learning research, informed by what was discussed in the previous sections. We start by addressing the motivation for these research directions, followed by a brief overview of existing work, and finally justifying the importance of each concept.\n4.1 Rethinking memory and compute assumptions\nIn all of the problems described in the previous section, optimizing or restricting compute complexity plays an important role, often a more central one than memory capacity does. This is in stark contrast to the results of the survey in Section 2. The vast majority of papers does not qualitatively approach compute complexity, while not storing, or only very few, samples. Two popular reasons for arguing a low storage solution are the cost of memory and privacy concerns, but these arguments are often not relevant in practice. Prabhu et al. (2023b) calculate that the price to store ImageNet1K for one month is just 66\u00a2, while training a model on it requires 500$. This means storing the entire dataset for 63 years is as expensive as training ImageNet once. Further, privacy and copyright concerns are not solved by simply deleting data from the training set, as data can be recovered from derivative models (Haim et al., 2022), and rulings to remove data might only be viable by re-training from scratch (Zhao, 2022) (hence making continual learning superfluous), at least until reliable model editing exists (see Section 3.1). Section 3.3 showed that use cases in low memory settings exist, but, as the four of the five problems show, there are many reasons to study algorithms that restrict computational cost just like restricted memory settings are studied today. We believe it is important to reconsider these common assumptions on memory and computational cost, and instead derive them from the real-world problems that continual algorithms aim to solve.\nTo achieve this goal, we should agree on how to measure computational cost, which is necessary to restrict it. Yet it is not straightforward to do so. Recent approaches use the number of iterations (Prabhu et al., 2023a) and forward/backward passes (Kumari et al., 2022; Harun et al., 2023c), which works well if the used model is exactly the same, but cannot capture architectural differences that influence computational cost. Similarly, when the number of parameters is used (Wang et al., 2022a), more iterations or forward passes do not change the perceived cost. The number of floating point operations (FLOPs) is often used to measure computational cost in computer science, and is a promising candidate, yet is sometimes hard to measure accurately (Wang et al., 2022b). Additionally, time to convergence should also be considered, as faster convergence would also lower compute time. See Schwartz et al. (2020) for an elaborate discussion. To properly benchmark compute time and memory use in continual learning algorithms, we should build on this existing literature to attain strong standards for measuring both compute and memory cost and the improvements thereof.\n Example: 3.5\n Typical RL methods store millions or more transitions in a replay memory. Schaul et al. (2016) showed that theoretically exponential training speed-ups are possible when cleverly selecting the transitions to replay. By approximating \u2018how much the model can learn\u2019 from a transition, they prioritize some samples over others and practically show a linear speed-up compared to uniform selection, the default at that point. Current state-of-the-art in the Atari-57 benchmark, MuZero (Schrittwieser et al., 2020), relies on this prioritized selection and confirms its importance, yet from the initial theoretical results, it is clear that improved continual learning could further improve convergence speeds and results (e.g. Pritzel et al., 2017).\n 8\n"}, {"chunk": "                FD 1: re-considering the current compute and memory assumptions\nFD 2: better theoretic understanding of the limits and guarantees in CL\nFD 3: towards large scale continual learning and allowing small updates in large models.\nFD 4: integrating the labeling process and data acquiring steps into the CL-algorithm\nFigure 2: An overview of the future directions (FD) discussed in Section 4\nAs illustrated in Section 2, there are works that have started to question our common assumptions in continual learning (Harun et al., 2023b). SparCL optimizes compute time explicitly (Wang et al., 2022b), while (Prabhu et al., 2023b;a) compare methods while constraining computational cost. Chavan et al. (2023) establish DER (Yan et al., 2021) as a promising method when compute complexity is constrained, while other works suggest that experience replay is likely most efficient (Harun et al., 2023c; Prabhu et al., 2023a). These early works have laid the groundwork, and we believe that it is in continual learning\u2019s best interest to push further in this direction, and develop strategies for learning under a tight compute budget, with and especially without memory constraints.\n4.2 Theory\nIn the past, continual learning research has achieved interesting empirical results. In contrast to classic machine learning, not much is known about whether and under which conditions, we can expect results. Many theoretical results rely on the i.i.d assumption, among which the convergence of stochastic gradient descent and the difference between expected and empirical risk in many PAC-bound analyses (although there are some exceptions, e.g. Pentina & Lampert 2014). Crucially, the i.i.d. assumption is almost always broken in continual learning, as illustrated by the problems in Section 3. To a certain extent this also happens in training with very large datasets, due to the computational cost of sampling data batches in an i.i.d. fashion compared to ingesting them in fixed but random order. Not having theoretical guarantees means that continual learning research is often shooting in the dark, hoping to solve a problem that we do not know is solvable in the first place.\nTo understand when and under which assumptions we can find solutions, new concepts in a number of directions need to be developed in order to theoretically grasp continual learning in its full breadth. A key aspect is optimization. In which sense and under which conditions do continual learning algorithms converge to stable solutions? And what kind of generalization can we expect? We want to emphasize that we should not be misguided by classical notions of those concepts. It might be, for instance, more insightful to think of continual learning as tracking a time-varying target when reasoning about convergence (e.g. Abel et al., 2023), and classic, static, notions of generalization might not work here, although initial results by Zimin & Lampert (2019) are promising. Even if it is possible to find a good solution, it is unclear whether this is achievable in reasonable time, and crucially, whether it can be more efficient than re-training from scratch. Knoblauch et al. (2020) show that even in ideal settings continual learning is NP-complete, yet Mirzadeh et al. (2021) empirically illustrate that often there are linear low-loss paths to the solution, reassuring that solutions that are easy to find are not unlikely to exist.\nNot all continual learning is equally difficult. An important factor is the relatedness of old and new data. In domain adaptation, David et al. (2010) have shown that without assumptions on the data, some adaptation tasks are simply impossible. Empirically (Zamir et al., 2018) and to some extent theoretically (Prado &\n9\n"}, {"chunk": " Riddle, 2022), we know that in many cases transfer is successful because most tasks are related. Similar results for continual learning are scarce. Besides data similarity, the problem setting is an important second facet. For instance, class incremental learning is much harder than its task-incremental counterpart, as it additionally requires the predictions of task-identities (van de Ven et al., 2022; Kim et al., 2022). We believe that understanding the difficulty of a problem and having formal tools expressive enough to describe or understand relatedness between natural data will allow a more principled approach, and better guarantees on possible results.\nFinally, theory in continual learning might simply be necessary to deploy continual learning models in a trustworthy manner. It requires models to be certified (Huang et al., 2020), i.e. they need to be thoroughly tested before deployment to work as intended. It is however unclear how this would fare in a continual learning setting, as by design, such models will be updated after deployment.\n4.3 Large scale continual learning\nMost of the problems in Section 3 start when there is a change in the environment of the model and it needs to be updated. These changes are often are small compared to the preceding training. The initial models, often referred to as foundation models, are typically powerful generalist models that can perform well on various downstream tasks, e.g. Oquab et al. (2023); Radford et al. (2021). However, performance gains are generally seen when adapting these models to specific tasks or environments, which compromises the initial knowledge in the pretrained model. In a continuously evolving world, one would expect that this knowledge is subject to be continuous editing, updating, and expansion, without losses in performance. When investigating continual learning that starts with large-scale pretrained models, the challenges might differ from those encountered in continual learning from random initializations and smaller models.\nIn contrast to smaller models, the required adjustments to accommodate new tasks are usually limited compared to the initial training phase, which may result in forgetting being less pronounced than previously anticipated. It is an open questions which continual learning techniques are more effective in such a case. For example, Xiang et al. (2023) suggest that parameter regularization mechanisms (Kirkpatrick et al., 2017) are more effective than functional regularization (e.g. distillation approaches (Li & Hoiem, 2017)) in reducing forgetting in a large language model. Additionally, it might not be necessary to update all parameters, which in itself is computationally expensive for large models. Approaches considering adapters (Houlsby et al., 2019; Jia et al., 2022; Li & Liang, 2021), low rank updates (Hu et al., 2022a) or prompting (Jung et al., 2023), are argued to be more feasible in this setting. Freezing, or using non-uniform learning rates, might also be necessary when data is limited to prevent optimization and overfitting issues. How to adapt models if the required changes are comparatively small to the original training remains an interesting research direction, with promising initial results (Wang et al., 2022c; Li et al., 2023; Panos et al., 2023).\nLastly, in the large scale learning setting there is a paradigm shift from end-to-end learning towards more modular approaches, where different components are first trained and then stitched together. It is somewhat of an open question of what implication this has for continual learning (Ostapenko et al., 2022; Cossu et al., 2022). In the simplest scenario, one could decouple the learning of a representation, done with e.g. contrastive unsupervised learning, versus that of classifier with supervision (e.g. Alayrac et al., 2022). Yet this idea can be extended towards using multiple (e.g. domain specific) experts (Ramesh & Chaudhari, 2021) and using more than one modality (e.g. vision and speech) (Radford et al., 2021). A better understanding of how continual learning algorithms can exploit these setting is required to expand beyond the end-to-end paradigms currently used.\nWhile there has been promising research in these directions, we believe that considerably more is needed. So far, we do not have a strong understanding of the possibilities and limits of small updates on large pre- trained models, and how the training dynamics are different than the smaller-scale models typically used in continual learning. Further research in the relation between new data and pre-training data might open up new opportunities to more effectively apply these smaller updates, and will ultimately make continual learning more effective in handling all sorts of changes in data distributions. Understanding the interplay between memory and learning, and how to exploit the modular structure of this large model could enable specific ways to address the continual learning problem.\n10\n"}, {"chunk": " 4.4 Continual learning in a real-world environment\nContinual learning, in its predominant form, is centered around effective and resource-efficient accumulation of knowledge. The problem description typically starts whenever there is some form of new data available, see Section 3. How the data is produced is a question that is much less considered in continual learning. We want to emphasize that there is a considerable overlap between machine learning subfields (Mundt et al., 2022), in particular in those that are concerned with both detecting change in data distributions and techniques that reduce the required effort in labeling data. It will be important to develop continual learning algorithms with these in mind. These fields depend on and need each other to solve real-world problems, making it crucial that their desiderata align.\nOpen world learning (Bendale & Boult, 2015) is such a closely related field. Early work on open-world learning focused on detecting novel classes of objects that were not seen during training, relaxing the typical closed-world assumption in machine learning. A first step to realize open-world learning is detecting a change in incoming data, more formally known as out-of-distribution (OOD) or novelty detection. Detecting such changes requires a certain level of uncertainty-awareness of a model, i.e. it should quantify what it does and does not know. This uncertainty can be split into aleatoric uncertainty, which is an irreducible property of the data itself, and epistemic uncertainty, a result of the model not having learned enough (Hu\u0308llermeier & Waegeman, 2021). When modeled right, the latter can provide a valuable signal to identify what should be changed in continually trained models (Ebrahimi et al., 2020). Alternatively, it provides a theoretically grounded way for active learning, which studies how to select the most efficient unlabeled data points for labeling (Settles, 2009; Nguyen et al., 2022).\nEven when OOD data is properly detected, it might not be directly usable. It can be unlabeled, without sufficient meta-data, or in the worst case corrupted. Many CL algorithms require the new data to be labeled before training, which is always costly and often difficult in e.g. on-device applications. This process makes it likely that when solving problems as described in Section 3, a model has access to a set of unlabeled data, possibly extended by some labeled samples that are obtained using active learning techniques. To successfully work in such an environment, a model should be able to update itself in a self- or semi-supervised way, an idea recently explored in Fini et al. (2022).\nContinual learning depends on the data available to update a model. It is thus important to develop CL algorithms that are well calibrated, capable of OOD detection and learning in an open world. Further, in many settings (see Section 3.3), new data will not, or only partly, be labeled, which requires semi- or self- supervised continual learning (Mundt et al., 2023). We recommend working towards future continual learning algorithms with these considerations in mind, as methods that rely less on the fully labeled, closed-world assumption will likely be more practically usable in the future.\n5 Conclusion\nIn this work, we first surveyed the current continual learning field, and showed that many papers study the memory-restricted setting with little or no concern for the computational cost. The problems we introduced all require some form of continual learning, not because it is a nice-to-have, but because the solution inherently depends on continual learning. Finally, we established four research directions in continual learning that we find promising, in the light of the scenarios we described. In summary, many of these applications are more compute-restricted than memory-restricted, so we vouch for exploring this setting more. Further, we believe a better theoretical understanding, a larger focus on pre-training and comparatively small future updates, and greater attention to how data is attained, will help us solving these problems, and make continual learning a practically useful tool to solve the described and other machine learning problems. A summary of the talks and discussions at the Deep Continual Learning seminar in Dagstuhl that inspired this paper can be found in Tuytelaars et al. (2023).\n11\n"}, {"chunk": " Broader impact\nThis paper does not present any new algorithm or dataset, hence the potential direct societal and ethical implications are rather limited. However, continual learning and applications thereof, as we have examined, may have a long-term impact. Reducing computational cost can positively affect the environmental impact machine learning has. Easily editable networks, or ways to quickly update parts of networks as discussed in Section 3.1 and 3.4, may further democratize the training of machine learning model. Yet this also means that it can be exploited by malicious actors to purposely inject false information in a network. Predictions made by those networks could misinform people or lead to harmful decisions. Excessive personalization as described in Section 3.2 may negatively impact community solidarity, yet benefit the individual.\nReferences\nDavid Abel, Andre\u0301 Barreto, Benjamin Van Roy, Doina Precup, Hado van Hasselt, and Satinder Singh. A definition of continual reinforcement learning. arXiv preprint arXiv:2307.11046, 2023.\nJean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katie Millican, Malcolm Reynolds, et al. Flamingo: a visual language model for few-shot learning. arXiv preprint arXiv:2204.14198, 2022.\nSridhar Alla, Suman Kalyan Adari, Sridhar Alla, and Suman Kalyan Adari. What is MLOPs? Beginning MLOps with MLFlow: Deploy Models in AWS SageMaker, Google Cloud, and Microsoft Azure, pp. 79\u2013124, 2021.\nDario Amodei and Danny Hernandez. AI and compute. https://openai.com/research/ai-and-compute, 2018. Online; accessed 20-June-2023.\nJordan Ash and Ryan P Adams. On warm-starting neural network training. Advances in Neural Information Processing Systems, 33:3884\u20133894, 2020.\nIz Beltagy, Kyle Lo, and Arman Cohan. Scibert: A pretrained language model for scientific text. arXiv preprint arXiv:1903.10676, 2019.\nAbhijit Bendale and Terrance Boult. Towards open world recognition. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pp. 1893\u20131902, 2015.\nYoshua Bengio, Je\u0301ro\u0302me Louradour, Ronan Collobert, and Jason Weston. Curriculum learning. In Proceedings of the 26th annual International Conference on Machine Learning, pp. 41\u201348, 2009.\nYoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new perspec- tives. IEEE transactions on pattern analysis and machine intelligence, 35(8):1798\u20131828, 2013.\nTudor Berariu, Wojciech Czarnecki, Soham De, Jorg Bornschein, Samuel Smith, Razvan Pascanu, and Claudia Clopath. A study on the plasticity of neural networks. arXiv preprint arXiv:2106.00042, 2021.\nVivek Chavan, Paul Koch, Marian Schlu\u0308ter, and Clemens Briese. Towards realistic evaluation of industrial continual learning scenarios with an emphasis on energy consumption and computational footprint. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 11506\u201311518, 2023.\nNiv Cohen, Rinon Gal, Eli A Meirom, Gal Chechik, and Yuval Atzmon. \u201cthis is my unicorn, fluffy\u201d: Personalizing frozen vision-language representations. In European Conference on Computer Vision, pp. 558\u2013577. Springer, 2022.\nAndrea Cossu, Tinne Tuytelaars, Antonio Carta, Lucia Passaro, Vincenzo Lomonaco, and Davide Bacciu. Continual pre-training mitigates forgetting in language and vision. arXiv preprint arXiv:2205.09357, 2022.\nWilliam Dally. On the model of computation: point. Communications of the ACM, 65(9):30\u201332, 2022. 12\n"}, {"chunk": " Shai Ben David, Tyler Lu, Teresa Luu, and Da\u0301vid Pa\u0301l. Impossibility theorems for domain adaptation. In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, pp. 129\u2013136. JMLR Workshop and Conference Proceedings, 2010.\nSaket Dingliwal, Monica Sunkara, Srikanth Ronanki, Jeff Farris, Katrin Kirchhoff, and Sravan Bodapati. Personalization of CTC speech recognition models. In 2022 IEEE Spoken Language Technology Workshop (SLT), pp. 302\u2013309. IEEE, 2023.\nShibhansh Dohare, Juan Hernandez-Garcia, Parash Rahman, Richard Sutton, and Rupam Mahmood. Loss of plasticity in deep continual learning. Research Square preprint PPR: PPR727015, 2023. doi: 10.21203/ rs.3.rs-3256479/v1.\nSayna Ebrahimi, Mohamed Elhoseiny, Trevor Darrell, and Marcus Rohrbach. Uncertainty-guided continual learning with bayesian neural networks. International Conference on Learning Representations, 2020.\nEnrico Fini, Victor G Turrisi Da Costa, Xavier Alameda-Pineda, Elisa Ricci, Karteek Alahari, and Julien Mairal. Self-supervised models are continual learners. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9621\u20139630, 2022.\nRobert M French. Catastrophic forgetting in connectionist networks. Trends in Cognitive Sciences, 3(4): 128\u2013135, 1999.\nHaotian Fu, Shangqun Yu, Michael Littman, and George Konidaris. Model-based lifelong reinforcement learning with bayesian exploration. Advances in Neural Information Processing Systems, 35:32369\u201332382, 2022.\nYasir Ghunaim, Adel Bibi, Kumail Alhamoud, Motasem Alfarra, Hasan Abed Al Kader Hammoud, Ameya Prabhu, Philip HS Torr, and Bernard Ghanem. Real-time evaluation in online continual learning: A new hope. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 11888\u201311897, 2023.\nEileen Guo. A roomba recorded a woman on the toilet. how did screenshots end up on facebook? https://www.technologyreview.com/2022/12/19/1065306/ roomba-irobot-robot-vacuums-artificial-intelligence-training-data-privacy/, 2022. Online; accessed 11-October-2023.\nGuy Hacohen, Leshem Choshen, and Daphna Weinshall. Let\u2019s agree to agree: Neural networks share classification order on real datasets. In Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 3950\u20133960. PMLR, 2020.\nRaia Hadsell, Dushyant Rao, Andrei A Rusu, and Razvan Pascanu. Embracing change: Continual learning in deep neural networks. Trends in Cognitive Sciences, 24(12):1028\u20131040, 2020.\nNiv Haim, Gal Vardi, Gilad Yehudai, Ohad Shamir, and Michal Irani. Reconstructing training data from trained neural networks. Advances in Neural Information Processing Systems, 35:22911\u201322924, 2022.\nMd Yousuf Harun, Jhair Gallardo, Tyler L. Hayes, and Christopher Kanan. How efficient are today\u2019s continual learning algorithms? In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 2431\u20132436, June 2023a.\nMd Yousuf Harun, Jhair Gallardo, Tyler L Hayes, Ronald Kemker, and Christopher Kanan. SIESTA: Efficient online continual learning with sleep. Transactions on Machine Learning Research, 2023b.\nMd Yousuf Harun, Jhair Gallardo, and Christopher Kanan. GRASP: A rehearsal policy for efficient online continual learning. arXiv preprint arXiv:2308.13646, 2023c.\nTyler L Hayes and Christopher Kanan. Online continual learning for embedded devices. In Conference on Lifelong Learning Agents, 2022.\n13\n"}, {"chunk": " Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Ges- mundo, Mona Attariyan, and Sylvain Gelly. Parameter-efficient transfer learning for NLP. In International Conference on Machine Learning, pp. 2790\u20132799. PMLR, 2019.\nEdward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations, 2022a. URL https://openreview.net/forum?id=nZeVKeeFYf9.\nHexiang Hu, Ozan Sener, Fei Sha, and Vladlen Koltun. Drinking from a firehose: Continual learning with web-scale natural language. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(5): 5684\u20135696, 2022b.\nXiaowei Huang, Daniel Kroening, Wenjie Ruan, James Sharp, Youcheng Sun, Emese Thamo, Min Wu, and Xinping Yi. A survey of safety and trustworthiness of deep neural networks: Verification, testing, adversarial attack and defence, and interpretability. Computer Science Review, 37:100270, 2020.\nE. Hu\u0308llermeier and W. Waegeman. Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods. Machine Learning, 110(3):457\u2013506, 2021. doi: 10.1007/s10994-021-05946-3.\nChip Huyen. Real-time machine learning: challenges and solutions, Jan 2022. URL https: //huyenchip.com/2022/01/02/real-time-machine-learning-challenges-and-solutions.html# towards-continual-learning. Online; accessed 14-November-2023.\nMenglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie, Serge Belongie, Bharath Hariharan, and Ser- Nam Lim. Visual prompt tuning. In Computer Vision\u2013ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23\u201327, 2022, Proceedings, Part XXXIII, pp. 709\u2013727. Springer, 2022.\nDahuin Jung, Dongyoon Han, Jihwan Bang, and Hwanjun Song. Generating instance-level prompts for rehearsal-free continual learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 11847\u201311857, 2023.\nZixuan Ke, Bing Liu, Nianzu Ma, Hu Xu, and Lei Shu. Achieving forgetting prevention and knowledge transfer in continual learning. Advances in Neural Information Processing Systems, 34, 2021.\nZixuan Ke, Yijia Shao, Haowei Lin, Hu Xu, Lei Shu, and Bing Liu. Adapting a language model while preserving its general knowledge. In Proceedings of The 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP-2022), 2022.\nGyuhak Kim, Changnan Xiao, Tatsuya Konishi, Zixuan Ke, and Bing Liu. A theoretical study on solving continual learning. In Advances in Neural Information Processing Systems, 2022.\nJames Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114(13):3521\u20133526, 2017.\nJeremias Knoblauch, Hisham Husain, and Tom Diethe. Optimal continual learning has perfect memory and is np-hard. In International Conference on Machine Learning, pp. 5327\u20135337. PMLR, 2020.\nAkinwande Komolafe. Retraining model during deployment: Continuous training and continuous testing, 2023. URL https://neptune.ai/blog/ retraining-model-during-deployment-continuous-training-continuous-testing. Online; accessed 30-June-2023.\nDominik Kreuzberger, Niklas Ku\u0308hl, and Sebastian Hirschl. Machine learning operations (MLOPS): Overview, definition, and architecture. IEEE Access, 2023.\nDhireesha Kudithipudi, Mario Aguilar-Simon, Jonathan Babb, Maxim Bazhenov, Douglas Blackiston, Josh Bongard, Andrew P Brna, Suraj Chakravarthi Raja, Nick Cheney, Jeff Clune, et al. Biological underpin- nings for lifelong learning machines. Nature Machine Intelligence, 4(3):196\u2013210, 2022.\n14\n"}, {"chunk": " Dhireesha Kudithipudi, Anurag Daram, Abdullah Zyarah, Fatima tuz Zohora, James B. Aimone, Angel Yanguas-Gil, Nicholas Soures, Emre Neftci, Matthew Mattina, Vincenzo Lomonaco, Clare D. Thiem, and Benjamin Epstein. Uncovering design principles for lifelong learning ai accelerators. Nature Electronics (Final Revisions), 2023.\nSaurabh Kumar, Henrik Marklund, Ashish Rao, Yifan Zhu, Hong Jun Jeon, Yueyang Liu, and Benjamin Van Roy. Continual learning as computationally constrained reinforcement learning. arXiv preprint arXiv:2307.04345, 2023.\nLilly Kumari, Shengjie Wang, Tianyi Zhou, and Jeff A Bilmes. Retrospective adversarial replay for continual learning. Advances in Neural Information Processing Systems, 35:28530\u201328544, 2022.\nSebastian Lapuschkin, Stephan Wa\u0308ldchen, Alexander Binder, Gre\u0301goire Montavon, Wojciech Samek, and Klaus-Robert Mu\u0308ller. Unmasking clever hans predictors and assessing what machines really learn. Nature communications, 10(1):1096, 2019.\nAngeliki Lazaridou, Adhi Kuncoro, Elena Gribovskaya, Devang Agrawal, Adam Liska, Tayfun Terzi, Mai Gimenez, Cyprien de Masson d\u2019Autume, Tomas Kocisky, Sebastian Ruder, et al. Mind the gap: Assessing temporal generalization in neural language models. Advances in Neural Information Processing Systems, 34:29348\u201329363, 2021.\nSergey Levine, Aviral Kumar, George Tucker, and Justin fu. Offline reinforcement learning: Tutorial, review, and perspectives on open problems. arXiv preprint arXiv:2005.01643, 2020.\nXiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv preprint arXiv:2101.00190, 2021.\nZhizhong Li and Derek Hoiem. Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence, 40(12):2935\u20132947, 2017.\nZhuowei Li, Long Zhao, Zizhao Zhang, Han Zhang, Di Liu, Ting Liu, and Dimitris N Metaxas. Steering prototype with prompt-tuning for rehearsal-free continual learning. arXiv preprint arXiv:2303.09447, 2023.\nJunfan Lin, Zhongzhan Huang, Keze Wang, Xiaodan Liang, Weiwei Chen, and Liang Lin. Continuous transi- tion: Improving sample efficiency for continuous control problems via mixup. In 2021 IEEE International Conference on Robotics and Automation (ICRA), pp. 9490\u20139497. IEEE, 2021.\nLong-Ji Lin. Self-improving reactive agents based on reinforcement learning, planning and teaching. Machine learning, 8:293\u2013321, 1992.\nClare Lyle, Mark Rowland, Will Dabney, Marta Kwiatkowska, and Yarin Gal. Learning dynamics and generalization in deep reinforcement learning. In International Conference on Machine Learning, pp. 14560\u201314581. PMLR, 2022.\nSeyed Iman Mirzadeh, Mehrdad Farajtabar, Dilan Gorur, Razvan Pascanu, and Hassan Ghasemzadeh. Lin- ear mode connectivity in multitask and continual learning. In International Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=Fmg_fQYUejf.\nEric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, and Christopher D Manning. Fast model editing at scale. In International Conference on Learning Representations, 2022. URL https://openreview. net/forum?id=0DcZxeWfOPt.\nVolodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al. Human-level control through deep reinforcement learning. nature, 518(7540):529\u2013533, 2015.\nMartin Mundt, Steven Lang, Quentin Delfosse, and Kristian Kersting. CLEVA-compass: A continual learn- ing evaluation assessment compass to promote research transparency and comparability. International Conference on Learning Representations, 2022.\n15\n"}, {"chunk": " Martin Mundt, Yongwon Hong, Iuliia Pliushch, and Visvanathan Ramesh. A wholistic view of continual learning with deep neural networks: Forgotten lessons and the bridge to active and open world learning. Neural Networks, 160:306\u2013336, 2023.\nV.L. Nguyen, M.H. Shaker, and E. Hu\u0308llermeier. How to measure uncertainty in uncertainty sampling for active learning. Machine Learning, 111(1):89\u2013122, 2022. doi: 10.1007/s10994-021-06003-9.\nMaxime Oquab, Timothe\u0301e Darcet, The\u0301o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, et al. Dinov2: Learning robust visual features without supervision. arXiv preprint arXiv:2304.07193, 2023.\nOleksiy Ostapenko, Timothee Lesort, Pau Rodri\u0301guez, Md Rifat Arefin, Arthur Douillard, Irina Rish, and Laurent Charlin. Foundational models for continual learning: An empirical study of latent replay, 2022. URL https://arxiv.org/abs/2205.00329.\nAristeidis Panos, Yuriko Kobe, Daniel Olmeda Reino, Rahaf Aljundi, and Richard E Turner. First session adaptation: A strong replay-free baseline for class-incremental learning. arXiv preprint arXiv:2303.13199, 2023.\nAnastasia Pentina and Christoph H. Lampert. A PAC-bayesian bound for lifelong learning. In ICML, 2014.\nIuliia Pliushch, Martin Mundt, Nicolas Lupp, and Visvanathan Ramesh. When Deep Classifiers Agree: Analyzing Correlations Between Learning Order and Image Statistics. European Conference on Computer Vision (ECCV), pp. 397\u2013413, 2022.\nAmeya Prabhu, Hasan Abed Al Kader Hammoud, Puneet K Dokania, Philip HS Torr, Ser-Nam Lim, Bernard Ghanem, and Adel Bibi. Computationally budgeted continual learning: What does matter? In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 3698\u20133707, 2023a.\nAmeya Prabhu, Zhipeng Cai, Puneet Dokania, Philip Torr, Vladlen Koltun, and Ozan Sener. Online con- tinual learning without the storage constraint. arXiv preprint arXiv:2305.09253, 2023b.\nDiana Benavides Prado and Patricia Riddle. A theory for knowledge transfer in continual learning. In Conference on Lifelong Learning Agents, 2022.\nAlexander Pritzel, Benigno Uria, Sriram Srinivasan, Adria Puigdomenech Badia, Oriol Vinyals, Demis Has- sabis, Daan Wierstra, and Charles Blundell. Neural episodic control. In International Conference on Machine Learning, pp. 2827\u20132836. PMLR, 2017.\nAlec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International Conference on Machine Learning, pp. 8748\u20138763. PMLR, 2021.\nRahul Ramesh and Pratik Chaudhari. Model zoo: A growing\" brain\" that learns continually. arXiv preprint arXiv:2106.03027, 2021.\nDavid Rolnick, Arun Ahuja, Jonathan Schwarz, Timothy Lillicrap, and Gregory Wayne. Experience replay for continual learning. Advances in Neural Information Processing Systems, 32, 2019.\nKhalid Salama, Jarek Kazmierczak, and Donna Schut. Practitioners guide to MLOPS: A framework for continuous delivery and automation of machine learning. Google Could White paper, 2021.\nShibani Santurkar, Dimitris Tsipras, Mahalaxmi Elango, David Bau, Antonio Torralba, and Aleksander Madry. Editing a classifier by rewriting its prediction rules. Advances in Neural Information Processing Systems, 34:23359\u201323373, 2021.\nTom Schaul, John Quan andIoannis Antonoglou, and David Silver. Prioritized experience replay. In 4th International Conference on Learning Representations, ICLR 2016, 2016.\n16\n"}, {"chunk": " Julian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen Simonyan, Laurent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart, Demis Hassabis, Thore Graepel, et al. Mastering atari, go, chess and shogi by planning with a learned model. Nature, 588(7839):604\u2013609, 2020.\nRoy Schwartz, Jesse Dodge, Noah A Smith, and Oren Etzioni. Green AI. Communications of the ACM, 63 (12):54\u201363, 2020.\nBurr Settles. Active learning literature survey. Computer Sciences Technical Report 1648, University of Wisconsin\u2013Madison, 2009.\nRichard S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction. The MIT Press, second edition, 2018. URL http://incompleteideas.net/book/the-book-2nd.html.\nTinne Tuytelaars, Bing Liu, Vincenzo Lomonaco, Gido van de Ven, and Andrea Cossu. Deep Continual Learning (Dagstuhl Seminar 23122). Dagstuhl Reports, 13(3):74\u201391, 2023. ISSN 2192-5283. doi: 10.4230/ DagRep.13.3.74. URL https://drops.dagstuhl.de/entities/document/10.4230/DagRep.13.3.74.\nEuropean Union. Regulation (eu) 2016/679 of the european parliament and of the council of 27 april 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing directive 95/46/ec (general data protection regulation). Official Journal L110, 59:1\u201388, 2016.\nGido M van de Ven, Tinne Tuytelaars, and Andreas S Tolias. Three types of incremental learning. Nature Machine Intelligence, 4(12):1185\u20131197, 2022.\nLiyuan Wang, Xingxing Zhang, Qian Li, Jun Zhu, and Yi Zhong. Coscl: Cooperation of small continual learners is stronger than a big one. In European Conference on Computer Vision, pp. 254\u2013271. Springer, 2022a.\nZifeng Wang, Zheng Zhan, Yifan Gong, Geng Yuan, Wei Niu, Tong Jian, Bin Ren, Stratis Ioannidis, Yanzhi Wang, and Jennifer Dy. SparCL: Sparse continual learning on the edge. Advances in Neural Information Processing Systems, 35:20366\u201320380, 2022b.\nZifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, and Tomas Pfister. Learning to prompt for continual learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 139\u2013149, 2022c.\nMaciej Wo\u0142czyk, Micha\u0142 Zaja\u0328c, Razvan Pascanu, \u0141ukasz Kucin\u0301ski, and Piotr Mi\u0142os\u0301. Continual world: A robotic benchmark for continual reinforcement learning. Advances in Neural Information Processing Sys- tems, 34:28496\u201328510, 2021.\nMaciej Wolczyk, Micha\u0142 Zaja\u0328c, Razvan Pascanu, \u0141ukasz Kucin\u0301ski, and Piotr Mi\u0142os\u0301. Disentangling transfer in continual reinforcement learning. Advances in Neural Information Processing Systems, 35:6304\u20136317, 2022.\nMitchell Wortsman, Gabriel Ilharco, Jong Wook Kim, Mike Li, Simon Kornblith, Rebecca Roelofs, Raphael Gontijo Lopes, Hannaneh Hajishirzi, Ali Farhadi, Hongseok Namkoong, et al. Robust fine-tuning of zero-shot models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recog- nition, pp. 7959\u20137971, 2022.\nJiannan Xiang, Tianhua Tao, Yi Gu, Tianmin Shu, Zirui Wang, Zichao Yang, and Zhiting Hu. Language mod- els meet world models: Embodied experiences enhance language models. arXiv preprint arXiv:2305.10626, 2023.\nShipeng Yan, Jiangwei Xie, and Xuming He. Der: Dynamically expandable representation for class incremen- tal learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 3014\u20133023, 2021.\n17\n"}, {"chunk": " Amir R Zamir, Alexander Sax, William Shen, Leonidas J Guibas, Jitendra Malik, and Silvio Savarese. Taskonomy: Disentangling task transfer learning. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pp. 3712\u20133722, 2018.\nZeyu Zhao. The application of the right to be forgotten in the machine learning context: From the perspective of european laws. Cath. UJL & Tech, 31:73, 2022.\nAlexander Zimin and Christoph H. Lampert. Tasks without borders: A new approach to online multi-task learning. In ICML Workshop on Adaptive & Multitask Learning, 2019. URL https://openreview.net/ forum?id=HkllV5Bs24.\nA Survey details\nTo verify the keywords \u2018incremental\u2019, \u2018continual\u2019, \u2018forgetting\u2019, \u2018lifelong\u2019 and \u2018catastrophic\u2019, used to filter the papers based on their titles, we tested them using a manually collected validation set of which we are certain that they are continual learning related. This set was manually collected while doing research on continual learning over the past few years. The keywords were present in 96% of the paper titles. From each conference, we randomly picked 20 out of all matched papers, disregarding false positives.\nIt is common for to evaluate new methods and analyses on more than one benchmark. Often this means that the percentage of stored samples is not uniform across the experiments in a paper. In Figure 1, we showed the minimum percentage used, in Figure 3 we show the maximum. The conclusion remains the same, and the amount of stored samples is constrained in all but two benchmarks.\nIn Table 1 we provide a table of all the papers we used in the survey of Section 2, showing their minimal and maximal sample store ratio (SSR) i.e. the percentage of samples stored, as well as possibly other memory consumption. The last column mentions how they approached the computational cost.\nOptimized\nConstrained\nCompared\nDiscussed\nNot discussed\n34\nNone \u22641% 1-5% 5-10% 10-99% 100%\nPercentage of stored data\nFigure 3: Most papers strongly restrict memory use and do not discuss computational cost. This figure is an alternate version of Figure 1, with the maximum percentage of stored samples rather than the minimum. Each dot represents one paper, illustrating what percentage of data their methods store (horizontal axis) and how computational complexity is handled (vertical axis). The majority of surveyed papers are in the lower-left corner: those that strongly restrict memory use and do not quantitatively approach computational cost (i.e. it is at most discussed). For more details, see Appendix.\n18\n 1\n3\n10\n12\n      Computational cost\n"}, {"chunk": "    Table 1: All papers used in the survey of Section 2. SSR refers to the sample store ratio, i.e. how much samples are stored in relation to the entire dataset.\n# Conference Title\nSSR (min) SSR (max) Memory (other) Compute\n1 ECCV\n2 ECCV\n3 ECCV\n4 ECCV\n5 ECCV\n6 ECCV\n7 ECCV\n8 ECCV\n9 ECCV\n10 ECCV\n11 ECCV\n12 ECCV\n13 ECCV\n14 ECCV\n15 ECCV\n16 ECCV\n17 ECCV\n18 ECCV\n19 ECCV\n20 ECCV\n21 CVPR\n22 CVPR\n23 CVPR\n24 CVPR\n25 CVPR\n26 CVPR\n27 CVPR\n28 CVPR\n29 CVPR\n30 CVPR\n31 CVPR\n32 CVPR\n33 CVPR\n34 CVPR\n35 CVPR\n36 CVPR\n37 CVPR\n38 CVPR\n39 CVPR\n40 CVPR\n41 NeurIPS\n42 NeurIPS\n43 NeurIPS\n44 NeurIPS\n45 NeurIPS\n46 NeurIPS\n47 NeurIPS\n48 NeurIPS\n49 NeurIPS\n50 NeurIPS\n51 NeurIPS\n52 NeurIPS\n53 NeurIPS\n54 NeurIPS\n55 NeurIPS\n56 NeurIPS\n57 NeurIPS\n58 NeurIPS\n59 NeurIPS\n60 NeurIPS\nBalancing Stability And Plasticity Through Advanced Null Space In Continual Learning Class-Incremental Novel Class Discovery\nPrototype-Guided Continual Adaptation For Class-Incremental Unsupervised Domain Adaptation Few-Shot Class-Incremental Learning Via Entropy-Regularized Data-Free Replay Anti-Retroactive Interference For Lifelong Learning\nLong-Tailed Class Incremental Learning\nDlcft: Deep Linear Continual Fine-Tuning For General Incremental Learning Generative Negative Text Replay For Continual Vision-Language Pretraining Online Continual Learning With Contrastive Vision Transformer Coscl: Cooperation Of Small Continual Learners Is Stronger Than A Big One R-Dfcil: Relation-Guided Representation Learning For Data-Free Class Incremental Learning Continual Semantic Segmentation Via Structure Preserving And Projected Feature Alignment Balancing Between Forgetting And Acquisition In Incremental Subpopulation Learning Few-Shot Class-Incremental Learning For 3d Point Cloud Objects Meta-Learning With Less Forgetting On Large-Scale Non-Stationary Task Distributions Novel Class Discovery Without Forgetting\nRbc: Rectifying The Biased Context In Continual Semantic Segmentation Coarse-To-Fine Incremental Few-Shot Learning\nContinual Variational Autoencoder Learning Via Online Cooperative Memorization Dualprompt: Complementary Prompting For Rehearsal-Free Continual Learning Incrementer: Transformer For Class-Incremental Semantic Segmentation With Knowledge Distillation Focusing On Old Class Real-Time Evaluation In Online Continual Learning: A New Hope Heterogeneous Continual Learning\nDecoupling Learning And Remembering: A Bilevel Memory Framework With Knowledge Projection For Task-Incremental Learning Geometry And Uncertainty-Aware 3d Point Cloud Class-Incremental Semantic Segmentation Continual Detection Transformer For Incremental Object Detection Continual Semantic Segmentation With Automatic Memory Sample Selection Adaptive Plasticity Improvement For Continual Learning\nVqacl: A Novel Visual Question Answering Continual Learning Setting Task Difficulty Aware Parameter Allocation & Regularization For Lifelong Learning Computationally Budgeted Continual Learning: What Does Matter? Comformer: Continual Learning In Semantic And Panoptic Segmentation Pivot: Prompting For Video Continual Learning\nClass-Incremental Exemplar Compression For Class-Incremental Learning\nPcr: Proxy-Based Contrastive Replay For Online Class-Incremental Continual Learning Attriclip: A Non-Incremental Learner For Incremental Knowledge Learning Learning With Fantasy: Semantic-Aware Virtual Contrastive Constraint For Few-Shot Class-Incremental Learning On The Stability-Plasticity Dilemma Of Class-Incremental Learning\nMetamix: Towards Corruption-Robust Continual Learning With Temporally Self-Adaptive Data Transformation Exploring Data Geometry For Continual Learning\nUncertainty-Aware Hierarchical Refinement For Incremental Implicitly-Refined Classification Learning A Condensed Frame For Memory-Efficient Video Class-Incremental Learning\nS-Prompts Learning With Pre-Trained Transformers: An Occam\u2019s Razor For Domain Incremental Learning Note: Robust Continual Test-Time Adaptation Against Temporal Correlation\nDecomposed Knowledge Distillation For Class-Incremental Semantic Segmentation\nFew-Shot Continual Active Learning By A Robot\nNavigating Memory Construction By Global Pseudo-Task Simulation For Continual Learning\nSparcl: Sparse Continual Learning On The Edge\nA Simple But Strong Baseline For Online Continual Learning: Repeated Augmented Rehearsal\nLifelong Neural Predictive Coding: Learning Cumulatively Online Without Forgetting\nA Theoretical Study On Solving Continual Learning\nBeyond Not-Forgetting: Continual Learning With Backward Knowledge Transfer\nTask-Free Continual Learning Via Online Discrepancy Distance Learning\nDisentangling Transfer In Continual Reinforcement Learning\nLess-Forgetting Multi-Lingual Fine-Tuning\nModel-Based Lifelong Reinforcement Learning With Bayesian Exploration\nAlife: Adaptive Logit Regularizer And Feature Replay For Incremental Semantic Segmentation\nRetrospective Adversarial Replay For Continual Learning\nAcil: Analytic Class-Incremental Learning With Absolute Memorization And Privacy Protection\nMemory Efficient Continual Learning With Transformers\n0\n0\n0\n0\n0.02 0.01 0.001\n0\n0.001\n0\n0\n0\n0\n0.001 0.002\n0\n0\n0\n0.02\n0\n0\n0.001\n0\n0\n0\n0.1 0.001\n0\n0.001\n0\n1\n0\n0.006 0.003 0.002\n0\n0\n0.01 0.01 0.004\n0\n0.001\n0\n0.5 0.008\n0\n0.004 0.004 0.01\n0\n0.004\n0\n0.04\n0.1\n0.5\n1\n0.01 0.004\n0\n0.1\n0 0 0 0 0.2 0.04 0.04 0 0.02 0.04 0 0 0 0.001 0.002 0 0 0 0.1 0 0 0.001 0.004 0 0 0.1 0.01 0 0.09 0 1 0 0.1 0.02 0.1 0 0 0.01 0.06 0.04 0 0.03 0 0.5 0.1 0 0.04 0.01 0.1 0 0.04 0 0.2 0.1 0.5 1 0.04 0.2 0 0.16\nnull spaces prototypes prototypes generators / / / / / / generators / / prototypes / prototypes model copies / / prompts model copies / generators model copies model copies model copies / gradient bases / model copies / model copies / / / / prototypes / / / model copies / / / / prototypes / / / / / gradient bases / / / / / / / /\ncompared not discussed not discussed not discussed discussed not discussed not discussed not discussed not discussed not discussed not discussed discussed not discussed not discussed compared not discussed not discussed not discussed discussed not discussed not discussed constrained discussed compared not discussed not discussed discussed compared not discussed discussed constrained not discussed not discussed discussed not discussed not discussed not discussed discussed compared not discussed not discussed not discussed not discussed discussed discussed not discussed compared optimized compared not discussed discussed compared compared not discussed not discussed discussed not discussed constrained not discussed compared\n19\n"}, {"chunk": " NEUROBENCH: ADVANCING NEUROMORPHIC COMPUTING THROUGH COLLABORATIVE, FAIR AND REPRESENTATIVE BENCHMARKING\nJason Yik 1 Soikat Hasan Ahmed 2 Zergham Ahmed 1 Brian Anderson 3 Andreas G. Andreou 4 Chiara Bartolozzi 5 Arindam Basu 6 Douwe den Blanken 7 Petrut Bogdan 8 Sander Bohte 9 Younes Bouhadjar 2 Sonia Buckley 10\nGert Cauwenberghs 11 Federico Corradi 12 Yigit Demirag 15 16 Jason Eshraghian 17 Giacomo Indiveri 15 16 Siddharth Joshi 21\nGuido de Croon 7 Jeremy Forest 18 Vedant Karia 14\nAndreea Danielescu 13 Anurag Daram 14 Mike Davies 3\nSteve Furber 19 Michael Furlong 20 Aditya Gilra 9 Lyes Khacef 22 James C. Knight 23 Laura Kriener 24\nRajkumar Kubendran 25 Dhireesha Kudithipudi 14 Gregor Lenz 26 Rajit Manohar 27 Christian Mayr 28\nKonstantinos Michmizos 29 Dylan Muir 26 Noah Pacik-Nelson 13 Priyadarshini Panda 27\nEmre Neftci 2 Thomas Nowotny 23 Fabrizio Ottati 30 Ayca Ozcelikkale 31 Sun Pao-Sheng 6 Melika Payvand 15 16 Christian Pehle 32 Mihai A. Petrovici 33\nYulia Sandamirskaya 3 35 Clemens JS Schaefer 21 Andre \u0301 van Schaik 36\nMarian Verhelst 42 Craig M. Vineyard 43 Bernhard Vogginger 28 Amirreza Yousefzadeh 39 Biyan Zhou 6 Fatima Tuz Zohora 14\nCharlotte Frenkel 7 * Vijay Janapa Reddi 1 *\nABSTRACT\nThe field of neuromorphic computing holds great promise in terms of advancing computing efficiency and capabilities by following brain-inspired principles. However, the rich diversity of techniques employed in neuromorphic research has resulted in a lack of clear standards for benchmarking, hindering effective evaluation of the advantages and strengths of neuromorphic methods compared to traditional deep-learning-based methods. This paper presents a col- laborative effort, bringing together members from academia and the industry, to define benchmarks for neuromorphic computing: NeuroBench. The goals of NeuroBench are to be a collaborative, fair, and representative benchmark suite developed by the community, for the community. In this paper, we discuss the challenges associated with benchmarking neuromorphic solutions, and outline the key features of NeuroBench. We believe that NeuroBench will be a significant step towards defining standards that can unify the goals of neuromorphic computing and drive its technological progress. Please visit neurobench.ai for the latest updates on the benchmark tasks and metrics.\nChristoph Posch 34 Alpha Renner 15 16\nJohannes Schemmel 32 Catherine Schuman 37 Jae-sun Seo 38 Sadique Sheik 26 Sumit Bam Shrestha 3 Manolis Sifalakis 39 Amos Sironi 34 Kenneth Stewart 40 2 Terrence C. Stewart 41 Philipp Stratmann 3 Guangzhi Tang 39 Jonathan Timcheck 3\n1 INTRODUCTION\nIn recent years, the rapid growth of artificial intelligence (AI) and machine learning (ML) has led to a surge in demand for computational resources. Conventional computing architec- tures, such as von Neumann architectures, are increasingly struggling to meet these demands due to their separation of processing and memory, which limits energy efficiency and parallelization. These issues are further magnified by the ex- ponential increase in data and computational requirements\n*Equal contribution 1Harvard 2Forschungszentrum Ju \u0308lich 3Intel 4Johns Hopkins University 5Istituto Italiano di Tecnologia 6City University of Hong Kong 7Delft Uni- versity of Technology 8Innatera 9Centrum Wiskunde & Informatica 10National Insti- tute of Standards and Technology 11UC San Diego 12Eindhoven University of Tech- nology 13Accenture Labs 14UTSA 15University of Zurich 16ETH Zurich 17UCSC 18Cornell University 19University of Manchester 20U Waterloo 21University of Notre Dame 22Sony 23University of Sussex 24Universitiy of Bern 25University of Pitts- burgh 26SynSense 27Yale University 28Technische Universita \u0308t Dresden 29Rutgers 30Politecnico di Torino 31Uppsala University 32Heidelberg University 33University of Bern 34Prophesee 35ZHAW 36Western Sydney University 37University of Tennessee 38Arizona State University 39IMEC Netherlands 40UCI 41National Research Coun- cil Canada 42KU Leuven 43Sandia National Laboratories. Please contact Jason Yik <jyik@g.harvard.edu> for any correspondence with regards to the project. Visit neurobench.ai for the latest project updates.\nassociated with cloud-based workloads, the imperative for energy-efficient edge-computing devices to accommodate the swift expansion of the Internet of Things (IoT), and the ne- cessity for real-time systems capable of functioning in closed- loop environments.\nAs a result, the urgency for alternative computational paradigms has intensified. In order to bridge this supply- demand gap, a remarkable diversification of computer ar- chitectures has emerged, ranging from deep neural network accelerators to the widespread adoption of custom application- specific integrated circuits (ASICs) [50, 114]. However, progress in deep learning has mostly been accuracy-driven, with little consideration for energy efficiency. This led us to today\u2019s infrastructures running large-scale AI solutions be- ing unaffordable for a majority of organizations, with this trend exhibiting no indications of deceleration, and to current AI techniques requiring extensive rework for a deployment within edge-computing power budgets. Consequently, the demand for solutions that demonstrate competitiveness not only in accuracy but also in energy efficiency is more salient\n arXiv:2304.04640v2 [cs.AI] 15 Apr 2023\n "}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n than ever before.\nNeuromorphic computing, inspired by the structure and function of the human brain, has emerged as a promising area in addressing these challenges. Neuromorphic comput- ing is the practice of porting computational strategies em- ployed in the brain into man-made computing devices and methods to unlock key hallmarks of biological intelligence while using fewer resources than conventional computing systems [118, 116, 62, 134]. Neuromorphic systems hold a critical position in the investigation of novel architectures, as the brain exemplifies an exceptional model for accomplishing scalable, energy-efficient, and real-time embodied computa- tion.\nIn recent years, quite a few neuromorphic computing systems have demonstrated these capabilities [116, 22, 36, 44, 111]. Analogous to the biological substrate, these neuromorphic computing systems and algorithms display a significant de- gree of heterogeneity in multiple aspects. These include the scale, with dimensions ranging from sensor-edge devices to expansive data-center network sizes, which highlights the adaptability of neuromorphic computing to various physical and computational constraints. Moreover, the complexity of neuromorphic computing primitives varies extensively, from more abstract, simplified models to those that accurately repli- cate biophysical characteristics, providing researchers with a range of options to suit specific application requirements. Furthermore, the implementation substrate in neuromorphic computing systems is not only confined to traditional digital and analog silicon technologies, it also encompasses emerging ones such as memristive devices and novel materials, which offer the potential for enhanced performance and energy ef- ficiency [24, 100]. This remarkable diversity of solutions grants researchers the ability to tailor neuromorphic comput- ing technologies to a vast range of tasks across a rich array of domains, including robotics, healthcare, natural language processing, and computer vision.\nThe extensive heterogeneity of neuromorphic algorithms and systems complicates the formulation of proportional, equi- table, and standardized approaches for comparison and evalu- ation, which is needed to systematically assess state-of-the-art advances in neuromorphic computing.\nTo tackle this challenge, this paper represents a collaboration of academic and industry partners with a stake in neuromor- phic computing solutions. We propose a multi-task bench- mark suite, NeuroBench, to fairly compare neuromorphic solutions with each other, without excluding alternative, non- neuromorphic solutions. Other neuromorphic benchmarks have also been proposed, from classical vision [96, 7] and au- dition tasks [32] to open-loop [98] and closed-loop [86] tasks, or on the performance of SNN simulators [71]. The proposed NeuroBench benchmark suite advances prior work in three distinct ways. Firstly, it establishes a continuous, community-\ndriven endeavor that is designed to evolve over time, anal- ogous to MLPerf [110]. Establishing collaborative and im- partial benchmarks is essential for promoting progress in the development of neuromorphic technology. Secondly, the benchmark suite reduces assumptions regarding the specific neuromorphic solution being assessed, encompassing general benchmark tasks and metrics that foster fairness and inclusiv- ity through key performance indicators. Lastly, the benchmark incorporates two sub-categories: an algorithm track that ad- dresses algorithmic solutions to the challenges posed by the neuromorphic community, and a systems track that tackles full-system solutions to the same problems (see [135] for a recent example of a system-level benchmark). This will initi- ate a virtuous cycle where trends extracted from algorithmic explorations will drive future neuromorphic hardware design, which can in turn either (i) accelerate algorithmic exploration, or (ii) be optimized for a low-footprint real-world deployment, thereby fueling further progress in the field.\nYet, for NeuroBench to be successful, it needs to observe the following guidelines for benchmarking:\n\u2022 Standard Evaluation: NeuroBench will provide a stan- dard set of metrics and workloads that enable the sys- tematic evaluation and comparison of different neuro- morphic computing solutions. This will offer insights into the relative strengths and weaknesses of each algo- rithm/system, guiding researchers and engineers in the development and optimization of solutions.\n\u2022 Design Validation: NeuroBench will help in validating the design choices made during the development of a solution. By assessing the solution under specific work- loads and metrics, we can ascertain whether the proposed approach meets the intended goals and requirements, and make adjustments where required.\n\u2022 Fairness, Reproducibility, and Transparency: Neu- roBench will help us ensure that all solutions are assessed on a level playing field, allowing for fair and objective comparisons across solutions. This is crucial for both academia and industry, as it fosters healthy competition, drives innovation, and accelerates the adoption of new approaches and technologies.\n\u2022 Community-Driven Iteration: NeuroBench will seek consensus and build on support from the community to ensure a representative set of inclusive benchmarks. NeuroBench will iteratively evolve to encompass further capabilities and continue to provide actionable, relevant benchmarks.\n\u2022 Guiding Future Research: NeuroBench will reveal bot- tlenecks and limitations in existing solutions, thereby in- forming future research directions. By identifying areas in need of improvement, NeuroBench will help direct\n"}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n research efforts, both short-term and long-term, towards developing novel solutions and innovations that address the shortcomings of current state-of-the-art or widely adopted solutions.\nThis paper shows how NeuroBench adopts these guidelines and outlines (i) the first milestone in this initiative with a community-driven selection of tasks and metrics for the al- gorithmic track, and (ii) the next steps, from the benchmark implementation to the systems track requirements. The paper is organized as follows: Section 2 overviews neuromorphic algorithms and hardware, Section 3 lists challenges in neuro- morphic benchmarking and the directions NeuroBench takes towards defining benchmarks, Sections 4 and 5 describe the progress on the algorithms track and systems track, respec- tively, and finally Sections 6 and 7 offer discussion into project impact and conclude.\n2 BACKGROUND\nThe breadth of neuromorphic computing approaches allows for the exploration of brain-inspired ideas that diverge signifi- cantly from traditional deep learning algorithms and hardware. Initially, the term \u2018neuromorphic\u2019 referred specifically to ap- proaches that aimed to imitate the biophysics of the brain through the use of the physical properties of the silicon sub- strate, as proposed by Mead in 1990 [83]. However, the field has since evolved into a blanket term that encompasses a wide range of brain-inspired computing techniques. These techniques include analog emulation and digital simulation, spike- or event-based computation and communication, non- von-Neumann architectures, near- and in-memory processing with emerging memory devices, as well as various properties such as low-resolution, sparse, noisy, and adaptive processing. This section aims to provide background into the algorithmic and hardware approaches. In practice, there can be a tight cou- pling between the two, but for the sake of clarity we describe them individually.\nSection 2.1 provides background on the algorithms that build on the aforementioned techniques, while Section 2.2 provides an overview of the underlying hardware that implements said solutions. These sections collectively aim to demonstrate that the field lacks a systematic approach for identifying which of these properties are most promising for a given use case. This lack of consolidation highlights both the need for and the challenges towards defining objective and impartial metrics and benchmarks.\n2.1 Neuromorphic Algorithms\nNeuromorphic algorithms encompass three main categories: emerging brain-inspired algorithms, algorithms that can be ac- celerated on neuromorphic hardware, and algorithms adapted from deep learning. The first category is typically informed\nby neuroscience research and, depending on their develop- ment stage, may not yet be adequately supported by existing neuromorphic hardware. As such, a significant portion of these neuromorphic algorithms are explored using simulators such as those outlined in Kulkarni et al. [71]. The second category encompasses established brain-inspired algorithms (e.g., spiking neural networks, SNNs) as well as traditional algorithms that are not inherently bio-inspired but may benefit from the sparse, event-driven, temporal, and distributed nature of neuromorphic hardware (e.g., graph search and constrained optimization problems, as discussed in [36]). Finally, the third category starts from successful deep learning algorithms, e.g. the backpropagation of error algorithm, and adapts them either for deployment with SNNs or toward increased bioplau- sibility [94, 74].\nGenerally, we can divide neuromorphic algorithms into four main categories:\n1. Learning algorithms \u2013 Unlike in deep learning, for which the error backpropagation algorithm is nearly ex- clusively used for learning, neuromorphic learning algo- rithm approaches widely vary. These algorithms incorpo- rate a variety of plasticity and adaptation mechanisms at different levels of abstraction, ranging from local synap- tic plasticity rules [13, 64, 124] to network-level error- driven feedback mechanisms [20, 54, 147, 118]. Learn- ing algorithms can be employed to train SNNs from scratch or provide them with the ability to adapt to their environment. The primary objective of deploying these algorithms on neuromorphic hardware is to facilitate on- device learning in an online, few-shot, and/or continual manner. To do so, given that porting emerging algorithms to custom silicon hardware requires a development time of a few years, hardware-in-the-loop setups offer an in- teresting stepping stone where a non-learning-enabled neuromorphic chip can be trained online by an external workstation [49, 19].\n2. Network topologies \u2013 Network topologies in neuromor- phic computing are akin to those in standard artificial neural networks (ANNs), which involve fully-connected, convolutional, and recurrent layers, among others. While these topologies can also be applied to SNNs, neuro- morphic algorithms commonly prioritize brain-inspired topologies that are hierarchical, modular, randomly con- nected, or small-world, with dense local connections and sparse global connections [52, 33, 92].\n3. Dynamics and computational primitives \u2013 The dy- namics and computational primitives of neuromorphic al- gorithms are analogous to activation functions in ANNs, and strongly condition the overall algorithm complex- ity, performance, and applicative use cases. While the simple leaky integrate-and-fire (LIF) neuron model pro-\n"}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n vides a qualitative description of a biological neuron as a leaky integrator with spiking non-linearity, researchers are exploring a broad range of neuron models with varying degrees of biophysical accuracy (e.g., Hodgkin- Huxley, Izhikevich, Adaptive Exponential, as reviewed in [60, 57]). It is important to note that this explo- ration extends beyond the selection of a neuron model and includes synaptic dynamics [64], dendritic compu- tation [81], as well as robust computational primitives such as winner-take-all networks [76, 56].\n4. Information encoding \u2013 Spike-based representations are widely used in neuromorphic algorithms, and re- quire encoding of real-world data to spiking formats. Several spike conversion strategies have been explored, including delta/threshold based encoding [122, 25], pop- ulation encoding [20], latency encoding [48], rate encod- ing [51, 79, 139], generalized linear model [107, 108], cochlear encoding [151, 78], direct encoding [66] and many more. Notably, information encoding not only impacts the efficiency, precision, and robustness of the whole computation but also has significant implications for data pre-processing compute cost, which must be considered for fair performance comparisons.\nThe categories above aim at providing a broad high-level overview; neuromorphic algorithms usually innovate not only within, but also across them, including with unconventional approaches such as vector-symbolic architectures [67].\nTo achieve fair evaluation and comparison of neuromorphic algorithms, two primary challenges must still be addressed: evaluating neuromorphic algorithms independently of any hardware substrate can prove challenging, while standard- ized definitions as proxies for the system-level footprint are missing. Thus, in terms of evaluation methodologies and met- rics, NeuroBench has a crucial role to play by tackling these challenges, which we discuss further in Section 3.1.\n2.2 Neuromorphic Hardware\nIn deep learning, GPU-based exploration is primarily relied upon with the assistance of specialized ASICs for specific application scenarios. However, unlike this mainstream tra- dition, various areas of neuromorphic computing research are supported by different families of neuromorphic hard- ware [22, 44]. As these hardware platforms support different end goals, a variety of feature sets and circuit design styles are selected, which will be introduced in this section. For a comprehensive up-to-date list of neuromorphic hardware, please refer to [111, 15, 4].\nLarge-scale neuromorphic platforms can be viewed as anal- ogous to what GPUs represent for the field of deep learn- ing. Many of these platforms serve as excellent testbeds for the exploration and development of neuromorphic algo-\nrithms, and all of them benefit from well-supported soft- ware development kits (SDKs). These platforms include SpiNNaker 1 and 2 [46, 45], IBM TrueNorth [84], Intel Loihi 1 and 2 [35, 97], Tianjic [103], as well as BrainScaleS 1 and 2 [115, 102], and support from tens of thousands to millions of neurons. The distinctions between platforms is evident in several key factors, such as:\n\u2022 Circuit design \u2013 The majority of neuromorphic plat- forms currently in widespread use are fully digital, in part because they are easier to program and offer more con- sistent and reproducible results than analog and mixed- signal platforms. Analog implementations1, however, offer distinct advantages in high-bandwidth emulation of continuous-time dynamics. Among large-scale neuro- morphic platforms, BrainScaleS is a notable exception that utilizes above-threshold analog circuits, replicating essential biophysical dynamics with time constants that are accelerated by four orders of magnitude. While digi- tal platforms also support accelerated-time processing, the magnitude of acceleration is typically smaller and it is often dependent on the workload.\n\u2022 Flexibility \u2013 SpiNNaker is a platform that utilizes clus- ters of ARM cores specifically optimized for simulating spiking neural networks. Its primary advantage lies in offering full programmability, albeit at the expense of efficiency and simulation speed compared to other plat- forms. In contrast, BrainScaleS 1 and TrueNorth repre- sent the least flexible platforms as they solely support fixed neuron and synapse models. The remaining plat- forms aim to strike a balance between efficient execution from dedicated circuits and programmability from stan- dard digital co-processors. The co-processor of Brain- ScaleS 2 supports hybrid plasticity and parallel access to analog system observables for calibration via two spe- cialised fixed-point vector-units, as well as two general purpose scalar cores for system tasks, configuration and orchestration of experiments. In Loihi 2, neuromorphic cores support microcode-programmed neuron models and synaptic learning rules, while a number of conven- tional processor cores provide additional programmabil- ity for spike I/O data conversion and general application management.\n\u2022 Communication \u2013 All platforms rely on an event-based communication infrastructure, with key exceptions. Tian- jic focuses on supporting hybrid ANN-SNN setups. SpiNNaker2 also offers efficient hybrid ANN-SNN pro- cessing by integrated accelerators for ANN layers. Simi- larly, Intel Loihi 2 introduces graded spikes, i.e. spikes\n1It is a convention to use the term \u201canalog\u201d when referring to the core computation, even though all analog designs are actually mixed-signal in nature due to their utilization of digital circuits for spike-based communication.\n "}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n with integer-valued magnitudes, thereby supporting net- works that go beyond binary spike-based representations.\nIn a similar vein to portable GPUs and machine-learning- enabled microcontroller units (MCUs), smaller-scale neuro- morphic platforms have recently emerged that allow for flexi- ble exploration of edge-computing scenarios. These platforms, along with their accompanying SDKs, include the SynSense Xylo [21] and Speck [5], the BrainChip Akida [138], GrAI Matter Labs NeuronFlow [89], and the Innatera Spiking Neu- ral Processor [73]. These platforms aim to facilitate the ex- ploration of new algorithms and use cases for neuromorphic computing.\nFinally, a wide range of other neuromorphic hardware serves more specific purposes, such as research chips that embed from a few tens to thousands of neurons but have limited SDK support. Some of the key categories of such hardware include the following:\n\u2022 Sub-threshold analog neuromorphic chips \u2013 In con- trast to the above-threshold analog approach utilized in BrainScaleS, which enables acceleration up to four orders of magnitude when compared to biological time constants, sub-threshold analog designs employ the MOS transistor\u2019s physics to emulate the biophysics of the brain at biological time constants. This approach is uti- lized in designs such as in Brink et al. [23], and the ROLLS [109], DYNAPs [88], and Braindrop [93] neuro- morphic processors. As emulation leads to a close rela- tionship between the algorithm\u2019s implementation and its hardware, sub-threshold analog designs typically follow an \u201cunderstand-by-building\u201d approach in close collabo- ration with neuroscience research and tend to focus on low-power, real-time use cases.\n\u2022 Small-scale digital chips \u2013 Digital neuromorphic chips have been proposed to accelerate progress in various cate- gories of neuromorphic algorithms, owing to the flexibil- ity and robustness of digital design. Learning algorithms have been explored in designs such as those proposed by prior work [68, 121, 99, 27, 43, 41], while network topologies have been studied using locally-competitive algorithms [68] and small-world networks [42], all of which cover a wide range of neuron and synapse dy- namics. While the previously-mentioned designs were implemented in a standard synchronous fashion with a global clock, some designs such as \u03bcBrain [132] and the design presented in [30] are fully asynchronous, allowing for event-driven executions.\n\u2022 Memristive neuromorphic chips \u2013 Memory devices known as memristors physically implement in-memory computing with a small footprint [119, 87]. Recently, proof-of-concept neuromorphic chips embedding mem- ristive devices have been demonstrated in [140, 136, 65].\nHowever, memristive devices can be subject to noise, low resolution, limited endurance, and reduced yield. Thus, it is crucial to evaluate the efficiency and performance of memristive neuromorphic chips at the system level to determine their feasibility [87, 104]. Such inherent physical properties, however, can also be exploited to reproduce some of the brain\u2019s dynamics [100, 37, 17].\nThe diversity of targeted use cases, circuit design styles, and implementation strategies in neuromorphic hardware plat- forms presents a challenge for direct comparison.2 Circuit- level metrics may not adequately capture system-level perfor- mance, leading to the need for objective task-level metrics. The NeuroBench project aims to address this need by provid- ing such metrics for neuromorphic design evaluation.\n3 CHALLENGES AND DIRECTIONS\nThe rich landscape of neuromorphic approaches supports the exploration of brain-inspired ideas that radically depart from mainstream deep learning algorithms and hardware. However, the field is lacking a principled approach to help identify which of these properties are the most promising ones for a given use case. This lack of consolidation stresses the need for fair and objective metrics and benchmarks.\nNumerous calls to action [34, 118] and efforts3 have been made to drive toward a common set of neuromorphic bench- mark tasks. To this end, we outline challenges towards con- verging on a common set of benchmarks for evaluating and comparing different neuromorphic algorithms and systems, many of which are left open by the benchmarks currently in use in the neuromorphic community. Subsequently, in Section 3.2 we introduce NeuroBench for comparing neu- romorphic solutions against each other, establishing base- lines against traditional approaches, and tracking the current progress and future milestones of neuromorphic research.\n3.1 Challenges\nThe unique and emerging features of neuromorphic com- puting in comparison to traditional deep learning systems present challenges for readily adopting existing efforts such as MLPerf [110, 82] for neuromorphic tasks and applica- tions. The rich diversity of solutions and the lack of standard methods for effectively comparing inputs into neuromorphic processing elements further exacerbate this issue. Addition- ally, the lack of portable frameworks across different solutions makes it particularly challenging to make apples-to-apples comparisons of neuromorphic solutions.\n2This diversity expands beyond the main categories surveyed in this section, e.g. with emerging photonic, superconducting, organic approaches [113].\n3 For example, the Telluride and Capo Caccia neuromorphic work- shops.\n "}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n 3.1.1 Limitations of Existing Benchmarks\nMany researchers in the field of neuromorphic computing have traditionally adopted benchmarks from deep learning, such as ImageNet, CIFAR, and MNIST [112, 70, 38]. How- ever, these benchmarks have limitations when applied to neu- romorphic designs, as they focus on offline, sequential batch processing and task performance without considering com- pute cost by default. In contrast, neuromorphic systems are of- ten designed for real-time processing of single, asynchronous samples in resource-constrained, event-driven scenarios. Fur- thermore, conventional benchmarks, when considering com- pute cost, often use measures such as floating-point operations (FLOPs) or integer operations (OPs). However, such defini- tions do not accurately represent the compute cost of neuro- morphic hardware, where the notion of an \u201coperation\u201d spans a broad range of resolutions and computations (Section 2.1). Consequently, conventional benchmarks are ill-matched to the specific features enabled by neuromorphic solutions, such as low-precision, sparse, event-based computation. For exam- ple, image or frame-based vision tasks lack inherent temporal dimensions that can be exploited by event-based processing.\nVarious benchmarks have been developed by the neuromor- phic community, which are specifically designed to leverage the strengths of neuromorphic architectures, such as operating on sparse, event-based time-series input data. N-MNIST4, the Spiking Heidelberg Datasets, and DVS Gesture are some of the most widely used benchmarks in this regard [96, 32, 8]. But even so, a standardized evaluation methodology for ana- lyzing compute cost at the algorithmic or system performance levels is still lacking for these benchmarks. As scalability, energy efficiency, and real-time processing are critical opti- mization criteria for neuromorphic solutions, it is crucial for neuromorphic benchmarks to be cost-aware by comparing the complexity and performance of solutions in addition to the correctness of results.\n3.1.2 Diversity of Neuromorphic Solutions\nAs we have previously discussed in Section 2, the term \u201cneuro- morphic\u201d has evolved into a blanket term that refers to a broad range of algorithmic and system design approaches. Such a variability of approaches introduces challenges towards defin- ing suitable benchmark tasks and workloads which adequately capture the broader field of neuromorphic computing. This di- versity of solutions often leads to self-defined benchmarks that only highlight the strengths of a particular design. Such bench- marks hinder fair comparisons of approaches both within and across different neuromorphic solution categories, which lim- its the development of deeper general insights within the field. In order to capture the performance of neuromorphic solu-\n4Note that the temporal dimension of N-MNIST has been arti- ficially introduced by saccading movements from the event-based camera.\ntions and facilitate fair comparisons between them and with conventional approaches, thoughtfully designed benchmark methodology and metrics are required.\n3.1.3 Varied Information Encoding Methods\nAs discussed in section 2.1, several information encoding methods are used in spike-based representations for convert- ing data into spiking formats. While event-based sensors like the dynamic vision sensor (DVS) and silicon cochlea inher- ently produce spiking data, algorithmic encoding methods are commonly used as a form of preprocessing to convert inputs to spiking formats for a neuromorphic model, and the optimal way to encode information using spikes remains an open challenge [117, 12].\nThe data encoding process used in spike-based neuromorphic representations can have a significant impact on the complex- ity of the resulting model. For instance, when classifying TIDIGITS [6] audio data, population encoding yields a sim- pler model compared to N-TIDIGITS [9], where a silicon cochlea is used for data encoding [125, 126]. Therefore, it is essential to consider the cost of any data encoding and pre-processing during benchmarking. While measuring pre- processing as part of the complete solution is straightforward at the system level, it is non-trivial to measure the cost of preprocessing at the algorithmic level.\n3.1.4 Disparate Frameworks & Software Stacks\nA wide array of different frameworks are used in neuromor- phic research. Generally, they aim towards different goals, distinctively including features to support neuroscientific sim- ulation (e.g., NEST [47], Brian [131], PyGeNN [69]), interfac- ing with custom neuromorphic hardware (e.g., hxtorch [128], Lava [58]), or automatic configuration of SNNs (e.g., Rock- pool [90], Norse [101], snnTorch [39], SpikingJelly [40]), for example. While this diversity has been instrumental in exploring the landscape of bio-inspired techniques following different methodologies and abstraction levels, the broad vari- ation of framework goals and independent implementation styles create barriers in dialogue and comparison between solutions written using different frameworks.\nMoreover, the lack of common software stacks adds to the complexity of comparing and evaluating neuromorphic sys- tems across different platforms and use cases. Software and compiler stacks are highly customized and cannot be easily reused across implementations. SNNs lack a common net- work exchange format such as ONNX [14] for traditional deep learning. This lack of uniformity prevents simple portability of algorithms and datasets across the neuromorphic commu- nity and makes it challenging to perform ideal benchmarking across platforms via standardized workload translation. In the absence of mature tools in the neuromorphic community, benchmarks must enforce fair heterogeneity in system imple-\n "}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n mentation, in part by utilizing application-level workloads instead of network- or circuit-level workloads.\n3.2 Directions\nThe need for standardization and equitable comparison within neuromorphic computing presents a set of difficulties, but it also presents an opening for cooperative benchmark estab- lishment. The objective of NeuroBench is to address this requirement by offering an impartial and comprehensive set of benchmarking procedures that reflect the objectives of the neuromorphic community. To this end, we outline our bench- mark design philosophy, followed by a detailed exposition of the practical implementation of these benchmarks.\n3.2.1 Benchmark Design Philosophy\nThe benchmarks developed in NeuroBench aim to achieve two primary objectives: 1) to facilitate advancements in the field of neuromorphic research by identifying the unique strengths and capabilities of various neuromorphic solutions, and 2) to enable unbiased and rigorous comparisons of per- formance among different types of solutions, including non- neuromorphic ones.\nNeuroBench is a community-driven benchmark suite. At present, the NeuroBench community comprises researchers from over 60 institutions, spanning both industry and academia, and representing a broad spectrum of neuromor- phic approaches. The design of the benchmark suite is a result of collective agreement and consensus within the community, which ensures that the benchmarks accurately represent and include the diverse range of neuromorphic research. More- over, the NeuroBench suite is incremental, moving forward in actionable steps to systematically address the needs of the community, and also follow the evolving trends and ap- proaches of emerging neuromorphic technologies.\nAddressing all challenges at once is unrealistic, and it is among the reasons why progress in developing widely adopted neuromorphic benchmarks has been slow [34]. To avoid this pitfall, NeuroBench will establish a solid foundation by first developing benchmark methods and metrics for a carefully-selected subset of key algorithms and applications. This approach will create a strong basis for future extensions to hardware-supported neuromorphic systems, as well as a broader range of trends and applications.\n3.2.2 Benchmark Development Principles\nIn order to accommodate the broad spectrum of neuromorphic solutions, NeuroBench avoids imposing rigid criteria to define what qualifies as \u201cneuromorphic\u201d. Instead, the benchmark suite is designed in a general manner, enabling the compar- ison of various types of solutions and facilitating inclusive competition that encompasses traditional approaches. The\ndetermination of which solutions meet the criteria of being \u201cneuromorphic enough\u201d is left to the community, based on leaderboard results and a transparent description of the solu-\ntion, which will be supported by explicit guidelines.\nThe NeuroBench benchmark suite is divided into two tracks, namely the algorithms track and the systems track. The former is focused on benchmarking and evaluating the performance of neuromorphic algorithms, regardless of the underlying sys- tems used (Section 4). This track is primarily concerned with assessing the correctness of solutions, while also taking into account the complexity of the algorithms being evaluated. On the other hand, the systems track aims to benchmark the performance of neuromorphic systems as an end-to-end com- puting solution deployed on actual hardware, with a particular focus on metrics such as latency and energy consumption (Section 5).\nThe algorithms and systems dual-track approach is proposed as an actionable starting point for benchmarking neuromor- phic solutions. The two tracks are visualized in Figure 1. Uti- lizing the two tracks, NeuroBench aims to enable cross-stack innovation by supporting a virtuous cycle between algorithms and systems. Promising methods from the former can inform the next generations of system design, both in terms of target algorithms to optimize towards and system workloads to be benchmarked. And progress towards the latter can accelerate algorithmic exploration and enable more powerful deployed methods. System-level performance metrics can also inform algorithmic complexity metrics for more informative algorith- mic prototyping.\n4 NeuroBench ALGORITHMS TRACK\nIn this section, we present the first iteration of the algorithmic track, which reflects the proclivities of the NeuroBench com- munity towards devising challenging, practical, and relevant tasks that showcase the potential of neuromorphic techniques. The NeuroBench algorithmic track encompasses a series of benchmark tasks that have been identified by the commu- nity as areas of interest for neuromorphic approaches. In Section 4.1, we present the objectives of this track. In Sec- tion 4.2, we expound upon the metrics that hold relevance across a diverse spectrum of benchmark tasks. Furthermore, in Section 4.3, we elucidate the manner in which pre-existing benchmarks are assimilated into the NeuroBench framework through the standardization of tasks. In Section 4.4, we in- troduce a novel and forward-looking suite of tasks that poses a greater challenge to present and future neuromorphic solu- tions.\n4.1 Goals\nThe objectives of the algorithmic track tasks are 1) to provide a standard for evaluating neuromorphic algorithmic efficacy,\n"}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n      Dataset\nAlgorithm\nAlgorithm Metrics\n  Algorithms Track\nSystems Track\n      Dataset\nAlgorithm\nSystem\nSystem Metrics\nFigure 1. The three proposed tracks of NeuroBench. Red boxes designate what is defined by the benchmark, and blue boxes signify what is unique to the solution. Connecting arrows indicate co-development between the two tracks.\n2) to present challenges that can direct and steer neuromorphic research, and 3) to demonstrate the advantages of neuromor- phic approaches over traditional methods.\nThe algorithms track addresses the heterogeneity of neuro- morphic methods and facilitates comparisons with traditional, non-neuromorphic approaches by defining quality and com- plexity metrics which are independent of the underlying sys- tem details. The metrics, which are discussed in Section 4.2, promote inclusivity between different solution types for fair comparison, while also providing at-a-glance insights into the performance of algorithmic solutions on hardware. They provide a framework for evaluating the trade-offs between correctness, performance, and footprint.\n4.2 Metrics\nIn the algorithms track, we have established accuracy and complexity metrics that hold relevance across a spectrum of solution types. It is incumbent upon each benchmark solution to report these primary metrics, with averages and standard deviations calculated over multiple runs.\nMoreover, NeuroBench outlines solution-specific metrics that may exclusively apply or be meaningful within a single solu- tion type category. These finer-grained metrics are optional and are officially defined by NeuroBench to facilitate standard comparisons within specific solution categories.\n4.2.1 Solution-agnostic Metrics\nCorrectness: Accuracy, along with other metrics that gauge the correctness of the algorithmic outputs, such as mean av- erage precision (mAP) and root mean square error, serve as quantitative assessments of the algorithm\u2019s output quality. As the interpretation of correctness is closely linked to the bench- mark task, we define these metrics in each of the subsequent task-specific subsections.\nComplexity: Algorithmic complexity metrics quantify the computational demands imposed by the solution. They are measured independently of the underlying hardware and there- fore do not explicitly correlate with post-deployment latency or power consumption figures. Nevertheless, complexity met- rics provide valuable insights into algorithm performance, enabling high-level comparisons and facilitating prototyping efforts. The following complexity metrics are expected to be reported by all benchmark solutions:\n\u2022 Network size:\n1. Number of neurons (regardless of the model)\n2. Number of synapses\n3. Total memory footprint accounting for every state variable and parameters such as synaptic weights, delays, and intermediate variables. Quantization is taken into account.\n\u2022 Inference time:\n1. Inference throughput (i.e. frequency), defined as the time window of each algorithmic step which measures model output\n2. Average output latency, defined as the mean number of algorithmic steps necessary to process an input.\n\u2022 Computational operations:\n1. Number of multiply-and-accumulates (MACs)\n2. Number of accumulates (ACs), which may be used to update the neuron and synapse states.\nDisclaimer: The current definitions of metrics as pre- sented are in their prototype stage and have certain limita- tions. The metric for inference time is currently defined based on algorithmic steps, which is most analogous to timestepped synchronous digital systems, thus limiting its\n"}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n solution-agnosticism. Furthermore, the computational opera- tions metric does not account for the computation of dynamics, leading to incomplete measurement, while it also assumes a digital implementation/simulation. Therefore, we recognize the need for improving these metrics and are open to commu- nity feedback towards this end.\n4.2.2 Solution-specific Metrics\nIn addition to the complexity metrics, NeuroBench stipulates finer-grained metrics that are specific to certain solution cat- egories. These metrics are intended to offer deeper insights into the comparison of solutions within the same category, and they are not mandatory for all solutions. Currently, the proposed solution-specific metrics encompass communication operations and the number of connections to post-synaptic neurons (fanout) for SNNs. Furthermore, for solutions geared towards analog hardware, the robustness to noise represents an important solution-specific metric that is under consideration.\n4.3 Standardizing Existing Benchmarks\nA primary objective of the first version of the NeuroBench algorithms track is to enhance existing benchmarks by lever- aging the previously defined metrics and delineating clear task specifications. In pursuit of this objective, we outline the tasks that are already familiar to the community in this section, with the intent of establishing the most effective practices for standardizing the evaluation methodology.\n4.3.1 Keyword Spotting\nUse Case\nVoice commands represent a natural and easily accessible modality for human-machine interaction. Keyword detec- tion, in particular, is frequently employed in edge devices that operate in always-listening, wake-up situations, where it triggers more computationally demanding processes such as automatic speech recognition [85]. Keyword spotting finds application in activating voice assistants, speech data mining, audio indexing, and phone call routing [53, 150]. Given that it generally operates in always-on and battery-powered edge sce- narios, keyword detection represents a pertinent benchmark for energy-efficient neuromorphic solutions.\nPrior work has explored a variety of conventional and neu- romorphic solutions aimed at enabling keyword spotting in resource-constrained and energy-limited environments [26, 16, 133, 10, 120, 144, 143, 41]. Additionally, the prior work has initiated some initial benchmarking endeavors for key- word spotting algorithms on various neuromorphic hardware platforms [18, 31, 41]. However, most of these solutions are not evaluated in a uniform manner, and there is currently no standard approach for evaluating audio processing into spiking formats (see Section 3.1.3).\nDataset\nThe Google Speech Commands (GSC) dataset (V2) [142] represents the dataset of choice for assessing the performance of keyword spotting algorithms. The second version of the dataset comprises 105829 one-second utterances of 35 words from 2618 distinct speakers. The sample data is encoded as linear 16-bit single-channel pulse code modulation (PCM) values, at a 16 kHz rate.\nPresently, we are evaluating methods of quantifying the al- gorithmic cost associated with the encoding of audio sam- ples into spiking formats. We are also considering utilizing the widely-adopted Heidelberg Spiking Speech Commands dataset [32] as a familiar encoding of the GSC dataset.\nBenchmark Task\nThe goal of this task is to develop a model that trains using the designated train and validation sets, followed by an evaluation of generalization to a separate test set.\nIn this task, a model trains using the designated train and validation sets, and it is evaluated on its generalization to a separate test set. Concerning keyword spotting, the GSC dataset is partitioned into training, validation, and test sets in line with the default distribution [142], encompassing 84.8k, 9.9k, and 11k samples, respectively.\nMetrics\nClassification accuracy on the test set will measure the cor- rectness of the algorithmic solution. To measure algorithmic complexity, we are investigating how the previously defined metrics of network size, inference time, and computational operations will need to be further specified, especially given the encoding flexibility. In particular, we are evaluating meth- ods to measure the algorithmic complexity of data encoding, and how to account for inference time for e.g. solutions in which audio samples are coded into MFCC frames.\n4.3.2 Gesture Recognition\nUse Case\nMid-air gestures represent a natural modality of communica- tion that holds benefits in a range of human-computer interac- tion applications owing to its touchless and efficient nature. Gesture recognition systems find utility in edge scenarios such as car infotainment systems, high-traffic public areas, or as al- ternative interaction modes for individuals with speech or hear- ing impairments. Recent advancements in sensors capable of detecting mid-air gestures have been made [148, 63, 141]; however, accurate recognition continues to pose a challenge. Analogous to KWS, the recognition of mid-air gestures on always-on, real-time edge devices holds the potential to ex- hibit the unique merits of neuromorphic methods compared to existing alterantives.\n"}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n Dataset\nThe IBM Dynamic Vision Sensor (DVS) Gesture dataset [7] is composed of recordings of 29 distinct individuals executing 10 different types of gestures, including but not limited to clapping, waving, etc. Additionally, an 11th gesture class is included that comprises gestures that cannot be categorized within the first 10 classes. The gestures are recorded under four distinct lighting conditions, and each gesture is associated with a label that indicates the corresponding lighting condition under which it was performed.\nBenchmark Task\nThe benchmark task is to use samples from the 23 initial sub- jects as training and generalize to samples from the remaining 6 subjects.\nMetrics\nSimilarly to above, algorithm correctness will be measured as classification accuracy on the test set. We are also con- sidering further quality metrics which incentivize reducing false-positive rates by particularly using samples from the 11th uncategorized class. Complexity metrics of network size, inference time, and computational operations will be reported in line with section 4.2.\n4.4 Novel Benchmark Tasks\nAs part of our effort to establish standardized benchmarks, we have also developed new benchmark challenges for neu- romorphic methods, which are evaluated using our metrics. The list of tasks highlight features which are relevant to neu- romorphic research interests: adaptive learning, detection utilizing the high dynamic range and temporal resolution of DVS, sensorimotor emulation based on cortical signals, and small predictive modeling useful for prototyping resource- constrained networks such as in mixed-signal simulation and design.\n4.4.1 Adaptive Learning of Keywords and Gestures\nUse Case\nThe ability to rapidly adapt to new tasks is a characteristic of cognitive function and a long-standing objective of artificial intelligence (AI). However, traditional deep learning methods often face challenges when adapting to previously unseen tasks. Neuromorphic algorithms have recently shown promise in the area of continual adaptation [145, 72, 127] and few- shot online learning capabilities [129, 55]. As a result, the establishment of formally defined tasks is needed.\nDataset\nContinual domain adaptation and few-shot online learning are evaluated using the GSC and DVS Gesture datasets for keyword and gesture classification. It should be noted that\nthese tasks can be applied to datasets in any domain.\nBenchmark Task(s)\nOur benchmark emphasizes three aspects of adaptation: few- shot, which aims to achieve rapid learning of new tasks using a minimal number of training samples; continual, which focuses on retaining previously learned tasks while learning new ones; and online, which is concerned with making these adaptations at the edge in a streaming fashion while still carrying out inference. To model the online aspect algorithmically, we expose adaptive training samples in single-sample batches.\nContinual Domain Adaptation\nThe proposed benchmark evaluates domain-incremental learn- ing in adaptive scenarios [137], where the model must learn to solve tasks with similar structures but varying input distribu- tions. The dataset is initially split into two sets, T raininit and Traincont, based on the t speakers (GSC) or subjects (DVS Gesture) as follows: S = {S1, S2...St}. The sets T raininit and T raincont are disjoint, i.e., T raininit \u2229 T raincont = \u2205.\nAt the outset, the model is trained on all 35 keywords or 11 gesture classes, however, the training process is limited to the speakers/subjects of Traininit set. Thereafter, the model is trained in a continual learning setup, where each speaker/subject from the T raincont set is sequentially trained as a task. Specifically, each task corresponds to a batch from a speaker/subject of the T raincont set. The test set will con- sist of unseen samples from all previously learned speak- ers/subjects at the current learning iteration.\nIncremental Few-Shot Learning\nThis benchmark evaluates the ability of a model to perform class-incremental learning over its lifetime, where the model is required to learn new keywords or gestures as they are introduced. The dataset is initially divided into T raininit and T raincont sets based on the classes of keywords or gestures, where T raininit represents the initial set of classes that the model is pre-trained on. The remaining classes are included in the T raincont set. Each task in T raincont is represented by a N \u2217K sample batch (N-way K-shot) with unique keywords or gestures for every task. The model trains sequentially over these batches with each task introducing N new keywords or gestures to learn. The test set consists of unseen samples of all the keywords or gestures that have been exposed.\nMetrics\nFor continual domain adaptation, the benchmark evaluates the accuracy of classification on previously unseen samples from all the speakers/subjects learned until the current iteration us- ing the test set. Correctness metrics will determine the quality of the adaptive learning method by assessing the difference between classification accuracy on the learned batches before and after each epoch of adaptation. Additionally, the contin-\n"}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n ual characteristics will be measured by reporting accuracy on all previously learned speakers/subjects. The benchmark also aims to evaluate formalized correctness and complexity metrics, which are currently under evaluation.\nFor incremental few-shot learning, the correctness metrics are determined by measuring the difference in classification accuracy before and after learning for all previously learned classes. The evaluation of formal metrics, as well as the best way to structure the task relative to speakers and subjects, is currently under consideration.\n4.4.2 DVS Object Detection\nUse Case\nReal-time object detection is a widely used computer vision task with applications in several domains, including robotics, autonomous driving, and surveillance. Its applications in- clude event cameras for smart home and surveillance systems, drones that monitor and track objects of interest, and self- driving cars that detect obstacles to ensure safe operation. Efficient energy consumption and real-time performance are crucial in such scenarios, particularly when deployed on low- power or always-on edge devices.\nDataset\nThe object detection benchmark utilizes the Prophesee 1 Megapixel Automotive Detection Dataset [1], which was intro- duced in prior art Perot et al. [106]. This dataset was recorded with a high-resolution event camera with a 110 degree field of view mounted on a car windshield. The car was driven in various areas under different daytime weather conditions over several months. The dataset was labeled using the video stream of an additional RGB camera in a semi-automated way, resulting in over 25 million bounding boxes for seven differ- ent object classes: pedestrian, two-wheeler, car, truck, bus, traffic sign, and traffic light. The labels are provided at a rate of 60Hz, and the recording of 14.65 hours is split into 11.19, 2.21, and 2.25 hours for training, validation, and testing, re- spectively. This dataset is currently one of the largest labeled object detection datasets available, comprising approximately 3.4 TB of raw data.\nBenchmark Task\nThe task of object detection in event-based spatio-temporal data involves identifying bounding boxes of objects belonging to multiple predetermined classes in an event stream. Training for this task is performed offline based on the data splits provided by the original dataset.\nMetrics\nThe correctness of the task is measured using mean average precision (mAP), which is the area under the precision-recall curve for various Intersection over Union (IoU) thresholds.\nThe evaluation metric employed is COCO mAP [75, 3], which has been adapted for event-based data as outlined in Section B of Perot et al. [106]. Complexity metrics are defined accord- ing to section 4.2, but we add the further real-time requirement that inference throughput must be at least equal to the ground truth frequency of 60Hz.\nGiven that the label frequency of 60Hz is slower than the DVS input time resolution, it is possible for models to gen- erate outputs faster than ground truth is available. We are currently exploring the possibility of interpolating bounding boxes to enable assessment of faster models. If this approach is unfeasible, we may measure correctness as an average of predictions or only utilize predictions when ground truth is available.\n4.4.3 Motor Prediction\nUse Case\nThere is significant interest in models that not only take inspi- ration from but also strive to accurately replicate features of biological computation. The study of these models presents opportunities to gain a more comprehensive understanding of sensorimotor behavior and the underlying computational primitives that facilitate them, which can be used to develop closed-loop and model-predictive control tasks essential for controlling future robotic agents [146]. Additionally, this research has implications for the development of wearable or implantable neuro-prosthetic devices that can accurately predict motor activity from neural or muscle signals. Hence, motor prediction is important.\nDataset\nThe dataset that we utilize in this study consists of multi- channel recordings obtained from the sensorimotor cortex of two non-human primates (NHP) during self-paced reaching movements towards a grid of targets [95]. The variable x is represented by threshold crossing times (or spike times) and sorted units for each of the recording channels. The target y is represented by 2-dimensional position coordinates of the fingertip of the reaching hand, sampled at a frequency of 250 Hz. The complete dataset contains 37 sessions spanning 10 months for NHP-1 and 10 sessions from NHP-2 spanning one month. For this study, three sessions from each NHP were selected to include the entire recording duration, resulting in a total of 6774 seconds of data.\nBenchmark Task\nIn the context of predictive modeling, time series prediction is a task which entails the forecasting of one or more observa- tions of a target variable, y, at some point between the current time, t, and a future time, t + tf , by utilizing a sequence of another variable, x, from the past, {x(t \u2212 th ), . . . , x(t)}.\nSpecifically, in the context of the motor prediction task, it\n"}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n entails predicting the X and Y components of finger velocity, y, from past neural data, x, with a minimum frequency of 10 Hz. The model architecture may be trained separately for each session to account for inter-day neural variability. The train- ing data is divided into either 50% or 80% for training, while the remaining split is distributed equally between validation and testing. This allows for testing of the model\u2019s generaliza- tion capabilities with varying data sizes and comparison with related work in the field [80, 123].\nMetrics\nThe correctness of predictions is evaluated by the coefficient of determination (R2) and the normalized root mean square error (NRMSE). Additionally, diagnostic information on in- stantaneous predictions is provided by reporting the NRMSE of trajectory predictions as a function of time. Other metrics and variable data-splits are being explored to measure the quality of solutions, including an area-under-curve (AUC) approach. Model complexity is measured according to the metrics described in Section 4.2.\n4.4.4 Chaotic Function Prediction\nUse Case\nAll benchmarks presented thus far have relied on real-world in- put data to assess the performance of methods on practical ap- plications. However, real-world data can be high-dimensional and require large networks to achieve high accuracy, present- ing challenges for solution types with limited I/O support and network capacity, such as mixed-signal prototype solutions. To address this, we propose a synthetic data benchmark task that can be effectively tackled by smaller networks, providing a means to evaluate such solution types within the benchmark- ing framework.\nDataset\nWe propose using the Mackey-Glass time series. The Mackey- Glass dataset has been widely adopted as a standard bench- mark for evaluating various temporal prediction models, in- cluding those in the neuromorphic computing domain. Prior work has demonstrated the efficacy of neuromorphic temporal predictors using this dataset [61, 91, 29].\nThe Mackey-Glass dataset is a one-dimensional non-linear time delay differential equation [77], defined as follows:\ndx =\u03b2 x(t\u2212\u03c4) \u2212\u03b3x(t). dt 1+x(t\u2212\u03c4)n\nHere the parameters \u03b3, n, \u03b2, \u03c4 \u2208 R+ control the evolution of the signal x(t). Given particular settings of the parameters the task can be easy to predict, or can produce more challenging chaotic dynamics. Parameter choices for the benchmark task are currently being determined.\nIn addition to the Mackey-Glass dataset, we plan to include\nother synthetic datasets in future iterations of the benchmark, in order to increase its complexity and challenge the capabili- ties of neuromorphic systems [11].\nBenchmark Task\nThe proposed task is a sequence-to-sequence prediction prob- lem, similar to the motor control prediction task. In this case, the task is formulated in a self-supervised setting where the in- put sequence x is used to predict the future values of the same sequence, y(t) = x(t). The dynamics of the system will be integrated using a fixed time step \u2206t, and the performance of the system will be tested in a multi-horizon prediction setting, where future values of the sequence are predicted at a rate of \u2206t. The task\u2019s difficulty will be varied by adjusting the ratio between the integration time step \u2206t and the timescale \u03c4 of the underlying dynamics.\nWe are currently identifying appropriate function parameters to differentiate the level of chaos in the function dynamics, which will impact the relative complexity of the benchmark.\nMetrics\nSimilar to the preceding prediction task, the correctness of predictions in this benchmark will be evaluated using the coefficient of determination, R2, and the normalized root mean square error (NRMSE). We will report performance as a function of the prediction horizon, tf . Moreover, complexity metrics will be assessed in a similar manner to the preceding task.\n4.5 Release Date\nThe algorithms track is anticipated to be released around Q2 2023. This release will comprise finalized benchmark specifications, baseline algorithm measurements, open-source benchmark harnesses, and detailed documentation to facili- tate the evaluation of additional solutions. Furthermore, the release will include a leaderboard of results to enable the com- munity to compare and contrast the performance of different solutions on the NeuroBench benchmarks.\n5 NeuroBench SYSTEMS TRACK\nAn upcoming addition to the NeuroBench initiative is the systems track, which is designed to evaluate system-level so- lutions for their deployable performance in latency and energy efficiency. Similarly to the algorithms track, the systems track will be iterative and developed in collaboration with the com- munity. Also, much like the algorithms track, this is work in progress. We anticipate that the first iteration of the systems track will be released in Q4 2023, and it will represent a sig- nificant step forward in benchmarking system-level solutions for neuromorphic computing.\nOne of the primary objectives of the systems track is to\n "}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n facilitate fair and accurate comparisons between different neuromorphic systems, including those listed in Section 2.2. Achieving this goal will require the development of fair and comprehensive benchmarking methodologies that can account for the unique features and performance characteristics of each system. By enabling these comparisons, we aim to pro- vide valuable insights into the strengths and limitations of different neuromorphic systems, and thereby facilitate the continued evolution and improvement of the field.\nGiven the significant heterogeneity between different neu- romorphic system approaches, it is a major challenge when creating system benchmarks to establish fair and accurate methods for measuring performance characteristics such as latency and energy costs. As a first step, we propose starting with a finer granularity approach of evaluating individual sys- tems, rather than attempting to define general methods that can be applied across all systems. This way, we can take ac- tionable steps towards benchmarking a known set of systems, before attempting to generalize broadly to all neuromorphic systems.\nSimilar to the algorithms track, the initial iteration of the NeuroBench systems track will most likely only consider can- didates that have reached a sufficient level of maturity. The benchmark tasks, datasets and metrics will be tailored to showcase the strengths and capabilities of these candidates. Candidate systems should benefit from well-supported SDKs and provide a representative coverage of the diversity of neu- romorphic platforms. Currently, a tentative list of system candidates for the first iteration includes Loihi [35, 59], SpiN- Naker [45, 46], Xylo [21], and BrainScaleS [102]. Future iterations of the systems track will seek to accommodate fair comparisons between additional types of system designs, and our eventual goal is to welcome entries from all neuromorphic hardware and system platforms.\nA tentative list of the candidate benchmark tasks for the first it- eration of the NeuroBench systems track benchmarks includes keyword and gesture classification, time-series prediction, constraint satisfaction, and adaptive motor control. These tasks have been initially identified as they are representative of a broad range of applications that can benefit from neuromor- phic system solutions. As the algorithms track and systems track evolve over time, we aim to incorporate community feedback and adapt to the needs of the field to continually en- hance the alignment between the two tracks, moving towards the material realization of neuromorphic technologies.\nAs discussed in Section 2, certain neuromorphic methods such as sub-threshold analog design cannot be neatly differ- entiated into algorithmic and system-level solutions to be benchmarked. To extend the NeuroBench suite to encompass such solutions, in the future we may consider a \u2018co-design\u2019 track as a third track which aims to compare solutions for which the algorithm and hardware cannot be distinguished.\nThis track may require the development and maturation of simulation or analysis frameworks, which can be fairly and rigorously used in the benchmark tasks.\n6 DISCUSSION\nThe NeuroBench suite is designed to drive progress in the field of neuromorphic computing through an iterative approach. The current proposal includes benchmark tasks in a variety of domains, such as keyword classification, gesture recogni- tion, object detection using event-based sensors, and effector position prediction using cortical recordings. However, the ap- plications and domains for which neuromorphic systems can be utilized are vast and diverse [45, 36]. Therefore, the scope of benchmark tasks included in NeuroBench could expand to encompass additional areas, such as closed-loop scenar- ios [86, 130] and graph analytics [36], or tasks requiring a large number of parameters and strict timing constraints, such as robotic control [105] or large language models [149].\nWith the growth of the benchmark, we anticipate that the es- tablishment of NeuroBench standards for benchmarking will facilitate the adoption of uniform tool stacks and program- ming flows throughout the neuromorphic community. Such well-developed, uniform tools can be integrated with future benchmarks to expand their scope and enable more mean- ingful comparisons. In particular, we hope to foster bridges between different neuromorphic programming frameworks through initiatives such as network exchange formats (e.g., ONNX [14]) or compile stacks (e.g., TVM [28]).\nBy developing the algorithm and systems tracks, as well as possible future iterations, NeuroBench can potentially facil- itate more accurate and informative comparisons between traditional and neuromorphic computing solutions, covering a wide range of neuromorphic principles for next-generation technology and AI. Furthermore, the NeuroBench consortium seeks to establish an open system, with the community tak- ing the lead in proposing and implementing future additions, similar to the structure of MLCommons [2]. This ensures that additional tasks or tracks remain consistent with the commu- nity\u2019s vision of neuromorphic computing.\nNeuroBench represents an ongoing endeavor aimed at en- abling the benchmarking of neuromorphic computing solu- tions, and as such, we acknowledge that there is still consid- erable scope for further refinement and improvement. In this regard, we are open to receiving feedback from the commu- nity, and we welcome any constructive input that can help enhance the functionality and effectiveness of the NeuroBench platform. As we continue to evolve and expand our offerings, we anticipate that the feedback we receive will be instrumental in guiding the evolution of the NeuroBench platform towards a more robust and comprehensive benchmarking solution for the field of neuromorphic computing.\n"}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n 7 CONCLUSION\nNeuromorphic computing represents a burgeoning field of research that encompasses diverse AI and system design methodologies. These approaches are grounded in neural structures, resulting in a range of complexities and varia- tions. In this paper, we introduced the underlying philoso- phy and preliminary framework for NeuroBench, an initiative aimed at establishing benchmarks for neuromorphic com- puting through community-driven efforts. We envision the NeuroBench benchmarks as a collaborative, fair, and inclusive framework that can catalyze progress in neuromorphic meth- ods and technological advancements. Our iterative approach to the release of NeuroBench benchmarks seeks to foster a spirit of cooperation and drive concrete advances in the field of neuromorphic computing.\nFinally, the NeuroBench project is founded on the principles of community-driven efforts, with the primary objective of facili- tating collaborative advancements in the field of neuromorphic computing. We firmly believe that the collective expertise and contributions of individuals from diverse backgrounds can drive the development of effective and fair benchmarks that can benefit the broader scientific community. In essence, Neu- roBench is a project that is driven by and for the community. We encourage interested parties to access neurobench.ai to obtain the most recent and accurate information regarding the project. Additionally, the website provides details on how to join and contribute to the project, thereby enabling inter- ested individuals to participate in shaping the development of NeuroBench.\nACKNOWLEDGEMENTS\nThe NeuroBench project represents a collaborative and in- clusive effort, wherein contributions from a diverse group of researchers from both academia and industry have been instrumental in shaping the benchmark design and motivating its release. The authors listed in this paper are only a small subset of the larger community whose collective expertise and dedication have been integral to the development of the Neu- roBench initiative. Our project also builds off prior efforts and collaborations from Telluride, Capo Caccia, and NICE, which have driven the NeuroBench community development and trailblazed paths towards inclusive benchmark design. We are immensely grateful to the NeuroBench community for their wisdom, effort, and passion, which they have shared with us in the form of countless meetings, research publications, and other forms of engagement. Without their support and input, NeuroBench would not have been matured from concept to a full-scale community-driven effort, and we look forward to continued collaboration with the community in the evolution of the project.\nREFERENCES\n[1] 1megapixel automative object detection dataset.\nhttps://www.prophesee.ai/2020/11/24/ automotive-megapixel-event-based- dataset/.\nhttps://mlcommons.org/en/. [3] COCO api. https://github.com/\n[2] Mlcommons.\n(Accessed on 04/04/2023).\ncocodataset/cocoapi.\n[4] fabrizio-ottati/awesome-neuromorphic-hw: A list of papers, docs, codes about neuromorphic hard- ware. this repo aims at providing the info for neuromorphic hardware research, we are continu- ously improving the project. welcome to pr the works (papers, repositories) that are missed by the repo. https://github.com/fabrizio- ottati/awesome-neuromorphic-hw. (Ac- cessed on 04/03/2023).\n[5] Speck. https://www.synsense.ai/ products/speck/. Accessed: 2023-04-03.\n[6] R. Gary Leonard, and George Doddington. TIDIGITS LDC93S10. Web Download. Philadelphia: Linguistic Data Consortium, 1993.\n[7] Amir, A., Taba, B., Berg, D., Melano, T., McKinstry, J., Di Nolfo, C., Nayak, T., Andreopoulos, A., Garreau, G., Mendoza, M., et al. A low power, fully event- based gesture recognition system. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7243\u20137252, 2017.\n[8] Amir, A., Taba, B., Berg, D., Melano, T., McKinstry, J., Di Nolfo, C., Nayak, T., Andreopoulos, A., Garreau, G., Mendoza, M., et al. A low power, fully event-based gesture recognition system. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 7243\u20137252, 2017.\n[9] Anumula, J., Neil, D., Delbruck, T., and Liu, S.-C. Feature representations for neuromorphic audio spike streams. Frontiers in neuroscience, 12:23, 2018.\n[10] Arik, S. O., Kliegl, M., Child, R., Hestness, J., Gibian- sky, A., Fougner, C., Prenger, R., and Coates, A. Con- volutional recurrent neural networks for small-footprint keyword spotting. arXiv preprint arXiv:1703.05390, 2017.\n[11] Atiya, A. F. and Parlos, A. G. New results on re- current network training: unifying the algorithms and accelerating convergence. IEEE transactions on neural networks, 11(3):697\u2013709, 2000.\n"}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n [12] Auge, D., Hille, J., Mueller, E., and Knoll, A. A survey of encoding techniques for signal processing in spiking neural networks. Neural Processing Letters, 53(6): 4693\u20134710, 2021.\n[13] Azghadi, M. R., Iannella, N., Al-Sarawi, S. F., Indiveri, G., and Abbott, D. Spike-based synaptic plasticity in silicon: design, implementation, application, and challenges. Proceedings of the IEEE, 102(5):717\u2013737, 2014.\n[14] Bai, J., Lu, F., Zhang, K., et al. Onnx: Open neural network exchange. https://github.com/onnx/ onnx, 2019.\n[15] Basu, A., Deng, L., Frenkel, C., and Zhang, X. Spiking neural network integrated circuits: A review of trends and future directions. In IEEE Custom Integrated Cir- cuits Conference (CICC), 2022.\n[16] Berg, A., O\u2019Connor, M., and Cruz, M. T. Keyword transformer: A self-attention model for keyword spot- ting. arXiv preprint arXiv:2104.00769, 2021.\n[17] Bhattacharjee, A., Kim, Y., Moitra, A., and Panda, P. Examining the robustness of spiking neural networks on non-ideal memristive crossbars. In Proceedings of the ACM/IEEE International Symposium on Low Power Electronics and Design, pp. 1\u20136, 2022.\n[18] Blouw, P., Choo, X., Hunsberger, E., and Eliasmith, C. Benchmarking keyword spotting efficiency on neuro- morphic hardware. In Proceedings of the 7th annual neuro-inspired computational elements workshop, pp. 1\u20138, 2019.\n[19] Bohnstingl, T., S\u02c7urina, A., Fabre, M., Demirag \u0306, Y., Frenkel, C., Payvand, M., Indiveri, G., and Pantazi, A. Biologically-inspired training of spiking recurrent neural networks with neuromorphic hardware. In 2022 IEEE 4th International Conference on Artificial Intel- ligence Circuits and Systems (AICAS), pp. 218\u2013221. IEEE, 2022.\n[20] Bohte, S. M., Kok, J. N., and La Poutre, H. Error- backpropagation in temporally encoded networks of spiking neurons. Neurocomputing, 48(1-4):17\u201337, 2002.\n[21] Bos, H. and Muir, D. R. 7. Sub-mW Neuromor- phic SNN Audio Processing Applications with Rock- pool and Xylo, pp. 69\u201378. 2022. URL https:// ieeexplore.ieee.org/document/9967462.\n[22] Bouvier, M., Valentian, A., Mesquida, T., Rummens, F., Reyboz, M., Vianello, E., and Beigne, E. Spiking neu- ral networks hardware implementations and challenges: A survey. ACM Journal on Emerging Technologies in Computing Systems (JETC), 15(2):1\u201335, 2019.\n[23] Brink, S., Nease, S., Hasler, P., and et. al. A learning- enabled neuron array ic based upon transistor channel models of biological phenomena. IEEE Transactions on Biomedical Circuits and Systems, 7(1):71\u201381, 2013.\n[24] Cassidy, A. S., Georgiou, J., and Andreou, A. G. De- sign of silicon brains in the nano-CMOS era: spiking neurons, learning synapses and neural architecture op- timization. Neural Networks, 45:4\u201326, June 2013. doi: 10.1016/j.neunet.2013.05.011.\n[25] Chan, V., Liu, S.-C., and van Schaik, A. AER EAR: A matched silicon cochlea pair with address event repre- sentation interface. IEEE Transactions on Circuits and Systems I: Regular Papers, 54(1):48\u201359, 2007.\n[26] Chen, G., Parada, C., and Heigold, G. Small-footprint keyword spotting using deep neural networks. In 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 4087\u2013 4091. IEEE, 2014.\n[27] Chen, G. K., Kumar, R., Sumbul, H. E., Knag, P. C., and Krishnamurthy, R. K. A 4096-neuron 1m-synapse 3.8-pj/sop spiking neural network with on-chip stdp learning and sparse weights in 10-nm finfet cmos. IEEE Journal of Solid-State Circuits, 54(4):992\u20131002, 2018.\n[28] Chen, T., Moreau, T., Jiang, Z., Zheng, L., Yan, E., Cowan, M., Shen, H., Wang, L., Hu, Y., Ceze, L., Guestrin, C., and Krishnamurthy, A. Tvm: An auto- mated end-to-end optimizing compiler for deep learn- ing, 2018.\n[29] Chilkuri,N.R.andEliasmith,C.Parallelizinglegendre memory unit training. In International Conference on Machine Learning, pp. 1898\u20131907. PMLR, 2021.\n[30] Chundi, P. K., Wang, D., Kim, S. J., Yang, M., Cerqueira, J. P., Kang, J., Jung, S., Kim, S., and Seok, M. Always-on sub-microwatt spiking neural network based on spike-driven clock-and power-gating for an ultra-low-power intelligent device. Frontiers in Neuro- science, 15:684113, 2021.\n[31] Cramer, B., Billaudelle, S., Kanya, S., Leibfried, A., Gru \u0308bl, A., Karasenko, V., Pehle, C., Schreiber, K., Stradmann, Y., Weis, J., Schemmel, J., and Zenke, F. Surrogate gradients for analog neuromorphic comput- ing. Proc. Natl. Acad. Sci. U. S. A., 119(4), January 2022.\n[32] Cramer, B., Stradmann, Y., Schemmel, J., and Zenke, F. The heidelberg spiking data sets for the system- atic evaluation of spiking neural networks. IEEE Transactions on Neural Networks and Learning Sys- tems, 33(7):2744\u20132757, jul 2022. doi: 10.1109/\n"}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n tnnls.2020.3044364. URL https://doi.org/ 10.1109%2Ftnnls.2020.3044364.\n[33] Dalgaty, T., Moro, F., Demirag \u0306, Y., Pra, A. D., In- diveri, G., Vianello, E., and Payvand, M. The neu- romorphic mosaic: in-memory computing and rout- ing for small-world graphical networks. March 2023. doi: 10.21203/rs.3.rs-2651639/v1. URL https: //doi.org/10.21203/rs.3.rs-2651639/v1.\n[34] Davies, M. Benchmarks for progress in neuromorphic computing. Nature Machine Intelligence, 1(9):386\u2013 388, 2019.\n[35] Davies, M., Srinivasa, N., Lin, T.-H., Chinya, G., Cao, Y., Choday, S. H., Dimou, G., Joshi, P., Imam, N., Jain, S., Liao, Y., Lin, C.-K., Lines, A., Liu, R., Mathaikutty, D., McCoy, S., Paul, A., Tse, J., Venkataramanan, G., Weng, Y.-H., Wild, A., Yang, Y., and Wang, H. Loihi: A Neuromorphic Manycore Processor with On-Chip Learning. IEEE Micro, 38(1):82\u201399, February 2018. doi: 10.1109/MM.2018.112130359.\n[36] Davies, M., Wild, A., Orchard, G., Sandamirskaya, Y., Guerra, G. A. F., Joshi, P., Plank, P., and Risbud, S. R. Advancing neuromorphic computing with loihi: A survey of results and outlook. Proceedings of the IEEE, 109(5):911\u2013934, 2021.\n[37] Demirag \u0306, Y., Moro, F., Dalgaty, T., Navarro, G., Frenkel, C., Indiveri, G., Vianello, E., and Payvand, M. Pcm-trace: scalable synaptic eligibility traces with re- sistivity drift of phase-change materials. In 2021 IEEE International Symposium on Circuits and Systems (IS- CAS), pp. 1\u20135. IEEE, 2021.\n[38] Deng, L. The mnist database of handwritten digit images for machine learning research. IEEE Signal Processing Magazine, 29(6):141\u2013142, 2012.\n[39] Eshraghian, J. K., Ward, M., Neftci, E., Wang, X., Lenz, G., Dwivedi, G., Bennamoun, M., Jeong, D. S., and Lu, W. D. Training spiking neural networks\n[42] Frenkel, C., Legat, J.-D., and Bol, D. Morphic: A 65-nm 738k-synapse/mm \u02c6 2 quad-core binary-weight digital neuromorphic processor with stochastic spike- driven online learning. IEEE transactions on biomedi- cal circuits and systems, 13(5):999\u20131010, 2019.\n[43] Frenkel, C., Legat, J.-D., and Bol, D. A 28-nm convolu- tional neuromorphic processor enabling online learning with spike-based retinas. In 2020 IEEE International Symposium on Circuits and Systems (ISCAS), pp. 1\u20135. IEEE, 2020.\n[44] Frenkel, C., Bol, D., and Indiveri, G. Bottom-up and top-down neural processing systems design: Neuro- morphic intelligence as the convergence of natural and artificial intelligence. arXiv preprint arXiv:2106.01288, 2021.\n[45] Furber, S. and Bogdan, P. A. SpiNNaker: A Spik- ing Neural Network Architecture. now publishers, 2020. ISBN 978-1-68083-653-0. doi: 10.1561/ 9781680836530.\n[46] Furber, S. B., Galluppi, F., Temple, S., and Plana, L. A. The spinnaker project. Proceedings of the IEEE, 102(5):652\u2013665, 2014. doi: 10.1109/ JPROC.2014.2304638.\n[47] Gewaltig, M.-O. and Diesmann, M. Nest (neural simu- lation tool). Scholarpedia, 2(4):1430, 2007.\n[48] Gollisch, T. and Meister, M. Rapid neural coding in the retina with relative spike latencies. science, 319 (5866):1108\u20131111, 2008.\n[49] Go \u0308ltz, J., Kriener, L., Baumbach, A., Billaudelle, S., Breitwieser, O., Cramer, B., Dold, D., Kungl, A. F., Senn, W., Schemmel, J., et al. Fast and energy-efficient neuromorphic deep learning with first-spike times. Na- ture machine intelligence, 3(9):823\u2013835, 2021.\n[50] Guo, K., Li, W., Zhong, K., Zhu, Z., Zeng, S., Han, S., Xie, Y., Debacker, P., Verhelst, M., and Wang, Y. Neural network accelerator comparison. NICS Lab of Tsinghua University. http://nicsefc. ee. tsinghua. edu. cn/projects/neural-network-accelerator, 2020.\n[51] Heeger, D. et al. Poisson model of spike generation. Handout, University of Standford, 5(1-13):76, 2000.\n[52] Hilgetag, C. C. and Goulas, A. Is the brain really a small-world network? Brain Structure and Function, 221:2361\u20132366, 2016.\n[53] Hoy, M. Alexa, siri, cortana, and more: An intro- duction to voice assistants. Medical Reference Ser- vices Quarterly, 37:81\u201388, 01 2018. doi: 10.1080/ 02763869.2018.1404391.\nusing lessons from deep learning. arXiv:2109.12894, 2021.\narXiv preprint\n[40] Fang, W., Chen, Y., Ding, J., Chen, D., Yu, Z., Zhou, H., Masquelier, T., Tian, Y., and other con- tributors. Spikingjelly. https://github.com/ fangwei123456/spikingjelly, 2020. Ac- cessed: YYYY-MM-DD.\n[41] Frenkel, C. and Indiveri, G. Reckon: A 28nm sub- mm2 task-agnostic spiking recurrent neural network processor enabling on-chip learning over second-long timescales. In 2022 IEEE International Solid- State Cir- cuits Conference (ISSCC), volume 65, pp. 1\u20133, 2022. doi: 10.1109/ISSCC42614.2022.9731734.\n"}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n [54] Hunsberger, E. and Eliasmith, C. Training spiking deep networks for neuromorphic hardware. arXiv preprint arXiv:1611.05141, 2016.\n[55] Imam, N. and Cleland, T. A. Rapid online learning and robust recall in a neuromorphic olfactory circuit. Nature Machine Intelligence, 2(3):181\u2013191, 2020.\n[56] Indiveri, G. and Liu, S.-C. Memory and information processing in neuromorphic systems. Proceedings of the IEEE, 103(8):1379\u20131397, 2015.\n[57] Indiveri, G., Linares-Barranco, B., Hamilton, T., van Schaik, A., Etienne-Cummings, R., Delbruck, T., Liu, S.-C., Dudek, P., Ha \u0308fliger, P., Renaud, S., Schemmel, J., Cauwenberghs, G., Arthur, J., Hynna, K., Folowosele, F., SA \u0308IGHI, S., Serrano-Gotarredona, T., Wijekoon, J., Wang, Y., and Boahen, K. Neuromorphic silicon neu- ron circuits. Frontiers in Neuroscience, 5, 2011. ISSN 1662-453X. doi: 10.3389/fnins.2011.00073. URL https://www.frontiersin.org/articles/ 10.3389/fnins.2011.00073.\n[58] Intel. Lava software framework, 2021. URL https: //github.com/lava-nc/lava.\n[59] Intel. Taking neuromorphic\nto the next level with loihi 2. //www.intel.com/content/www/us/en/ research/neuromorphic-computing- loihi-2-technology-brief.html, 2021.\n[60] Izhikevich, E. M. Which model to use for cortical spik- ing neurons? IEEE transactions on neural networks, 15(5):1063\u20131070, 2004.\n[61] Jaeger, H. and Haas, H. Harnessing nonlinearity: Pre- dicting chaotic systems and saving energy in wireless communication. science, 304(5667):78\u201380, 2004.\n[62] James, C. D., Aimone, J. B., Miner, N. E., Vineyard, C. M., Rothganger, F. H., Carlson, K. D., Mulder, S. A., Draelos, T. J., Faust, A., Marinella, M. J., Naegle, J. H., and Plimpton, S. J. A historical survey of algo- rithms and hardware architectures for neural-inspired and neuromorphic computing applications. Biologi- cally Inspired Cognitive Architectures, 19, 1 2017. doi: 10.1016/j.bica.2016.11.002.\n[63] Keselman, L., Iselin Woodfill, J., Grunnet-Jepsen, A., and Bhowmik, A. Intel realsense stereoscopic depth cameras. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, July 2017.\n[64] Khacef, L., Klein, P., Cartiglia, M., Rubino, A., Indi- veri, G., and Chicca, E. Spike-based local synaptic plasticity: A survey of computational models and neu- romorphic circuits, 2022.\n[65] Khaddam-Aljameh, R., Stanisavljevic, M., Mas, J. F., Karunaratne, G., Bra \u0308ndli, M., Liu, F., Singh, A., Mu \u0308ller, S. M., Egger, U., Petropoulos, A., et al. Hermes- core\u2014a 1.59-tops/mm 2 pcm on 14-nm cmos in- memory compute core using 300-ps/lsb linearized cco- based adcs. IEEE Journal of Solid-State Circuits, 57 (4):1027\u20131038, 2022.\n[66] Kim, Y., Park, H., Moitra, A., Bhattacharjee, A., Venkatesha, Y., and Panda, P. Rate coding or direct coding: Which one is better for accurate, robust, and energy-efficient spiking neural networks? In ICASSP 2022-2022 IEEE International Conference on Acous- tics, Speech and Signal Processing (ICASSP), pp. 71\u2013 75. IEEE, 2022.\n[67] Kleyko, D., Davies, M., Frady, E. P., Kanerva, P., Kent, S. J., Olshausen, B. A., Osipov, E., Rabaey, J. M., Rachkovskij, D. A., Rahimi, A., et al. Vector symbolic architectures as a computing framework for emerging hardware. Proceedings of the IEEE, 110(10):1538\u2013 1571, 2022.\n[68] Knag, P., Kim, J. K., Chen, T., and Zhang, Z. A sparse coding neural network asic with on-chip learning for feature extraction and encoding. IEEE Journal of Solid- State Circuits, 50(4):1070\u20131079, 2015.\n[69] Knight, J. C., Komissarov, A., and Nowotny, T. PyGeNN: A Python Library for GPU- Enhanced Neural Networks. Frontiers in Neu- roinformatics, 15(April), apr 2021. ISSN 1662- 5196. doi: 10.3389/fninf.2021.659005. URL https://www.frontiersin.org/articles/ 10.3389/fninf.2021.659005/full.\n[70] Krizhevsky, A. Learning multiple layers of features from tiny images. 2009.\n[71] Kulkarni, S. R., Parsa, M., Mitchell, J. P., and Schuman, C. D. Benchmarking the performance of neuromorphic and spiking neural network simulators. Neurocomput- ing, 447:145\u2013160, 2021. ISSN 0925-2312. doi: https:// doi.org/10.1016/j.neucom.2021.03.028. URL https: //www.sciencedirect.com/science/ article/pii/S0925231221003969.\n[72] Laborieux, A., Ernoult, M., Hirtzlin, T., and Quer- lioz, D. Synaptic metaplasticity in binarized neural networks. Nature communications, 12(1):2549, 2021.\n[73] Levy, M. Innatera\u2019s spiking neural processor - brain- like architecture targets ultra-low power ai, 2021.\n[74] Lillicrap, T. P., Santoro, A., Marris, L., Akerman, C. J., and Hinton, G. Backpropagation and the brain. Nature Reviews Neuroscience, 21(6):335\u2013346, 2020.\ncomputing\nhttps:\n"}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n [75] Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dolla \u0301r, P., and Zitnick, C. L. Microsoft COCO: Common objects in context. In Computer Vision \u2013 ECCV 2014, pp. 740\u2013755, 2014.\n[76] Maass, W. On the computational power of winner-take- all. Neural computation, 12(11):2519\u20132535, 2000.\n[77] Mackey, M. C. and Glass, L. Oscillation and chaos in physiological control systems. Science, 197(4300): 287\u2013289, 1977.\n[78] Magnasco, M. O. A wave traveling over a hopf instabil- ity shapes the cochlear tuning curve. Physical review letters, 90(5):058101, 2003.\n[79] Mainen, Z. F. and Sejnowski, T. J. Reliability of spike timing in neocortical neurons. Science, 268(5216): 1503\u20131506, 1995.\n[80] Makin, J. G., O\u2019Doherty, J. E., Cardoso, M. M. B., and Sabes, P. Superior arm-movement decoding from cortex with a new, unsupervised-learning algorithm. J. Neural Eng., 15(2), 2018. doi: 10.1088/1741-2552/ aa9e95.\n[81] Mannion, D. J. and Kenyon, A. J. Artificial dendritic computation: The case for dendrites in neuromorphic circuits. arXiv preprint arXiv:2304.00951, 2023.\n[82] Mattson, P., Cheng, C., Diamos, G., Coleman, C., Mi- cikevicius, P., Patterson, D., Tang, H., Wei, G.-Y., Bailis, P., Bittorf, V., et al. Mlperf training bench- mark. Proceedings of Machine Learning and Systems, 2:336\u2013349, 2020.\n[83] Mead, C. A. Neuromorphic electronic systems. Pro- ceedings of the IEEE, 78(10):1629\u20131636, 1990. doi: 10.1109/5.58356.\n[84] Merolla, P. A., Arthur, J. V., Alvarez-Icaza, R., Cas- sidy, A. S., Sawada, J., Akopyan, F., Jackson, B. L., Imam, N., Guo, C., Nakamura, Y., Brezzo, B., Vo, I., Esser, S. K., Appuswamy, R., Taba, B., Amir, A., Flickner, M. D., Risk, W. P., Manohar, R., and Modha, D. S. A million spiking-neuron integrated circuit with a scalable communication network and in- terface. Science, 345(6197):668\u2013673, August 2014. doi: 10.1126/science.1254642.\n[85] Michaely, A. H., Zhang, X., Simko, G., Parada, C., and Aleksic, P. Keyword spotting for google assis- tant using contextual speech recognition. In 2017 IEEE Automatic Speech Recognition and Understand- ing Workshop (ASRU), pp. 272\u2013278, 2017. doi: 10.1109/ASRU.2017.8268946.\n[86] Milde, M. B., Afshar, S., Xu, Y., Marcireau, A., Joubert, D., Ramesh, B., Bethi, Y., Ralph, N. O., El Arja, S., Dennler, N., van Schaik, A., and Co- hen, G. Neuromorphic engineering needs closed-loop benchmarks. Frontiers in Neuroscience, 16, 2022. doi: 10.3389/fnins.2022.813555.\n[87] Moitra, A., Bhattacharjee, A., Kuang, R., Krishnan, G., Cao, Y., and Panda, P. Spikesim: An end-to- end compute-in-memory hardware evaluation tool for benchmarking spiking neural networks. arXiv preprint arXiv:2210.12899, 2022.\n[88] Moradi, S., Qiao, N., Stefanini, F., and Indiveri, G. A scalable multicore architecture with heterogeneous memory structures for dynamic neuromorphic asyn- chronous processors (dynaps). IEEE Transactions on Biomedical Circuits and Systems, 12(1):106\u2013122, 2018. doi: 10.1109/TBCAS.2017.2759700.\n[89] Moreira, O., Yousefzadeh, A., Chersi, F., Cinserin, G., Zwartenkot, R.-J., Kapoor, A., Qiao, P., Kievits, P., Khoei, M., Rouillard, L., et al. Neuronflow: a neuro- morphic processor architecture for live ai applications. In 2020 Design, Automation & Test in Europe Confer- ence & Exhibition (DATE), pp. 840\u2013845. IEEE, 2020.\n[90] Muir, D., Bauer, F., and Weidel, P. Rockpool documen- taton, 2019.\n[91] Mukhopadhyay, S. and Banerjee, S. Learning dynam- ical systems in noise using convolutional neural net- works. Chaos: An Interdisciplinary Journal of Nonlin- ear Science, 30(10):103125, 2020.\n[92] Mysore, N., Hota, G., Deiss, S. R., Pedroni, B. U., and Cauwenberghs, G. Hierarchical network connectivity and partitioning for reconfigurable large-scale neuro- morphic systems. Frontiers in Neuroscience, 15:1891, 2022.\n[93] Neckar, A., Fok, S., Benjamin, B. V., Stewart, T. C., Oza, N. N., Voelker, A. R., Eliasmith, C., Manohar, R., and Boahen, K. Braindrop: A mixed-signal neuro- morphic architecture with a dynamical systems-based programming model. Proceedings of the IEEE, 107(1): 144\u2013164, 2018.\n[94] Neftci, E. O., Mostafa, H., and Zenke, F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to spiking neural networks. IEEE Signal Processing Magazine, 36(6):51\u201363, 2019.\n[95] O\u2019Doherty, J. E., Cardoso, M. M. B., Makin, J. G., and Sabes, P. N. Nonhuman primate reaching with multichannel sensorimotor cortex electrophysiology,\n"}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n May 2017. URL https://doi.org/10.5281/ zenodo.788569.\n[96] Orchard, G., Jayawant, A., Cohen, G., and Thakor, N. Converting static image datasets to spiking neuromor- phic datasets using saccades, 2015.\n[97] Orchard, G., Frady, E. P., Rubin, D. B. D., San- born, S., Shrestha, S. B., Sommer, F. T., and Davies, M. Efficient neuromorphic signal processing with loihi 2. In 2021 IEEE Workshop on Signal Pro- cessing Systems (SiPS), pp. 254\u2013259, 2021. doi: 10.1109/SiPS52927.2021.00053.\n[98] Ostrau, C., Klarhorst, C., Thies, M., and Ru \u0308ckert, U. Benchmarking neuromorphic hardware and its energy expenditure. Frontiers in Neuroscience, 16, 2022. ISSN 1662-453X. doi: 10.3389/fnins.2022.873935.\nURL https://www.frontiersin.org/ articles/10.3389/fnins.2022.873935.\n[99] Park, J., Lee, J., and Jeon, D. A 65-nm neuromorphic image classification processor with energy-efficient training through direct spike-only feedback. IEEE Journal of Solid-State Circuits, 55(1):108\u2013119, 2019.\n[100] Payvand, M., Nair, M. V., Mu \u0308ller, L. K., and Indiveri, G. A neuromorphic systems approach to in-memory computing with non-ideal memristive devices: From mitigation to exploitation. Faraday Discussions, 213: 487\u2013510, 2019.\n[101] Pehle, C. and Pedersen, J. E. Norse - A deep learning library for spiking neural net- works, January 2021. URL https://doi.org/\non-chip training. IEEE Transactions on Computer- Aided Design of Integrated Circuits and Systems, 40 (11):2306\u20132319, 2020.\n[105] Peres, L. and Rhodes, O. Parallelization of neural processing on neuromorphic hardware. Frontiers in Neuroscience, 16, 5 2022. ISSN 1662453X. doi: 10.3389/fnins.2022.867027.\n[106] Perot, E., de Tournemire, P., Nitti, D., Masci, J., and Sironi, A. Learning to detect objects with a 1 megapixel event camera. In Proceedings of the 34th International Conference on Neural Information Processing Systems, NIPS\u201920, 2020.\n[107] Pillow, J. W., Paninski, L., Uzzell, V. J., Simoncelli, E. P., and Chichilnisky, E. Prediction and decoding of retinal ganglion cell responses with a probabilistic spiking model. Journal of Neuroscience, 25(47):11003\u2013 11013, 2005.\n[108] Pillow, J. W., Shlens, J., Paninski, L., Sher, A., Litke, A. M., Chichilnisky, E., and Simoncelli, E. P. Spatio- temporal correlations and visual signalling in a com- plete neuronal population. Nature, 454(7207):995\u2013999, 2008.\n[109] Qiao, N., Mostafa, H., Corradi, F., Osswald, M., Ste- fanini, F., Sumislawska, D., and Indiveri, G. A re- configurable on-line learning spiking neuromorphic processor comprising 256 neurons and 128k synapses. Frontiers in neuroscience, 9:141, 2015.\n[110] Reddi, V. J., Cheng, C., Kanter, D., Mattson, P., Schmuelling, G., Wu, C.-J., Anderson, B., Breughe, M., Charlebois, M., Chou, W., Chukka, R., Coleman, C., Davis, S., Deng, P., Diamos, G., Duke, J., Fick, D., Gardner, J. S., Hubara, I., Idgunji, S., Jablin, T. B., Jiao, J., John, T. S., Kanwar, P., Lee, D., Liao, J., Lokhmo- tov, A., Massa, F., Meng, P., Micikevicius, P., Osborne, C., Pekhimenko, G., Rajan, A. T. R., Sequeira, D., Sir- asao, A., Sun, F., Tang, H., Thomson, M., Wei, F., Wu, E., Xu, L., Yamada, K., Yu, B., Yuan, G., Zhong, A., Zhang, P., and Zhou, Y. Mlperf inference benchmark, 2020.\n[111] Roy, K., Jaiswal, A., and Panda, P. Towards spike- based machine intelligence with neuromorphic com- puting. Nature, 575(7784):607\u2013617, 2019.\n[112] Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bern- stein, M., Berg, A. C., and Fei-Fei, L. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 115(3):211\u2013252, 2015. doi: 10.1007/s11263-015-0816-y.\n10.5281/zenodo.4422025. https://norse.ai/docs/.\nDocumentation:\n[102] Pehle, C., Billaudelle, S., Cramer, B., Kaiser, J., Schreiber, K., Stradmann, Y., Weis, J., Leibfried, A., Mu \u0308ller, E., and Schemmel, J. The brainscales-2 ac- celerated neuromorphic system with hybrid plasticity, 2022.\n[103] Pei, J., Deng, L., Song, S., Zhao, M., Zhang, Y., Wu, S., Wang, G., Zou, Z., Wu, Z., He, W., Chen, F., Deng, N., Wu, S., Wang, Y., Wu, Y., Yang, Z., Ma, C., Li, G., Han, W., Li, H., Wu, H., Zhao, R., Xie, Y., and Shi, L. Towards artificial general intelligence with hybrid tianjic chip architecture. Nature, 572(7767):106\u2013111, Aug 2019. ISSN 1476-4687. doi: 10.1038/s41586- 019-1424-8. URL https://doi.org/10.1038/ s41586-019-1424-8.\n[104] Peng, X., Huang, S., Jiang, H., Lu, A., and Yu, S. Dnn+ neurosim v2.0: An end-to-end benchmarking framework for compute-in-memory accelerators for\n"}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n [113]\n[114]\n[115]\n[116]\n[117]\n[118]\n[119]\n[120]\n[121]\n[122]\nSangwan, V. K. and Hersam, M. C. Neuromorphic nanoelectronic materials. Nature nanotechnology, 15 (7):517\u2013528, 2020.\nSanni, K. A. and Andreou, A. G. A Historical Per- spective on Hardware AI Inference, Charge-Based Computational Circuits and an 8bit Charge-Based Multiply-Add Core in 16nm FinFET CMOS. IEEE Journal on Emerging and Selected Topics in Circuits and Systems, 9(3):532\u2013543, September 2019. doi: 10.1109/JETCAS.2019.2933795.\nSchemmel, J., Bru \u0308derle, D., Gru \u0308bl, A., Hock, M., Meier, K., and Millner, S. A wafer-scale neuromor- phic hardware system for large-scale neural modeling. In 2010 ieee international symposium on circuits and systems (iscas), pp. 1947\u20131950. IEEE, 2010.\nSchuman, C. D., Potok, T. E., Patton, R. M., Birdwell, J. D., Dean, M. E., Rose, G. S., and Plank, J. S. A sur- vey of neuromorphic computing and neural networks in hardware, 2017.\nSchuman,C.D.,Plank,J.S.,Bruer,G.,andAnantharaj, J. Non-traditional input encoding schemes for spiking neuromorphic systems. In 2019 International Joint Conference on Neural Networks (IJCNN), pp. 1\u201310. IEEE, 2019.\nSchuman, C. D., Kulkarni, S. R., Parsa, M., Mitchell, J. P., Date, P., and Kay, B. Opportunities for neuromor- phic computing algorithms and applications. Nature Computational Science, 2(1):10\u201319, January 2022.\nSebastian, A., Le Gallo, M., Khaddam-Aljameh, R., and Eleftheriou, E. Memory devices and applications for in-memory computing. Nature nanotechnology, 15 (7):529\u2013544, 2020.\nSeo, D., Oh, H.-S., and Jung, Y. Wav2kws: Trans- fer learning from speech representations for keyword spotting. IEEE Access, 9:80682\u201380691, 2021.\nSeo, J.-s., Brezzo, B., Liu, Y., Parker, B. D., Esser, S. K., Montoye, R. K., Rajendran, B., Tierno, J. A., Chang, L., Modha, D. S., et al. A 45nm cmos neuro- morphic chip with a scalable architecture for learning in networks of spiking neurons. In 2011 IEEE Custom Integrated Circuits Conference (CICC), pp. 1\u20134. IEEE, 2011.\nSerrano-Gotarredona, R., Oster, M., Lichtsteiner, P., Linares-Barranco, A., Paz-Vicente, R., Gomez- Rodriguez, F., Kolle Riis, H., Delbruck, T., Liu, S.-C., Zahnd, S., et al. AER building blocks for multi-layer multi-chip neuromorphic vision systems. Advances in neural information processing systems, 18, 2005.\n[123]\n[124]\n[125]\n[126]\n[127]\n[128]\n[129]\n[130]\n[131]\n[132]\nShaikh, S., So, R., Sibindi, T., Libedinsky, C., and Basu, A. Towards intelligent intracortical bmi (i2bmi): Low-power neuromorphic decoders that outperform kalman filters. IEEE Transactions on Biomedical Circuits and Systems, 13(6):1615\u20131624, 2019. doi: 10.1109/TBCAS.2019.2944486.\nShrestha, A., Ahmed, K., Wang, Y., and Qiu, Q. Stable spike-timing dependent plasticity rule for multilayer unsupervised and supervised learning. In 2017 inter- national joint conference on neural networks (IJCNN), pp. 1999\u20132006. IEEE, 2017.\nShrestha, S. B. and Orchard, G. SLAYER: Spike layer error reassignment in time. Advances in neural infor- mation processing systems, 31, 2018.\nShrestha, S. B., Zhu, L., and Sun, P. Spikemax: Spike- based loss methods for classification. In 2022 Interna- tional Joint Conference on Neural Networks (IJCNN), pp. 1\u20137. IEEE, 2022.\nSoures, N., Helfer, P., Daram, A., Pandit, T., and Ku- dithipudi, D. Tacos: Task agnostic continual learning in spiking neural networks. In Theory and Foundation of Continual Learning Workshop at ICML\u20192021, July 2021.\nSpilger, P., Arnold, E., Blessing, L., Mauch, C., Pehle, C., Mu \u0308ller, E., and Schemmel, J. hxtorch. snn: Machine-learning-inspired spiking neural net- work modeling on brainscales-2. arXiv preprint arXiv:2212.12210, 2022.\nStewart, K., Orchard, G., Shrestha, S. B., and Neftci, E. Online few-shot gesture learning on a neuromorphic processor. IEEE Journal on Emerging and Selected Topics in Circuits and Systems, 10(4):512\u2013521, 2020.\nStewart, T. C., DeWolf, T., Kleinhans, A., and Eliasmith, C. Closed-loop neuromorphic benchmarks. Frontiers in Neuroscience, 9, 2015. doi: 10.3389/fnins.2015.00464. URL https://www.frontiersin.org/articles/ 10.3389/fnins.2015.00464.\nStimberg, M., Brette, R., and Goodman, D. F. Brian 2, an intuitive and efficient neural simulator. eLife, 8: e47314, August 2019. ISSN 2050-084X. doi: 10.7554/ eLife.47314.\nStuijt, J., Sifalakis, M., Yousefzadeh, A., and Corradi, F. \u03bcbrain: An event-driven and fully synthesizable architecture for spiking neural networks. Frontiers in neuroscience, pp. 538, 2021.\n"}, {"chunk": "NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair, and Representative Benchmarking\n [133]\n[134]\n[135]\n[136]\n[137]\n[138]\n[139]\n[140]\n[141]\n[142]\nSun, M., Raju, A., Tucker, G., Panchapagesan, S., Fu, G.,Mandal,A.,Matsoukas,S.,Strom,N.,andVitalade- vuni, S. Max-pooling loss training of long short-term memory networks for small-footprint keyword spotting. In 2016 IEEE Spoken Language Technology Workshop (SLT), pp. 474\u2013480. IEEE, 2016.\nThakur, C. S., Molin, J., Cauwenberghs, G., Indiveri, G., Kumar, K., Qiao, N., Schemmel, J., Wang, R., Chicca, E., Hasler, J. O., sun Seo, J., Yu, S., Cao, Y., van Schaik, A., and Etienne-Cummings, R. Large- scale neuromorphic spiking array processors: A quest to mimic the brain, 2018.\nTimcheck, J., Shrestha, S. B., Rubin, D. B. D., Kupry- janow, A., Orchard, G., Pindor, L., Shea, T., and Davies, M. The intel neuromorphic dns challenge. 3 2023. URL http://arxiv.org/abs/2303.09503.\nValentian, A., Rummens, F., Vianello, E., Mesquida, T., de Boissac, C. L.-M., Bichler, O., and Reita, C. Fully integrated spiking neural network with analog neurons and rram synapses. In 2019 IEEE International Electron Devices Meeting (IEDM), pp. 14\u20133. IEEE, 2019.\nVandeVen,G.M.andTolias,A.S.Threescenariosfor continual learning. arXiv preprint arXiv:1904.07734, 2019.\nvanderMade,P.A.andMankar,A.S.Neuralprocessor based accelerator system and method, October 26 2021. US Patent 11,157,800.\nVan Rullen, R. and Thorpe, S. J. Rate coding versus temporal order coding: what the retinal ganglion cells tell the visual cortex. Neural computation, 13(6):1255\u2013 1283, 2001.\nWan, W., Kubendran, R., Schaefer, C., Eryilmaz, S. B., Zhang, W., Wu, D., Deiss, S., Raina, P., Qian, H., Gao, B., et al. A compute-in-memory chip based on resistive random-access memory. Nature, 608(7923):504\u2013512, 2022.\nWang, S., Song, J., Lien, J., Poupyrev, I., and Hilliges, O. Interacting with soli: Exploring fine-grained dy- namic gesture recognition in the radio-frequency spec- trum. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology, UIST \u201916, pp. 851\u2013860, New York, NY, USA, 2016. Associa- tion for Computing Machinery. ISBN 9781450341899. doi: 10.1145/2984511.2984565. URL https:// doi.org/10.1145/2984511.2984565.\nWarden, P. Speech commands: A dataset for limited-vocabulary speech recognition. arXiv preprint arXiv:1804.03209, 2018.\n[143]\n[144]\n[145]\n[146]\n[147]\n[148] [149]\n[150]\n[151]\nYan, Y., Stewart, T. C., Choo, X., Vogginger, B., Partzsch,J.,Ho \u0308ppner,S.,Kelber,F.,Eliasmith,C., Furber, S., and Mayr, C. Comparing loihi with a spinnaker 2 prototype on low-latency keyword spot- ting and adaptive robotic control. Neuromorphic Computing and Engineering, 1(1):014002, jul 2021. doi: 10.1088/2634-4386/abf150. URL https:// dx.doi.org/10.1088/2634-4386/abf150.\nY\u0131lmaz, E., Gevrek, O. B., Wu, J., Chen, Y., Meng, X., and Li, H. Deep convolutional spiking neural net- works for keyword spotting. In Proceedings of INTER- SPEECH, pp. 2557\u20132561, 2020.\nYin, B., Guo, Q., Corradi, F., and Bohte, S. Attentive decision-making and dynamic resetting of continual running srnns for end-to-end streaming keyword spot- ting. In Proceedings of the International Conference on Neuromorphic Systems 2022, pp. 1\u20138, 2022.\nZador, A. and et. al. Catalyzing next-generation artifi- cial intelligence through neuroai. Nature Communica- tions, 14(1597), 2023.\nZenke, F. and Neftci, E. O. Brain-inspired learning on neuromorphic substrates. Proceedings of the IEEE, 109(5):935\u2013950, 2021.\nZhang, Z. Microsoft kinect sensor and its effect. IEEE MultiMedia, 19(2):4\u201310, 2012.\nZhu, R.-J., Zhao, Q., and Eshraghian, J. K. Spikegpt: Generative pre-trained language model with spiking neural networks. arXiv preprint arXiv:2302.13939, 2023.\nZhuang, Y., Chang, X., Qian, Y., and Yu, K. Unre- stricted Vocabulary Keyword Spotting Using LSTM- CTC. In Proc. Interspeech 2016, pp. 938\u2013942, 2016. doi: 10.21437/Interspeech.2016-753.\nZilany, M. S., Bruce, I. C., and Carney, L. H. Up- dated parameters and expanded simulation options for a model of the auditory periphery. The Journal of the Acoustical Society of America, 135(1):283\u2013286, 2014.\n"}, {"chunk": "TENT: Efficient Quantization of Neural Networks on the tiny Edge with Tapered FixEd PoiNT\nHamed F. Langroudi\u2217, Vedant Karia\u2217, Tej Pandit, Dhireesha Kudithipudi Neuromorphic AI Lab, University of Texas at San Antonio, TX, USA\nABSTRACT\nIn this research, we propose a new low-precision framework, TENT, to leverage the benefits of a tapered fixed-point numerical format in TinyML models. We introduce a tapered fixed-point quantization algorithm that matches the numerical format\u2019s dynamic range and distribution to that of the deep neural network model\u2019s parameter distribution at each layer. An accelerator architecture for the ta- pered fixed-point with TENT framework is proposed. Results show that the accuracy on classification tasks improves up to \u224831% with an energy overhead of \u224817-30% as compared to fixed-point, for ConvNet and ResNet-18 models.\nKEYWORDS\nDeep neural networks, low-precision arithmetic, tapered fixed- point\n1 INTRODUCTION\nIn the last decade, there has been a surge in deep neural network (DNN) development and deployment for a wide range of use-cases, from bio-medicine [34] to precision agriculture [27]. One of the reasons for this success can be attributed to the dramatic enhance- ment in the knowledge capacity of DNN models. For instance, the knowledge capacity of DNNs for language translation has boosted by 629x from the GNMT model (278 million parameters) [38] to the recent GPT-3 model (175 billion parameters) [4] within a four year timespan. Increasing the knowledge capacity of DNN models also in- creases the number of operations, mostly multiply-and-accumulate (MAC), at trillions of operations per ML inference [15]. However, these large networks, classified as CloudML models are deployed on cloud based datacenters where each node utilizes massive compute resources which require hundreds of watts of power (eg., RTX-3070 Nvidia GPU has 8 GB memory, with 20 TFLOPs throughput, and 220 watt power consumption).\nTangential to the trend of upscaling cloudML models to improve performance, a new class of models have emerged. MobileML [33, 35] and TinyML [2, 3, 12, 22, 23, 30] models address the rapidly growing demand to deploy DNNs on the edge and on the tiny edge (<1W) devices.\nTo deploy these models on such resource constrained tiny edge platforms (eg., ARM M-7 MCU with 2 MB, 216 million cycles per second (MCPS) throughput, and 0.3 watt power consumption [2]), the TinyML models are either designed from scratch through neural architecture search (NAS) [2, 22, 23] or by compressing a version of the CloudML models. Often these compression mechanisms include approaches such as low-precision arithmetic [9, 21, 30], model prun- ing [12], knowledge distillation [5], and low-rank approximation\n* Equal Contribution.\n[36]. Of the aforementioned techniques for TinyML models, low- precision arithmetic has been gaining significant traction. With this technique, the performance of the models can be compromised based on the numerical format selected.\nTinyML models with low-bit precision have been deployed on tiny edge devices [30]. Unfortunately, reducing the bit-precision in fixed-point numerical formats (binary/ternary in extreme cases) can jeopardize the model performance due to the limited and fixed dy- namic range [26, 29]. Equispaced distribution of values expressed by these numerical formats exacerbates the issue to some degree [26]. Pre- and post-processing approaches such as quantization aware training (QAT) [7, 16, 18], retraining [24] and calibration [25] to boost the performance of TinyML models using fixed-point increase their computational complexity. To overcome the performance loss with minimal hardware overhead, a new numerical format with unequal-magnitude spacing (tapered accuracy) and flexible dynamic range is needed. The tapered fixed-point format [20] offers both of these characteristics lacking in the conventional fixed-point format.\nIn this introductory paper, we are motivated to evaluate the effi- cacy of the tapered fixed-point numerical format compared to the standard fixed-point numerical format on multiple benchmarks. To study the performance of this new numerical format, a new frame- work, TENT, has been developed that quantizes TinyML model parameters to tapered fixed-point. The dynamic range and distri- bution (tapered or uniform) of the numerical format is adapted proportional to the dynamic range and distribution of parameters of each layer in the model. Furthermore, a hardware architecture is designed to study the complexity of the approach compared to fixed-point for \u2264 8-bit TinyML model inference in terms of latency and energy (on the CIFAR-10 dataset).\n2\nThe key contributions of this work are as follows:\n(1) a tapered fixed-point quantization algorithm that adapts the numerical format to best represent the layerwise dynamic range and distribution of parameters within a TinyML model.\n(2) alow-precisiondeeplearningframework,TENT,thatdemon- strates better performance of tapered fixed-point over fixed- point formats for multiple classification tasks.\n(3) an implementation of the TENT framework as a custom hardware architecture to study the latency and energy con- sumption of tapered fixed-point vs standard fixed-point.\nTAPERED FIXED-POINT FORMAT\nThe tapered fixed-point numerical format (TFX) which is also called as taper [20] can be illustrated as a combination of the posit [13] and fixed-point numerical formats. It combines the hardware-oriented characteristics of fixed-point and the high accuracy of posit with tapered precision; where the values are distributed in a non-uniform tent shape which closely resemble the shape of DNN statistics. Specifically, the binary encoding to represent the integer bits in\n arXiv:2104.02233v1 [cs.LG] 6 Apr 2021\n "}, {"chunk": "fixed-point is replaced with the signed unary encoding that was\npreviously used to represent the regime bits in posit [13]. This\nchange adds tapered precision characteristics to the fixed-point\nnumerical format. The fraction remains the same as the standard\nfixed-point where the fraction is added to the integer rather than\nscaling, which reduces the hardware complexity as compared to\nposit and floating-point. The tapered fixed-point is defined as TFX(\ud835\udc5b,\n\ud835\udc3c\ud835\udc46, \ud835\udc46\ud835\udc36) where \ud835\udc5b refers to the total number of bits, \ud835\udc3c\ud835\udc46 (in a range of\n[1,\ud835\udc5b]) indicates the maximum number of unary encoded integer \ud835\udefd\ud835\udefd\nFor instance, 3.875 in the TFX(8,8,0) numerical format is repre-\n\ud835\udc53\nsented by 3 as an integer (\ud835\udc3c ), 0.875 as a fraction (\nFig. 2. More details about the tapered fixed-point number format can be found in [20].\nFigure 2: Representation of a number in the tapered fixed point TFX(8,8,0) format\n3 RELATED WORK\nStudies considering low-precision arithmetic have experimentally shown that TinyML models using 8-bit fixed-point numbers can achieve inference accuracy comparable to that of 32-bit floating- point numbers [2, 9, 21\u201323]. However, it requires either pre-processing such as calibration [25], quantization aware training (QAT) [7, 16, 18], or post-processing such as retraining [24]. For instance, Ban- bary et al. demonstrate the efficacy of 8-bit fixed-point for TinyML models on the visual wake words (VWW) dataset [2]. The outcome of this study, which uses the QAT approach to quantize weights and activations, indicates that 8-bit fixed-point model parameters are sufficient to achieve inference performance comparable to that of MobileNetV2 on the VWW corpora [8] (within <1% variation) which uses 32-bit floats.\nWhile it is possible to achieve similar inference performance of TinyML models (32-bit float conversion to 8-bit fixed-point) through pre- or post processing approaches, reducing the bit-precision to fewer than 8 bits degrades the performance significantly [26, 29]. To mitigate this problem, researchers have explored mixed-precision fixed-point numerical format [10, 11, 14, 17, 30, 31, 37]. However, uti- lizing mixed-precision fixed-point required a precision-assignment policies for TinyML model parameters across layers. For instance, Rusci et al. leveraged the combination of reinforcement learning and QAT to automatically select the appropriate precision of TinyML parameters across layers [30]. And thus demonstrates that it is pos- sible to evaluate even the ImageNet corpora using mixed-precision fixed-point formats on MobileNetV2, with results within <1% vari- ation as compared to inference with 32-bit floats.\nThis research proposes a tapered fixed-point quantization algo- rithm for TinyML models where the dynamic range of this numeri- cal format is adapted to the dynamic range of the TinyML model parameters. A notable difference between this work and previous works is that this quantization approach does not required complex hardware or algorithmic approaches such as precision-assignment policies, QAT or calibration.\n4 TENT FRAMEWORK\nThe goal of the TENT empirical framework is to emulate ML in- ference with quantization using low-precision tapered fixed-point\n bits and SC \u2208 [\u2212 2 .. 2 ] is the power-of-2 scaling downward or upward where \ud835\udefd can be selected based on application. The \ud835\udc3c\ud835\udc46 value controls both the dynamic range (\ud835\udc37TFX) as in (1) and the tapered precision.\n\ud835\udc37TFX=\n= IS 2\ud835\udc5b\u22122 ,\n(1)\n\ud835\udc40\ud835\udc4e\ud835\udc65TFX \ud835\udc40\ud835\udc56\ud835\udc5bTFX\n(1 2\ud835\udc5b\u22121 ,\nif IS= 1 otherwise\n2\ud835\udc53\ud835\udc60\n), as shown by\n The dynamic range and tapered precision are scaled proportional\nto \ud835\udc3c\ud835\udc46 as shown in Fig. 1. For instance, the TFX(\ud835\udc5b, \ud835\udc3c\ud835\udc46, \ud835\udc46\ud835\udc36) numerical\nformatwith\ud835\udc5b=5,\ud835\udc46\ud835\udc36=0,\ud835\udc3c\ud835\udc46=1and\ud835\udc3c\ud835\udc46=2hasthetwosmallest 12\ndynamic ranges ( 0.0625 ) and ( 0.125 ) respectively, and behaves sim-\n ilar to fixed-point numerical format with uniform precision. Also,\n\ud835\udc5b = \ud835\udc3c\ud835\udc46 = 5 and \ud835\udc46\ud835\udc36 = 0 represents the maximum dynamic range 5\n( 0.125 ) and maximum tapered precision. The dynamic range and precision does not change with variation in \ud835\udc46\ud835\udc36 parameter, how- ever, the TFX number represented can be scaled by a multiplication factor of 2 raised to the power \ud835\udc46\ud835\udc36.\nThe value of a TFX number is represented by (2), where \ud835\udc3c is computed in (3) representing the integer value, \ud835\udc53 indicates the fraction value and fs the maximum number of bits allocated for the fraction.\n\ud835\udc4b=(\ud835\udc3c+ f)\u00d72SC (2) 2fs\nThe integer bit-field is encoded based on the runlength \ud835\udc5a of iden- tical bits (\ud835\udc56...\ud835\udc56) which is terminated by either an integer terminating bit \ud835\udc56 or the end of the \ud835\udc5b-bit value. Note that the sign bit (\ud835\udc60) is flipped and is also considered as the first bit of the integer (\ud835\udc60 = \ud835\udc56).\n(\u2212\ud835\udc5a, if \ud835\udc56 = 0\n\ud835\udc3c= (3)\n\ud835\udc5a\u22121, if\ud835\udc56=1\n 200 175 150 125 100 75 50 25 0\nTFX(5,1,-1)\nTFX(5,2,-1) TFX(5,3,-1) TFX(5,4,-1)\n6420246 Value\n    Density\n  TFX(5,5,-1)\nFigure 1: An Illustration of distribution of values in tapered fixed-point format with \ud835\udc5b = 5, \ud835\udc3c\ud835\udc46 = {1, 2, 3, 4, 5} and \ud835\udc46\ud835\udc36 = \u22121\n/\n0/1 1 1 1 0 1 1 1 ()\n"}, {"chunk": " TAPERED FIXED-POINT MAC STRUCTURE\nAT EVERY LAYER\n     TAPERED FORMAT DISTRIBUTION\nSIGN BIT TERMINATING BIT FINAL IS BIT\nIS BITS FRACTION BITS\n  \ud835\udc68\ud835\udc68\ud835\udc92\ud835\udc92\n\ud835\udc7e\ud835\udc7e\ud835\udc92\ud835\udc92\n\ud835\udc78\ud835\udc78\ud835\udc93\ud835\udc93 R ReLU\n   +SC- FIXED-POINT\nTAPERED QUANTIZED FORMAT\nSELECTION OF IS & SC ALGORITHM-1\nLAYERWISE PARAMETER DISTRIBUTION\n\ud835\udf4e\ud835\udf4e\ud835\udfcf\ud835\udfcf\ud835\udfcf\ud835\udfcf\nWEIGHTS\n& ACTIVATIONS [no SC shifting]\nIS FS\n           CIFAR-10 EXAMPLE\nCLASSIFIER OUTPUT\n           CONV+ MAX POOL\nCONV 2-3-4\nCONV 5-6-7\nCONV 8-9-10\nCONV 44-45-46\nCONV 47-48-49\nCONV\n11-12-13\nFC\n   Figure 3: TENT: a low-precision framework for TinyML inference with tapered fixed-point parameters. The framework is applied to each layer individually, selecting specific IS and SC values to match the distribution and range of parameters within the layer. IS specifies the \ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc56\ud835\udc5a\ud835\udc62\ud835\udc5a number of integer bits, and SC specifies the degree of shift required (left-shift if positive, right-shift if negative). The MAC structure displays the multiply-and-accumulate unit explained in Fig. 4.\nformat. Formally, the TinyML model parameters are quantized to tapered fixed-point such that the dynamic range and distribution of TinyML model parameters matches the distribution of values rep- resented by tapered fixed-point. Therefore, the TENT framework, as shown in Fig. 3, approximates the optimal tapered fixed-point numerical format for TinyML model parameters in each layer by se- lecting appropriate IS and SC values. These parameters are selected based on dynamic range of TinyML model parameters in each layer. After this step, the learned weights and activations (32-bit floats) are quantized to the low-precision tapered fixed-point format, upon which the dot product operations are then carried out.\nIn particular, the TENT empirical framework comprises of three key aspects: Tapered fixed-point parameters selection, quantization to tapered fixed-point, and the low-precision tapered fixed-point dot product.\n4.1 Tapered Fixed-Point Parameter Selection\nAlgorithm 1 presents the IS and SC optimization procedure. To\nselect these parameters, in the first step, the maximum absolute\nvalue of the DNN parameters at each layer (\ud835\udc4a , and \ud835\udc34 ) are \ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc65 \ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc65\ncomputed (lines 2\u20133) and rounded up to generate the appropriate IS value. Algorithm 1, defines the process by which IS is selected to tailor the numerical format to the range and distribution of param- eters in each individual layer. In the worst case scenario, when the dynamic range of DNN parameters is larger than dynamic range of tapered fixed-point, the maximum possible value \ud835\udc5b (total number of bits represented in tapered fixed-point format) is selected for IS (lines 4\u201313). Selecting IS based on the algorithm 1 reduces the over- flow error in quantization. However, when the maximum absolute value of a DNN parameter is less than the maximum absolute value\nrepresentable by the tapered fixed-point format selected; many bit- patterns in the numerical format are unused. To mitigate this issue, the the maximum absolute value of tapered fixed-point format is scaled down by 2 raised power of SC that determines as a base-2\nlogarithm of \ud835\udc64\n\ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc65\n(lines 14\u201319).\n4.2 Quantization with Tapered Fixed-Point\nIn this paper, the quantization function \ud835\udc44(\ud835\udc65\ud835\udc56,\ud835\udc5e) defined in (4) ap-\n\u2032\nproximates each parameter \ud835\udc65\ud835\udc56 to \ud835\udc65\nthe quantization procedure, the values that lie outside the dynamic range of a given tapered fixed point format configuration, \ud835\udc44 (\u00b7, \u00b7, \u00b7, \u00b7), clips to the format maximum (\ud835\udc62 ) or minimum (\ud835\udc59 ) appropriately. A value that is between consecutive tapered fixed-point numbers is rounded to the nearest even number (RNE(\ud835\udc65\ud835\udc56 )).\n\uf8f1\uf8f4 \ud835\udc59 , \ud835\udc65 \u2264 \ud835\udc59\n\ud835\udc65\ud835\udc56\u2032 = \ud835\udc44(\ud835\udc65\ud835\udc56,\ud835\udc59,\ud835\udc62,\ud835\udc5e) = \uf8f4\uf8f2RNE(\ud835\udc65\ud835\udc56), \ud835\udc59 < \ud835\udc65 < \ud835\udc62 (4)\n\uf8f4\ud835\udc62, \ud835\udc65\u2265\ud835\udc62 \uf8f3\n4.3 Tapered Fixed-Point Dot Product\nThe tapered fixed-point dot product is presented in Algorithm 2. In the first step, a set of quantized weights and activations are de- coded to the tapered fixed-point (lines 2\u20133). To decode the tapered fixed point format, the sign bit, integer bits (through leading zero detection algorithm), and remaining fractional bits require to be extracted (lines 4\u20137). Then, the product of the tapered fixed-point weights and activations are calculated without truncation or round- ing after multiplication operations (lines 8\u20139). The products are then stored in a wide register (quire [13]) for \ud835\udc5a multipliers with\nsize of \ud835\udc64\n\ud835\udc5e\ud835\udc62\ud835\udc56\ud835\udc5f\ud835\udc52\nas in (5) (lines 10\u201312).\n\ud835\udc56\n(a \ud835\udc5e-bit tapered fixed-point). In\n"}, {"chunk": "  Algorithm 1 Compute the maximum integer bit width (IS) and\nscaling factor (SC) of tapered fixed-point for DNN parameters\nAlgorithm 2 Tapered fixed-point dot product operations for \ud835\udc5b-bit inputs each with \u2308log \ud835\udc5b\u2309 bits for RS, 3 bits for SC.\nInput: layers weights (\ud835\udc4a ), layers activations (\ud835\udc34 )\n\ud835\udc59\ud835\udc59 \ud835\udc59\ud835\udc5e\n), layers quantized activations\nOutput: \ud835\udc3c\ud835\udc46 ,\ud835\udc3c\ud835\udc46 ,\ud835\udc46\ud835\udc36 tapered fixed-point parameters \ud835\udc64\ud835\udc59 \ud835\udc34\ud835\udc59 \ud835\udc64\ud835\udc59\n\ud835\udc59\ud835\udc5e\nOutput: \ud835\udc45 as Dot Product result\nInput: layers quantized weights (\ud835\udc4a (\ud835\udc34)\n1: procedureTaperedfixed-pointDP(\ud835\udc4a\ud835\udc59 ,\ud835\udc34\ud835\udc59 ) \ud835\udc5e\ud835\udc5e\n2: signw,Intw,fracw \u2190 Decode(\ud835\udc4a\ud835\udc59 ,\ud835\udc3c\ud835\udc46\ud835\udc64) \ud835\udc5e\n3: signa, Inta, fraca \u2190 Decode(\ud835\udc34\ud835\udc59 , \ud835\udc3c\ud835\udc46\ud835\udc4e) \ud835\udc5e\nMultiplication\n4: signmult \u2190 signw \u2295 signa\n5: Valuew \u2190 (Intw + fracw) \u226a fracbitw + |SCw|\n6: Valuea \u2190 (Inta + fraca) \u226a fracbita\n7: pmult \u2190 {sign, Valuew \u00d7 Valuea }\nAccumulation & Normalize\n 1: procedure\ud835\udc3c\ud835\udc46,\ud835\udc46\ud835\udc36Selection(\ud835\udc4a\ud835\udc59,\ud835\udc34\ud835\udc59)\n 2: 3:\n4: 5: 6: 7: 8: 9:\n10: 11: 12: 13:\n14: 15: 16: 17: 18: 19:\nwamax \u2190 max(|wl|) Aamax \u2190 max(|Al|)\nCompute the \ud835\udc3c\ud835\udc46 ,\ud835\udc3c\ud835\udc46 \ud835\udc64\ud835\udc59 \ud835\udc34\ud835\udc59\nif \u230aWamax\u230b + 1 \u2264 nbit then ISw \u2190\u230aWamax\u230b+1\nelse\nISw \u2190 nbit end if\nif \u230aAamax\u230b + 1 \u2264 nbit then ISA \u2190\u230aAamax\u230b+1\nelse\nISA \u2190 nbit end if\nCompute the \ud835\udc46\ud835\udc36\ud835\udc64\ud835\udc59 SCwl \u21900\nif Wamax < 0.5 then\nSCW \u2190\u230alog2(Wamax)\u230b+1 end if\nreturn ISwl,ISAl,SCwl end procedure\n\ud835\udc64\ud835\udc5e\ud835\udc62\ud835\udc56\ud835\udc5f\ud835\udc52 = \u2308log2(\ud835\udc5a)\u2309 + 2 \u00d7 \u2308log2(\n8: sumquire \u2190 pmul + sumquire\n   \u22b2 Accumulate 9: sumnquire \u2190 sumquire \u226b fraca + fracw + |SCw |\n    \ud835\udc40\ud835\udc4e\ud835\udc65\n\ud835\udc47\ud835\udc39\ud835\udc4b\n\ud835\udc40\ud835\udc56\ud835\udc5b\n\ud835\udc47\ud835\udc39\ud835\udc4b\n)\u2309 + 2\n(5)\nRounding & Encode\n10: result \u2190 Rounding & Encoding(sumnquire)\n11: return result\n12: endprocedure\nrange of the format. Each MAC unit first reads an n-bit activa- tion and weight in tapered fixed-point format and decodes them to \u2308\ud835\udc59\ud835\udc5c\ud835\udc542 (\ud835\udc5b)\u2309 + \ud835\udc5b bits fixed-point value with \u2308\ud835\udc59\ud835\udc5c\ud835\udc542 (\ud835\udc5b)\u2309 + 1 integer bits and \ud835\udc5b \u2212 2 fraction bits. The decoding process utilizes a count leading zeros (CLZ) unit, which counts the total number of leading zeros (from MSB), representing the integer value of the fixed-point as shown in Fig. 5. Furthermore, the 3-bit \ud835\udc46\ud835\udc36 signal controls the scaling factor of the weight by shifting the fixed-point number based on the magnitude and the sign of the \ud835\udc46\ud835\udc36 signal. The decoded activations and scaled weights are multiplied using a fixed-point multiplier which is further accumulated. Unlike other dataflows, the output stationary dataflow does not require the quantization of the accumulated value at every step which avoids generation of partial sums and thus eliminates the quantization error which normally occurs in intermediate stages. The accumulated fixed-point value uses a unary encoding mechanism, based on the magnitude and sign of the integer, while converting to the n-bit tapered fixed-point format.\nThe memory hierarchy consists of 128 MB off-chip main mem- ory (DRAM) and 3\u00d7108 kB on-chip scratchpad memory (SRAM). The main memory is dedicated to storing input data, activations and weights/filters that are loaded by the host processor, whereas the scratchpad memory serves as a global buffer. In order to es- timate latency, we bridge our framework with the SCALE-Sim tool [32]. SCALE-Sim, however, does not consider the cycles con- sumed in shuttling data back and forth between the global buffer and the DRAM. Therefore, the total latency is re-approximated by considering PE array execution time and DRAM access time (Micron MT41J256M4). For energy estimation analysis, calculation of execution time, and power utilization, we factor in 45nm CMOS technology node.\n The stored products are then converted and accumulated with fixed- point arithmetic. At the end, the accumulated result is encoded back into the tapered fixed-point numerical format (lines 16-18).\n5 SYSTEM DESIGN AND ARCHITECTURE\nThe TENT framework gives insights into adopting a new numerical format for storing the weights and activations which reduce the quantization loss at low precision. This section describes the frame- work designed to simulate DNNs on hardware platforms in order to evaluate the performance of the tapered fixed-point representation in terms of latency and energy consumption. Fig. 4 shows the high- level architecture of the designed framework guided by the design of Eyeriss v2 [6]. Primarily, it is composed of processing elements (PEs) arranged in a 2D systolic array architecture accompanied by a hierarchical memory organization. Systolic architectures have shown promising results in computing convolutions at low energy cost due to the data reuse characteristics and parallel processing fea- tures [19]. Most systolic architectures, commonly used to perform convolution operations, adopt input stationary, weight stationary, and output stationary dataflows. Of which, output stationay has shown to reduce execution time and energy consumption when PE computations are confined to a single pixel in the output feature map, and was thus selected for this architecture.\nThe PE in the systolic array has a tapered fixed-point based MAC unit with configurable bit-precision. It is controlled by an external control signal (IS) which defines the integer value and dynamic\n"}, {"chunk": "  HOST PROCESSOR\n   16x NBITS\n16x NBITS\n16x NBITS\nSYSTEM ARCHITECTURE\n16 COLUMNS\n       PE PE PE PE PE PE PE PE PE PE PE PE\nPE PE PE PE\n       16 ROWS\n    CONTROL UNIT\n  NBITS\nINPUT FEATURE\nPE\nDECODER\nDECODER\nENCODER\nIS\nc log (N) 2\nSC\n3BITS\nOUTPUT\nFEATURE NBITS\nPROCESSING ELEMENT STRUCTURE\nWEIGHT\nNBITS\n SRAM SRAM SRAM SRAM\nBANK.0 BANK.1 BANK.2 BANK.3\nFILTER SRAM\n108 KB\n  SRAM SRAM SRAM SRAM\nBANK.0 BANK.1 BANK.2 BANK.3\nIFmap SRAM\n108 KB\n HOST INTERFACE\nMEMORY INTERFACE\n  DDR3 DRAM\n  SRAM SRAM SRAM SRAM\nBANK.0 BANK.1 BANK.2 BANK.3\nOFmap SRAM\n108 KB\n   Figure 4: Deep Neural Network accelerator architecture for TENT, with custom tapered fixed-point processing elements. The architecture is evaluated in a full cycle-emulator to analyze the performance and energy constraints.\nIS\nlog(n)\nn1 n-1\n`[n-2: 1]`\n>>\n`[n-2: 0]`\nRIGHT SHIFT\nSIGN BIT\nDECODER\nlog(n)\nENCODER\nIS\nlog(n) +n log(n) +n\n/\n/ /\nlog(n) +1\nSIGN BIT\nFRACTION BITS\nFRACTION BITS\nn\n1\nn-1\n/\nn-1\nn\n<<\nLEFT SHIFT\nlog(n) +1\nn-1\n1\nlog(n) +1 CLZ\nlog(n) +1\nINTEGER BITS\nn-1\nFRACTION BITS\nlog(n) +n\n/ //\n1\n/\n1\n/\n01 10\nn+1\nFigure 5: RTL design for decoder, converting tapered point precision to fixed- point with count leading zero governed by \ud835\udc3c\ud835\udc46 parameter and encoder, converting fixed-point to tapered fixed-point with rounding off fraction bits to nearest value.\n6 EXPERIMENTAL SETUP, RESULTS & ANALYSIS\nThe TENT framework is implemented in C++ and extended to sup- port the TensorFlow framework [1]. To demonstrate the efficacy of the TENT framework, the performance of low-precision tapered fixed-point is evaluated on three inference tasks and is compared to the standard low-precision fixed-point numerical format with rounding quantization. The specifics of the evaluation tasks and the inference performance achieved on them with 32-bit float DNNs are summarized in Table 1. The MNIST and CIFAR-10 datasets are cho- sen for evaluation, as they are ideal for tinyML applications [3]. To appropriately evaluate the benefits of the tapered fixed point format,\nthe Fashion-MNIST dataset is also considered which presents addi- tional challenges to the classification task, while still falling under a similar category as the MNIST dataset. The base model selected to perform the classification task on these datasets is an extremely compact model containing less than 2 million parameters that can be stored on tiny edge devices (eg., ARM M-7 MCU) [2]. In the evaluation of each format, \ud835\udc3c\ud835\udc46 \u2208 [1..\ud835\udc5b] and \ud835\udc46\ud835\udc36 \u2208 [0..3] are consid- ered for tapered fixed-point, and \ud835\udc3c \u2208 [1..\ud835\udc5b \u2212 1] and \ud835\udc53 \ud835\udc60 \u2208 [1..\ud835\udc5b \u2212 1] are considered for standard fixed-point. The inference accuracy performance was realized on the tinyML model by quantizing the parameters to either low-precision tapared fixed-point or standard fixed-point through post-training quantization approch.\n/\n>>>\nARITHMETIC RIGHT SHIFT\n     \u2309\u2308\u2309\u2308\n\u2309\u2308\n\u2309\u2308\n\u2309\u2308\n\u2309\u2308 \u2309\u2308\n\u2309\u2308\n\u2309\u2308\n /\n/\n/\n//\n//\n////\n/\n/\n/\n STICKY_BIT\n/\nFIXED- POINT\nTAPERED FIXED- POINT\nTAPERED FIXED- POINT FIXED- POINT\n MUX\nMUX MUX\n         "}, {"chunk": "1 2 3 4\nW: Weights; A: Activations\nThe number of MACs are calculated for a DNN inference with a batch size of 1.\n2 Convolutional layers, 2 fully-connected layers, and 1 Pooling layer\n3 Convolutional layers, 2 fully-connected layers, 2 Pooling layers, 1 Batch normalization layer\nTable 1: Description of the TinyML models and benchmarks using 32-bit float parameters.\n Dataset\nMNIST Fashion-MNIST CIFAR-10\nTinyML Model\nConvNet 3 ConvNet 4 ResNet-18\n112\nW-Range\n[\u22120.78, 0.62] [\u22120.74, 0.45] [\u22122.12, 1.17]\nA-Range\n# Parameters\n1.40 M 1.88 M 0.27 M\n# MACs\nPerformance\n99.32% 92.54% 91.54%\n [0, 3.61]\n[0, 5.97] [0, 10.21]\n58.7 K\n69.8 K 286.72 K\n Table 2: Performance of TinyML models during inference with the tapered fixed-point (TFX) and fixed-point.\n Bit Precision\n8-bit 7-bit 6-bit 5-bit\nMNIST\nFixed-Point\n99.18% 97.14% 97.08% 96.96%\nFashion-MNIST\nCIFAR-10\n TFX\n99.33% 99.32% 99.30% 99.29%\nTFX\n92.59% 92.47% 92.14% 89.35%\nFixed-Point\n89.59% 88.63% 85.31% 83.46%\nTFX\n81.66% 75.90% 46.79% 23.44%\nFixed-Point\n54.20% 24.50% 12.96% 11.11%\n              6.1 Inference Performance with TENT\nThe efficacy of the TENT framework is evaluated on DNN infer- ence with varied IS and SC, as shown in Table 2. The findings show that the low-precision tapered fixed-point outperforms the standard fixed-point on various benchmarks by up to \u224831%. For instance, the performance of an 8-bit low-precision tapered fixed- point ResNet-18 network on the CIFAR-10 dataset is improved by 27.44% compared to the fixed-point based network. Furthermore, we observed that the tapered fixed-point shows greater benefits on TinyML models whose parameters have a large dynamic range, such as ResNet model shown in Table 1 and Table 2. These per- formance benefits can be intuitively explained by the auto-tuning capability of the TENT framework, which adapts the format to the dynamic range of the weights and activations, so as to reduce the quantization error. The best performance observed on all the bench- marks (when analyzed across the full [5..8]-bit range) is achieved with tapered fixed-point.\n6.2 Hardware System Results\nThe execution time of the DNN model is mainly governed by the dataflow and the PE array architecture. The output stationary dataflow offers a 24% reduction in latency as compared to weight stationary dataflow while performing inference [32]. For a compute- bound DNN this is a significant improvement, considering that infer- ence favors latency over throughput [28]. The homogeneous 16\u00d716 PE configuration with no sophisticated architectural features offers improvement in computing efficiency from 89.58% to 91.82%, with a significant reduction in energy consumption. Fig. 6(c) illustrates the energy-delay product (EDP) for the tapered fixed-point network ResNet-18 while performing inference on the CIFAR-10 dataset. It is worth noting that tapered fixed-point offers 31% improvement in classification accuracy with a negligible EDP overhead ( 17 \u2212 30%) as compared to fixed-point. Reduced bit-precision economizes the\nlocal memory storage size and the number of operational cycles in both tapered and standard fixed-point.\nOverall, the use of the tapered fixed-point numerical format helps in paving a path towards minimizing the power consump- tion (inference), which aligns with the ultimate goal envisioned by the TinyML community (\u2264 1 mw [3]). Our analyses have shown that this work\u2019s adaptation of the ResNet-18 architecture consumes power within the range of 189-270 mw to classify a single sample of the CIFAR-10 dataset, which befits the low-power requirements of devices that operate on the edge [2]. Additionally, the proposed TENT framework further enhances the performance by leverag- ing the flexibility of a tapered precision numerical format and its affinity to represent parameters with reduced quantization error (as compared to standard fixed point formats).\n7 CONCLUSIONS\nThis paper presents a low-precision framework, TENT, that offers quantization using tapered fixed point to perform inference on TinyML models. The maximum integer bit width and scaling factor parameters are dynamically selected to best fit the variability of the parameter and activation distributions within each layer of the model. We observe reduction in total quantization error that leads to an improvement in inference accuracy by \u2248 31% over fixed-point models. Furthermore, we show that tapered fixed-point achieves this with a moderate increase in energy consumption over fixed- point.\nREFERENCES\n[1] Marti\u0301n Abadi et al. 2015. TensorFlow: Large-Scale Machine Learning on Het- erogeneous Systems. https://www.tensorflow.org/ Software available from tensorflow.org.\n[2] Colby Banbury, Chuteng Zhou, Igor Fedorov, Ramon Matas Navarro, Urmish Thakkar, Dibakar Gope, Vijay Janapa Reddi, Matthew Mattina, and Paul N What- mough. 2020. MicroNets: Neural Network Architectures for Deploying TinyML Applications on Commodity Microcontrollers. arXiv preprint arXiv:2010.11267 (2020).\n"}, {"chunk": "    Figure 6: Plots depict (a) Maximum frequency, (b) Area of Tapered fixed point and standard fixed point MAC unit, (c) Energy consumption of computing one MAC operation, and (d) Energy-delay product vs error of ResNet-18 model benchmarked with CIFAR-10 for tapered fixed-point and standard fixed-point. The performance was evaluated for different bit widths to represent the weights and activations.\n[3] Colby R Banbury, Vijay Janapa Reddi, Max Lam, William Fu, Amin Fazel, Jeremy Holleman, Xinyuan Huang, Robert Hurtado, David Kanter, Anton Lokhmotov, et al. 2020. Benchmarking TinyML Systems: Challenges and Direction. arXiv preprint arXiv:2003.04821 (2020).\n[4] Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. arXiv preprint arXiv:2005.14165 (2020).\n[5] Gianmarco Cerutti, Rahul Prasad, Alessio Brutti, and Elisabetta Farella. 2019. Neural Network Distillation on IoT Platforms for Sound Event Detection.. In Interspeech. 3609\u20133613.\n[6] Yu-Hsin Chen, Tien-Ju Yang, Joel Emer, and Vivienne Sze. 2019. Eyeriss v2: A flexible accelerator for emerging deep neural networks on mobile devices. IEEE Journal on Emerging and Selected Topics in Circuits and Systems 9, 2 (2019), 292\u2013308.\n[7] Jungwook Choi, Zhuo Wang, Swagath Venkataramani, Pierce I-Jen Chuang, Vijayalakshmi Srinivasan, and Kailash Gopalakrishnan. 2018. Pact: Parameterized clipping activation for quantized neural networks. arXiv preprint arXiv:1805.06085 (2018).\n[8] Aakanksha Chowdhery, Pete Warden, Jonathon Shlens, Andrew Howard, and Rocky Rhodes. 2019. Visual wake words dataset. arXiv preprint arXiv:1906.05721 (2019).\n[9] Miguel de Prado, Romain Donze, Alessandro Capotondi, Manuele Rusci, Serge Monnerat, Luca Benini, and Nuria Pazos. 2020. Robust navigation with tinyML for autonomous mini-vehicles. arXiv preprint arXiv:2007.00302 (2020).\n[10] Zhen Dong, Zhewei Yao, Daiyaan Arfeen, Amir Gholami, Michael W Mahoney, and Kurt Keutzer. 2020. Hawq-v2: Hessian aware trace-weighted quantization of neural networks. Advances in Neural Information Processing Systems 33 (2020).\n[11] A. T. Elthakeb, P. Pilligundla, F. Mireshghallah, A. Yazdanbakhsh, and H. Es- maeilzadeh. 2020. ReLeQ : A Reinforcement Learning Approach for Automatic Deep Quantization of Neural Networks. IEEE Micro 40, 5 (2020), 37\u201345.\n[12] Igor Fedorov, Ryan P Adams, Matthew Mattina, and Paul Whatmough. 2019. Sparse: Sparse architecture search for cnns on resource-constrained microcon- trollers. In Advances in Neural Information Processing Systems. 4977\u20134989.\n[13] John L Gustafson and Isaac T Yonemoto. 2017. Beating Floating Point at its Own Game: Posit Arithmetic. Supercomputing Frontiers and Innovations 4, 2 (2017),\n71\u201386.\n[14] Philipp Gysel, Jon Pimentel, Mohammad Motamedi, and Soheil Ghiasi. 2018.\nRistretto: A framework for empirical study of resource-efficient inference in con- volutional neural networks. IEEE Transactions on Neural Networks and Learning Systems (2018).\n[15] Tom Henighan, Jared Kaplan, Mor Katz, Mark Chen, Christopher Hesse, Ja- cob Jackson, Heewoo Jun, Tom B Brown, Prafulla Dhariwal, Scott Gray, et al. 2020. Scaling Laws for Autoregressive Generative Modeling. arXiv preprint arXiv:2010.14701 (2020).\n[16] Benoit Jacob, Skirmantas Kligys, Bo Chen, Menglong Zhu, et al. 2018. Quanti- zation and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).\n[17] Patrick Judd, Jorge Albericio, Tayler Hetherington, Tor Aamodt, Natalie En- right Jerger, Raquel Urtasun, and Andreas Moshovos. 2018. Proteus: Exploiting precision variability in deep neural networks. Parallel Comput. 73 (2018), 40\u201351.\n[18] Raghuraman Krishnamoorthi. 2018. Quantizing deep convolutional networks for efficient inference: A whitepaper. arXiv preprint arXiv:1806.08342 (2018).\n[19] Hsiang-Tsung Kung. 1982. Why systolic architectures? IEEE computer 15, 1 (1982), 37\u201346.\n[20] John L. Gustafson. 2020. A Generalized Framework for Matching Arithmetic Format to Application Requirements. In https://posithub.org/.\n[21] Liangzhen Lai, Naveen Suda, and Vikas Chandra. 2018. CMSIS-NN: efficient neural network kernels for arm cortex-M CPUS. CoRR abs/1801.06601 (2018). arXiv preprint arXiv:1801.06601 (2018).\n[22] Edgar Liberis, \u0141ukasz Dudziak, and Nicholas D Lane. 2020. muNAS: Constrained Neural Architecture Search for Microcontrollers. arXiv preprint arXiv:2010.14246 (2020).\n[23] Ji Lin, Wei-Ming Chen, Yujun Lin, Chuang Gan, Song Han, et al. 2020. Mcunet: Tiny deep learning on iot devices. Advances in Neural Information Processing Systems 33 (2020).\n[24] Jeffrey L McKinstry, Steven K Esser, Rathinakumar Appuswamy, Deepika Bablani, John V Arthur, Izzet B Yildiz, and Dharmendra S Modha. 2018. Discovering low-precision networks close to full-precision networks for efficient embedded inference. arXiv preprint arXiv:1809.04191 (2018).\n[25] S Migacz. 2017. 8-bit inference with TensorRT. In GPU Technology Conference.\n"}, {"chunk": "[26] Asit Mishra and Debbie Marr. 2017. Apprentice: Using Knowledge Distilla- tion Techniques To Improve Low-Precision Network Accuracy. arXiv preprint arXiv:1711.05852 (2017).\n[27] Alex Olsen, Dmitry A Konovalov, Bronson Philippa, Peter Ridd, et al. 2019. Deep- Weeds: A Multiclass Weed Species Image Dataset for Deep Learning. Scientific Reports 9, 1 (2019), 2058.\n[28] David A Patterson. 2004. Latency lags bandwith. Commun. ACM 47, 10 (2004), 71\u201375.\n[29] Hadi Pouransari, Zhucheng Tu, and Oncel Tuzel. 2020. Least squares binary quantization of neural networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops. 698\u2013699.\n[30] Manuele Rusci, Marco Fariselli, Alessandro Capotondi, and Luca Benini. 2020. Leveraging Automated Mixed-Low-Precision Quantization for tiny edge micro- controllers. arXiv preprint arXiv:2008.05124 (2020).\n[31] Charbel Sakr and Naresh Shanbhag. 2018. An analytical method to determine minimum per-layer precision of deep neural networks. In 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 1090\u20131094.\n[32] Ananda Samajdar, Yuhao Zhu, Paul Whatmough, Matthew Mattina, and Tushar Krishna. 2018. Scale-sim: Systolic cnn accelerator simulator. arXiv preprint arXiv:1811.02883 (2018).\n[33] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang- Chieh Chen. 2018. Mobilenetv2: Inverted residuals and linear bottlenecks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 4510\u20134520.\n[34] Andrew W Senior, Richard Evans, John Jumper, James Kirkpatrick, et al. 2020. Improved protein structure prediction using potentials from deep learning. Nature (2020), 1\u20135.\n[35] Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew Howard, and Quoc V Le. 2019. Mnasnet: Platform-aware neural architecture search for mobile. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2820\u20132828.\n[36] Murad Tukan, Alaa Maalouf, Matan Weksler, and Dan Feldman. 2020. Compressed deep networks: Goodbye svd, hello robust low-rank approximation. arXiv preprint arXiv:2009.05647 (2020).\n[37] Kuan Wang, Zhijian Liu, Yujun Lin, Ji Lin, and Song Han. 2019. Haq: Hardware- aware automated quantization with mixed precision. In Proceedings of the IEEE conference on computer vision and pattern recognition. 8612\u20138620.\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. 2016. Google\u2019s neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint arXiv:1609.08144 (2016).\n"}, {"chunk": "OverHear: Headphone based Multi-sensor Keystroke Inference\nRaveen Wijewickrama\u2217, Maryam Abbasihafshejani\u2217, Anindya Maiti\u2020, Murtuza Jadliwala\u2217\n\u2217University of Texas at San Antonio {raveen.wijewickrama, maryam.abbasihafshejani, murtuza.jadliwala}@utsa.edu \u2020University of Oklahoma\nam@ou.edu\nAbstract\nHeadphones, traditionally limited to audio playback, have evolved to integrate sensors like high-definition microphones and accelerometers. While these advancements enhance user experience, they also introduce potential eavesdropping vul- nerabilities, with keystroke inference being our concern in this work. To validate this threat, we developed OverHear, a keystroke inference framework that leverages both acoustic and accelerometer data from headphones. The accelerometer data, while not sufficiently detailed for individual keystroke identification, aids in clustering key presses by hand posi- tion. Concurrently, the acoustic data undergoes analysis to extract Mel Frequency Cepstral Coefficients (MFCC), aiding in distinguishing between different keystrokes. These features feed into machine learning models for keystroke prediction, with results further refined via dictionary-based word predic- tion methods. In our experimental setup, we tested various keyboard types under different environmental conditions. We were able to achieve top-5 key prediction accuracy of around 80% for mechanical keyboards and around 60% for membrane keyboards with top-100 word prediction accuracies over 70% for all keyboard types. The results highlight the effectiveness and limitations of our approach in the context of real-world scenarios.\n1 Introduction\nIn the rapidly evolving landscape of mobile device hardware, sensors have emerged as pivotal components that enhance user experience and functionality. Among these sensors, ac- celerometers stand out for their ability to detect motion, while microphones, especially those embedded in headphones and headsets, have been refined to high-definition standards suit- able for applications such as high fidelity voice recording and enabling active noise cancellation. Interestingly, these head- phones not only come equipped with multiple microphones but also often incorporate accelerometers to discern if they are being worn, and for advanced applications such as ges- ture controls [10, 13], adaptive noise cancellation [37], spatial\naudio [24], and fitness tracking [29, 31]. However, the inte- gration of such advanced sensors presents potential security challenges. Given this rich sensor integration, headphones present themselves as an attractive and novel attack vector, especially for eavesdropping applications such as keystroke inference. Their proximity to the user and their surrounding devices (e.g., keyboards), combined with their multi-sensor capabilities, offers a unique advantage for capturing sensitive data. Despite these inherent advantages, the potential of head- phones as a medium for keystroke inference has remained largely unexplored.\nAcoustic eavesdropping has been a thoroughly investigated side-channel for inferring keystrokes on both physical and touchscreen keyboards. Lie et al. [19] harnessed sound waves produced by typing on a traditional keyboard using a smart- phone\u2019s microphone. In contrast, Narain et al. [27] and Lu et al.\u2019s KeyListener [22] focused on touchscreen keyboards, with the the latter using an adjacent adversarial phone. Sim- ilarly, Bai et al. [7] applied stereo audio recording from a mobile phone near a physical keyboard for keystroke infer- ence. These prior works mainly utilized fixed audio recording devices, such as mobile phones controlled by attackers or specific computer microphones, to detect the acoustic signals from keystrokes. In practical situations, it\u2019s unlikely that an individual would overlook unknown devices in their vicinity. Though an intruder could consider leveraging the victim\u2019s mobile phone (via a malicious app), the unpredictable and user-dependent placement of the phone relative to a keyboard often diminishes the feasibility of acoustic-only inference.\nPast research has also explored the use of motion sensors for keystroke inference, often utilizing mobile phones or wear- ables such as smartwatches [9,20,23,39]. Marquardt et al. [25] notably employed a smartphone\u2019s accelerometer to detect vi- brations from nearby keyboard keystrokes. However, such methods are limited by the need for close and/or fixed prox- imity to the keyboard or require the victim to wear or hold the infiltrated wearable device on their hand, limiting their practicality (as in the earlier case).\nDiverging from the traditional attacker controlled devices\n1\narXiv:2311.02288v1 [cs.CR] 4 Nov 2023\n"}, {"chunk": "or infiltrated user mobile phone based methods, we look into the possibility of using smart headphones for keystroke in- ference. Modern headphones, especially the latest Bluetooth- enabled variants, often come equipped with multiple micro- phones on both ears. These microphones serve dual purposes: capturing audio and facilitating noise cancellation. Such a design makes headphones an enticing vector for a keystroke inference attack. Further, recognizing that the latest varieties of headphones, particularly Bluetooth enabled ones, come with smartphone/desktop apps for their respective devices, we speculate that a malicious app which has firmware level API access to the headphone can potentially exploit this con- nection to discreetly record sensor data in order to carry out keystroke inference on unsuspecting users. A likely scenario would be an instance where a manufacturer itself acting as an adversary using its native app to offload data to its back-end server in order to further process this data to infer sensitive information about the users beyond the recorded audio.\nOne of the significant challenges in the domain of keystroke inference is training-free inference, where an attacker lacks labeled training data specific to the victim. More specifically, in a headphone-based keystroke inference attack scenario, the relative position between the headphones and the keyboard can vary considerably based on user traits such as height, arm length, and the distance from the chair to the table. This is compounded by both voluntary and involuntary head move- ments. Prior research that utilized dual microphones, primar- ily relied on a technique called Time Difference of Arrival (TDoA) which uses time difference that results when sound travels to the individual microphones, yielding stable results primarily because the data collection device was either on the same surface as the keyboard or was the input device itself (e.g., mobile phone qwerty keypad keystroke inference) [44]. Further, these prior works on acoustic keystroke inference relied on recording devices that were mostly stationary, while in our situation, due to the motion of the headphone induced by user head movements, the recording devices are not static and thus may record much more noisier/inconsistent data.\nGiven the opportunity of being able to employ modern headphones equipped with a variety of on-board sensors as a novel attack vector and the associated challenges, in this paper we propose OverHear, a framework to infer keystroke using acoustic and motion sensor data collected from headphones. While the accelerometer data alone lacks the granularity to distinguish individual keystrokes, it proves to be useful in clus- tering keys corresponding to each hand especially when tra- ditional acoustic based sound source localization techniques may not be working well due to potentially unsteady behav- ior of the victims. From the acoustic data, we extract Mel- frequency cepstral coefficients (MFCC) features, and train and test several machine learning models to predict individual keys. This prediction is then refined using a dictionary-based spell-correction approach to further improve the success of a keystroke inference in a context-aware manner. We attained a\ntop-5 key prediction accuracy of approximately 80% for me- chanical keyboards and about 60% for membrane keyboards. Furthermore, our framework demonstrated a top-50 word pre- diction accuracy nearing 50%, and surpassed 70% in top-100 word prediction accuracy across all keyboard types.\nOur main contributions are as follows.\n\u2022 Development of a new keystroke inference framework: To overcome the unique challenges encountered in head- phone based keystroke inference, we propose a novel infer- ence framework called OverHear. OverHear integrates data from both microphones and accelerometers to enhance the accuracy of keystroke inference. OverHear also includes a keyboard type identification module to identify the type of the keyboard a victim may be using (e.g., mechanical or membrane).\n\u2022 Enhanced word prediction mechanism: We incorporate a word prediction technique based on spell-correction to further improve the efficacy and prediction performance of OverHear.\n2\n\u2022\n2\nComprehensive empirical evaluation of the proposed attack: OverHear is evaluated using data sourced from real-world participants under realistic/unconstrained set- tings, spanning across various environmental/ambient noise scenarios. This ensures that the findings are reflective of practical, day-to-day scenarios, offering insights into the framework\u2019s robustness and applicability.\nMotivation and Related Work\nAnalysis of acoustic signals for the purpose of inferring user input on a variety of mobile and computing devices has been the subject of several studies in recent years, each employ- ing unique methodologies and achieving varying degrees of accuracy. Asonov and Agarwal [5] in 2004 employed acous- tic data collected using a dedicated PC microphone with a trained neural network that uses frequency domain features to show that individual key presses can be recognized with an accuracy of 79%. They demonstrated that their inference framework works across multiple different computer key- boards as well as telephone and ATM key pads. In a similar line of research, Liu et al. [19] proposed a novel approach for inferring keystrokes on a mobile device by using the resulting audio signals. They developed a system that utilizes the built- in stereo microphones of a smartphone positioned adjacent to keyboard to record sound waves produced by a user\u2019s typing. By means of a purely non-ML based approach such as a Time- Difference-of-Arrival (TDoA) technique, they were able to identify unique patterns in these recorded acoustic waves and match them to specific keys (being typed). Their framework was able to produce key inference accuracies close to 85%. While both the above two research efforts are significant, they were tested under rather restrictive conditions and focused solely on individual key presses rather than more complex scenarios involving word or sentence typing and prediction.\n"}, {"chunk": "Similar to Asonov and Agarwal [5], Zhuang et al. used a Hidden Markov Model (HMM) to infer keystrokes from audio signals recorded by a PC microphone, and then employed a language model to facilitate word prediction. They were able to achieve a prediction accuracy of 88% and 96% for word and keys, respectively. Narain et al. [27] proposed a framework to infer keystrokes on a touchscreen QWERTY keyboard of a mobile device using acoustic signals. They employed a Decision Tree based learning algorithm, achieving a fairly high accuracy of close to 95% in a single attempt. The most notable aspect of this study was its language-agnostic approach, suggesting that regardless of the language or the content being typed, the methodology can accurately infer the keystrokes.\nSimilar to Narain et al.\u2019s approach [27], Lu et al.\u2019s KeyLis- tener [22] attempts to infer touch screen QWERTY keyboard keystrokes on a smartphone, but with a nearby adversarial smartphone\u2019s microphone. They used a Time-Difference-of- Arrival (TDoA) based approach, achieving a top-1 word ac- curacy of around 50% and a top-10 accuracy of around 90%. Zhu et al. [45] also proposed keystroke inference framework based on TDoA and achieved a key prediction accuracy of 72%. However, their framework requires at least two mali- cious mobile phones to be in physical proximity of the victim keyboard which making executing the attack practicality chal- lenging. Lastly, Bai et al. [7], drawing parallels with Lie et al. [19] and Zhu et al. [45], employed stereo audio record- ings from a mobile phone situated near a keyboard to deduce keystrokes. Their methodology integrates (TDoA) and Power Spectral Density (PSD) features within a SVM model. They achieved a top-1 accuracy of 71% and a further enhanced top-5 accuracy of 92%.\nSeveral past studies have also explored the use of motion sensors for keystroke inference [9, 20, 23, 39]. These investi- gations typically harness motion sensors in mobile phones to deduce in-device keystrokes or employ smart wearables, like smartwatches, to infer keystrokes on physical keyboards. Mar- quardt et al. [25] introduced (sp)iPhone, where accelerometer data from a device placed near a physical keyboard could be used to infer keystrokes. For their attack, they capitalized on the vibrations generated by the keystrokes on the key- board and transmitted through the table to the smartphone\u2019s accelerometer.\nOur extensive literature review has shown key research gaps, which motivates us to explore the feasibility of a new attack surface for carrying out keystroke inference attacks (on external keyboards). First, previous research which em- ployed acoustic and/or motion/vibration signals for such at- tacks primarily relied on stationary recording sources/devices, such as attacker-controlled mobile phones or dedicated PC microphones, to capture the motion/vibration and/or sounds produced by the keystrokes. In real-world scenarios, it\u2019s un- likely that a victim wouldn\u2019t notice unfamiliar (recording) devices nearby which makes actually carrying out such at-\ntacks challenging. While an attacker might attempt to use the victim\u2019s own mobile phone (by installing some Trojan app) for such purposes, the unpredictable positioning of the phone near a keyboard makes this approach less practical. Further, headphones, especially the wireless type, are ubiquitous and often worn continuously by users, even when not in active use (e.g., for noise cancelling purposes). This constant presence provides a persistent eavesdropping opportunity.\nOur attack model diverges from these existing approaches by leveraging the user\u2019s own headphones, which typically has a fixed position over the user\u2019s head. Given that many of these headphones come with companion apps for smartphones or desktops (especially modern Bluetooth ones), we assume that a malicious companion app could serve as a side-channel to extract sensor data (e.g., acoustic and motion sensors) from the unsuspecting victim in order to carry out keystroke infer- ence attacks. However, our attack setup is not free of chal- lenges. The acoustic stream in our attack scenario presents its own set of challenges. Unlike stationary microphones or mobile devices placed on a surface, headphones are subject to the nuances of human behavior. The user\u2019s head movements, whether subtle shifts or more pronounced turns (while typing), can introduce variability in the captured acoustic data. Fur- thermore, individual anatomical traits, such as the shape and size of the user\u2019s head, length of the arms, can influence how sound waves are received by the headphone microphones. On the other hand, the motion sensor data streams have their own challenges, i.e., the vibrations (due to keystrokes) sensed by the on-board motion sensor are less pronounced as they have to traverse from the hands/body to the head of the user. Con- sequently, relying solely on accelerometer or motion sensor data for keystroke inference would not be very effective. Our key insight is whether acoustic/sound data as sensed by the microphones can be combined with motion sensor data, both of which are readily available in most modern headphones, can be used to effectively carry out keystroke inference in this unique, yet realistic, setup. We are the first to explore this novel attack setup for keystroke inference.\n3 Background and Preliminaries\nThis section briefly introduce the type of sensors used in our keystroke inference framework (OverHear), their sensor feed- back, and the concept of Time Difference of Arrival (TDoA) which are required to understand the rest of the paper.\n3.1 Microphones in Headphones\nMicrophones function by capturing sound waves (acoustic energy) and converting them into electrical signals that can then be recorded and utilized in various audio and voice ap- plications. The electrical signal is generated by vibrations of a diaphragm or membrane, which moves a coil of wire or a capacitor in response to sound waves. Microphones come in a variety of forms, including dynamic, ribbon, condenser, MEMS (Micro-Electro-Mechanical Systems) and electret.\n3\n"}, {"chunk": "  The two most common polar patterns used in microphones are omnidirectional and cardioid. In an omnidirectional mi- crophone, sound is picked up equally from all directions. As a result, it can detect sound coming from the front, sides, and back of the microphone. Conversely, a cardioid microphone is unidirectional, which means it picks up sound primarily from one direction (usually the front) and rejects it from other directions. In modern headsets and earbuds where the mi- crophones are built into the earpiece itself (compared to the ones where a microphone arm protrudes from the earpiece to near the mouth), omnidirectional microphones are used. This is mainly due to the positioning, since the microphones are not placed near the mouth, it would be challenging for the a cardioid microphone to consistently pick up user voice. How- ever, one drawback of using omnidirectional microphones is the potential for more background noise. To overcome this, many modern high-end headsets employ noise-cancellation techniques to help isolate user\u2019s voice and reduce ambient noise primarily aided by the presence of multiple microphones present in these headphones, i.e., for user input and dedicated noise cancelling purposes [18, 33].\n3.2 Motion Sensors in Headphones\nThere has been a rising trend in incorporating intelligent fea- tures into headphone, in order to enable smart applications. Early adapters of this innovation, such as the Microsoft Sur- face headphones and Bose QC35 headphones, have embedded motion sensors, enhancing user interaction with gesture-based controls. These headphones empower users to perform actions like playing or pausing audio and summoning voice assistants like Siri or Alexa through intuitive gestures [10,13]. Central to these advancements are two critical sensors: accelerometers and gyroscopes. Together, these sensors capture movements of the device in three-dimensional space, breaking them down along the x, y, and z axes. While accelerometers focus on linear acceleration \u2013 encompassing actions such as tilting or straightforward motion \u2013 the gyroscopes are designed to mea- sure angular velocity, effectively capturing rotational move- ments around the three principal axes. This ability allows for precise discernment of the device\u2019s orientation and angular shifts [43].\n3.3 Sensor Fusion for Keystroke Inference\nOur particular interest is in the potential application of these sensors beyond their intended use, specifically in keystroke inference. Keyboards possess distinct mechanical characteris- tics, resulting in the emission of unique acoustic signatures when keys are pressed and released. As leveraged in previ- ous works [5, 7], these audible vibrations are detectable by microphones integrated into nearby devices (see Figure 1a). Furthermore, as a user engages with a keyboard, the act of typing creates additional non-acoustic vibrations. These vi- brations, originating from keystrokes, could travel through the fingers, palms, and further along the arms. Figure 1b shows\n1.5 Left\nRight\n1.0\nee 0.5\ndd utilutil 0.0\npp mm AA 0.5\n1.0\n1.5\n6.25 6.30 6.35 6.40 6.45 6.50 6.55 Time(s)\n0.015 0.010 0.005 0.000 0.005 0.010 0.015\nLeft Right\n2 3 4 5 6 7 8 9 10 Time(s)\n4\n(a)\n(b)\nFigure 1: Typing captured through a pair headphones, (a) audio, (b) accelerometer.\nthe accelerometer feedback recorded from a pair of prototype headphones (equipped with accelerometers on each ear piece) during a typing task. The noticeable peaks correlate to the key presses that are occurring indicating the potential of ac- celerometers for keystroke inference. Though the strength of these waves diminishes with distance, the sensitivity of mo- tion sensors in headphones might be adept enough to pick up certain subtle motions which could facilitate keystroke infer- ence. This ability to capture such nuanced data from motion sensors by combining it with audio data could be instrumental in building a more comprehensive detection and inference system. Such data fusion provides a comprehensive view of the data, capturing different perspectives and nuances. As a result of the integration of these diverse data streams, the de- tection system overcomes the limitations and biases inherent in individual sensors, enhancing the identification of patterns. Additionally, integrating multiple data reduces false positives and false negatives, resulting in better accuracy.\n3.4 Sound Source Localization via Time Dif- ference of Arrival (TDoA)\nTime Difference of Arrival (TDoA) is a method used in acous- tic, radar, or radio signals to estimate the location of an object using two or more sensors. The overarching principle behind TDoA is the sound produced by a source travels through a medium (often air) and reaches one microphone before the other, if the sound source isn\u2019t equidistant to the two micro- phones. This difference in time that the sound signal takes to reach each microphone is appositely called the Time Differ- ence of Arrival. Although the process of calculating TDoA is simple in theory, it becomes complex in practice due to factors like signal distortion, background noise, and reflec- tion of sound waves from surfaces. These factors can affect the signal and make it more difficult to accurately identify the arrival time of the signal at each microphone. Several acoustic based inference works in the past have successfully used TDoA based techniques to predict keystroke [11, 19]. However, the problem becomes even more challenging if the microphones are not in a fixed position, such as from a pair of headphones due to the head movements that may occur while a person is wearing the headphones. Further, specifically in an inference attack scenario, victim specific anatomical dif- ferences (e.g., height, arm length) and voluntary/involuntary head movements could make the use of TDoA less effec-\n"}, {"chunk": "  Motion\nAudio\nPreprocessing\nKey\nKey Grouping\nLabeled Training Data\nFeature Extraction & Key Classification\nPredicted Keys\nSpell Correction\nCAR\nWord Prediction\n Segmentation\ntive. In Section 5.3 we detail the observations we made using real-world participants data on shortcomings of TDoA in our attack scenario and describe the alternative techniques we used to overcome such challenges.\n4 OverHear Overview\nIn this section, we describe our adversary model followed by an overview of our inference attack.\n4.1 Adversary Model\nThe primary objective of an adversary in our attack is to infer sensitive information typed by the user on a physical key- board, such as passwords, credit card numbers, and personal identification details. We assume that the adversary has the ability to access and acquire both audio and accelerometer data from the target user\u2019s headphones where the adversary intercepts the communication between the headset and the connected device. This can be done via either a Trojan appli- cation installed in the paired device such as a desktop com- puter/laptop or a mobile phone which will have firmware level API access to the headphones. Such an attack setup or adver- sarial scenario can be easily realized by the headphone device manufacturer themselves acting as the adversary [8, 30, 38]. The captured data is then transferred to an adversary con- trolled server elsewhere in which the victim data will be run through a pre-trained model to infer/predict what the target victim typed. The adversary has knowledge of the type of keyboard (i.e., a mechanical keyboard, membrane keyboard (external) or a laptop membrane keyboard) the victim uses by employing a keyboard identification model as described in Section 5.5. The adversary does not have any other medium of inferring the private text typed, and must rely entirely on the data streams originating from the headphones.\n4.2 Inference Framework\nFigure 2 illustrates our OverHear inference framework ar- chitecture. A malicious companion app associated with the victim\u2019s headphones is used to covertly capture data from the headphones\u2019 built-in accelerometers and stereo microphones during typing activities. For building the training dataset, a custom application connected to the headphones are used to capture the data streams. The raw accelerometer and audio data are then transmitted to a remote server, which houses the remaining components of our inference framework. This server processes the data, constructs training models, and conducts evaluations on the test data.\nRecording and Data Pre-processing. OverHear uses raw audio and accelerometer data captured through their head- phones during keyboard interactions of the victim. The type of keyboard in use is then identified to tailor the subsequent processing steps. Noise filtering techniques are applied to remove any background/ambient noise that may be present in the recorded streams. Once cleaned, a segmentation algorithm is employed to isolate and identify individual keystrokes.\nFigure 2: OverHear inference framework overview.\nTraining Dataset Assembly. Using the insights gained from the pre-identified keyboard type and other criteria, a compre- hensive training dataset is curated using acoustic and motion sensor data captured using headphones. This involves data collection sessions with a select group of participants, ensur- ing a diverse and representative sample that captures various typing patterns and styles.\nFeature Extraction and Model Training. With the train- ing data in place, the system extracts a set of features for each keystroke which encapsulate the unique characteristics of keystrokes. The keys are then clustered into three groups based on their potential typing hand; left, right and ambiguous (see Section 5.3.2 for more details) and then used to train a machine learning model, optimizing it for accuracy and gen- eralization across different users/victims with varying typing traits.\nPrediction on Victim Data. Using the trained inference model from the previous step, the framework now processes unlabeled data from the victim to infer their keystrokes. The audio and motion sensor data streams captured through vic- tim\u2019s headphones go through the same pipeline as the training dataset where the data streams are first pre-processed and segmented to identify keystrokes. The unlabeled keystrokes are then tested via the trained machine learning models to pre- dict keystrokes. The sequences of keystrokes are then further processed in a word prediction module with the aid of a spell correcting algorithm to predict the closest matching words.\n5 Framework Design and Implementation\nIn this section, we outline the design of our OverHear frame- work and then discuss the specifics of its implementation, including our experimental setup and data collection proce- dure.\n5.1 Data Pre-processing\nAudio Noise Filtering. To ensure the clarity and relevance of our audio data in the context of keystrokes, we employed fil- tering to mitigate background noise, which typically occurs at higher frequencies distinct from those of keystrokes. Through analysis of the audio captured via our headphone setup, we discerned that keystrokes predominantly occur within the fre- quency range of 1200 - 3800 Hz. Consequently, a bandpass filter was tailored to retain information within this specific range while filtering out extraneous frequencies. However, while this range effectively captures both mechanical and\n5\n"}, {"chunk": "membrane type keyboard keystrokes tested in our study, ad- justments might be necessary to accommodate the unique sound profiles of other keyboards.\nAccelerometer Noise Filtering. The raw accelerometer data very often contain noise, primarily stemming from involuntary body movements, if from a body worn device. Specifically, in our headphone based attack scenario, this can be accounted to minor head movements. To address this, we employed a low-pass filter designed to eliminate high-frequency noise while preserving the lower-frequency vibrations induced by key presses.\n5.2 Keystroke Segmentation\nA keystroke consists of two main components in its acoustic signal, namely the the key hit and key release which produces two different peaks in the signal. Figure 3 illustrates the typi- cal acoustic feedback captured from the stereo microphones on a pair of headphones from a keyboard key press event. The initial more pronounced peak represents the key hit event, while the subsequent, lower peak indicates the key release event.\nwhere, ksi is the ith keystroke in the continuous signal, psi is the start point of the keystroke, and psi + 80ms is the end point of the keystroke.\n5.3 Key Group Clustering\nOne of the challenges in a keystroke inference attack is the number of potential keys on a keyboard, which can make the prediction task complex. Training a single model to dis- tinguish between each key individually may require a vast amount of data for each key to achieve reasonable accuracy. By grouping keys, the dimensionality of the problem can be reduced, making the training and inference processes more practical. We first look into methods used for key grouping in previous acoustic based keystroke inference works [19,27] for their applicability in our attack scenario, identify challenges posed by them, followed by proposing techniques that suits our headphone based inference setting.\n5.3.1 Traditional TDoA Based Clustering\nWe first look into the possibility of using traditional Time\nDifference of Arrival (TDoA) based key identification/key\ngroup clustering methods to identify similar keystrokes with\nsimilar sound profiles [11]. We compute TDoA via the cross-\ncorrelation method for the 2-channel audio signal. TDoA\nestimation using cross-correlation involves finding the lag (or\nshift) at which two signals are most similar [7]. The cross-\ncorrelation TDoA formula is as follows:\n\u0012\u0013\nTDoA = argmax \u2211S1[n]\u00b7S2[n+k] (3) kn\nwhere S1[n] is the signal at the first microphone at discrete time n, S2[n+k] is the signal at the second microphone shifted by k samples and arg maxk indicates the shift k at which the cross-correlation is maximized, i.e., the shift where the two signals look the most similar.\nHowever, the dynamic nature of head movements during typing tasks presented a significant challenge. Typists fre- quently shift their gaze, alternating between various sections of the screen and sometimes the keyboard. This constant change in head orientation rendered TDoA an unreliable met- ric for uniquely determining key positions. This is evident not only for individual users/typists, as shown in Figure 4a, but also when considering multiple users, as depicted in Figure 4b. The extensive spread of data points across all keys or classes further corroborates this observation. Moreover, our attempts to identify distinct key groups/clusters based on similar TDoA values, as was done in some previous works [11, 19], proved to be unsuccessful. The high variability and inconsistency in TDoA values, exacerbated by the previously mentioned anatomical differences and head movements of the users, ren- dered the task of grouping keys with similar acoustic charac- teristics nearly impossible. This further highlights the unique challenges posed by our headphone-based setup compared to previous keystroke inference methodologies [7, 19, 27].\n 4\n2\neduti\n0\nmA\n2\n4\n0.20\nLeft Channel Right Channel\nlp\nHit Peak\n0.15 0.10 Time (s)\n0.05\nRelease Peak\n0.00 +1.696618e9\nFigure 3: Acoustic waveform of a keystroke.\nWe observed that the average duration of a keystroke is about 80 ms. We use a sliding window with a size of 1 ms (em- pirically determined) and calculates the energy (Equation (1)), which is the sum of the squares of the audio amplitude values for each window and is given by the following formula:\nEx = \u2211|x(n)|2 (1) n\nwhere E is the energy of the signal, n is the index of the audio sample and x(n)2 is the square of the amplitude of the signal at the nth sample. We then pass each window through an adaptive thresholding peak picking algorithm called Music Structure Analysis Framework (MSAF) [28] which considers a local average to pick the prominent keystroke related peaks and to discard insignificant noise peaks. The windows with the detected peaks are then considered to be potential keystroke start points, ps. The consecutive start points less than 100 ms are discarded. For each start point, we extract the keystroke as follows:\nksi = (psi \u2212 5ms, psi + 80ms) (2)\n6\n"}, {"chunk": "                      0.20 0.15 0.10 0.05 0.00\nClasses\nTDoA Value\n abcde fgh i jk l mn o p q r s t u vw x y z\n       0.40 0.35 0.30 0.25 0.20 0.15 0.10 0.05 0.00\nClasses\nTDoA Value\n abcde fgh i jk l mn o p q r s t u vw x y z\n  (a) (b)\nFigure 4: Variability of TDoA values (a) for a single partici- pant, (b) across all participants.\n5.3.2 Energy Based Clustering\nWe next explored other techniques that could aid our frame- work in identifying key groups. Specifically, we explored the energy levels of keystrokes in the acoustic signal. As we can observe in Figure 5a, the energy for the keystrokes towards the right of the keyboard is higher on the right audio chan- nel compared to left channel and vice versa. Under a setting similar to previous works [7, 19], where the audio recording happens from a fixed position such as a phone kept nearby the keyboard, this type of energy based clustering can easily be used to cluster the keys into left and right groups. However, due to the constantly varying head direction changes that hap- pen during typing tasks, which may include either looking at different parts of the screen or looking at the keyboard and then looking back at the screen, the energy differences for left and right audio channels also turned out to be not reliable and consistent.\nprototype (detailed in Section 5.7) headphone. when pressing key \u2018a\u2019 using the left hand in which the z axis energy profile of the left channel is clearly distinct from all the other axes.\nWith the aforementioned observations on energy signifi- cance on accelerometer z-axis, to quantify the distribution of energy between the left and right accelerometer channels, we introduce an energy ratio metric. For each channel, the energy, E, is computed as the sum of the squares of its samples (see Equation (1)). The energy ratio, ER, is then defined as the proportion of the left channel\u2019s energy to the total energy of both channels, formulated as:\nER = Eleft (4) Eleft + Eright + \u03b5\nwhere \u03b5 is a minuscule constant introduced to prevent division by zero. This metric provides a relative energy measurement between the two channels. If a key is pressed from the left- hand, the energy registered on the left accelerometer channel (of the headphones) will be higher than the right accelerometer making the ER closer to 1 and if it\u2019s a right-hand pressed key, ER will be closer to 0. Since the energy ratio inherently normalizes the values between 0 and 1. This makes it easier to adapt across different users, as the absolute energy values can vary based on factors like distance from the source of vibration/key press (due to anatomical differences), or even the user\u2019s typing intensity.\nGiven the energy ratio, we heuristically label three key groups based on their spatial positioning and the hand pre- dominantly used to press them. Specifically, we define:\nG1: Keys predominantly pressed by the left hand, namely {a, s, d, z, x, q, w}.\nG2: Keys predominantly pressed by the right hand, namely {o, p, k, l, n, m, i, j}.\nG3: Ambiguous keys that could be pressed by either hand, namely {r, t, y, u, f, g, h, v, b, c, e}.\nWe observed that keys within groups G1 and G2 are pre-\ndominantly pressed by the left and right hands, respectively,\nacross different users, especially due to their spatial posi-\ntioning on the keyboard (extreme left and extreme right).\nHowever, the keys in group G3 presented ambiguity, with the\nchoice of hand varying from one user to another. Such vari-\nations could arise from individual typing habits or a user\u2019s\ninclination to favor their dominant hand. During the testing\nphase on unseen data, the median energy ratio, E med , is com- R\nputed for all samples for a given test user/victim. The rationale behind computing the median energy ratio is to account for the variability in key pressing intensities among different par- ticipants. Different participants may exert different pressures when pressing keys, leading to variations in the vibrational feedback recorded by the accelerometers. By using the me- dian, we aim to normalize this variability and achieve an adaptive clustering mechanism. Keys with an energy ratio\n200 150 100\n50\nLeft Right\nwhe e lspace\n1e 6 3.0\n2.5 2.0 1.5 1.0 0.5 0.0\nLeft-X Left-Y Left-Z Right-X Right-Y Right-Z\n0\n0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8\nTime (s)\n14.0 14.0 14.1 14.1 14.1 14.1 14.2 14.2 Time (s)\n(a)\nFigure 5: Difference between energy levels of left and right (a) audio channels for keystrokes when typing the word \u201cwheel\u201d, (b) accelerometer channels when pressing key \u2018a\u2019.\nAlthough, the audio channels are affected by the head move- ments and deemed unreliable for the use of key clustering, we discovered an alternative in the accelerometers embedded on both sides of the headset. These accelerometers showed potential in estimating whether a keystroke was made by the right or left hand, based on the motion feedback they recorded. Specifically, the upward and downward head move- ments, which often occur during typing (for instance, when participants glance at the keyboard and then refocus on the screen), is predominantly observed on the x-axis of the head- phone accelerometers. The side-way head movements that may occur during typing are noticeable on the y-axis. The z-axis was observed to be the most stable axis to capture the key press vibrations belonging to left or right hand. Figure 5b shows the accelerometer feedback captured from from our\n(b)\n7\n Energy\nEnergy\n"}, {"chunk": "greater than Emed are classified into G1, while those with R\nan energy ratio less than Emed are classified into G2. Keys R\nwith an energy ratio close to Emed, within a threshold \u03b3, are R\nclassified as G3.\nLater in Section 5.4 we train three different classification\nmodels, one for each group, to predict exact keys within each group. During this prediction, if a test keystroke is initially classified into G1 but the prediction probability is below a certain threshold \u03bb, the test keystroke is then also evaluated by the models for G2 and G3. The final prediction is chosen from the model that yields the highest prediction probability (see Algorithm 1).\nAlgorithm 1 Energy Ratio-Based Key Group Classification Require: ER, Emed, \u03bb\n1: 2: 3: 4: 5: 6: 7: 8: 9:\n10: 11: 12: 13: 14: 15: 16: 17: 18: 19:\n5.4\ninference framework, we extracted 14 MFCC coefficients for\neach audio channel (left and right). To capture the variability\nand characteristics of these coefficients, we computed sev-\neral statistical measures: mean, standard deviation, skewness,\nmaximum value, median, and minimum value. This resulted\nin 14\u00d76=84 features for each channel. Thus, combining both\nchannels, we derived a total of 168 features. In addition to\nthe MFCC features, we also included the Root Mean Square\nEnergy (RMSE) [40] of each keystroke per channel, bringing\nthe total feature count to 170. Building on this, we tested\nseveral models including Random Forest classifier, Decision\nTree Classifier and a Deep Neural Network for our analysis.\nTo optimize its performance, we utilized a Grid Search Cross-\nValidation approach for hyperparameter tuning. As described\nin Section 5.3.2, we train three different models for key groups\nG,G andG usinglabeledtrainingdata.Thetrainingand R 123\n  R\nif ER > Emed then\nif Prediction Probability of G1 < \u03bb then Evaluate using G2, G3 MaxProbability(G1 ,G2 ,G3 )\nelseclassify using G1\ntesting were executed in a Leave-One-Out Cross-Validation (LOOCV) manner, ensuring that a test/victim participant was excluded in each iteration.\n5.5 Keyboard Type Inference\nA preliminary step for an attacker aiming to execute a keystroke inference attack is to infer the type of keyboard the victim employs. Given the distinct acoustic signatures produced by different keyboard types, such as mechanical or membrane, understanding the keyboard type can pave the way for a more targeted and effective attack. In our study, we gathered data from two distinct brands for each of the key board categories: K1: mechanical, K2: membrane, and K3: laptop-based membrane keyboards. The rationale behind using two models for each category was to introduce a level of complexity to the inference task. If the model were trained solely on data from a single brand for each category, it would trivially classify that brand during testing. Our objective with keyboard type inference is to generalize across brands and variations within each category, ensuring the model can iden- tify the overarching category to which they belong. For the purpose of type inference, we segment the keyboard input audio data into 30-second windows, extracting 6 MFCC fea- tures and Root-Mean-Square-Energy RMSE (Equation (1) for each segment. We observed during our experiments that, while keystroke inference demands a much more detailed fea- ture set, keyboard type inference can be effectively achieved with just these 6 MFCC features. Subsequently, we employ a multi-class logistic regression model trained on this data to predict the keyboard type. The keyboards tested in our keyboard type inference experiment are as follows:\nK1: Monoprice MP810 (with red switches) [26] and Aukey KMG12 (with blue switches) [6].\nK2: Logitech K120 [21] and Dynex DX-PNC2019 [12]. K3: Tecknet Ultra Slim Compact [36] and the keyboard of\nthe HP Envy x360 15\" laptop [16]. 8\nend if\nelse if ER < Emed then\nR\nif Prediction Probability of G2 < \u03bb then\nEvaluate using G1, G3\nMaxProbability(G1 ,G2 ,G3 ) elseclassify using G2\nend if\nelse\nif Prediction Probability of G3 < \u03bb then\nEvaluate using G1, G2\nMaxProbability(G1 ,G2 ,G3 ) elseclassify using G3\nend if\nendif\nFeature Extraction and Model Training\n After the key clustering step, we then investigate acoustic based features which could be used to identify individual keys. One such set of features include the Mel Frequency Cepstral Coefficients (MFCC), which have been widely used in the field of speech and audio signal processing, particu- larly for applications such as speech recognition and speaker identification [2]. However, more recently MFCC based fea- tures have been used in other acoustic related applications such as keystroke recognition and acoustic activity recog- nition [19, 32]. The process broadly involves the following steps: (i) First the signal is divided fixed sized frames and for each frame Fast Fourier Transform (FFT) is applied to calculate the power spectrum. (ii) Then, Mel Filter Bank is applied on the power spectrum computed for each frame. The Mel Filter bank is a set of 20-40 (usually) triangular filters that are spaced according to the Mel scale, which ap- proximates the human ear\u2019s response more closely than the linearly-spaced frequency bands. This process converts the frequency power spectrum into Mel spectrum [19]. For our\n"}, {"chunk": " 5.6 Word Prediction\nAfter predicting individual keystrokes, we further look into the possibility of increasing the effectiveness of our attack in a context aware manner by predicting the possible word (com- prising of the inferred keystrokes). To this end, we mainly explored two methods to tackle our word prediction task. The first approach is a naive dictionary-based method, where each sequence derived from the top-k predicted letters (from the aforementioned key prediction models) is cross-referenced with a predefined dictionary. If a sequence matches an entry within the dictionary, it\u2019s deemed a valid word. However, this method has its limitations, especially when the key predictions contain inaccuracies such incorrect key predictions, missing certain keystrokes or having extra keystrokes. Our second method leverages the SymSpell algorithm [14]. SymSpell is a spelling correction algorithm that works by pre-computing possible spelling errors for every word in its dictionary, up to a given edit distance. Instead of searching for possible correc- tions during the lookup, it directly utilizes this pre-computed data to identify close matches. This design allows for rapid and memory-efficient word predictions and corrections, mak- ing it particularly suitable for our scenario due to the possi- bility of presence of missing, incorrect or extra keystrokes. The procedure (see Algorithm 2) starts by initializing the SymSpell library and loading a comprehensive frequency dictionary. Next, given a set of top-k letter predictions, we generate all possible word combinations. For each of these generated terms, we consult SymSpell to gather the closest matching words in the dictionary. This results in a collection of suggested words, each associated with its frequency of us- age. Finally, to provide the most probable corrections, we sort the accumulated suggestions based on their word frequencies and return the top-w predictions as the output. The rationale being that words that appear more frequently in the language (or specific corpus) are more likely to be the intended word when a spelling error is made. In essence, the frequency of usage helps in prioritizing common words over less common ones when suggesting corrections.\n5.7 Experimental Setup\nDue to the absence of published APIs in current generation of commercial headphones that allow for accelerometer data ex- traction, we were compelled to devise our own custom setup to evaluate OverHear. Our experimental setup comprises of a Raspberry Pi, and a 3D-printed over-the-ear headphone pro- totype (see Figure 6). To capture audio, we equipped each earpiece with an Adafruit I2S MEMS Microphone [1] and a MPU-6500 accelerometer [34] to record the motion data. The audio was sampled at a maximum of 96 kHz while accelerom- eter was sampled at a maximum of 500 Hz. The microphones and the accelerometers were connected to the Raspberry Pi via the GPIO interface and a Python script was used to record the data from each microphone/sensor. The data processing and inference framework evaluation was done on a Ubuntu\nAlgorithm 2 Word Prediction with SymSpell.\nRequire: predictions:top-k letter predictions Require: topK: number of words to return\n 1: 2: 3:\n4: 5: 6: 7:\n8: 9:\n10:\nfunctionSPELLCORRECTION(predictions,topK)\nInitialize sym_spell and load dictionary possible_combinations \u2190 GENERATECOMBINA-\nTIONS(predictions)\nInitialize predicted_words_with_counts as empty list for each input_term in possible_combinations do\nGet suggestions for input_term from sym_spell\nAppend unique suggest ions to predicted_words_with_counts\nend for\nSort predicted_words_with_counts by word frequency re- turn First top \u2212 w words from predicted_words_with_counts endfunction\n 22.04 virtual machine with 32GB memory and 32 cores using Python 3.10.\nOur experiments included a diverse range of keyboards to ensure a comprehensive evaluation. We used a AUKEY KMG12 [6], a full-sized mechanical keyboard (104 keys) to represent K1 category. For the K2 category, we utilized a Logitech K120 [21], another full-sized model. To closely replicate a keyboard of modern laptops a Tecknet Ultra Slim Compact keyboard (68 keys) [36], was used (representing the K3 category) This diversity in keyboard types allowed us to assess the robustness and adaptability of our framework across different tactile feedback mechanisms and form factors.\n5.8 Data Collection\nWe recruited 17 participants, in the age range from 18-38, to collect typing data using our custom prototype pair of head- phones. The participants conducted two experiments across three types of keyboard while wearing our custom headset (as described in Section 5.7. The experiments were conducted in- side a closed office space. For the first experiment, they typed individual keys/English alphabets displayed on the screen one at a time, where each key is repeated for five times at random. The second experiment involved them typing 300 English words from a 5000 most frequent words with number of let- ters ranging from three to seven [42]. Participants engaged in\nFigure 6: A user wearing our headphone setup.\n 9\n"}, {"chunk": "the typing tasks using a 24-inch computer monitor. To ensure comfort and a natural typing posture, they were provided with a height adjustable chair, allowing them to choose a seating level they found most comfortable. We did not impose any specific typing techniques on the participants; instead, they were encouraged to type in a manner consistent with their daily habits. The participants also filled out a short survey (see Appendix D) at the end of the experiments which included questions relating to their typing behaviors and headphone usage. Some useful/interesting insights obtained via the sur- vey are given in Appendix E. All participant recruitment and data collection experiments for our study were done under approval from our institution\u2019s Institutional Review Board (IRB).\n6 Evaluation\nIn this section, we comprehensively evaluate the performance of our proposed keystroke inference framework, OverHear, under a wide variety of different experimental settings and conditions.\n6.1 Metrics\nWe use the following metrics for quantifying the performance of OverHear.\nPrecision and Recall. Precision measures the number of cor- rectly predicted keystroke segments out of the total predicted keystroke segments, while recall (or sensitivity) calculates the number of correctly predicted keystroke segments out of the actual keystroke segments. We also use precision and recall to measure the prediction performance of our keyboard type inference module of the OverHear framework.\nTop-kkey Accuracy. This metric evaluates the accuracy of the top-k key predictions. Specifically, if the true label is within the top-k predicted labels, then the prediction is considered correct. We utilized top-kkey accuracy for assessing the per- formance of our OverHear framework at an individual key prediction level.\nTop-kword Accuracy. Evaluates the accuracy of the top-k word predictions. If the true word is within the top-k predicted words, the prediction is deemed accurate.\n6.2 Keyboard Type Inference\nAcross all keyboard type categories, our keyboard type identi- fication model demonstrated robust performance, consistently achieving an accuracy exceeding 0.95 when the training data includes data from the same brand of keyboard. However, when the type inference model is trained using one keyboard brand for each category, the performance slightly degrades, yet except for K2 category of keyboards, both the other cate- gories (see Table 1) demonstrated a recall over 0.95.\n6.3 Keystroke Detection\nOur keystroke segmentation algorithm, as part of the Over- Hear framework, exhibited consistent performance across\nTable 1: Keyboard Type Inference Performance.\n Keyboard Type\nMechanical (K1) Membrane Type 1 (K2) Membrane Type 2 (K3)\nPrecision Recall\n0.86 0.96 0.98 0.76 0.88 0.99\n  various keyboard types (see Figure 7). For keyboard type K1, the precision and recall were both measured at 0.80 (\u03c3=0.05 and \u03c3=0.08, respectively). For keyboard type K2, the preci- sion was 0.78 (\u03c3=0.07) and the recall was 0.77 (\u03c3=0.07). For keyboard type K3, we observed a precision of 0.75 (\u03c3=0.08) and a recall of 0.80 (\u03c3=0.06). While these results indicate stability in performance, there are inherent challenges that contribute to the slightly lower accuracy. One primary chal- lenge arises when keys are pressed quickly in succession. Particularly with adept typists, the acoustic energy from one key can overlap with the subsequent key, complicating the distinction between individual keystrokes. Additionally, the unique typing dynamics of each individual introduce vari- ability. Some users exert varied force on keys, while others occasionally press two keys nearly concurrently. These issues add layers of complexity to the keystroke detection process.\nFigure 7: Keystroke detection performance for different key- boards types.\n6.4 Overall Performance\nAs mentioned earlier, we evaluated OverHear\u2019s performance across three keyboard type categories, K1, K2, K3. The re- sults revealed that, K1, achieved the highest top-5key accuracy of 0.77 and a top-10key accuracy of 0.88. In comparison, K2, recorded a top-5key accuracy of 0.58, and K3, had a top-5key accuracy of 0.53. Mechanical keyboards, i.e., category K1 tend to produce near distinct tactile feedback and sound pro- files for each key press. This unique acoustic signature for each key can make it easier for the system to differentiate between keystrokes, leading to higher accuracy as observed in our results. While larger external membrane keyboards (cat- egory K2) too produce a some amount of tactile feedback, the sound profiles might not be as distinct as those of mechanical keyboards. The smaller, membrane type K3 which closely re- sembles laptop keyboards, typically have keys closer together, leading to overlapping or less distinct sound profiles, espe- cially when keys are pressed in rapid succession. Additionally,\n  Precision Recall\n0.9 0.8 0.7 0.6\nK1 K2 K3\nScore\n10\n"}, {"chunk": " 0.8 0.6 0.4 0.2 0.0\nRF DT DNN\n    K1 K2 K3\n    Accuracy\n the build and material of such keyboards might dampen the sound further, making it harder to infer keystrokes accurately. In evaluating the efficacy of our clustering algorithm, we\ncompared the accuracy of our model with and without the clustering approach. As presented in Table 2, the clustering algorithm considerably enhanced the accuracy across all key- board types. For the mechanical keyboard type, K1, the top- 5key accuracy improved from 0.59 to 0.77. Similarly, for the membrane type, K2, there was a noticeable increase from 0.41 to 0.58. The membrane type, K3, also saw an enhancement in accuracy, with top-5key accuracy rising from 0.37 to 0.52. These results shows the effectiveness of the accelerometer based clustering algorithm in refining the keystroke inference, making it an important component of our OverHear inference framework.\n6.5\nFigure 9: Model comparison (top-5key accuracy).\nSampling Rates\n  0.67\n 0.77\n 0.88\n 0.45\n 0.58\n 0.74\n 0.39\n 0.53\n 0.73\n Top 3\nTop 5 Accuracy Level\nTop 10\n0.8 0.7 0.6 0.5 0.4\nKeyboard Type K3 K2 K1\n 0.8 0.6 0.4 0.2 0.0\nK1 K2 K3\n    96kHz 48kHz 16kHz\n       Accuracy\n Figure 8: Top-kkey accuracy comparison across different key- board types.\nTable 2: Accuracy comparison (top-5key), with and with out the clustering algorithm.\nIn our experiments, we explored the impact of different sam- pling rates on the performance of our OverHear inference framework (see Figure 10), starting from our default rate of 96kHz for the audio signal. Our findings indicate that the performance at 48kHz is nearly on par with that at 96kHz. However, when the sampling rate is further reduced to 16kHz, we observed a considerable degradation in OverHear\u2019s per- formance. This indicates OverHear can work fairly well even at lower sampling rates.\nFigure 10: Top-5key prediction accuracy vs. sampling rates. 6.6 Ambient Noise\nWe evaluated the robustness of OverHear under various am- bient noise conditions. In a university cafeteria setting, the environment was busy with people eating, working on their laptops, and background music playing. The open office space had 2-3 individuals working nearby on computers, accompa- nied by the typical sounds of typing, mouse clicks, and the occasional mobile phone ringing. In contrast, the closed office space provided a quiet environment with minimal background noise. From the results (see Figure 11), it\u2019s evident that Over- Hear\u2019s accuracy is highest in quieter environments, such as a closed office, and decreases with increasing ambient noise, with the cafeteria setting being the most challenging with ac- curacies dropping below 0.45. This trend is consistent across all three keyboard types. This shows that OverHear works well in quieter (ideal) environments, but the accuracy is rea- sonable even in noisier (less ideal) environments.\n6.7 Word Prediction\nOur word prediction technique, leveraging the SymSpell li- brary, as seen in Figure 12, demonstrated considerable ef- ficacy, achieving top-50word accuracies nearing 0.50 across\n Keyboard Type\nK1 K2 K3\nw/o Clustering\n0.59 0.41 0.37\nwith Clustering\n0.77 0.58 0.53\n  In our evaluations, the Random Forest classifier consis- tently outperformed other models across all keyboard types (see Figure 9). Specifically, for K1, it achieved a top-5key accuracy of approximately 0.77, while for K2 and K3, the accuracies were 0.57 and 0.53, respectively. In contrast, the Decision Tree classifier managed a top-5key accuracy of 0.57 for K1 and around 0.33 for both K2 and K3. The Deep Neural Network (DNN) model was the least effective, with accuracies falling below 0.15 for all keyboard categories. The Random Forest classifier outperformed other models likely due to its ensemble nature, effectively capturing complex patterns with- out overfitting. In contrast, the Deep Neural Network (DNN) model struggled, likely because DNNs require substantial amount of data for effective training, beyond the dataset that we collected. Moving forward, exploring alternative models such as single- and few-shot learning techniques could poten- tially offer more robust solutions, especially when training data is limited [41].\n11\n"}, {"chunk": " 1.0 0.9 0.8 0.7 0.6 0.5\n15 20 25 30 35 40 Typing Speed (WPM)\n          Accuracy\n     0.8 0.6 0.4 0.2 0.0\nK1 K2 K3 Closed Office Open Office Cafe\nAccuracy\n     Figure 11: Top-5key accuracy under vs. types of ambient noise.\nall keyboard categories. Further, K1 reached a 0.76 accuracy for top-100word predictions, while K2 and K3 closely fol- lowed with 0.71 and 0.70, respectively. For K1, five out of six, participants achieved an accuracy exceeding 0.60 for top- 50word predictions, with only one participant falling below the 0.40 mark. In the case of K2 and K3, barring one outlier in each category, all participants consistently achieved around the 0.50 accuracy level for top-50word predictions. In con- trast, the naive dictionary-based approach, which relies solely on exact matches, lagged behind. Its limited adaptability to variations in keystroke data meant it consistently registered accuracies below 0.4 for all keyboard types. These results can be attributed to SymSpell\u2019s ability to efficiently handle typographical errors, which aids in more accurate word sug- gestions, especially in the presence of potentially inaccurate key predictions along with extra or missing keystrokes.\n6.9\nFigure 13: Typing speeds vs. key-level accuracy.\nFactors Affecting Accuracy\nIn our analysis of the factors that may be affecting accuracy OverHear, several patterns emerged. For the key group G2, no major misclassification patterns were observed. However, there are instances where the key \u2018k\u2019 is misinterpreted as \u2018i\u2019, and \u2018m\u2019 is confused with \u2018n\u2019. In the G3 group, the keys \u2018j\u2019 and \u2018h\u2019 as well as \u2018y\u2019 and \u2018r\u2019 are often interchanged. Furthermore, the keys \u2018q\u2019 and \u2018w\u2019 consistently exhibit lower accuracy rates. In G1 we observed that the key \u2018z\u2019 is frequently misclassified as \u2018x\u2019, and \u2018x\u2019 is often mistaken for \u2018s\u2019 (see Appendix B for further details). These confusion patterns can be mostly ac- counted to the spatial closeness of these keys on the keyboard leading to similar acoustic profiles that can be challenging to distinguish. Figure 14 visualizes this relationship between the frequency of misclassifications and the Euclidean distance between ground truth and predicted keys on a QWERTY key- board, categorized into our three key groups: G1, G2, and G3. A prominent observation from the plot is that misclassifica- tions are more frequent for keys that are closer in distance, particularly for the G3 group. This suggests that keys in the G3 group are often confused with their immediate neighbors on the keyboard. The plot shows the inherent challenge in distinguishing between keystrokes of adjacent keys, empha- sizing the spatial aspect of the misclassification problem on a physical keyboard layout.\n 0.8 0.6 0.4 0.2 0.0\nK1 K2 K3\nTop-10 Top-50 Top-100 Top-200\nAccuracy\n    2000 1500 1000\n500\n0\n123456789\nDistance Between Ground Truth and Predicted Key\nFrequency of\nMisclassifications\n  G1 G2 G3\n           Figure 12: Top-kword accuracies. 6.8 Effect of Typing Speeds\nWe initially observed that, faster typing speeds does not im- pact our keystroke segmentation step (see Appendix A). En- compassing keystroke segmentation and subsequent process- ing, OverHear demonstrates consistent key prediction perfor- mance across varying typing speeds (see Figure 13). While the majority of participants yielded consistent accuracy, an exception was observed in one participant with a typing speed of approximately 35 WPM, who registered an accuracy below 0.5. Despite this outlier, the overall robustness of OverHear across varied typing speeds is evident, highlighting its adapt- ability to diverse user behaviors.\nFigure 14: Frequency of misclassifications vs. key distance.\nCertain users possess the ability to type without glancing at the keyboard, maintaining a steady gaze on the screen. This consistent posture ensures minimal head movement, leading to relatively stable acoustic profiles. Conversely, users who\n    12\n"}, {"chunk": "frequently look down at the keyboard introduce regular verti- cal head movements. These continuous and pronounced shifts can also influence the acoustic signatures, potentially chal- lenging the models employed by OverHear to accurately dis- tinguish and classify keystrokes. To get a better understanding of such head movements and their potential correlation to the accuracy of OverHear, we analyzed the frequency spectrum of the gyroscope data (collected alongside accelerometer data with the MPU-6500 sensor used in our custom setup). Partic- ularly, we looked at the median frequency of each participant, which can be considered as the frequency below which 50% of the power of the signal lies. A higher median frequency in gyroscope data typically indicates more rapid changes in the signal, which can be interpreted as more intense or faster head movements. As it can be seen in Figure 15, the three partici- pants with the higher median gyroscope showed the lowest top-5key accuracies with values below 0.70 allowing us to po- tentially hypothesize that more intense head movements might introduce more noise or variability in the audio/accelerometer data, making keystroke inference more challenging.\nFigure 15: Participants vs. their median gyroscope frequency.\n7 Discussion\nAttack Impact. The ubiquity of headphones, equipped with advanced microphones and motion sensors, highlights the po- tential reach of our keystroke inference attack. Leading prod- ucts like the Pixel Buds [15], Apple AirPods [4], and the over- ear AirPods Max [3] not only promise superior audio/voice call quality but also come integrated with accelerometers and gyroscopes for a better user experience. These features, while enhancing user experience, inadvertently make these devices susceptible to OverHear. Our results, particularly the high accuracy on external mechanical and membrane keyboards, emphasize the feasibility and potential success of such an attack in real-world scenarios. Question 7 of the participant survey (Appendix D) further corroborates the threat landscape. With 12% of respondents using mechanical keyboards and 47% on membrane keyboards it\u2019s evident that a large seg- ment of users could be vulnerable. Specifically, mechanical keyboards have seen a resurgence in popularity over the past decade, especially among certain demographics, such as, the gaming community, technology enthusiasts and professional typists [35]. Given the projected Compound Annual Growth Rate (CAGR) of 6.79% from 2022-2027, it\u2019s evident that this user base is not only substantial but also expanding [35]. Our\nOverHear inference framework, which demonstrates height- ened efficacy for mechanical keyboards, poses a notable threat to this growing user base.\nMitigations. Noise-canceling features included in most mod- ern headphones offers a promising avenue to counteract the threat of acoustic keystroke inference. Originally designed to minimize ambient sounds, this can be further optimized to specifically target and suppress the unique acoustic sig- natures of key presses. While it\u2019s challenging to completely mute the sound of keystrokes, integrating such targeted noise- canceling features to the headphones can significantly degrade the quality of captured keystroke sounds, thereby reducing the effectiveness of inference attacks. Additionally, employing quieter keyboards, such as Scissor keyboards, can further mit- igate such attacks. Scissor keyboards [17], often in laptops, offer a slim profile and quiet typing due to their scissor-like hinge structure. They outperform mechanical keyboards with audible switches and membrane keyboards with rubber domes by minimizing key-press noise. Further at an operating sys- tem level of the paired smart device (e.g., smartphone or a computer), a system-level service could be introduced to mon- itor the amount and frequency of data being sent by each application. If an app, such as a headphone companion app, starts offloading unusually large amounts of data or at an unexpected frequency, it can be flagged for review. Limitations. While OverHear demonstrates promising re- sults in the context of keystroke inference using headphones, there are several limitations. Given the current accuracy levels, predicting complex passwords, especially those that incorpo- rate a mix of alphanumeric characters, symbols, and vary- ing cases, becomes challenging. This is particularly true for passwords that do not adhere to common linguistic patterns. Further, OverHear is robust only up to certain levels of am- bient noise. In extremely noisy environments, such as noisy cafeterias or situations where multiple overlapping acoustic sources are present, the attack performance is expected to significantly degrade (as also observed by us in Section 6.6).\n8 Conclusion\nHeadphones have transitioned from mere audio playback devices to sophisticated tools equipped with high-definition microphones and accelerometers. This evolution, while en- hancing user experience, has inadvertently opened doors to potential security threats, notably keystroke inference. In this study, we presented OverHear, a framework that adeptly har- nesses both acoustic and accelerometer data from headphones to infer keystrokes achieving a top-5 key accuracy nearing 80% for mechanical keyboards and 60% for membrane key- boards. Further, we were able to achieve top-100 word ac- curacy of over 70% for all categories of keyboards. While our results highlight the vulnerabilities introduced by modern headphones in real-world scenarios, they also emphasize the importance of understanding and addressing these emerging security challenges.\n 0.50 0.25 0.00 0.25 0.50\nParticipants\n                  Median Frequency (Hz)\n    13\n"}, {"chunk": "References\n[1] Adafruit. Adafruit I2S MEMS Microphone. https: //www.adafruit.com/product/3421, 2023. [Online; accessed 15-Oct-2023].\n[2] Shalbbya Ali, Safdar Tanweer, Syed Sibtain Khalid, and Naseem Rao. Mel frequency cepstral coefficient: a re- view. ICIDSSD, 2020.\n[3] Apple. AirPods Max. https://www.apple.com/ airpods-max/, 2022. [Online; accessed 15-Oct-2023].\n[4] Apple. AirPods Pro. https://www.apple.com/ airpods-pro/specs/, 2022. [Online; accessed 15- Oct-2023].\n[5] Dmitri Asonov and Rakesh Agrawal. Keyboard acoustic emanations. In IEEE S&P, 2004.\n[15] Google. Google Pixel Buds requirements and specifications. https://support.google.com/ googlepixelbuds/answer/7544332, 2022. [Online; accessed 15-Oct-2023].\n[16] HP. HP ENVY x360. https://support.hp.com/us- en/document/c06038609, 2023. [Online; accessed 15- Oct-2023].\n[17] KBE team. What Are Scissor Switch Key- boards. https://keyboardsexpert.com/what-are- scissor-switch-keyboards/, 2023. [Online; ac- cessed 15-Oct-2023].\n[18] Stefan Liebich, Johannes Fabry, Peter Jax, and Peter Vary. Signal processing challenges for active noise can- cellation headphones. In ITG-Symposium: Speech Com- munication, 2018.\n[19] Jian Liu, Yan Wang, Gorkem Kar, Yingying Chen, Jie Yang, and Marco Gruteser. Snooping keystrokes with mm-level audio ranging on a single phone. In ACM MobiCom, 2015.\n[20] Xiangyu Liu, Zhe Zhou, Wenrui Diao, Zhou Li, and Kehuan Zhang. When good becomes evil: Keystroke inference with smartwatch. In ACM CCS, 2015.\n[21] Logitech. Keyboard K120. https:// www.logitech.com/en-us/products/keyboards/ k120-usb-standard-computer.920-002478.html, 2023. [Online; accessed 15-Oct-2023].\n[22] Li Lu, Jiadi Yu, Yingying Chen, Yanmin Zhu, Xiangyu Xu, Guangtao Xue, and Minglu Li. Keylistener: In- ferring keystrokes on qwerty keyboard of touch screen through acoustic signals. In IEEE INFOCOM, 2019.\n[23] Anindya Maiti, Oscar Armbruster, Murtuza Jadliwala, and Jibo He. Smartwatch-based keystroke inference attacks and context-aware protection mechanisms. In ACM AsiaCCS, 2016.\n[24] Xiaodong Mao and Noam Rimon. Method and appara- tus for enhancing the generation of three-dimensional sound in headphone devices, April 17 2012. US Patent 8,160,265.\n[25] Philip Marquardt, Arunabh Verma, Henry Carter, and Patrick Traynor. (sp)iphone: Decoding vibrations from nearby keyboards using mobile phone accelerometers. In ACM CCS, 2011.\n[26] Monoprice. Monoprice MP810 Optical Mechan- ical Gaming Keyboard. www.monoprice.com/ product?p_id=34563, 2023. [Online; accessed 15-Oct-2023].\n[6] AUKEY. AUKEY KMG12 Keyboard 104key with Gaming https://www.aukey.com/products/km-g12- mechanical-keyboard-blue-switches, [Online; accessed 15-Oct-2023].\n[7] Jia-Xuan Bai, Bin Liu, and Luchuan Song. I know your keyboard input: a robust keystroke eavesdropper based- on acoustic signals. In ACM Multimedia, 2021.\n[8] BBC. Ring doorbell \u2019gives Facebook and Google user data. https://www.bbc.com/news/technology- 51281476, 2020. [Online; accessed 15-Oct-2023].\n[9] Liang Cai and Hao Chen. On the practicality of mo- tion based keystroke inference attack. In International Conference on Trust and Trustworthy Computing, 2012.\n[10] Christina Summer Chen. Earpieces with gesture control, February 5 2015. US Patent App. 13/959,109.\n[11] Kefei Cheng, Wenqi Li, Liang Zhang, Xiangjun Ma, and Jinghao Chen. Dictionary attacks based on tdoa using a smartphone. In IEEE IAEAC, 2022.\n[12] Dynex. Dynex - DX-PNC2019 Wireless Ergonomic Wireless Keyboard. https: //www.dynexproducts.com/pdp/DX-PNC2019/ 6350929, 2023. [Online; accessed 15-Oct-2023].\n[13] Xiaoran Fan, Longfei Shangguan, Siddharth Rupa- vatharam, Yanyong Zhang, Jie Xiong, Yunfei Ma, and Richard Howard. Headfi: bringing intelligence to all headphones. In ACM WiSec, 2021.\n[14] Wolf Garbe. SymSpell. wolfgarbe/SymSpell, 2012. Oct-2023].\nhttps://github.com/ [Online; accessed 15-\nMechanical Software.\n2023.\n14\n"}, {"chunk": "[27] Sashank Narain, Amirali Sanatinia, and Guevara Noubir. Single-stroke language-agnostic keylogging using stereo-microphones and domain specific machine learn- ing. In ACM WiSec, 2014.\n[28] Oriol Nieto and Juan Pablo Bello. Systematic Explo- ration of Computational Music Structure Research. In International Society for Music Information Retrieval Conference, 2016.\n[29] Christopher Prest and Quin C Hoellwarth. Sports moni- toring system for headphones, earbuds and/or headsets, February 18 2014. US Patent 8,655,004.\n[30] Trusted Reviews. Is your smart TV spying on you? All you need to know about smart TVs and your privacy. https://www.trustedreviews.com/news/smart- tv-privacy-problems-vizio-samsung-lg-sony- panasonic-2952175, 2020. [Online; accessed 15-Oct-2023].\n[31] Tobias Ro\u0308ddiger, Christopher Clarke, Paula Breitling, Tim Schneegans, Haibin Zhao, Hans Gellersen, and Michael Beigl. Sensing with earables: A systematic literature review and taxonomy of phenomena. ACM IMWUT, 6(3), 2022.\n[32] Joseph Roth, Xiaoming Liu, Arun Ross, and Dimitris Metaxas. Biometric authentication via keystroke sound. In International Conference on Biometrics (ICB), 2013.\n[33] Jon R Sank. Microphones. In Audio Engineering Soci- ety Conference: The Art and Technology of Recording, 1984.\n[34] TDK. MPU-6500 Six-Axis (Gyro + Accelerometer) MEMS. https://invensense.tdk.com/products/ motion-tracking/6-axis/mpu-6500/, 2023. [On- line; accessed 15-Oct-2023].\n[35] technavio. Mechanical Keyboard Market by Distribution Channel, Type, and and Ge- ography - Forecast and Analysis 2023-2027. https://www.technavio.com/report/mechanical- keyboard-market-industry-analysis, 2023. [Online; accessed 15-Oct-2023].\n[36] Tecknet. TECKNET 2.4G Wireless Key- board, Ultra Slim Compact Computer Keyboard. https://tecknet.com/products/tecknet-2-4g- wireless-quiet-keyboard, 2023. [Online; accessed 15-Oct-2023].\n[37] Jeffrey J Terlizzi. Systems and methods for noise can- cellation and power management in a wireless headset, October 9 2012. US Patent 8,285,208.\n[38] TheVerge. Anker finally comes clean about its Eufy security cameras. https://www.theverge.com/ 23573362/anker-eufy-security-camera- answers-encryption, 2023. [Online; accessed 15-Oct-2023].\n[39] HeWang,TedTsung-TeLai,andRomitRoyChoudhury. Mole: Motion leaks through smartwatch sensors. In ACM MobiCom, 2015.\n[40] Jian Wang, Rukhsana Ruby, Lu Wang, and Kaishun Wu. Accurate combined keystrokes detection using acoustic signals. In IEEE MSN, 2016.\n[41] Yaqing Wang, Quanming Yao, James T Kwok, and Li- onel M Ni. Generalizing from a few examples: A survey on few-shot learning. ACM Computing Surveys, 53(3), 2020.\n[42] WordFrequency. Introduction to the top 60,000 words in English. https://www.wordfrequency.info/ intro.asp, 2023. [Online; accessed 15-Oct-2023].\n[43] Zhi Xu, Kun Bai, and Sencun Zhu. Taplogger: Inferring user inputs on smartphone touchscreens using on-board motion sensors. In ACM WiSec, 2012.\n[44] Zhiyuan Yu, Zack Kaplan, Qiben Yan, and Ning Zhang. Security and privacy in the emerging cyber-physical world: A survey. IEEE Communications Surveys & Tutorials, 23(3), 2021.\n[45] Tong Zhu, Qiang Ma, Shanfeng Zhang, and Yunhao Liu. Context-free attacks using keyboard acoustic emana- tions. In ACM CCS, 2014.\nA Keystroke Detection vs. Typing Speeds\nFigure 16 illustrates the precision and recall of our keystroke detection algorithm (detailed in Section 5.2 and Section 6.3). Notably, the algorithm\u2019s performance remains consistent even at higher typing speeds.\n15\n"}, {"chunk": "  True jimnlkpo\nopklnmij Predicted\n0.6 0.4 0.2 0.0\n  15 20\n25\n30\n35\n0.90\n0.90\n0.85\n0.85 0.80 0.75\n0.70\n0.75\n0.80 0.75\n0.70\n0.65 0.70\n0.60 0.55\n0.80\n Recall\nPrecision\nTyping Speed (WPM)\nFigure 16: Precision and recall for keystroke detection vs. user typing speed (WPM) for K1.\nB Confusion Matrices for Key Predictions\nFigures 17 to 19 present confusion matrices for key predic- tions across groups G1, G2, and G3. Notably, while G2 and G3 exhibit minimal misclassifications, in G1, most keys sur- rounding \u2018a\u2019 are frequently mistaken for \u2018a\u2019.\nFigure 19: Confusion matrix for group G3 keys. C Word Prediction Under Noise\nFigure 20 illustrates the word-prediction performance in a cafe ambient noise setting. Despite the key prediction accu- racy being notably lower than in quieter environments, top- 100word predictions still approached an accuracy close to 0.60.\n 0.8 0.6 0.4 0.2 0.0\nK1 K2 K3\nTop-10 Top-50 Top-100 Top-200\nAccuracy\n    asdzxqw Predicted\n0.8 0.6 0.4 0.2 0.0\nTrue wqxzdsa\nFigure 17: Confusion matrix for group G1 keys.\nFigure 20: Word-level top-w accuracy under cafeteria ambient noise.\nD Participant Survey\n1. What is your age?\n2. What is your dominant hand? Right, Left\n3. Do you currently own any of the following digital de- vices?\n\u2022 Yes, No - Bluetooth Over-the-Ear Headsets \u2022 Yes, No - Bluetooth Earbuds\n4. How often do you type on a computer keyboard while wearing a pair of headsets/earbuds?\nNever, Rarely, Sometimes, Often, Always\n5. How many hours a day do you perform typing tasks in general?\n  opklnmij Predicted\n0.6 0.4 0.2 0.0\nTrue jimnlkpo\nFigure 18: Confusion matrix for group G2 keys.\n16\n"}, {"chunk": "6. How many hours a day do you perform typing tasks while wearing a headset/earbuds?\n7. What type of a keyboard do you own? Membrane, Mechanical,Not Sure\n8. Where do you typically perform your typing tasks? cafe\u0301, library, classroom, home, other (please specify)\n9. Do you keep your headphones/earbuds near your com- puter/keyboard while not wearing them?\nYes, No\n10. Have you installed the smartphone app that comes bun- dled with your headset/earbuds?\nYes, No\n11. Are you aware that modern headphones and earbuds have embedded motion sensors in them?\nYes, No\nE Insights from Participant Survey Responses\nThrough the responses from our participant survey, we were able to gain the below insights into the individual typing be- haviors and the prevalent patterns of headphone usage among participants.\n\u2022 A majority of participants (52.94%) often type on a com- puter keyboard while wearing headphones or earbuds, with 17.65% doing so always. On average, 11.76% type for 2.5 hours per day with these devices on (see Fig- ure 22).\n\u2022 Regarding awareness of modern headphone technology, 52.94% of participants know that headphones and ear- buds often have embedded motion sensors..\n\u2022 In terms of keyboard ownership (see Figure 23):\n\u2013 47.06% own a membrane keyboard.\n\u2013 11.76% own a mechanical keyboard.\n\u2013 41.18% are uncertain about their keyboard type.\n\u2022 A significant 88.24% of participants keep their head- phones or earbuds near their computer or keyboard when not in use, while only 11.76% store them away (see Figure 24).\n\u2022 As for typing locations, 33.33% of participants typically type at their home or apartment, and 24.24% prefer the library (see Figure 21).\nFigure 21: Distribution of locations for typing tasks.\n       % of Participants\n30 20 10\n0\nhome library classroom office lab\nLocation\n       % of Participants\n40 20 0\nOften Always Rarely Sometimes Frequency\nFigure 22: Frequency of typing on a computer keyboard while wearing headsets/earbuds.\n       % of Participants\n40 20 0\nMembrane Not sure Mechanical Keyboard Type\n Figure 23: Distribution of keyboard types owned.\n      % of Respondents\n75 50 25\n0\nYes No Headphone/Earbud Placement\n 17\nFigure 24: Distribution participants who do/do not keep their headphones/earbuds near the computer.\n"}, {"chunk": "TorMult: Introducing a Novel Tor Bandwidth Inflation Attack\nChristoph Sendner\u2217, Jasper Stang\u2217, Alexandra Dmitrienko\u2217, Raveen Wijewickrama\u2020, and Murtuza Jadliwala\u2020 \u2217University of Wu \u0308rzburg, Germany\n\u2020University of Texas at San Antonio, USA\nAbstract\u2014The Tor network is the most prominent system for providing anonymous communication to web users, with a daily user base of 2 million users. However, since its inception, it has been constantly targeted by various traffic fingerprinting and correlation attacks aiming at deanonymizing its users. A critical requirement for these attacks is to attract as much user traffic to adversarial relays as possible, which is typically accomplished by means of bandwidth inflation attacks. This paper proposes a new inflation attack vector in Tor, referred to as TorMult, which enables inflation of measured bandwidth. The underlying attack technique exploits resource sharing among Tor relay nodes and employs a cluster of attacker-controlled relays with coordinated resource allocation within the cluster to deceive bandwidth measurers into believing that each relay node in the cluster possesses ample resources. We propose two attack variants, C-TorMult and D-TorMult, and test both versions in a private Tor test network. Our evaluation demonstrates that an attacker can inflate the measured bandwidth by a factor close to n using C-TorMult and nearly half n \u2217 N using D-TorMult, where n is the size of the cluster hosted on one server and N is the number of servers. Furthermore, our theoretical analysis reveals that gaining control over half of the Tor network\u2019s traffic can be achieved by employing just 10 dedicated servers with a cluster size of 109 relays running the TorMult attack, each with a bandwidth of 100MB/s. The problem is further exacerbated by the fact that Tor not only allows resource sharing but, according to recent reports, even promotes it.\nI. INTRODUCTION\nIn an era where Internet-based service providers, adver- tisers, and government agencies are increasingly focused on tracking web users and monitoring their activities, privacy- enhancing technologies have emerged as a powerful defense against malicious web-based user tracking. Among these technologies, anonymous communication networks, such as Tor [18] (short for The Onion Router), have demonstrated their effectiveness and are rapidly gaining popularity. Tor relies on more than 7000 volunteer-run servers, called onion routers or relays, to route encrypted web traffic for nearly two million users daily through anonymity-preserving circuits comprised of anywhere between 3 to 8 (normally, 3) of these relays.\nDue to its open-source nature, transparent development process, and appeal to privacy-concerned web users, Tor has attracted considerable attention in the research community. Researchers have extensively investigated various attacks, in- cluding deanonymization attempts, aiming to gain insights into the network traffic flowing through Tor. Some of the significant attack vectors on Tor include website fingerprinting [34], [39], [47], [54], [60], [67], routing [66], [63], [62], end-to-end correlation [46], [48], [51], congestion [37], [38], [43], and side channel [40], [50] attacks. These attacks pose a realistic threat to Tor users\u2019 security and privacy, as there have been multiple reports of their usage in the wild by state-sponsored entities [59], [7], [24]. However, one common requirement for\nall these attacks is that the attacker needs to attract as much user traffic as possible to its servers or relays, all while using as few resources as possible. How an attacker can effectively accomplish this pre-requisite is our main focus in this paper.\nAs an integral part of its regular operation, the Tor network maintains a list of active relays in the form of a consensus file containing useful self-reported and measured state information about the relays in the network, including the estimated bandwidth available at each relay. Tor clients employ a path selection algorithm which utilizes the most recent consensus file as input. This algorithm forms communication circuits composed of relays through which user data is transmitted. To determine the available bandwidth at the relays, Tor employs its bandwidth-scanning techniques that involve the establish- ment of a two-hop measurement circuit through the relay and performing data transfer (downloading/uploading) to a web server along this path. By utilizing this approach, Tor can measure the bandwidth at the relays and incorporate this information into the consensus file.\nThe issue is that measurement circuits created and used during bandwidth measurements are built using only two relays, while traffic needs to pass through at least three relays to ensure anonymity [26]. This makes the traffic generated by bandwidth measurers easily distinguishable from the regular user traffic. Once such measurement circuits are detected, attackers can stop serving user traffic and utilize their entire available bandwidth to forward only measurement traffic, thereby inflating their available bandwidth during measure- ment. It has been shown in the literature that by employing such a strategy, attackers were able to increase their measured bandwidth and probability of being selected for forwarding users\u2019 traffic up to 177\u00d7 [64], [44]. Another straightforward strategy for an inflation attack involves malicious relays mis- reporting their available bandwidth in their descriptors [32]. These relays attempt to increase their share of users\u2019 traffic by providing false and exaggerated reports, regardless of their actual bandwidth capabilities.\nOur study of Tor\u2019s bandwidth measurement mechanisms unveils another critical weakness. Currently, nothing prevents relay operators from deploying them on shared resources, such as physical machines or network links. For instance, several attacker-controlled relay nodes can be hosted using virtual ma- chines executed on a single physical host, or, even if residing on separate physical machines, they can share a network link. We find out that this fact can be leveraged by attackers to even further inflate their measured bandwidth by devoting the entire resources of a physical host (with co-resident relays) and/or of the network link to the currently detected measurement traffic while dropping all the user traffic targeting not just one, but all attacker-controlled relay nodes, thus overall increasing the impact of previously known inflation attacks (with the factor of\narXiv:2307.08550v1 [cs.CR] 17 Jul 2023\n"}, {"chunk": "up to 177\u00d7 [64], [44]) by an additional factor equal to the count of attacker-controlled relays in the cluster. The effectiveness of our attack diminishes when bandwidth scanners simultane- ously measure two or more malicious relays within the cluster. However, the impact of such co-measurements remains limited due to the small number of bandwidth scanners responsible for measuring the entire Tor network. Consequently, the likelihood of such co-measurements occurring is low. Yet, it is interesting to explore how the number of bandwidth scanners influences the inflation factor of the proposed attack.\nContributions. Building upon the insights gained from the above-mentioned observations, this paper provides the follow- ing contributions:\n\u2022 Novel inflation attack strategy: We introduce and in- vestigate TorMult, a novel inflation attack strategy for the Tor network. The core idea is to leverage resource sharing within a cluster of attacker-controlled relays, allowing for the dynamic allocation of networking and computational resources of the entire cluster to a relay currently being measured. Our inflation strategy can be combined with other known strategies (e.g., false and exaggerated bandwidth self- reporting [32], or dropping user traffic during bandwidth measurements [64], [44]), thus providing an additional in- flation factor and further reducing resources required for attracting a sufficiently large amount of user traffic.\n\u2022 Two TorMult attack variations: We propose two attack variants: (i) C-TorMult, and (ii) D-TorMult. In C-TorMult, an attacker deploys Co-resident relays on a single physical host and dynamically assigns the entire host\u2019s computational and networking resources to the measured relay. In D- TorMult, attacker-controlled relays share the network link with a Dedicated server, to which all the measurement traffic, once detected, is diverted. As a result, each malicious relay (measured by the bandwidth scanner) can claim the total bandwidth available on the shared network link.\n\u2022 Attack Evaluation: We evaluated both attack variations through tests conducted in a small private Tor test network1 based on Chutney [4], and are able to empirically demon- strate an inflation factor very close to n and n \u2217 N for C- TorMult and D-TorMult, respectively. To study the effect of diminishing inflation due to co-measurements likely to happen in larger networks, we studied the probability of such co-measurements based on data collected from the real Tor network (bandwidth files) and performed theoretical modeling. Our analysis reveals that the inflation factor grows almost linearly to n with up to 15 relays. However, the attack\u2019s potential diminishes to at least 76% of the linear growth as the number of relays in a cluster increases.\n\u2022 Studying the resilience of existing bandwidth scanning alternatives: We investigate the resilience of other band- width measurement techniques proposed in the literature against TorMult and other inflation attack techniques and identify pitfalls and promising directions. For instance, we show (experimentally) that the state-of-the-art Machine Learning (ML)-based method [69] can effectively (with F1 score 99%) and quickly (in less than 0.5 ms) distinguish user and measurement traffic even in a 3-hop measure- ment circuit by analyzing just headers and metrics such as\n1Attack tests on real Tor network were disapproved by the Tor research safety board\ninter-arrival time of transmitted packets. This proves that increasing the number of relays in a measurement circuit isn\u2019t a viable measurement alternative. From our analysis, it follows that only methods that eliminate measurement traffic altogether but rather leverage user traffic for bandwidth estimations, such as [61], have the potential to provide an inflation-resilient bandwidth measurement solution. Yet, ex- isting solutions of this kind have limitations (e.g., vulnerable to Sybil attacks) that need to be addressed in future work. We also devise less intrusive mitigation strategies, such as co-residency and measurement anomaly detection, that can be used with currently deployed bandwidth measurement methods.\n\u2022 Analysis of Tor: In order to investigate the potential us- age of TorMult in the Tor network by real attackers, we analyzed the Tor network. Our analysis revealed specific characteristics displayed by certain Tor relays that could potentially serve as indicators of an ongoing TorMult attack. For instance, we discovered that some relay families offer similar bandwidth and share the same uptime, while others leverage alternate port numbers, which might imply the co-resident execution of Tor relay clusters. While we lack the means to definitively confirm the malicious nature of those relays or relay families, we propose a strategy that bandwidth scanning services could employ to validate our hypothesis.\nIn summary, the paper contributes a novel inflation attack strategy, evaluates its effectiveness, explores the resilience of existing bandwidth scanning techniques, and provides an analysis of the Tor network to identify potential indicators of ongoing attacks. Overall, our work strongly advocates for the pursuit of additional research focused on the development of inflation-resilient bandwidth measurement techniques.\nOutline. The remaining part of the paper is organized as follows. Section II provides a concise overview of back- ground information on Tor. In Section III, we define our adversary model and introduce underlying attack techniques. The evaluation results of our attack are presented in Section IV, accompanied by additional insights gained on Tor in Section V. Section VI discusses the resilience of our attack in relation to existing solutions and explores potential countermeasures. Furthermore, Section VIII delves into related works focusing on Tor inflation attacks. Finally, we conclude our findings in Section IX.\nII. BACKGROUND\nIn this section, we introduce the technical background related to Tor and its bandwidth measurement protocols.\nTor Relays and Circuits. Tor users, also known as clients, select three or more relays randomly from the Tor network to establish a communication circuit. The initial hop of this circuit, also known as the guard relay, serves as the entry point for client connections and typically remains in use for 2-3 months before being rotated. To be considered a guard relay, it meets specific criteria, including stability, sufficient uptime (typically 8-68 days [16]), and a minimum bandwidth of 2 Mbps. The concluding relay in this anonymity-preserving communication circuit is known as the exit relay. It represents the last hop, responsible for transmitting the client\u2019s traffic to\n 2\n"}, {"chunk": "its desired destination on the Internet, beyond the Tor network. Consequently, the IP address visible to service providers is that of the exit relay, ensuring the client\u2019s IP address remains concealed. The relays between the guard and the exit relays, known as middle relays, serve as intermediate hops within the circuit. They simply forward the traffic in both directions, enabling communication between a Tor client and its intended destination on the Internet. Tor relays are run by a global community of volunteers known as relay operators. One such operator can provide multiple relays grouped into families. The Tor network also allows for the hosting of two Tor relays using the same public IP address [12].\nDirectory and Bandwidth Authorities. When establishing connections, Tor clients select relays for a circuit from a list supplied by specialized entities known as Directory Authorities (DAs). These DAs maintain an up-to-date roster of active relays, including their flag status (guard, middle, or exit) and bandwidth information. The DAs update this list every hour, and the consensus among the DAs is cryptographically signed and made available for clients.\nA subset of these DAs, typically six in number, also serve as Bandwidth Authorities (BAs). These BAs are tasked with the additional responsibility of conducting active measurements to estimate the available bandwidth of Tor relays. It is worth noting that these six BAs are responsible for measuring more than 7000 relays (with each BA typically running 4-5 parallel measurement threads). The BAs have a limited timeframe of approximately 60 minutes to complete the measurement round and to include results in the subsequent consensus file [20]. Furthermore, there are occasions where BAs may be temporarily out of service for several hours or even up to a few months due to various reasons such as updates, deployment issues, or ongoing attacks. Consequently, many measurements may be incomplete or missing during these periods.\nBandwidth Measurements in Tor. The initial bandwidth scanning mechanism used by BAs was the TorFlow scanner in 2011 [55], [28]. However, it has been gradually replaced by the Simple Bandwidth Scanner (SBWS) [14] mechanism since 2018 [3]. Our focus in this work primarily revolves around SBWS as it has completely replaced TorFlow by now [3].\nBoth TorFlow and SBWS methods employ bandwidth measurement by downloading large files multiple times from a web server through two-hop circuits. It is important to note that circuits with two relays do not provide anonymity [26], hence, the measurement traffic can be trivially distinguished from user traffic. In SBWS, the first relay in the circuit is the target relay being measured, while the second relay is a randomly selected exit relay that is at least twice as fast as the target relay [36]. The web-server provides a 1GB file over HTTPS for the SBWS scanner to download. The SBWS scanner randomly selects a byte range between 0 and 1GB, typically in 16MiB increments, such as 0-16MiB or 16MiB-32MiB, and so on. If the download completes in less than 5 seconds, the range is expanded, and if it takes more than 10 seconds, the range is reduced. Once an appropriate range is determined, five files of appropriate size, meaning they can be downloaded within the time range of 5-10 seconds, are downloaded and the number of bytes and the time taken for each file download is recorded [8]. As such, it follows that one measurement takes at least 25 seconds.\nIt is noteworthy that the bandwidth files generated by both SBWS and TorFlow methods contain only a single timestamp per measurement, indicating the end of the measurement process. However, they do not include the starting timestamp or the duration of the measurement. This omission is significant because it prevents the deterministic reproduction of the mea- surement timeline from the bandwidth files. This information would be valuable, for instance, when identifying co-measured relays (as discussed in Section IV-E). Once valid measurements are obtained, both SBWS and TorFlow incorporate them into the bandwidth file, which is subsequently forwarded to the DAs for aggregation.\nBuilding Consensus. Bandwidth measurement files, also known as BA\u2019s votes, are processed by DAs to aggregate the results and compute the bandwidth weights in accordance with the Tor directory protocol [22]. In essence, the consensus weight for each relay is calculated based on its self-reported bandwidth and the bandwidth measured by BAs using band- width scanners. It is important to note that SBWS computes bandwidth weights relative to all Tor relays. The resulting consensus file is signed by all the DAs and then distributed to Tor clients.\nDespite the presence of BAs that assist in cross-verifying self-reported relay bandwidth values by conducting actual measurements, an attacker can still effectively execute inflation attacks through a selective denial-of-service (DoS) strategy. In this scenario, a malicious relay only responds to measurement traffic while dropping all other user traffic [45]. These attacks are feasible due to the publicly available identity information of the BAs, such as their IPv4 and IPv6 addresses [21]. Consequently, the detection of measurement traffic originating from the BAs becomes straightforward upon the arrival of the first packet.\nIII. TORMULT ATTACKS\nIn this section, we start by introducing the adversary model and discussing the capabilities of the attacker. Following that, we present two variants of TorMult, namely the co-resident relay attack (C-TorMult) and the dedicated server attack (D- TorMult).\nA. Adversary Model & Capabilities\nWe consider an adversary who controls multiple instances of Tor relays, either as physical machines, virtual machines, or processes/dockers in the same machine. The adversary controls a machine with multiple public IP addresses. For the D-TorMult variation, the adversary additionally controls the network router or gateway between the Internet and the servers running the relays.\nFurthermore, we assume that the attacker is able to dis- tinguish measurement and user traffic in real-time. Currently, this can be trivially accomplished in Tor, as SBWS scanners utilize 2-hop circuits for the measurements (Section II). In Section VI-A, we also show that Machine Learning techniques can effectively distinguish user and measurement traffic in 3- hop circuits.\nWe further assume that the adversary possesses the capabil- ity to promptly forward each type of traffic to a preferred Tor relay instance with minimal delay. Specifically, the adversary\n3\n"}, {"chunk": " C-TorMult Co-resident Server\n        Clients\nBandwidth Authority\nTor Traffic\nTor Relay 1\n(A Measured Relay)\nTor Relay 2\nTor Relay 3\nTor Relay 4 Tor Relay n\n    Traffic Classifier\nMeasurement Traffic Client Traffic\n    directs measurement traffic to a high-resource, high-bandwidth relay while diverting other traffic to a low-resource relay or dropping it altogether with the goal of achieving bandwidth inflation.\nB. High-level idea and attack variations\nIn this study, we present and explore TorMult, a novel tactic for carrying out inflation attacks on the Tor network. Our main concept revolves around utilizing resource sharing among a group of relays under the control of the attacker. This enables the cluster to dynamically allocate networking and computational resources to a relay whose bandwidth is currently being assessed. By combining our inflation strategy with other established techniques, such as false and exag- gerated bandwidth self-reporting or selectively dropping user traffic during bandwidth measurements, we can amplify the inflation effect and minimize the resources needed to attract a substantial volume of user traffic.\nWe introduce two versions of TorMult, namely C-TorMult and D-TorMult. C-TorMult capitalizes on the utilization of shared bandwidth and computational resources from a single server among all the relays hosted on it. In contrast, D- TorMult takes this concept to the next level by expanding the distribution of resources across a network that operates behind a router.\nC. C-TorMult - TorMult with Co-Residing Relays\nDesign. As shown in Fig. 1, the attacker operates several co- residing Tor relays as a cluster within a machine (i.e., server) in the C-TorMult attack. Each co-resident relay can be operated as an additional CPU process, a Docker container, or a Virtual Machine (VM) inside the physical machine, up to two of them using a unique public IP address. Every relay must define a unique combination of IP address and port number in its configuration. One advantage of deploying co-resident relays as separate processes is allowing an attacker to simply alter the Tor relay configuration to different port numbers and IP addresses for each relay, minimizing the configuration and computational overhead. Once the measurement traffic directed towards one of the co-residing relays is detected by the Traffic Classifier, the regular user\u2019s traffic is dropped, thus giving the entire bandwidth and computational resources on the physical machine to the bandwidth scanner, leading to an inflation of the measured bandwidth. We note that the bandwidth inflation strategy based on dropping the user traffic was previously proposed and evaluated in [64], [44]. Previous works, however, focused on individual relays and did not consider scenarios with clusters of co-resident relays. Hence, beyond known attack techniques, our attacker can further inflate the bandwidth by dedicating resources of the entire cluster, not just of the single relay server, to the measured relay. This implies that the inflation factor can be further amplified by the number of co-resident relays.\nWhile it can potentially happen that two co-residing relays are co-measured at the same time, we show in our analysis presented later in Section IV-E that this does not happen very often. With only six BAs responsible for measuring about 7000 relays, and despite the fact that each BA runs 4-5 parallel measurement threads, the probability of such a co- measurement is insignificant, with up to 30 co-residing relays in one cluster.\nFig. 1: C-TorMult: TorMult with Co-Resident Relays.\nAttack Instantiation. An attacker can instantiate the Traffic Classifier (see Fig. 1) either as an IP filtering system or a machine learning technique. However, information about the BAs, including their current IPv4 and IPv6 addresses, is available publicly at Tor Metrics platform [21]. To detect two-hop measurement traffic originating from BAs, we utilize a filter based on BA IP addresses obtained from the same platform. This filter, implemented using Netfilters [17], allows us to distinguish such measurement traffic right from the time of arrival of its very first packet and drop user traffic during measurement.\nWe have various choices available for executing the relay deployment, including the usage of processes, containers, or virtual machines. Given the increased computational require- ments associated with containers and virtual machines, we opt to utilize processes for launching our attack. For each relay, we create separate configurations and start a Tor process based on the corresponding configuration file. To ensure proper functioning, each Tor relay configuration requires a distinct combination of IP address and port number when employing processes. In contrast, an attacker could leverage Docker containers to eliminate the necessity of specifying these details in the configuration files and instead adopt a more dynamic approach utilizing the Docker ecosystem.\nD. D-TorMult - TorMult with Dedicated Server\nDesign. In the D-TorMult scenario, the attacker has control over a network segment and utilizes a physical router or switch to filter and manipulate traffic (see Fig. 2). This is different from the C-TorMult attack, where traffic filtering and routing functionality is co-resident with the Tor relays (i.e., happens inside the same physical machine). As shown in Fig. 2, the attacker allocates a high-resource dedicated server to handle measurement traffic, while low-resource servers (virtual machines or cost-effective physical machines) are used to host a Tor Relay Cluster and to handle regular user traffic. Each Tor Relay Cluster can accommodate its own cluster of co-resident relays, similar to the C-TorMult attack.\nWhen the attacker-controlled router or switch detects mea- surement traffic, it forwards the traffic to the dedicated server. This allows all the attacker-controlled relays to falsely claim the total available bandwidth allocated to the dedicated server, similar to the behavior in C-TorMult. Meanwhile, the relay clusters could continue serving client Tor traffic, e.g., for\n4\n"}, {"chunk": "the purpose of intercepting it and conducting further de- anonymization attacks without much impact on the measure- ment traffic.\nFig. 2: D-TorMult: TorMult with Dedicated Master Server\nAttack Instantiation. The attack scenario of D-TorMult can be instantiated using physical servers and routers. However, the cost of such a setup would be substantial due to the need for a router with multiple public IPv4 addresses. Hence, such a setup is generally more suitable for state-sponsored attackers or other powerful adversaries. For cost-efficiency reasons, we instantiated a virtualized version, where the router was deployed using a VM. Each relay cluster VM is connected to the virtualized router using OpenVPN connections. As such, we also refer to this attack instantiation as \u201dtunneled\u201d version. In contrast to the instantiation of C-TorMult, the relays in D-TorMult are running in Docker containers. We chose containers since the orchestration of many relays is easier using descriptive definitions via Platform as a Service (PaaS) tools.\nIV. EVALUATION\nIn this section, we will begin by outlining the ethical con- siderations we adhered to during our evaluation. Next, we will present the evaluation environment for our attacks. Following that, we will present the evaluation results for both C-TorMult and D-TorMult. These results will demonstrate the impact and success of the attacks in terms of inflating the measured bandwidth of the attacker-controlled relays. In addition, we will provide a theoretical analysis of the diminishing impact on the inflation factor that can occur when two or more Bandwidth Authorities (BAs) simultaneously measure the bandwidth of the same attacker-controlled relay. Finally, we determine the required amount of attack resources to gain control over a specific part of the Tor Network.\nA. Ethical Considerations\nWe initiated the process of responsible disclosure with the Tor team by submitting a bug report via Tor\u2019s bug bounty program on HackerOne [19]. Additionally, we contacted the Tor Safety Board [13] to request permission to conduct our experiments on the live Tor network. Unfortunately, our request was declined due to concerns about potential disruptions to user traffic and the quality of service provided by the Tor network. As a result, we were recommended to perform our experiments with special Tor experimentation tools (i.e., a private Tor network), which we precisely did, as described in Sections III-C and III-D. Our objective was to ensure\nthe ethical conduct of our research while contributing to the enhancement of the Tor network\u2019s security and privacy capabilities.\nFurthermore, in the experiments detailed in Section VI-A, we gathered both self-generated measurement traffic and client traffic from the real Tor network. It is important to empha- size that when generating measurement traffic, we strictly adhered to the guidelines provided by the Tor Safety Board. Specifically, we scheduled the measurements at different time intervals and utilized various guard and exit relays to prevent any potential denial-of-service (DoS) issues. Regarding the collection of user data, we meticulously designed our process to fully comply with the European General Data Protection Regulation (GDPR) requirements [11]. We particularly focused on the principle of data minimization (Article 5c) and the regulations for collecting data for scientific purposes (Article 89). As a result, the user traffic we collect is limited to the relay node positioned in the middle, which means the captured packets contain information about the guard and exit relays but do not reveal any details about the users or the specific services they accessed. Additionally, we exclusively capture packet headers such as TCP/IP headers, including TCP high- precision timestamps, while disregarding payloads that carry (encrypted) data.\nB. Evaluation Environment\nOur experimental setup includes a host machine running Debian Bullseye with 32/64 Cores/Threads, 126 GB of RAM, and 3.2 TB NVMe disk space. We instantiate our evaluation environment on this host by running our own private Tor test network. This environment is used for both attack evaluations. First, we create the Tor configuration files for a private Tor test network using Chutney [4], which allows us to create the Tor configuration files based on our input. Chutney can run a private Tor test network as processes. However, this won\u2019t be sufficient for us to instantiate the scenario where (only) co-resident Tor relays share computational resources. Hence, we use Chutney only for bootstrapping the Tor test network configuration. Our Tor test network comprises three DAs, five exit relays, and two clients (see Fig. 3). Additionally, the evaluation environment contains a BA, a web server, and a connection to the internet. Furthermore, we have the flexibility to dynamically add relays to the private Tor test network even after the evaluation environment has been established.\nFig. 3: Evaluation environment instantiated on the host.\nAfter the bootstrap via Chutney, these configuration files are used to create a virtualized environment using a hypervi- sor. Here, we use Vagrant [25] as an orchestration tool and VirtualBox [52] as the targeted hypervisor. Both (Vagrant and VirtualBox) allow us to: (1) Emulate resources of a server\n       Clients\nBandwidth Authority\nTor Traffic\nRouter\n1 MB/s\nTor Dedicated Relay Server\nTor Relay Cluster 1\nRelay 1 Relay n\nTor Relay Cluster 2\nRelay 1\nRelay n\nTor Relay Cluster 3 Relay 1\nRelay n\nTor Relay Cluster N Relay 1\nRelay n\n         Measurement Traffic Client Traffic\n   25 MBps 25 MBps\nTor Clients Unlimited\nBandwidth Authority\nDA/Guard/Middle Relay Guard/Middle/Exit Relay\nPrivate Tor Test Network 50 MBps\n200 MBps\n200 MBps\n50 MBps\n  200 MBps\n50 MBps 50 MBps\nDestination Client Traffic\nUnlimited\nDestination Web Server\n50 MBps\n5\n"}, {"chunk": "with VMs (not directly possible using Chutney). (2) Create a network environment with bandwidth limitations. A VM is a virtualized physical platform that can run a single relay, a dedicated server, or a cluster of co-residing relays. The DAs, exit relays, and client relays, previously defined, all operate within their respective VMs. Each VM has two vCPUs and 4 GB RAM if not otherwise declared.\nSince we conduct our TorMult attacks in a virtual setting with a Tor test network, the inflation factor must be computed the same way as in the real Tor network. As a result, we deploy an SBWS instance for bandwidth measurement and report the mean bandwidth published by SBWS. Thus, we have a separate VM for the BA (using SBWS) and another VM serving as the destination web server for measuring purposes. To control the network bandwidth for the VMs, we make use of VirtualBox\u2019s bandwidth limitation mechanism. Specifically, we set the bandwidth limit to 200 MBps for the DAs, 50 MBps for the relay VMs, 25 MBps for the clients, and leave the BA and the web server with unlimited bandwidth.\nOnce the VMs are instantiated, we utilize Ansible [1] playbooks to orchestrate the installation of the Tor package [12] and include the configuration files. Furthermore, the SBWS service is configured to use our target web server as a measurement destination. This enables us to measure each relay\u2019s bandwidth in our evaluation environment. Next, we run a VM for each relay (i.e., DAs, BA, clients, exit relays) with a unique IP address and a unique set of ports. The most important configuration is the port number, as this value will be advertised for incoming Tor connections. The corresponding ports are then opened in the firewall to allow incoming packets. Finally, we start each relay as a separate CPU process.\nAfter setting up the private Tor test network\u2019s benign en- tities, we include malicious entities such as relays performing the TorMult attacks and a single malicious relay dropping user traffic. We also set identical \u201cMyFamily\u201d values for malicious relays of our TorMult attacks by adding the identity fingerprints of each relay so that the clients avoid using more than one of them in the same circuit (i.e., avoid using middle and guard relays in the same circuit), thereby avoiding an overload on our server due to \u2018short circuits\u2019.\nTo introduce traffic in our network, the clients request the download of random files. To establish a baseline, we measure the provided bandwidth of our test networking using the SBWS service without an ongoing TorMult attack (e.g., only a single malicious relay dropping user traffic is deployed, but no clusters). The baseline measurement indicated a bandwidth of approximately 25 MBps. This value served as the starting point for our subsequent evaluations and comparisons.\nC. Evaluation of C-TorMult\nIn our implementation of C-TorMult, we deployed five malicious relays in a single VM to assess their effectiveness within our evaluation environment. Each of these relays was executed as a separate process for ease of deployment. It\u2019s important to note that the choice of five relays was determined by the computational limits assigned to the VMs used in our setup, and this number can be adjusted accordingly. Addition- ally, we conducted tests using a deployment strategy in which co-resident relays were introduced to the network at staggered\nintervals, ranging from a few hours to a few days. This approach was implemented to minimize the likelihood of co- resident relays being simultaneously measured in the actual Tor network. The attack is launched once all deployed relays are connected to our Tor test network. We activated our IP-based traffic detection mechanism (as outlined in Section III-A) to distinguish measurement traffic from the BA and drop user traffic during measurement.\nWe observed that with the addition of any new relay, the average of the measurement reported by SBWS after at least three measurements slightly changes, as depicted in Fig. 4. For example, the average measurements of the \u2018blue\u2019 relay (Relay 1) steadily increase. We have noticed that the mea- surements obtained from new relays surpass the established baseline. Upon investigation, we discovered that the baseline measurements incorporate some \u2019unlucky\u2019 measurements. A similar observation can be made regarding the measurements of C-TorMult. Slight changes are caused by the encryption/de- cryption and the overhead introduced by packet dropping that occurs until user connections are closed. Further, exit relays involved in the measurement circuit may also be used by other circuits in our Tor test network, which can potentially reduce the impact of the attack, e.g., measured bandwidth. As seen from Fig. 4, C-TorMult attack strategy allows an attacker to boost an inflation attack by a factor above n linearly due to variance in the measurements.\n  160 140 120 100\n80 60 40 20\n0\n12345 n, Number of Relays\nSum of Measurements in MB/s\n    Relay 1 Relay 2 Relay 3 Relay 4 Relay 5\n24.77\n35.61 27.63\n32.36\n36.75 36.71\n35.35 34.27 28.88 30.22\n34.65\n33.33\n35.34\n33.97\n30.97\n6\nFig. 4: C-TorMult - Measurements for 5 co-resident relays\nD. Evaluation of D-TorMult\nFor D-TorMult, we instantiate three relay clusters as VMs (with a bandwidth limit of 25 MBps), each hosting and carrying a cluster of six Tor relays as Docker containers in the same physical platform as the virtual router (also a VM with 200 MBps bandwidth limit). Further, we add a dedicated relay server with 6 vCPUs, 12 GB RAM, and apply a bandwidth limit of 50 MBps. The rest of the evaluation environment is the same as in our experiments for C-TorMult.\nWe generate continuous user traffic to each of the six relays deployed in the three relay cluster VMs. We simulated the behavior of the BAs by running an instance of SBWS to measure the bandwidth of the relays. As a result of SBWS measurements, each relay claimed more than a fifth (10 MBps) of the virtual server\u2019s bandwidth, which is reduced from 50 MBps due to the VPN, routing, and Tor\u2019s overhead. As shown in Fig. 5, the attacker claimed over 65 MBps for all six relays in Cluster 1. Just by adding two additional clusters to the VPN router, an attacker can achieve an impressive 204.43 MBps with 16 relays in three clusters.\n"}, {"chunk": "The results demonstrate that the D-TorMult attack variation exhibits a linear relationship with the number of relays n in each cluster, which are distributed across N relay cluster servers. As a result, the attacker has the ability to amplify the inflation by a factor of nearly half n \u2217 N by combining our attack with any other inflation attack. This means that the attack\u2019s impact can be significantly increased by scaling up the number of attacker-controlled relays inside a cluster and increasing the number of attack servers (i.e., clusters).\nComparison of C-TorMult and D-TorMult. When compar- ing C-TorMult and D-TorMult attack versions, it is evident that the routing and VPN overhead significantly affect the available bandwidth in D-TorMult. Nonetheless, the practical expenses associated with deploying numerous servers on the real Tor network are higher when employing C-TorMult. Conversely, D-TorMult offers a more cost-effective alternative, enabling the attacker to acquire a small server and multiple IPs.\nindicates the end of a measurement. However, to calculate co-measurements, it is crucial to have information about the duration of the measurement, which can only be determined by knowing the start timestamp as well. To address this gap in knowledge, we employed a method of creating speculative realities or simulations. In these simulations, we randomly assigned start timestamps while adhering to known constraints such as the minimum duration of the measurement. We then analyzed the results from multiple simulations and calculated the average values of measurement durations. This approach allowed us to estimate the coincidence rate by simulating different measurement scenarios and obtaining insights into the likelihood of relays being measured simultaneously. By conducting this analysis, we gained valuable information about the coincidence rate in the Tor network and its impact on the effectiveness of co-resident relay attacks.\nMeasurement Duration. To analyze the duration of mea- surements in the collected bandwidth files, we conducted the following steps: First, we obtained the bandwidth files from all Bandwidth Authorities (BAs) for the months of May, June, and July in 2022 from CollecTor [5]. This dataset consisted of 10,440 files from 2,208 measurement rounds, providing a comprehensive view of the measurements conducted dur- ing that period. Due to the downtime of the \u201dmoria1\u201d BA since April 2022 and intermittent downtime of other BAs, we observed a limited number of bandwidth files per hour during data collection. On average, we had only four or five bandwidth files available per hour. Second, we extracted the fingerprints of the measured relays for each hour using the Stem library. The fingerprint uniquely identifies a relay in the Tor network and allows us to track its measurements over time. Third, since the bandwidth files only provide the ending timestamp of a measurement, we needed to infer the duration of the measurements. We relied on the information provided in the SBWS documentation, which states that a single measurement takes at least 5 seconds but no more than 10 seconds. Based on observations, where measurements from the same BA were found to be less than 25 seconds apart, we have accounted for BAs employing multiple processes or threads for measurement. To gain further insights into measurement duration, we randomly assigned each measure- ment a thread identifier, ranging from 0 to n, based on the ordering of the measurements by their ending timestamp. We calculated the duration of each measurement by subtracting the ending timestamp of the (i \u2212 1)-th measurement from the i-th measurement. In cases where an existing identifier did not satisfy the 25-second constraint (the minimum measurement duration), we incrementally created a new identifier (n + 1). Since there are numerous possible combinations of thread identifier arrangements, we repeated the random assignment process for 120 iterations.\nIn the majority of iterations (88.37%), the measurements were assigned four unique threads, fulfilling the 25-second constraint. In 99.49% of the random assignment iterations, the BAs utilized between one and six threads for their measure- ments. We considered measurements that were less than 50 seconds apart in these timelines to be executed sequentially without failed measurements in between. This assumption is based on the observation that the duration of a measurement can be calculated by subtracting the end timestamp of the previous measurement (i \u2212 1) from the end timestamp of\n  200 175 150 125 100\n75 50 25\n0\n123 N, Number of Servers\nSum of Measurements in MB/s\n    Cluster 1 Cluster 2 Cluster 3\n11.43 11.49 11.38 11.34 10.63 10.57\n12.50 11.18 11.74 11.25\n11.44 11.60\n11.45 11.61\n11.43 11.60 11.32 11.82\n11.98 11.53 11.35 11.50 11.16 11.57 11.13 11.34 10.98 11.27 10.72 11.25\n11.15 11.33 11.47 11.54 11.61 11.43\nFig. 5: D-TorMult - Measurements for 3 clusters with 6 relays each.\nE. Exploring the Inflation Factor\nThe presence of multiple relays in an attacker\u2019s co-resident cluster increases the likelihood of simultaneous measurements, also known as \u201dcoincidence,\u201d occurring on multiple relays. This coincidence phenomenon reduces the ability of these co- resident relays to falsely claim the total available bandwidth on the co-resident server, resulting in a decrease in the inflation factor. This effect didn\u2019t manifest in experiments we conducted in Section IV-C and Section IV-D due to the small sizes of attacker-controlled clusters.\nThe coincidence rate refers to the probability of measure- ments occurring simultaneously on more than one co-residing relay within the cluster. It quantifies the frequency at which multiple relays in the cluster experience measurement events at the same time, which impacts the effectiveness of the inflation attack. By calculating the coincidence rate, an attacker can make informed decisions regarding the number of co-resident relays to deploy in order to maximize their expected bandwidth inflation gain or inflation factor.\nWe conducted an analysis of the coincidence rate in the real Tor network by examining the published bandwidth files that contain measurement information from the Bandwidth Author- ities (BAs). The objective of this analysis was to determine the number of relays from a selected group that were co-measured, meaning they were measured simultaneously.\nA challenge in this analysis is that the bandwidth files provided by the BAs only include a single timestamp, which\n7\n"}, {"chunk": "     Bandwidth Scanner\nmaatuska-1 longclaw-1 bastet-2\n10:15:30 10:15:50 10:16:10 10:16:30 10:16:50 10:17:10 10:17:30 10:17:50 Time\n   Event 1\nnt 2\nnt 3\n Relay 4 Relay 5 Relay 1 Relay 3 Relay 2\nEve\nEve\n the current measurement (i). If there are failed measurements in between, the resulting duration would exceed 50 seconds, indicating that the two measurements were not executed se- quentially. For those measurements meeting the sequential execution criteria, we calculated a median measurement dura- tion of 39 seconds. This calculation provides an estimation of the typical duration for measurements conducted by the BAs, considering the constraints and observations described above.\nCoincidence Rate. For our experiment, we focused on a specific group of relays within the Tor network. After ana- lyzing various families of relays, we decided to work with the \u201dArtikel10\u201d family [2], which consists of 120 relays with a combined total bandwidth of 2069.17 MBps. This family showed indications of co-residing relays, such as multiple pairs of relays sharing the same IP address. Additionally, within the family, there were several sets of relays that exhibited the same up-time and advertised similar bandwidth values. These observations suggested that these relays might be deployed on the same physical machine, exhibiting behavior similar to our C-TorMult attack.\nTo determine the coincidence rate, we utilized the insights gained earlier regarding measurement duration. We assigned each measurement a start timestamp that occurred 39 seconds before the measurement\u2019s end timestamp. By doing this, we simulated the duration of the measurements. To investigate the coincidence rate, we selected a random subset of N relays from the \u201cArtikel10\u201d family and filtered the bandwidth files to include only the relays present in our chosen set. We then examined the measurements within the filtered dataset and identified those with overlapping ranges. An overlapping range indicates that another measurement started prior to the current one and was still ongoing, or that a measurement started during the current measurement.\nWe proceeded to count the occurrence of specific events, namely, the number of simultaneously measured relays out of the N relays in our set. We varied the value of n from 1 to N to analyze the incidence of simultaneous measurements across different numbers of relays.\nIn Figure 6, we illustrate an example of how the counting of measurement events is performed. The timeline represents the measurement periods for a group of five relays, where three different events occur. In the first event (Event 1), Relay 4 (blue) is measured separately without any overlap with other relays. The second event (Event 2) shows an overlap between the measurements of Relay 1 (red) and Relay 3 (green). This overlap results in two out of the five relays being counted as co- measured since their measurement periods coincide. Similarly, the third event (Event 3) exhibits an overlap among three out of the five relays, namely Relay 1, Relay 3, and Relay 5.\nAlthough short periods of overlap, even less than one second, may cause a minor delay in measurement results, we counted all the simultaneous measurements regardless of the overlap duration. To calculate the probability of each event, we compute the ratio of its occurrence to the total number of measurements within the three-month time period. This allows us to determine the likelihood of each event happening relative to the overall measurements conducted during that period.\nMeasurement Distribution. In Fig. 7a, we present the dis- tribution of measurements among the selected relay set. We\nFig. 6: An example of measurement events.\nobserved that the occurrence of three or more relays being co-measured is rare when the number of relays ranges from 1 to 30. However, as the number of relays increases, the probability of two relays being co-measured also increases. The probability reaches its peak at 27.91% when there are 120 relays in the set. Nonetheless, the majority of relays are still measured individually, accounting for 59.17% of the measurements. This allows them to claim the full bandwidth of the dedicated server.\nTo recall, we defined the cluster size as the number of relays per dedicated server. For a cluster size of 45 relays, the probability of three relays from the set being co-measured is only 0.014%. Even with 120 relays, the probability remains very low at 0.15%. These low probabilities indicate that the occurrence of three or more relays being co-measured is a rare event.\nIn our study, we also investigate the impact of the number of relays in the set and the duration of the simulation on the distribution of co-measurements. We focus our temporal analysis on the event of two relays being co-measured, as this event is more likely to occur compared to three or four relays being co-measured, as shown in Fig. 7a. By varying the number of relays in the set and the duration of the simulation, we can observe how the probability of two relays being co-measured changes over time. This analysis provides insights into the likelihood of such coincidences occurring and helps us understand the influence of different factors on co- measurements.\nThe results depicted in Fig. 7b illustrate the outcomes for different time periods and sets of varying sizes. One notewor- thy observation is that longer simulation periods tend to yield more occurrences of simultaneous measurements. For instance, in the case of a set containing 120 relays, the probability of two relays being co-measured is 12 times higher over a span of three months compared to just one week. This finding suggests that, from an attacker\u2019s perspective, considering the simulation results within a three-month timeframe would be more appropriate as it represents the worst-case scenario. It is important to note that results may differ in the context of an even more extended attack period.\nInflation Factor. The theoretical analysis of the inflation factor for our attack, considering the worst-case scenario of a three- month period, provides insights into the attack\u2019s potential based on real measurement data. However, it is important to note that the actual inflation factor may be affected by factors such as packet overhead and network latency.\nIn our analysis, we take into account that relays mea- sured by a single BA can claim the full bandwidth of the\n    8\n"}, {"chunk": "  100 80 60 40 20 0\n0 20 40 60 80 100 120 Number of Relays\nMeasurement Distribution %\n      25 20 15 10\n5\n0\n0 20 40 60 80 100 120 Number of Relays\nMeasurement Distribution %\n   80 60 40 20\n0\n0 20 40 60 80 100 120 Number of Relays\nInflation Factor\n          Measured 1 times Measured 2 times Measured 3 times Measured 4 times Measured 5 times\n1 week\n2 weeks 1 month 2 months 3 months\n      (a) (b) (c)\nFig. 7: Measurement distribution (a) for a simulation with a 3-month time window, (b) for two relays being measured at the same time for different time windows and cluster sizes. (c) Theoretical inflation factor per relay for no. of relays.\ndedicated server, while relays co-measured by two or more BAs must evenly share the available bandwidth. We calculate the expected inflation factor for different numbers of relays, assuming a contribution factor of one for a single relay and a contribution factor of 0.5 for relays co-measured by two BAs.\nAs illustrated in Fig. 7c, the inflation factor gradually decreases as the number of relays increases. For small cluster sizes, the attack demonstrates nearly linear inflation rates. For example, with a cluster of 10 relays, the inflation factor reaches 9.91. This value nearly doubles to 19.16 when using 20 relays, and employing 30 relays results in a nearly tripled inflation factor of 28.03. These findings highlight the potential for significant bandwidth inflation with a relatively small cluster of co-resident relays.\nHowever, as the number of relays in the set increases, the inflation factor no longer exhibits a linear relationship. For ex- ample, with 120 relays, the inflation factor is 92.52, indicating that approximately 28 relays are not actively contributing to the attack due to the higher rate of co-measurements in larger cluster sizes.\nTo summarize, in sets with a small number of relays, individual relays are more likely to be measured independently, allowing them to claim the full bandwidth of the dedicated server. Only a few cases show three or more relays from the set being co-measured simultaneously. Theoretical analysis demonstrates that the attack\u2019s capacity shows almost linear growth when employing a small number of relays. However, as the number of relays in the set increases, the attack\u2019s effectiveness diminishes, leading to a decrease in the inflation factor.\nF. Estimation of Required Attack Resources\nWe used a curve fitting algorithm to create a curve that matches the inflation factor data (cf. Eq. (1) in Appendix). This curve allows for estimating the inflation factor for a given cluster size.\nAs an example, we calculated how many resources an adversary needs to control half of the Tor network traffic. On average, the Tor Network had an advertised bandwidth of around 678 GBit/s in the year 2022 [5]. Thus, we derive that, to control half of the traffic an adversary needs to advertise an additional 678 GBit/s to the network which can be achieved with 1090 relays (cluster size of 109) and ten dedicated servers, each providing 100MB/s. In summary, gaining control over half of the Tor network\u2019s traffic only requires a little effort and\ncan be accomplished by utilizing 10 dedicated servers with a bandwidth of 100MB/s running the TorMult attack.\nV. ADDITIONAL INSIGHTS ON TOR\nIn this section, we provide some noteworthy insights we gained while performing certain analyses on the Tor network.\nExistence of Relay Families. During our preliminary investi- gation of relays in the Tor network, we came across another interesting observation \u2212 co-resident relays, i.e., multiple re- lays deployed and operating within the same physical or virtual machine. The main identifiable attributes of such co-resident relays that we observed included, sharing of the same public IP address, same uptime and similar measurement results by multiple relays. Taking these identifiers into consideration, we closely examined relays located in Germany and were able to identify several families with potentially co-residing relays (see Table I). The largest family we observed consisted of 178 relays controlled by the same operator, while the most powerful (in terms of offered bandwidth) family observed, offered nearly 2600 Mbps. It is also important to highlight that these identifiable attributes were also found in families with number of relays as low as 3. Another important thing to note here is that it is possible for relays in such families (of co-resident relays) to claim the entire available bandwidth if each of them is measured separately. Evidence of the presence of families of co-resident relays controlled by the same entity in the Tor network, coupled with the fact that it is possible for relays in such families to claim the entire available bandwidth when measured by a BA, is a bit concerning as it could expose the Tor network to a potentially new form of inflation attack, as proposed by us in this work. A recent discussion in the Tor community suggests a proposal to change the two relays per IP limitation for relay operators either by a special request (by relay operator) or a general increase of 32 relays per IP address [23]. The main reasoning behind this increase is to make Tor more scalable in modern CPUs with a high number of cores and if successful, this will further enhance our TorMult attacks.\nPort Usage by Tor Relays. Before performing our analysis on the real Tor network, we also investigated the ports that could be used for our relays and observed that the relays use more than 581 different ports (see Fig. 11). Further, this could also potentially be a sign of co-residing relays operated by the same entities on Tor. Tor operators are free to set the port as per their convenience based on their firewall and routing policy [9]. Therefore, deploying TorMult co-residing relays with a different set of ports will not be considered suspicious.\n9\n"}, {"chunk": "VI. RESILIENCE OF ALTERNATE BANDWIDTH MEASUREMENT SOLUTIONS\nIn this section, we discuss the resilience of alternative bandwidth measurement solutions against TorMult attacks.\nA. 3-Hop Measurement Circuits\nGreubel et al. [30] already pointed out that 2-hop mea- surement circuits in Tor can be easily detected using BA\u2019s IP addresses. As a countermeasure, the authors proposed to utilize 3-hop circuits during measurements and place the measured relay in the middle position (see Fig. 10), in between randomly chosen guard and exit relays, thus obscuring the source and destination of the traffic. One needs to note, however, that such a solution puts an additional burden on the Tor network since more relays will be involved in carrying measurement traffic.\nHowever, given the rise of effective AI methods, it is questionable if such an approach can withstand modern ad- versaries and if the increased load on the network is justified. To this end, we evaluate the resilience of the 3-hop method by (i) collecting the dataset for training in a 3-hop circuit setting, and by (ii) building an ML model based on a traffic classifica- tion method that utilizes a Self-Attention Convolutional Neural Network (SA-CNN) proposed by Guorui et al. [69].\nData Collection. In order to train a supervised model such as SA-CNN, we collect Tor network data and label it as: (i) client traffic data, and (ii) measurement traffic data.\nCollecting Measurement Traffic. To collect measurement traf- fic, we first deployed our own measurement relay node within the Tor network and ensured that it reached phase four of its life cycle, i.e., the steady-state guard relay (reached after 68+ days) [16]. Then, by means of the Python-based Tor controller library Stem [15], we instantiated our own BA service which was modified to build 3-hop circuits for measurements. The measurement relay was placed in the middle position, while the guard and exit relays were randomly chosen among can- didates that (supposedly) offered higher bandwidth than the measurement relay (to eliminate bottlenecks). Additionally, the measurement relay was also used for traffic collection. We then used the 3-hop circuit to download four files with the sizes 16, 20, 50, and 100 MB from three different servers, mimicking a measurement service of SBWS (as described in Section II). Meanwhile, we captured traffic arriving at and leaving the measurement relay using tcpdump and filtered out any other Tor traffic. Doing this was straightforward as the time of measurements, as well as the IP addresses of the guard and exit relays built into our measurement circuits were known and under our control. By using this strategy, we captured roughly 3.4 GB of measurement traffic.\nCollecting Client Traffic. Client traffic was similarly collected on the measurement node of the 3-hop circuit. Client-generated traffic was separated from the self-generated measurement data by filtering out packets arriving from guard relays and ad- dressed to the exit relays. We also had to filter out measurement traffic produced by the legitimate Tor measurement service, which was done using the (known) IP addresses of the BAs. Our measured relay was able to capture 118 GB of client data in this setting.\nTraffic classification using Machine Learning. Next, we describe details of the ML model we employ for traffic clas-\nsification, specifically the Self-Attention Convolutional Neural Network (SA-CNN) proposed by Guorui et al. [69], including (a) traffic pre-processing, (b) feature engineering, (c) model training, and (d) model evaluation.\nTraffic Pre-processing. To clean up the captured measurement and client data, we removed all packets used for establishing TCP connections, for example, SYN and SYN-ACK, as they are not relevant to measurement traffic classification. We then matched each packet in the captured data to their correspond- ing network flow based on the source and the destination IP addresses (i.e., grouped packets belonging to the same source and destination combination), with each flow not exceeding 1,000 packets (as per specifications in the SA-CNN model [69]). In total, we obtained 747 self-generated measurement flows with 390,276 packets. Using only 20% of client data, we obtained 1,591,820 client traffic (non-measurement) flows with 12,776,330 packets in total. Note that we only used a fraction of the obtained non-measurement data during training to prevent class imbalance in the dataset.\nFollowing guidelines proposed in SmarTor [30], we also masked the source and destination IP addresses of the IP header in the packets to simulate a real 3-hop scenario where the guard and exit relays in the circuit are chosen at random, and thus the aforementioned information is not known. In addition, we also masked the checksum, identification, offset fields, source, and destination ports of the TCP header, the sequence number, and the ACK flag since, according to Guorui et al. [69], these confuse the Self Attention CNN model and could result in the model not generalizing well.\nFeature Engineering. As our captured TCP data also contains high-precision timestamps, to prevent the machine learning model from classifying the data based on timestamps, we calculated the inter-arrival time of subsequent packets and used that value for analysis. This enables our model to classify traffic data based on statistical features of the network flow. Further, as Akbari et al. [29] pointed out that traffic classifica- tion models trained using encrypted TLS payload data also fail to generalize, we omit encrypted payloads from our captured packet dataset to prevent our classification model from learning TLS cipher information.\nFinal Dataset. We trained our traffic classification model using the labeled dataset comprising of Tor measurement and client traffic data flows, as outlined above. The entire dataset was split into train, validation, and test sets with 70%, 20%, and 10% of total measurement flows in each set, respectively. The measurement to client traffic packet ratio in the train- ing, validation, and test sets was 52.1%, 57.8%, and 60.8%, respectively. We included only a fraction of the captured client traffic data in the training dataset, to keep the classes balanced.\nModel Building and Training. We select the Self-Attention Convolutional Neural Network (SA-CNN) proposed by Guorui et al. [69] for traffic classification. Their work is especially suitable for traffic classification needed for inflation attacks since it allows packet-level input and can produce output classification results as packets arrive without needing to observe large portions of traffic flows. Such online (or real- time) classification is a crucial requirement for inflation attacks such as TorMult due to the need for on-the-fly traffic re- routing to forward measurement and client traffic to a pre-\n10\n"}, {"chunk": "determined destination. While no major changes and parameter optimizations were required to adapt the SA-CNN model for our problem, the input dimension of the model was changed to a single packet with a total length of 44 Bytes (comprising of 20 Bytes of IP header, 20 Bytes of TCP header, and 4 Bytes to store the inter-arrival time calculation).\nAlthough we were able to achieve high accuracy for both the measurement and client traffic classes when using only 2.6% of the obtained client traffic in the training dataset, we noticed increased false positives (i.e., client traffic in- correctly classified as measurement traffic) when the model was evaluated on the whole dataset. Thus, to mitigate such false positives and improve accuracy, we employ a cascaded model where multiple classification outputs from the SA-CNN model are combined and classified using a Support Vector Machine (SVM), as shown in Figure 8. Specifically, we use a sliding window (with 80% overlap) to select windows of size five (packets) from a traffic flow, and each individual packet (in the window) is then input into the SA-CNN model. The binary classification outputs generated by the SA-CNN model for the five packets are then combined and passed on to the SVM as input. For every five packet-based window, the SVM outputs a final binary classification deciding between either a measurement or client traffic class. To generate a labeled dataset for the SVM model, we first obtained outputs for only client traffic input data, followed by only measurement traffic from the SA-CNN model. We used 20% of this new dataset to train the SVM model and 80% for testing.\nEvaluation. We analyze the performance of our above-trained classifier for detecting measurement traffic in 3-hop circuits using the standard performance metrics of precision, recall, and F1-Score. To recall, precision (or ratio of correct predictions) indicates how often our classifier is correct when it predicts measurement or client traffic packets. Recall (or sensitivity) is the proportion of measurement and client traffic packets that were correctly identified. The F1-score is calculated as the harmonic mean between the precision and recall (used as a reliable indicator for model performance, as it also accounts for class imbalance [56]).\nWe measured the inference time of our SA-CNN model on an Nvidia A16 (4x 16GB memory) graphics card [10] for different batch sizes (5, 128, 512, 2048, 4098, 8196). The mean inference times per packet were 0.34633 ms (\u03c3 = 0.2583), 0.03849 ms (\u03c3 = 0.3169), 0.03704 ms (\u03c3 = 1.018), 0.03704 ms (\u03c3 = 4.342), 0.03642 ms (\u03c3 = 20.024), and 0.03628 ms (\u03c3 = 28.220) for each batch size, respectively. The inference time for the SVM model was 0.1158 ms (\u03c3 = 0.06) for a single input (consisting of 5 classification outputs from SA-CNN). Thus, the total inference time for the cascaded model does not exceed 0.5 ms. Given this, we can argue that the inference time (of our models) is low enough to detect measurement traffic in a timely fashion. Also, we only need to classify the first five packets of a traffic flow to detect the measurement; all subsequent packets of the same flow can be re-routed using the IP address (of the first five packets).\n 1.0 0.8 0.6 0.4 0.2 0.0\nMeasurement Client\n            Precision\nRecall Plain SA-CNN\nF1-Score\nPrecision\nCascaded Model\nRecall F1-Score\n      Packet 1\nPacket 2\n. . .\nPacket 5\n Traffic 5 Packet Sliding SA-CNN SVM Flow Window\nClient Traffic\nMeasurement Traffic\nFig. 8: Cascaded Model.\nWe evaluated our proposed cascaded model approach, and as seen in Fig. 9, we were able to successfully mitigate the im- pact of false positives and achieve F1-Scores of above 99% for both classes (compared to the 67% F-Score for measurement class in Plain SA-CNN model). Although our cascaded model approach for traffic classification can only be applied once at least five packets in a traffic flow are captured, this introduces only a slight delay and is acceptable as measurement flows typically consist of thousands of packets.\nFig. 9: Performance comparison for Plain SA-CNN and Cas- caded Models.\nIn summary, our findings demonstrate that modern machine learning techniques can accurately and promptly differentiate between measurement and non-measurement packets within the 3-hop measurement circuit setup. As a result, it becomes evident that this approach cannot serve as an effective mitiga- tion measure.\nB. FlashFlow\nTraudt et al. [65] demonstrated through experiments that the true capacity of Tor network is underestimated by around 50% due to imperfections in the currently deployed bandwidth measurement mechanism in Tor. As a better alternative, they proposed a new method called FlashFlow, which forces relays to demonstrate their near-maximum capacity. In particular, measurements in FlashFlow are performed by teams of mea- surers, each coordinated by their own authority, referred to as BWAuth, who orchestrates the measurement process and aggregates the results. The target relay is simultaneously measured by a team of measurers over specially constructed measurement circuits, which are created and handled differ- ently from the circuits utilized by regular client traffic. In particular, measurers and target relays are connected through single-hop connections established with the help of BWAuths and their public keys. Remarkably, each relay will only ac- cept connections from a given BWAuth and its team once per measurement period, which implies that requests for the measurement circuit establishment can be denied for legitimate reasons. It is evident that identifying measurement traffic and dropping non-measurement data flows in FlashFlow is even more straightforward than in currently deployed SWBS or\n11\n"}, {"chunk": "TorFlow. Indeed, since the measurement and non-measurement circuits are handled differently by design, they can be trivially distinguished. Consequently, the client traffic can be dropped as required by C-TorMult, or the measurement traffic can be redirected to a powerful dedicated server as in D-TorMult. Further, FlashFlow allows an attacker to either accept or refuse being measured by specific BWAuths based on their preference. As a result, an attacker with several relays is able to schedule the measurements in such a way that all relays will be measured at different times. This avoids co-measurements, and further increases the inflation factor, strengthening our proposed attack.\nC. Other Solutions\nNext, we outline some other alternate measurement solu- tions in the literature for Tor and discuss them in relation to our proposed TorMult attacks. Although these solutions do not directly impact the efficacy of our proposed attacks, they are still vulnerable to inflation attacks such as TorMult, either due to their own issues as highlighted below or their dependency on existing bandwidth measurement mechanisms such as TorFlow.\nEigenSpeed. Snader and Borisov [61] proposed a peer-to- peer (P2P) bandwidth evaluation technique for Tor in which each relay observes and stores bandwidth attained while communicating with other relays in a vector. The vector is then forwarded to an authority that uses Principal Component Analysis (PCA) to produce consensus bandwidths for all Tor relays. Although EigenSpeed is not vulnerable to TorMult due to the absence of specialized measurement traffic, it has been shown that EigenSpeed is vulnerable to Sybil attacks, which also leads to inflation attacks [49].\nPeerFlow. This technique builds on the same P2P principle as EigenSpeed and uses two measurement techniques where each relay records the amount of traffic sent and received to/from other relays while also reporting their own available bandwidth. These measurements then get forwarded to the DAs who compute a consensus weight based on these reported values and by employing a set of trusted relays to verify them [44]. PeerFlow continues to use TorFlow during bootstrapping of new Tor relays and thus attacks on TorFlow will still have a considerable impact here making PeerFlow still vulnerable to TorMult [49].\nMLEFlow. This technique employs a maximum likelihood estimation (MLE) approach to estimate the real capacity of a relay by using a series of measurements and consensus weights published by the BAs [36]. The authors of MLEFlow were able to achieve estimation errors below 5% in contrast to TorFlow and SBWS which have estimation errors over 20%. However, similar to the above techniques, their technique also relies on BA-based measurements, thus making it vulnerable to measurement traffic detection and inflation attacks such as TorMult.\nVII. COUNTERMEASURES\nWe now briefly outline measures that could be poten- tially used to mitigate TorMult\u2019s bandwidth inflation strategies against Tor and discuss the challenges surrounding them.\nA. Detecting Measurement Anomalies\nAs demonstrated by us in Section IV-E, when two or more (adversarial) relays residing on the same machine are mea- sured simultaneously, a noticeable drop in the instantaneous bandwidth measurement (related to those relays) is observed, which is recorded and archived in the bandwidth files by the measuring BAs. Given that Tor archives all the bandwidth files generated since 2017, such trends indicating sudden drops in measured bandwidths of relays during co- or simultaneous measurements are easily detectable (by network BAs/DAs) by simply looking at the historical data inside the bandwidth files and can be used to flag suspicious relays. As mentioned in Section IV-E, bandwidth files only contain end timestamps of the measurements, making it difficult to accurately recreate the timeline of relay co-measurements. In order to overcome this, BAs can record the start of measurement timestamp information for their individual probes and can collaborate with other BAs to successfully recreate the co-measurement timelines from the bandwidth files to identify suspicious relays that may be involved in such bandwidth inflation attacks. BAs can then actively and collaboratively probe such suspicious relays by measuring them simultaneously in order to con- firm bandwidth measurement anomalies and detect cases of bandwidth inflation. Moreover, as each BA is able to run at least four measurement threads in parallel, even individual BAs (without collaboration with other BAs) can perform such active probing to detect cheating or malicious relays.\nB. Obscuring Measurement Traffic\nAnother mitigation strategy that could be employed by the BAs is to obfuscate measurement traffic, say by concealing or randomizing the origin and/or destination information (of the measurement flows), with the goal of making the detection of such traffic non-trivial and difficult. Such an approach seems plausible as the detection of measurement traffic is typically the first step in most bandwidth inflation attacks, including Tor- Mult. To this end, one option is to randomize the network (IP) address of the measurement file download server. However, file downloads (during bandwidth measurement) from these servers could produce uniquely identifiable traffic flows, which in turn could be used to detect measurement traffic (by the relays). For instance, in current Tor measurement mechanisms (e.g., in TorFlow and SBWS), the download throughput is swiftly increased at the start of the measurement until it reaches a constant state to measure the maximum possible throughput of the relay, followed by rapidly reducing it towards the end of the measurement. As demonstrated by us in VI-A, traffic classification is still possible even under masked IP addresses. We were able to identify measurement traffic from non-measurement traffic with only 5 packets (and only using their headers) from a network flow with over 0.99 precision and recall. Similar works in literature have also shown that traffic flow patterns can be used to achieve traffic classification using machine/deep learning mechanisms with accuracies over 95% [31], [58]. These research efforts show that obfuscation or randomization of download file server IP addresses, although intuitive, may not always be an effective mitigation strategy against bandwidth inflation attacks.\nC. Co-residency Detection\nAn increase in traffic could lead to the relays being overloaded and such relay overloads are self-reported in Tor\n12\n"}, {"chunk": "Metrics platform [5]. From an attack mitigation point of view, it is easy to see that such relay overload indicators can be employed to detect potential co-resident relays and neutralize bandwidth inflation attacks, including the proposed ones by us. However, since the overload status is self-reported, one possible workaround to override this default overload reporting behavior is to employ a modified (non-standard) Tor client code which conceals the overload-related information from being reported. Nonetheless, this form of detection is only possible as long as attackers are unaware of this detection method. In addition to the above, usage of the same public IP addresses and port numbers and exhibiting similar uptime and measurement results could also be indicative of co-residency.\nAnother possible indicator of co-residency could be relays running the same version of Tor, assuming the attacker installs these relays together or around the same time period (Tor currently has 44 different version releases in operation) [6].\nD. Eliminating Explicit Measurement Traffic\nAs discussed earlier, the presence of measurement traffic inherently makes the Tor network vulnerable to bandwidth inflation attacks due to the high possibility of measurement traffic detection. As a result, perhaps one of the most promising countermeasures is to eliminate the use of explicit measure- ment traffic to accomplish bandwidth measurement. To this end, one approach would be to use the existing Tor relay nodes themselves to measure their peers\u2019 bandwidth in a distributed fashion by using regular Tor client traffic. It must be noted that such a technique has already been proposed by some of the existing TorFlow/SBWS alternatives proposed in the literature, such as EigenSpeed [61] and PeerFlow [44] (as discussed earlier in Section VI-C), which employ a distributed (or peer- to-peer) network of measurements nodes. Although these solu- tions are currently incompatible with Tor and have their own shortcomings, as discussed in Section VIII and Section VI, we believe that improved versions of these solutions could be effective in hindering a wide range of bandwidth inflation attacks including TorMult.\nVIII. RELATED WORKS\nBandwidth inflation in Tor was initially exploited back in 2006 by Overlier et al. [53]. At the time, relays reported their own bandwidth measurements to DAs, and the authors reported inflated measurements to increase the weight of malicious relays in an attempt to achieve more efficient attacks against Tor hidden services. In 2007, Bauer et al. [32] exploited the same design flaw to propose a traffic analysis attack that affects client anonymity and showed that a low-resource adversarial entity could falsely report inflated bandwidths allowing them to acquire both entry and exit relays of the same client with an increased probability.\nConsequently, bandwidth authorities and scanning proto- cols (TorFlow) were introduced in Tor in 2011. TorFlow was gradually replaced by SBWS starting 2018. However, in 2013 Biryukov et al. [33] showed that an inflation attack is still feasible by detecting bandwidth measurement traffic and prioritizing the entire available bandwidth to such traffic while throttling bandwidth for all other traffic. They were able to achieve more than tenfold (10x) bandwidth inflation using this strategy. Johnson et al. [45] also confirmed this\nattack in a simulated environment and were able to achieve an 177\u00d7 inflation compared to the actual bandwidth where the alteration achieved for the consensus weight increased from 7% to 11%. They further showed that the bandwidth utilized by the adversarial relay dropped from 22.5 MBps to a mere 0.2 MBps which also validates that an attacker does not require heavy resources to perform such an attack. They further exposed a vulnerability in EigenSpeed which allows an attacker to kick out honest relays by adding a very large number of malicious relays (or Sybils). They used the same malicious relays (or Sybil nodes) to report false bandwidths for honest relays and obtained a 28\u00d7 bandwidth inflation.\nMore recently, Mitseva et al. [49] conducted a practical analysis of PeerFlow [44]. They observed that since PeerFlow uses TorFlow measurements in their initial phase when new relays join the Tor network, it is vulnerable to inflation attacks up to 9\u00d7 times compared to the specified security boundary of 4.6\u00d7 in PeerFlow. Mitseva et al. also identified a design flaw in PeerFlow due to its variable measurement period times, leading to malicious new relays compelling to be measured using TorFlow by avoiding connections to other relays.\nAll of these studies share similarities with our work, as they also delve into various strategies for bandwidth inflation, aiming to maximize user traffic routed through malicious relays while minimizing resource usage. Consequently, these strategies facilitate a wide range of privacy attacks in Tor, including website fingerprinting [27], [57], [42], [35], flow correlation [41], [70], [68], [51], and routing attacks [32], [62]. However, our approach distinguishes itself from previous methods by introducing a novel inflation attack technique. By combining this technique with existing approaches, attackers can achieve even more significant bandwidth inflation.\nIX. CONCLUSION\nIn this work, we presented a novel inflation attack on Tor which adversarial relays could use to inflate their bandwidth. We evaluated two attack variants, a co-residing relay attack (C-TorMult) which achieved an inflation gain of nearly n, and a dedicated server attack (D-TorMult) which achieved an inflation multiplier by nearly half n \u2217 N, where n is the size of the relay cluster and N the number of servers. Next, we explored the coincidence rate, which will help an attacker to optimally choose the number of co-resident relays to maximize their inflation factor. We found that the inflation factor increases almost linearly for cluster sizes up to 120 relays. In our theoretical examination, we demonstrate that by utilizing only 10 specialized servers employing the TorMult attack, each having a bandwidth of 100MB/s, it is possible to gain command over 50% of the Tor network\u2019s traffic. We also provided further insights on Tor relating to relay families and port usage distribution. Finally, we also demonstrated how TorMult is resilient against other alternative measurement techniques, followed by potential countermeasures against the proposed bandwidth inflation attacks.\nREFERENCES\n[1] Ansible Github Repository. https://github.com/ansible/ansible.\n[2] Artikel10 Tor family. https://metrics.torproject.org/rs.html#search/ contact:Artikel10%20.\n13\n"}, {"chunk": "[3] Bandwidth authorities timeline. https://gitlab.torproject.org/ tpo/network- health/bandwidth- authorities/- /wikis/bandwidth% 20authorities%20timeline.\n[4] Chutney. https://github.com/torproject/chutney.\n[5] CollecTor, the data-collecting service in the Tor network. https:\n//metrics.torproject.org/collector.html.\n[6] Core Tor Releases. https://gitlab.torproject.org/tpo/core/team/- /wikis/\n[34] Xiang Cai, Xin Cheng Zhang, Brijesh Joshi, and Rob Johnson. Touching from a distance: Website fingerprinting attacks and defenses. In Proceedings of the 2012 ACM conference on Computer and commu- nications security, pages 605\u2013616, 2012.\n[35] Giovanni Cherubin, Rob Jansen, and Carmela Troncoso. Online Website Fingerprinting: Evaluating Website Fingerprinting Attacks on Tor in the Real World. In 31st USENIX Security Symposium (USENIX Security 22), pages 753\u2013770, 2022.\n[36] Hussein Darir, Hussein Sibai, Chin-Yu Cheng, Nikita Borisov, Geir Dullerud, and Sayan Mitra. MLEFlow: Learning from History to Improve Load Balancing in Tor. Proceedings on Privacy Enhancing Technologies, 2022(1):75\u2013104, 2022.\n[37] Nathan S Evans, Roger Dingledine, and Christian Grothoff. A Practical Congestion Attack on Tor Using Long Paths. In USENIX Security Symposium, pages 33\u201350, 2009.\n[38] John Geddes, Rob Jansen, and Nicholas Hopper. How low can you go: Balancing performance with anonymity in tor. In International Symposium on Privacy Enhancing Technologies Symposium, pages 164\u2013 184. Springer, 2013.\n[39] Jamie Hayes and George Danezis. k-fingerprinting: A robust scalable website fingerprinting technique. In 25th USENIX Security Sympo- sium (USENIX Security 16), pages 1187\u20131203, 2016.\n[40] Nicholas Hopper, Eugene Y Vasserman, and Eric Chan-Tin. How much anonymity does network latency leak? ACM Transactions on Information and System Security (TISSEC), 13(2):1\u201328, 2010.\n[41] Amir Houmansadr, Negar Kiyavash, and Nikita Borisov. RAINBOW: A Robust And Invisible Non-Blind Watermark for Network Flows. In NDSS, volume 47, pages 406\u2013422. Citeseer, 2009.\n[42] Rob Jansen, Marc Juarez, Rafa Galvez, Tariq Elahi, and Claudia Diaz. Inside Job: Applying Traffic Analysis to Measure Tor from Within. In NDSS, 2018.\n[43] Rob Jansen, Florian Tschorsch, Aaron Johnson, and Bjo \u0308rn Scheuer- mann. The sniper attack: Anonymously deanonymizing and disabling the Tor network. Technical report, Office of Naval Research Arlington VA, 2014.\n[44] Aaron Johnson, Rob Jansen, Nicholas Hopper, Aaron Segal, and Paul Syverson. PeerFlow: Secure Load Balancing in Tor. PoPETs, 2017(2):74\u201394, 2017.\n[45] Aaron Johnson, Rob Jansen, Nicholas Hopper, Aaron Segal, and Paul Syverson. PeerFlow: Secure Load Balancing in Tor. Proceedings on Privacy Enhancing Technologies, 2017(2):74\u201394, April 2017.\n[46] Aaron Johnson, Chris Wacek, Rob Jansen, Micah Sherr, and Paul Syverson. Users get routed: Traffic correlation on tor by realistic adversaries. In Proceedings of the 2013 ACM SIGSAC conference on Computer & communications security, pages 337\u2013348, 2013.\n[47] Shuai Li, Huajun Guo, and Nicholas Hopper. Measuring information leakage in website fingerprinting attacks and defenses. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communica- tions Security, pages 1977\u20131992, 2018.\n[48] Zhen Ling, Junzhou Luo, Wei Yu, Xinwen Fu, Weijia Jia, and Wei Zhao. Protocol-level attacks against Tor. Computer Networks, 57(4):869\u2013886, 2013.\n[49] Asya Mitseva, Thomas Engel, and Andriy Panchenko. Analyzing PeerFlow \u2013 A Bandwidth Estimation System for Untrustworthy En- vironments. 2020.\n[50] Prateek Mittal, Ahmed Khurshid, Joshua Juen, Matthew Caesar, and Nikita Borisov. Stealthy traffic analysis of low-latency anonymous communication using throughput fingerprinting. In Proceedings of the 18th ACM conference on Computer and Communications Security, pages 215\u2013226, 2011.\n[51] Milad Nasr, Alireza Bahramali, and Amir Houmansadr. Deepcorr: Strong flow correlation attacks on tor using deep learning. In Pro- ceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pages 1962\u20131976, 2018.\n[52] Oracale. VirtualBox. https://www.virtualbox.org/.\n[53] Lasse Overlier and Paul Syverson. Locating hidden servers. In 2006 IEEE Symposium on Security and Privacy (S&P\u201906), pages 15\u2013pp. IEEE, 2006.\n[54] Andriy Panchenko, Fabian Lanze, Jan Pennekamp, Thomas Engel, An-\nNetworkTeam/CoreTorReleases.\n[7] Did the FBI Pay a University to Attack Tor Users?\nhttps:// [8] How SBWS Works. https://tpo.pages.torproject.net/network-health/\nblog.torproject.org/did- fbi- pay- university- attack- tor- users. sbws/how works.html.\n[9] Most Frequently Asked Questions - My firewall only allows a few outgoing ports . https://support.torproject.org.\n[10] NVIDIA A16 GPU. https://www.nvidia.com/en- us/data- center/ products/a16- gpu.\n[11] Regulation (EU) 2016/679 of the European Parliament and of the Council. https://eur- lex.europa.eu/legal- content/EN/TXT/HTML/?uri= CELEX:32016R0679&from=EN.\n[12] Relay Operations. https://community.torproject.org/relay/setup.\n[13] Research Safety Board. https://research.torproject.org/safetyboard/.\n[14] Simple Bandwidth Scanner - SBWS. https://tpo.pages.torproject.net/ network-health/sbws/man sbws.html.\n[15] Stem Docs. https://support.torproject.org/it/relay- operators/relay- bridge- overloaded.\n[16] The lifecycle of a new relay. new- relay/.\nhttps://blog.torproject.org/lifecycle- of- a-\n[17] The netfilter.org project. https://www.netfilter.org/.\n[18] The Tor Project, Inc. https://www.torproject.org.\n[19] Tor Bugbounty HackerOne. https://hackerone.com/torproject.\n[20] Tor Consensus. https://metrics.torproject.org/glossary.html#consensus.\n[21] Tor Directory Authorities. https://metrics.torproject.org/rs.html#search/ flag:Authority.\n[22] Tor directory protocol, version 3. https://github.com/torproject/torspec/ blob/main/dir- spec.txt.\n[23] Tor Project\u2019s Wiki Page. issues/40744.\nhttps://gitlab.torproject.org/tpo/core/tor/- /\n[24] Tor security advisory: \u201drelay early\u201d traffic confirmation attack. https://blog.torproject.org/tor- security- advisory- relay- early- traffic- confirmation- attack.\n[25] Vagrant. https://www.vagrantup.com/.\n[26] What is a Tor Relay? https://www.eff.org/de/pages/what-tor-relay.\n[27] Kota Abe and Shigeki Goto. Fingerprinting attack on Tor anonymity using deep learning. Proceedings of the Asia-Pacific Advanced Network, 42:15\u201320, 2016.\n[28] AdrienLE. Bandwidth Scanner specification. https://github.com/ AdrienLE/torflow/blob/master/NetworkScanners/BwAuthority/ README.spec.txt.\n[29] Iman Akbari, Mohammad A Salahuddin, Leni Ven, Noura Limam, Raouf Boutaba, Bertrand Mathieu, Stephanie Moteau, and Stephane Tuffin. Traffic classification in an increasingly encrypted web. Com- munications of the ACM, 65(10):75\u201383, 2022.\n[30] Greubel Andre, Dmitrienko Alexandra, and Kounev Samuel. SmarTor: smarter tor with smart contracts: Improving resilience of topology distribution in the tor network. In Proceedings of the 34th Annual Computer Security Applications Conference, pages 677\u2013691, 2018.\n[31] Erik Arestro \u0308m and Niklas Carlsson. Early online classification of encrypted traffic streams using multi-fractal features. In IEEE INFO- COM 2019-IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS), pages 84\u201389. IEEE, 2019.\n[32] Kevin Bauer, Damon McCoy, Dirk Grunwald, Tadayoshi Kohno, and Douglas Sicker. Low-resource routing attacks against Tor. In Proceed- ings of the 2007 ACM workshop on Privacy in electronic society, pages 11\u201320, 2007.\n[33] Alex Biryukov, Ivan Pustogarov, and Ralf-Philipp Weinmann. Trawling for Tor Hidden Services: Detection, Measurement, Deanonymization. In 2013 IEEE Symposium on Security and Privacy, pages 80\u201394, 2013.\n14\n"}, {"chunk": "dreas Zinnen, Martin Henze, and Klaus Wehrle. Website Fingerprinting at Internet Scale. In NDSS, 2016.\n[55] Mike Perry. TorFlow: Tor network analysis. Proc. 2nd HotPETs, pages 1\u201314, 2009.\n[56] David M. W. Powers. Evaluation: from precision, recall and f-measure to roc, informedness, markedness and correlation. 2020.\n[57] Vera Rimmer, Davy Preuveneers, Marc Juarez, Tom Van Goethem, and Wouter Joosen. Automated website fingerprinting through deep learning. arXiv preprint arXiv:1708.06376, 2017.\n[58] Ola Salman, Imad H Elhajj, Ali Chehab, and Ayman Kayssi. A multi-level internet traffic classifier using deep learning. In 2018 9th International Conference on the Network of the Future (NOF), pages 68\u201375. IEEE, 2018.\n[59] Bruce Schneier. Attacking Tor: How the NSA targets users\u2019 on- line anonymity. https://www.theguardian.com/world/2013/oct/04/tor- attacks- nsa- users- online- anonymity.\n[60] Payap Sirinam, Mohsen Imani, Marc Juarez, and Matthew Wright. Deep fingerprinting: Undermining website fingerprinting defenses with deep learning. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pages 1928\u20131943, 2018.\n[61] Robin Snader and Nikita Borisov. Eigenspeed: secure peer-to-peer bandwidth evaluation. In IPTPS, page 9, 2009.\n[62] Yixin Sun, Anne Edmundson, Laurent Vanbever, Oscar Li, Jennifer Rexford, Mung Chiang, and Prateek Mittal. RAP T OR : Routing attacks on privacy in tor. In 24th U S E N I X Security Symposium (USENIX Security 15), pages 271\u2013286, 2015.\n[63] Henry Tan, Micah Sherr, and Wenchao Zhou. Data-plane defenses against routing attacks on tor. Proc. Priv. Enhancing Technol., 2016(4):276\u2013293, 2016.\n[64] Fabrice Thill. Hidden Service Tracking Detection and Bandwidth Cheating in Tor Anonymity Network. PhD thesis, PhD thesis. Master thesis. University of Luxembourg. 2014., 2014.\n[65] Matthew Traudt, Rob Jansen, and Aaron Johnson. Flashflow: A secure speed test for tor. In 2021 IEEE 41st International Conference on Distributed Computing Systems (ICDCS), pages 381\u2013391. IEEE, 2021.\n[66] Ryan Wails, Yixin Sun, Aaron Johnson, Mung Chiang, and Prateek Mittal. Tempest: Temporal dynamics in anonymity systems. arXiv preprint arXiv:1801.01932, 2018.\n[67] Tao Wang and Ian Goldberg. Improved website fingerprinting on tor. In Proceedings of the 12th ACM workshop on Workshop on privacy in the electronic society, pages 201\u2013212, 2013.\n[68] Xinyuan Wang, Shiping Chen, and Sushil Jajodia. Network flow wa- termarking attack on low-latency anonymous communication systems. In 2007 IEEE Symposium on Security and Privacy (SP\u201907), pages 116\u2013 130. IEEE, 2007.\n[69] Guorui Xie, Qing Li, and Yong Jiang. Self-attentive deep learning method for online traffic classification and its interpretability. Computer Networks, 196:108267, 2021.\n[70] Wei Yu, Xinwen Fu, Steve Graham, Dong Xuan, and Wei Zhao. DSSS- based flow marking technique for invisible traceback. In 2007 IEEE Symposium on Security and Privacy (SP\u201907), pages 18\u201332. IEEE, 2007.\nAPPENDIX A OBSERVED RELAY FAMILIES\nThe relay families (located in Germany) we identified\nduring preliminary investigations with potentially co-residing relays are shown in Table I.\nTABLE I: A List of Observed Relay Families.\nAPPENDIX B\n2-HOP VS. 3-HOP MEASUREMENT CIRCUITS\nThe difference between a 2-hop and a 3-hop measurement circuit can be seen in Fig. 10 as previously described in Section VI-A.\n Guard Relay\nMeasured Relay\nMeasured Relay\nExit Relay\nExit Relay\n     Bandwidth Authority\nTor Project File Server\n 2-hop Circuit 3-hop Circuit\n  Fig. 10: 2-hop vs. 3-hop measurement circuits\nAPPENDIX C\nATTACK RESOURCE ESTIMATION EQUATIONS\nAs mentioned in Section IV-F, the curve fitting algorithm to construct a matching curve from the inflation factor of the attack is defined in Eq. (1). The fitted function (mean squared error is 0.0318 and coefficient of determination is 0.99995) returns the inflation factor for a cluster size, x.\nThe equation to calculate the required amount of dedicated servers in the D-TorMult attack, given a cluster size and how much traffic should be controlled, is shown by the equation Eq. (2). The parameter x refers to the cluster size, b is a constant that defines the total traffic in the Tor network, p defines the desired percentage of controlled traffic, and d defines the bandwidth of the dedicated servers. To calculate the perfect cluster size, one can create a linear program (LP) that minimizes both the cluster size and the number of dedicated servers (i.e., minimize x + s(x, b, p, d)).\ni(x) = 0.75895138 \u00b7 (1.44995314 \u00b7 x)0.96837148 (1) \u2212(0.03714758 \u00b7 x)2 \u2212 0.07672455\nDi =N\u2208[1,120]\nl2\u00b7b\u00b7 p m\ns(x, b, p, d) = 100 (2)\n d\u00b7i(x)\nDs = N4,x \u2208 [1,120],p \u2208 [1,100]\n Family\n8029928877A15A504D92996C65BFD4F0BDF4E702 2DF03D7B158DAE2EAF76078775451F1769506451 5B83DC983406651A0B4F6AE1940793CDD6A6F92E 526AD50C9DE6AF533DEBE8F9BBDF149BC1F5AB6E A4E47F08B8D56428DF76B17EDD6738BCBC3F5EFB 135F2A8B32F583845F2B0E133EFD84C25026761B 1050FC79C5F1103B185300EF72DDF5B4EDC683C9\nNo. of Relays\n88 85 56 178 55 32 94\nBandwidth (Mbps)\n2596.32 2003.7 1784.92 1278.92 1092.18 1077.46 936.37\nAPPENDIX D DISTRIBUTION OF PORTS BY TOR RELAYS\nThe analysis done on the real Tor network shows 581 dif- ferent port numbers being used by relays, suggesting possible co-resident relays (Fig. 11).\n  15\n"}, {"chunk": "  33.6%\n39%\n9001 443 8443 9000 9100 80 8080 9443 9002 993 5443 9090 444 9003 8000 143\n 2.76%\n2.74%\n2.64%\n Fig. 11: Distribution of different ports used by Tor relays.\n16\n"}, {"chunk": "BayBFed: Bayesian Backdoor Defense for Federated Learning\nKavita Kumari\u2020\u2217, Phillip Rieger\u2020, Hossein Fereidooni\u2020, Murtuza Jadliwala\u2021 and Ahmad-Reza Sadeghi\u2020 \u2020Technical University of Darmstadt, \u2021The University of Texas at San Antonio\nAbstract\u2014Federated learning (FL) is an emerging technology that allows participants to jointly train a machine learning model without sharing their private data with others. How- ever, FL is vulnerable to poisoning attacks such as backdoor attacks. Consequently, a variety of defenses have recently been proposed, which have primarily utilized intermediary states of the global model (i.e., logits) or distance of the local models (i.e., L2 \u2212 norm) with respect to the global model to detect malicious backdoors in FL. However, as these approaches directly operate on client updates (or weights), their effectiveness depends on factors such as clients\u2019 data distribution or the adversary\u2019s attack strategies. In this paper, we introduce a novel and more generic backdoor defense framework, called BayBFed, which proposes to utilize probability distributions over client updates to detect malicious updates in FL: BayBFed computes a probabilistic measure over the clients\u2019 updates to keep track of any adjustments made in the updates, and uses a novel detection algorithm that can leverage this probabilistic measure to efficiently detect and filter out malicious updates. Thus, it overcomes the shortcomings of previous approaches that arise due to the direct usage of client updates; nevertheless, our probabilistic measure will include all aspects of the local client training strategies. BayBFed utilizes two Bayesian Non- Parametric (BNP) extensions: (i) a Hierarchical Beta-Bernoulli process to draw a probabilistic measure given the clients\u2019 updates, and (ii) an adaptation of the Chinese Restaurant Process (CRP), referred by us as CRP-Jensen, which leverages this probabilistic measure to detect and filter out malicious updates. We extensively evaluate our defense approach on five benchmark datasets: CIFAR10, Reddit, IoT intrusion detection, MNIST, and FMNIST, and show that it can effec- tively detect and eliminate malicious updates in FL without deteriorating the benign performance of the global model.\n1. Introduction\nA machine learning framework is designed to learn from a single fused data collected from multiple data sources. This trainable data is comparable and homogeneous. However, in practice, data is heterogeneous and segregated across multiple decentralized devices. Learning a single machine learning model by using this scattered data is complex and challenging as it may disclose a user\u2019s identifiable and\n*. Work done while author was affiliated with The University of Texas at San Antonio.\nprotected information. Federated Learning (FL) overcomes these drawbacks by enabling multiple distributed clients to learn a global model in a collaborative fashion [23], [47]. For instance, multiple hospitals can participate in training a global model for cancer classification without revealing individual patients\u2019 cancer records [21], [36], [46]. Sim- ilarly, multiple smartphones could train together a word suggestion model without sharing the individually typed texts [24], or detect threats based on risk indicators [12]. In FL, each client locally trains a model on its private dataset and sends the parameters of this local model to a (global) server, which aggregates the different local mod- els from the clients into a global model (see App. A for more details). The server then responds by sending the aggregated model to each client in a single training round. By design, the global server is unaware of the training process being done locally on each client; thus, it is also susceptible to poisoning attacks from malicious clients. Poisoning Attacks and Defenses. Previous works have shown that FL is prone to poisoning attacks as a malicious client (or clients) can inject malicious weights into the global server model during training [2], [3], [4], [30], [37], [45]. As a consequence, the performance of the global model on all or some subsets of predictive tasks becomes degenerated. In the so-called targeted poisoning (or backdoor) attacks, the adversary\u2019s goal is to cause well-defined misbehavior of the global model on some trigger data points, i.e., predict a specific class if a particular pattern is present in the input data [3], [31], [42], [45].1 Our focus in this paper is to mitigate such targeted backdoor attacks.\nTo detect/mitigate backdoor attacks, existing defenses leverage either the models\u2019 outputs (i.e., predictions on some validation data2), intermediary states (i.e., logits) of the models, and/or distance of the local models (i.e., L2 \u2212 norm or cosine) with regard to the global model, or pairwise distances among the models. However, current defenses have several shortcomings and are not sufficiently robust to defend against different classes of backdoor attacks. For in- stance, some defenses are bypassed when multiple different backdoors are simultaneously inserted by different malicious clients [37]. Other defenses clip weights and add noise to negate the effect of malicious model updates, which reduces\n1. In contrast, non-targeted poisoning attacks aim to deteriorate the performance of the global model on all test data points [7].\n2. As pointed out by Rieger et al., it is not realistic to assume validation data to be present on the aggregation server [35].\narXiv:2301.09508v1 [cs.LG] 23 Jan 2023\n"}, {"chunk": "the benign performance of the global model [3], [26], [30], [40], or they make specific assumptions such as (i) the adver- sary inserts malicious updates (backdoors) in each training round [14], or (ii) the adversary attacks only at the end of the training [1], or (iii) the data of the benign clients having the same distribution [27], [30], [48], or (iv) each benign client must have a similar number of unique labels [35].\nMoreover, current state-of-the-art defenses against back- door attacks make several assumptions about the underlying data and the adversary\u2019s adopted strategies, as well as they directly employ client weights during detection. In this con- text, we encountered two main open challenges: First, how can we compute an alternate, more generic, representation of client weights (or updates), such as a probabilistic measure, which will encompass all adjustments made to the updates due to any local training strategy (by the clients). Second, can we design an efficient detection/clustering algorithm that can leverage such a probabilistic measure to effectively filter out malicious updates in FL, without deteriorating the benign accuracy of the global model. We intuitively believe, and later empirically show, that designing a de- tection algorithm with such a generic probabilistic measure as one of its inputs provides several significant advantages over existing defense solutions. First, different local client training strategies will not affect the detection process at the global server. Consequently, the defense mechanism\u2019s detection phase will remain agnostic about an adversary\u2019s attack strategies. Second, utilizing distributions over client updates in the defense, instead of directly employing client weights, makes the detection process uninfluenced by the underlying local data distributions used for training.\nOur Goals and Contributions. To tackle the challenges outlined above, we present the design and implementation of BayBFed, an unconventional and more general backdoor defense for FL that is based on a probabilistic machine learning framework. BayBFed comprises of two main mod- ules. The first module computes a probabilistic measure of the client weights that is governed by the posterior of the Hierarchical Beta-Bernoulli process [41] (see Sect. 4). The second module implements a detection algorithm which em- ploys this probabilistic measure as an input to differentiate malicious and benign updates. The main idea is to utilize a probabilistic measure to determine the distribution of the incoming local client updates. Additionally, in each FL round, we compute the distribution of existing groups that were assigned client updates (clusters) or a new group (client updates can get assigned to a new group). Then, we compute the (Jensen) divergence of these two distributions to detect malicious updates and compute the selected client\u2019s fit to an existing or a new cluster. The detection algorithm (described later) is mainly governed by the Chinese Restaurant Process (CRP), except that it uses Jensen-Divergence to compute clients\u2019 fit to the clusters.\nThe only work in the literature that has employed sim- ilar Bayesian Non-Parametric (BNP) models in the context of FL is by Yurochkin et al. [49], where BNP models, specifically the Beta-Bernoulli Process and the Indian Buffet Process, are used to reduce the communication overhead be-\ntween the global server and the clients. They accomplished this by finding the common subset of neurons between the local clients selected in a training round and combining them to form a global model. In contrast to [49], we use BNP models, specifically the Hierarchical Beta-Bernoulli process and CRP, for designing a defense mechanism against backdoor attacks in FL. We stress that [49] is vulnerable to backdoor attacks, as malicious training updates can easily be integrated into the global model.\nTo the best of our knowledge, this is the first work that employs BNP modeling concepts to design an accurate and robust defense against backdoor attacks in FL. Our main contributions can be summarized as:\n\u2022 WeproposeBayBFed,anovelgenericdefenseframework against backdoor attacks in FL that accurately and effec- tively detects backdoors without significantly impacting the benign performance of the aggregated model. Our proposed defense is relevant in many adversarial settings as, by design, the malicious update detection functionality utilizes distributions of client updates and, thus, is unaf- fected by any local client\u2019s strategy.\n\u2022 We take a new approach to the problem of mitigating backdoor attacks in FL by employing non-parametric Bayesian modeling in the design of the defense mech- anism. To the best of our knowledge, existing defenses mainly consider the model updates as a set of vectors and matrices, and directly administer these weights to filter out the malicious client updates [4], [14], [26], [27], [30], [37]. Given the client weights, BayBFed first estimates a probabilistic measure (such as the Beta posterior) that accurately captures the variations in the clients\u2019 weights and then uses a novel detection technique based on the Chinese Restaurant Process and Jensen-Divergence for identifying the poisoned models.\n\u2022 Weextensivelyevaluateourframeworkonfivebenchmark datasets: CIFAR-10, Reddit, MNIST, FMNIST, and a real- world IoT network traffic dataset. We show that BayBFed effectively mitigates different state-of-the-art as well as adaptive attacks, and accurately and effectively detects the backdoored models so that the benign performance of the aggregated model is not degraded, thus providing a significant advantage over state-of-the-art defenses.\n2. Background and Intuition\nOur approach is modeled in two steps. First, to determine the probabilistic distributions of clients\u2019 updates, we make use of several statistical tools such as Beta Processes (BP), Hierarchical Beta Processes (HBP), and Bernoulli Processes (BeP). Second, to design our detection algorithm, we outline an adaptation of the Chinese Restaurant Process (CRP), called CRP-Jensen, to detect and filter out malicious up- dates. Below, we briefly discuss the above two steps (see more technical details in the Appendix):\nDetermining probabilistic measure for client updates. We compute the probabilistic measure for each client selected in an FL round to keep track of the adjustments made during each update. For this, we first draw a baseline probabilistic\n"}, {"chunk": "measure, denoted by the baseline Beta Process (BP), which is computed using the initial global model. Informally, a BP quantifies a subset of points (measure). We use BPs in this work to quantify the client updates and the global model by creating distributions over them.\nA BP (A) is a stochastic process defined using two pa- rameters: a concentration function c over some space \u03a9 = R and a base measure H; denoted as A \u223c BP(c,H). In FL, the base measure H can represent any distribution of the initial global model (see Sect. 4), i.e., before the training starts, and a concentration function c quantitatively characterizes the similarity between the input base measure (H) and the output random measure A (because of the distribution over the random selection of elements in \u03a9). In this work, c determines the similarity between the input and the output distribution over \u03a9, and \u03a9 is a space of initial global model weights. The intuition here is to use this baseline BP, called baseline BP prior, to form hierarchies of BP, called hierarchical BP prior, for n different clients selected in the first FL round, i.e., create n sub-BP from the baseline BP.\nInformally, a prior is the previous knowledge of an event before any new empirical data is observed and is typically expressed as a probability distribution or random measure, while a posterior is the revised or updated knowledge of the event after considering the new data. Now, an HBP for each client i is denoted as Ai \u223c BP(ci , A). In the subsequent iterations of the FL, these priors (as computed above) will be updated, based on the new client updates, to compute the so-called BP posteriors, i.e., update the ci and Hi (Ai). In this work, we have assumed the new client updates in each round as the new data to update the previous knowledge of the BP priors, i.e., to compute the BP posteriors.\nIn this work, we flatten updates for each client i to a one-dimensional vector having l values, denoted as Wi. We assume that each value in this vector is drawn from a Bernoulli Process (BeP), given the client i\u2019s BP random measure Ai. Informally, a BeP is a stochastic process with two possible outcomes: success or failure \u2212 we use it in this work to show whether a client i\u2019s update will have a particular value (or not), given its BP random measure Ai. In FL, each client updates its local model using the common aggregated global model sent by the global server. Hence, we postulate that each client update vector values are drawn from its corresponding BP random measure Ai, using BeP. Thus, a weight vector Wi for client i \u2208 {1, ..., n} is charac- terized by a Bernoulli Process, given as Wi|Ai \u223c BeP(Ai). In other words, in Wi = {Wi,1,Wi,2,...,Wi,l}, l denotes the independent BeP draws over the likelihood function Ai.\nAnother reason to use BeP is that it has been shown in the literature that the Beta distribution is the conjugate of the Bernoulli distribution [6]. Hence, we do not have to use the computationally intensive Bayes\u2019 rule to compute the posteriors. We keep updating the corresponding HBP (Ai) for client i using the conjugacy of the BP and the BeP, as given in [41]. The posterior distribution of Ai after observing\nWi is still a BP with modified parameters:\nl!\nAi|Wi\u223cBP ci+l, ci H+ 1 \u2211Wi,l (1) ci +l ci \u00b7l l=1\nDesigning the backdoor detection algorithm. Next, we briefly describe how we adapt the Chinese Restaurant Pro- cess to detect malicious client updates. The CRP [39], [5], [22] is an infinite (unknown number of clusters) mixture model in which customers (client\u2019s updates) are assigned tables (clusters) in a restaurant. In the context of FL, the clusters represent groups of incoming client updates. The customer can either sit at the already occupied tables (existing clusters) or at the new table (a new cluster is created). Our main idea, as discussed earlier, is to uti- lize a probabilistic measure to determine the distribution of the incoming local client i\u2019s update. In addition, we also compute the distribution of the existing clusters of updates plus the new cluster. Then, we compute the Jensen- Divergence between client i\u2019s update distribution and each existing plus new cluster\u2019s distribution. Informally, Jensen- Divergence (or Jensen-Shannon Divergence) is a measure of how similar two distributions are. In consequence, we obtain a set of Jensen-Divergence values. We take the maximum of this set to determine whether local client i is malicious or not (intuition, as to why use maximum Jensen- Divergence, is shown in Sect. 4). Based on this maximum Jensen-Divergence value, we also determine the client i\u2019s update cluster assignment. After the cluster is determined, we append the client i\u2019s update to the selected cluster\u2019s list of client updates. Finally, we update the cluster\u2019s parameters, i.e., mean and standard deviation, using Chinese Restaurant Process (CRP). This adaptation of the CRP is also referred to by us as CRP-Jensen.\n3. Adversary Model\nAttack Objectives. The target system trains a Neural Network (NN) f taking samples from a domain D as input and returning predictions from the set L. The system realizes a function f : D \u2192 L. The goal of the adversary A is to inject a backdoor into the aggregated model making it predict a certain adversary-chosen label lA \u2208 L for all samples that contain the backdoor trigger, called the trigger set DA \u2282 D. The success of this objective is measured by calculating the accuracy for DA. The attack needs to be stealthy to prevent the backdoor from being detected. Therefore, A needs to ensure that the attack does not affect the model\u2019s performance on the benign main task, i.e., changing the predictions of samples d \u2208 D \\ DA . For conducting such stealthy backdoor attacks, we assume that A crafts poisoned model updates. A also needs to ensure that the poisoned model updates are indistinguishable from the benign model updates in terms of all the metrics that the aggregation server may use to detect poisoned models. As A knows the defense mechanism deployed on the server side (see below), it suffices to make the poisoned model updates indistinguishable from the benign model updates in\n "}, {"chunk": "  Global model, \ud835\udc3a\ud835\udc61\u22121\n Client 1\n\ud835\udc56,\ud835\udc59\n... Client \ud835\udc56 ...\nPosterior Computation Detection\nClient \ud835\udc5b\n\ud835\udc4a\ud835\udc4a 1,\ud835\udc59 \ud835\udc4a \ud835\udc5b,\ud835\udc59\n       BayBFed\n  Filter Malicious Updates\n \ud835\udc40\ud835\udc4e\ud835\udc65\ud835\udc56 \ud835\udc63\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\ud835\udc60 \ud835\udc3d\ud835\udc37\n Global model, \ud835\udc3a\ud835\udc61\nFigure 1: High-level overview of BayBFed.\nterms of the metrics that are used by the defense mechanism.\nAttacker\u2019s Capabilities. We assume A to have the follow- ing capabilities to achieve its objectives:\n1. Controlling malicious clients: Aligned with existing work [1], [30], [37], we assume A to fully control nA < n2 clients where n is the total number of participants. In partic- ular, A can arbitrarily manipulate the data and training pro- cess of the malicious clients. Therefore, besides poisoning the training data, A can freely adapt the hyperparameters of the training process, and the loss function and can also scale the model updates before sending them to the aggregation server. A does not control the benign clients. Moreover, it neither knows their training data nor their model updates, although it can make a rough estimation of the benign model updates by training a model using the benign training data (i.e., without backdoors) of the malicious clients.\n2. No control over the aggregation server. A has complete knowledge of the global server\u2019s aggregation operations, including the deployed backdoor defenses. However, A neither controls the server nor knows the parameters that are calculated by the server at runtime and can only interact with the server through the compromised clients. However, an adaptive A can manipulate the model updates based on the knowledge of the deployed backdoor defense at the global server.\n4. Design\nIn this section, we first discuss the requirements posed on BayBFed due to the BNP nature of our defense. Then, we outline the architecture of our BayBFed defense mechanism and describe each component in detail.\n4.1. Requirements\nIn BNP models, exchangeability (defined below) is a critical requirement that must be satisfied by a certain sequence of random variables to model different parameters such as pri- ors and posteriors (see Sect. 2). Since, the detection module (CRP-Jensen) takes client updates (Wi) as one of its inputs and its l values are modeled by employing the Hierarchical Beta-Bernoulli Process (HBBP), both the client updates, Wi and it\u2019s l values should satisfy the exchangeability property. Informally, the exchangeability property (of a sequence of\nrandom variables) states that the joint distribution of all the random variables remains the same for any permutation of random variables. Specifically, we identify the following two key requirements that we will use in the design of BayBFed. Requirement I. For the posterior computation, a flattened client update vector is a sequence of random variables and should be drawn from an exchangeable set of choices.\nWe consider that the l values in a client i\u2019s update vector Wi are drawn from an exchangeable set of choices. The reason is, in Eq. 1, we only utilize the summation of client i\u2019s l update values to update the base measure Hi. Hence, the order of the l values in client i\u2019s update will not affect the computation of Hi. Mathematically, a sequence of random variables X1 , X2 , ..., Xl is called an exchangeable sequence, if the distribution of X1 , X2 , ..., Xl is equal to the distribution of X\u03c01 , X\u03c02 , ..., X\u03c0l for any permutation (\u03c01,\u03c02,...,\u03c0l). We consider Wi = {Wi,1,Wi,2,...,Wi,l} to be an exchangeable sequence for the computation of Beta posterior in BayBFed.\nRequirement II. For the detection algorithm employing CRP-Jensen, each client update is a sequence of random variables and should be drawn from an exchangeable set of choices.\nCRP is an infinite mixture model which is used to assign data or samples to the mixtures (or clusters). The data or samples are assumed to be drawn from an exchangeable set of choices. Hence, irrespective of the order in which the data arrives, their assignment to the mixtures or clusters (i.e., their seating arrangement in CRP) is not affected. In this work, we assign client i\u2019s update Wi to a cluster by employing CRP and Jensen-Divergence (JD). Thus, we consider Wi to follow the exchangeability property. The reason is that client i\u2019s local training does not depend on another client\u2019s local training. Thus, permuting the client updates Wi or changing the order of the incoming client updates will not affect the output of the detection module. Thus, in this work, we consider the incoming client updates Wi, where 1\u2264i\u2264n and n is the number of clients, as an exchangeable sequence.\n4.2. BayBFed Components\nIn this section, we describe in detail the two main technical modules of BayBFed, i.e., the posterior computation module and the detection module.\n4.2.1. Posterior Computation. As briefly explained in Sect. 2, we compute Beta posteriors (using a concentration parameter and a base measure) to have a more generic representation of the client\u2019s weights, which can keep track of all the changes made in the client updates. The intuition here is to use the random measure parameters of the previous round t \u2212 1 (Beta prior), i.e., concentration parameter (ct\u22121) and the base measure (Ht\u22121), and combine them with client updates (Wit ) in round t , to compute the Beta posterior ct and Ht. This is done for each client i selected in round t. Then, the updated base measure Ht\n"}, {"chunk": "  Round \ud835\udc61 \u2212 1, \ud835\udc3a\ud835\udc61\u22121\nBaseline Beta Process (\ud835\udc68)\nRound \ud835\udc61\nRound \ud835\udc61 Client Weight Update\nand Measurement Error\n         Hierarchical Beta Process Bernoulli Process\n\ud835\udc68\ud835\udc95 \ud835\udfcf\u2264\ud835\udc8a\u2264\ud835\udc8f\nBeta Posterior Computation\n       Priors for \ud835\udc5b Clients \ud835\udc50\ud835\udc61\u22121, \ud835\udc3b\ud835\udc61\u22121,\n11 .\n.\n.\n\ud835\udc50\ud835\udc61\u22121, \ud835\udc3b\ud835\udc61\u22121 \ud835\udc5b\ud835\udc5b\nWeights of \ud835\udc5b Clients \ud835\udc4a\ud835\udc61,\n. . .\n\ud835\udc4a\ud835\udc61 \ud835\udc5b\n           Update Mean and Standard Deviation\nComputation of Jensen\nComputation of \ud835\udc5d and \ud835\udc5e\n Divergence (\ud835\udc74\ud835\udc82\ud835\udc99\ud835\udc8a \ud835\udc71\ud835\udc6b\n)\n        \ud835\udc5d\ud835\udc4e\ud835\udc5b\ud835\udc51\ud835\udc5e \ud835\udc57\ud835\udc60\ud835\udc56 \ud835\udc560=0\n\ud835\udc5d\ud835\udc4e\ud835\udc5b\ud835\udc51\ud835\udc5e \ud835\udc57\ud835\udc60\ud835\udc56 \ud835\udc561=1\n. .\n\ud835\udc5d \ud835\udc4e\ud835\udc5b\ud835\udc51\ud835\udc5e\n\ud835\udc56 \ud835\udc5b\ud835\udc5c\ud835\udc50= \ud835\udc5b\ud835\udc5c\ud835\udc50\n\ud835\udc57\ud835\udc60\ud835\udc56\n1\nPosterior for \ud835\udc5b Clients \ud835\udc50\ud835\udc61,\ud835\udc3b\ud835\udc61 ,\n11\n. . .\n\ud835\udc50\ud835\udc61 , \ud835\udc3b\ud835\udc61 \ud835\udc5b\ud835\udc5b\n   \ud835\udc4a\ud835\udc61 .\ud835\udc5b.\ud835\udf0f+\ud835\udf07.\ud835\udf0f \ud835\udf07\ud835\udc5b\ud835\udc52\ud835\udc64= \ud835\udc56,\ud835\udc62\ud835\udc5d \ud835\udc58 \ud835\udc58 0 0\n\ud835\udc5b\ud835\udc58 .\ud835\udf0f\ud835\udc58 + \ud835\udf0f0\n\ud835\udf0e\ud835\udc5b\ud835\udc52\ud835\udc64 = 1 + \ud835\udf0e2 \ud835\udc61 \ud835\udc5b\ud835\udc58 .\ud835\udf0f\ud835\udc58 + \ud835\udf0f0 \ud835\udc4a\ud835\udc56\n\ud835\udc5d=\ud835\udc41\ud835\udc4a\ud835\udc61 ;\ud835\udf07,\ud835\udf0e \ud835\udc56,\ud835\udc62\ud835\udc5d \ud835\udc5d \ud835\udc5d\n\ud835\udc5d = \ud835\udc65 + \ud835\udc3b\ud835\udc61 \u2200 \ud835\udc65 \u2208 \ud835\udc5d \ud835\udc56\n\ud835\udc5d=\ud835\udc41 \ud835\udc5d;1,\ud835\udc4a\ud835\udc61 \ud835\udc56,\ud835\udc62\ud835\udc5d\n\ud835\udc5e=\ud835\udc41\ud835\udc4a\ud835\udc61 ;\ud835\udf07,\ud835\udf0e \ud835\udc56,\ud835\udc62\ud835\udc5d \ud835\udc50\ud835\udc59 \ud835\udc50\ud835\udc59\n  Filtering and Aggregation\nRound \ud835\udc61, \ud835\udc3a\ud835\udc61\n\ud835\udc4a\ud835\udc61 \ud835\udc56,\ud835\udc58,\ud835\udc62\ud835\udc5d\n=\ud835\udc4a\ud835\udc61 +cos \ud835\udc4a\ud835\udc61,\ud835\udc3a\ud835\udc61\u22121 \ud835\udc56,\ud835\udc58 \ud835\udc56\n\u2200 \ud835\udc58 \u2208 (0, ... , \ud835\udc59)\n  \ud835\udf0e\ud835\udc4a\ud835\udc61 =\ud835\udc51\ud835\udc4a\ud835\udc61 \u2217cos \ud835\udc4a\ud835\udc56\ud835\udc61,\ud835\udc3a\ud835\udc61\u22121 \ud835\udc56 \ud835\udc56\n   Posterior Computation\nDetection\n Figure 2: Illustration of BayBFed\u2019s design, showing its two modules: Posterior computation and CRP-Jensen.\nis utilized in the detection module to filter the poisoned updates. This process is repeated for the subsequent iterations of FL, until the model converges. A high-level overview of BayBFed\u2019s architecture is depicted in Fig. 1. Below, we outline a more detailed understanding of the components of the posterior computation as shown in Fig. 2.\nBaseline Beta Process (BP). The first step is to create an initial or baseline BP (A) before any FL training starts. The goal is to use this baseline BP to create the sub-Beta priors using the HBP, for the clients selected in the first training round. In our experiments (as discussed later in Sect. 6), we initially choose a random baseline of c = 5 and continuously update it based on the posteriors of client updates. Further, we choose a base measure H =N(\u03bcp,\u03c3p) with \u03bcp equal to the mean of the flattened initial global model and \u03c3p equal to the standard deviation of the flattened initial global deviation, i.e., populating A with the initial global model weights. We assume that the data points (client updates) are normally distributed for the above mean and standard deviation computation.\nHierarchical Beta process (HBP). The next step is to create hierarchies of the baseline BP for the clients selected in the first round. For a client i selected in round t, HBP is used to define its BP as Ati \u223c BP(cti , A). In our experiments, before the training starts, we assign the same base measure of H to each client selected in the first training round, and concentration parameters (for each client) are computed as random variables of a Poisson process with parameter c. The Poisson process [18] creates randomized point patterns, and that is why we employ it to compute random concentration parameters (cti) for each client i. After the\nfirst round, each client\u2019s concentration and base measure gets updated according to Eq. (1).\nBernoulli Process (BeP). In this work, BeP is defined as the draw of an exchangeable sequence of weights, Wit = {Wi,1,Wi,2,...,Wi,l}, given the concentration parameter cti and the base measure Hit, i.e., Beta prior. This means the l-dimensional vector update of a client is considered to be the l independent BeP. Given the client update Wit at time t, we use Eq. (1) to obtain the Beta posterior of round t. The computedBetaposterior(cti andHit)overclienti\u2019supdateis integrated into the following detection module to determine whether incoming Wit is malicious or not.\n4.2.2. Detection Module. In this module, we design a\nvariation of the CRP, called CRP-Jensen, to filter the poi-\nsoned updates sent by malicious clients (see Sect. 2). CRP-\nJensen ensures that all malicious updates are detected (and\nremoved) without limiting the benign performance of the\ntarget global model. The intuition here is to integrate the\nupdated base measure (Ht) to compute the p distribution of\nupdated client weight, W t , as shown in Eq. (2). Further, we i,u p\ncompute a q distribution across the updated client weight, Wt , for the existing clusters of the client updates or a new\ni,u p\ncluster (client update, Wit , can get assigned to a new cluster).\nThen, we compute a set of JD between the client i\u2019s p and each cluster\u2019s q, obtaining a set (length: number of existing clusters + 1) of JD values for each client i.\nNext, we compute the maximum value (Maxi ) of this JD\nset and accordingly decide the cluster assignment for the\ncorresponding clients. In the experiments (see Sect. 6),\nwe show that this value (Maxi ) varies significantly JD\nfor malicious and benign updates. Thus, based on these\n"}, {"chunk": " acquired maximum JD values, we filter out the malicious updates and perform the aggregation operation on the remaining benign client updates to obtain the global model Gt . Below, we outline a more detailed understanding of the components of the detection module as shown in Fig. 2.\nClient weight update and measurement error. First, we\nupdate each client\u2019s local model using the cosine angular\ndistance (cos(Wit,Gt\u22121)) between the local model and the\nglobal model. The intuition for doing this is to integrate the\neffect of cos(Wit,Gt\u22121) into the weights. The reason is that\neven though an adversary can manipulate the cosine angular\ndistance, the poisoned weights have to differ (slightly) from\nthe benign weights. Otherwise, the poisoned models will\npredict the correct label rather than the backdoor target label\nthat A chooses. Therefore, to run an effective attack, A\nneeds to simulate the weights in the backdoor direction. For\nthe client\u2019s model Wt with l entries, where Wt denotes i i,k,u p\nthe element at index k, the updated client weights (Wt ) i,u p\nFigure 3: p and q distribution value range for (i) the mali- cious updates, (ii) the benign updates, and (iii) the clusters.\nwhere, Wt is the mean of Wt and \u03bcp and \u03c3p are i,u p i,u p\nthe mean and the variance of the initial global model, respectively. Ht is the updated round t base measure that is\nare computed as:\nW t = W t i,k,up i,k\n+ cos(W t , Gt \u22121 ) i\n\u2200k \u2208 {0, . . . , l } (2)\n In CRP, when a new sample is assigned to a cluster, the total error or variance is computed as a combination of two errors: the measurement error because of the new sample, and the errors due to already assigned samples. Thus, we compute the measurement error due to the new client\u2019s weight getting assigned to the specific cluster (in each round), given as:\n\u03c3wti = dwti \u00b7cos(Wit,Gt\u22121) (3) where dwti is the L2 \u2212 norm between the global model in the\nprevious round Gt\u22121 and client i update in the current round\nWit . Using the L2 \u2212 norm as the measurement error has the\nsame reasoning above for using the cosine angular distance.\nEven though an adversary can individually manipulate the\nL2 \u2212 norm and cosine distance, there is still a correlation\nbetween the two that differs for the malicious and the\nbenign weights. We found the above connections, shown\nin Eq. (2) and Eq. (3), using our extensive experimental\nevaluations. We integrate Wt and \u03c3 t into the detection i,up wi\nmodule to effectively eliminate all the malicious updates.\nComputation of p and q. We then compute the two probability distributions p and q, and use JD to compute their similarity. Here, we integrate the current round base measure Ht to compute p distribution of client updates, such that the detection phase of the defense is not affected by any local client training strategy. Thus, in round t, we compute each client\u2019s p and each cluster\u2019s q as given in Eq. (4) and Eq. (5), respectively.\np=N(Wt ;\u03bc,\u03c3) i,up p p\np = x + Ht \u2200x \u2208 p\np=N(p;1,Wt ) (4)\nq=N(Wt ;\u03bc ,\u03c3 ) (5) i,up cl cl\nct\u22121 1l\ngiven as i Ht\u22121+ \u2211 Wt (see Eq. (1)). \u03bc and\nct\u22121+l ct\u22121\u00b7l i=1 i cl ii\n \u03c3cl are the clusters\u2019 mean and variance, respectively. Then for each client i, we compute the JD of it\u2019s p with each cluster\u2019s q.\nComputation of Jensen-Divergence (JD). Next, we\ncompute the JD between each client\u2019s p and each\ncluster\u2019s q. By computing the JD of each client i\u2019s p\nvalues with each cluster\u2019s q values, we get a set of:\n{(pi,q0) : jsi0,(pi,q1) : jsi1,...,(pi,qnoc) : jsinoc}. Then,\nwe compute Maxi : max( jsi , jsi , ..., jsi ) to output the JD 01noc\nassigned cluster of client i weights Wt and to decide i,u p\nwhether it\u2019s a malicious update or a benign update. Here, noc is the total number of clusters formed yet.\nMean and standard deviation update. In the previous step, we computed the client\u2019s assigned cluster. Now, we update the mean and the variance of that particular cluster according to the equations:\n Wt nk\u03c4k+\u03bc0\u03c40\ni,up (6)\nnk\u03c4k +\u03c40\n1 +\u03c32t (7)\nwhere, nk is the number of client updates already assigned to it, \u03c4k represents the precision of the cluster, \u03bc0 and \u03c40 represent the initial mean and the precision assumed for\nthe new clusters. \u03c3w2t is the variance or the measurement i\nerror introduced by the new addition of the client update and is computed according to Eq. (3).\n\u03bcnew = \u03c3new =\nnk\u03c4k +\u03c40 wi\n   i,u p\n"}, {"chunk": " Filtering and Aggregation. Finally, we examine the\npatterns of the malicious updates based on the computed\nMaxi , which differs significantly from the benign updates. JD i\nWe encountered two patterns of malicious updates MaxJD in our experiments, as discussed later in Sect. 6: (i) the Maxi\nAlgorithm 1 BayBFed\u2019s workflow.\n1: Input: \u03bc , \u03c32, \u03c32t , \u03c4 = 1 , \u03c4 = 1 , noc.\n computed for malicious updates are much greater than that\nfor the benign updates, and (ii) the computed Maxi values t\nfor the malicious updates are similar to each other. For\npattern (i), we observed that the MaxJD value for benign\nupdates is less than the average of all the clients\u2019 Maxi JD\nvalues (experimentally evaluated). Therefore, conditioned\non this observation, we filtered the malicious updates during\nthe detection phase of BayBFed. For pattern (ii), we check\n7: 8: 9:\n10: 11: 12: 13: 14: 15: 16: 17: 18:\n19: 20: 21:\n22: 23: 24: 25: 26: 27:\nUpdate \u03c32t \u2190 d t \u00b7cos(Wt,i,Gt\u22121) and compute Wt . wi wi i,up\nif Maxi of the incoming update is already present in the JD\nend if forcl\u2190tonoc+1do\nCompute p and q.\nCompute the JD by p and q and store the values.\nDecide the cluster, c according to Maxi . i JD\nJD if cl,i=cl then\nUpdate Wt assigned cluster, {\u03bct , \u03c3t } according to i cl cl\ncl,i =cl. else\nIncrement: noc = noc + 1, a new cluster is formed. Set cl,i = noc and assign Wt to it. Append this new\ni\ncluster to the vector of non-empty clusters.\nend if end for\nend for\nCall DetectFilter(), fcp = DetectFilter(Maxstored). JD\nPerform FedAVG(fcp) and update the global model. end for\nset of computed Maxi for the n clients; if yes, we do not JD\ninclude the concerned malicious client\u2019s update in the final aggregation of updates to output the global model Gt.\nIntuition for the filtering step. To understand the rela- tionship between the computed maximum JD values Maxi\n(as outlined above) and the benign/malicious nature of the\nupdates, we conduct experiments utilizing a diverse set of\ndatasets (see Sect. 5). In these experiments, we illustrated\nthe Maxi values for malicious and benign updates and JD i\nobserved that MaxJD values of malicious and benign updates differ significantly. Fig. 3 gives an intuition of why Maxi\ndiffers for the malicious and benign updates by examining the range of p distribution values for the client updates against the clusters\u2019 q distribution values. In Fig. 3, the (i) plot demonstrates the malicious update\u2019s p values spanning area, the (ii) plot demonstrates the benign update\u2019s p values spanning area, and the (iii) plot demonstrates the clusters\u2019 q values spanning area, as observed from the experiments conducted. As seen in these plots, the benign update\u2019s p values lie at a larger distance than the malicious update\u2019s p values (as the values in p are either equal to or very close to zero). Thus, the distance between the p values of malicious updates, and the q values of the clusters is greater than the distance between the p and q values of benign updates. In other words, JD ( p (malicious update), q) > JD ( p (benign update), q). Hence, maximum JD is used as a metric to iden- tify malicious updates and assign them to the new cluster.\n4.3. BayBFed WorkFlow and Algorithms BayBFed\u2019s workflow and detection algorithm have been\noutlined in Algorithms 1 and 2. Here, \u03bc is the assumed 0\nAppend Maxi to Maxstored.\ninitial mean of the clusters and \u03c302 is the assumed variance corresponding to mean \u03bc0 . \u03c3 2t is the measurement error of\nwi\nthe client update Wit and is computed as shown in Eq. (3).\nThus, total measurement error or the variance is computed\nas shown in Eq. (7). If a new cluster is formed, it will\nhave a normal distribution with mean \u03bc0 and the combined\nvariance of \u03c32 + \u03c32t . The set {\u03bct , \u03c3t } represents the mean 0 wi cl cl\nand standard deviations of the cl clusters at time t. We start Algorithm 1 by looping through the number of rounds of FL training as shown in line 2. In each round, we initialize an\nempty array, Maxstored = [], to store the Maxi values of the JD JD\nJD\n5: Draw any client update Wi .\nJD [].\nJD\nJD\nJD\n0 0 wi 0 \u03c302 w \u03c3w2ti\n2: for each round till the model converges do\n3: Initialize an array to store Maxi\nin each round, Maxstored = JD\n4: for i1\u2190ton do\n6: Compute d t and cos(Wt,Gt\u22121) . i wii\nifnoc==0then Assign c0 \u2190Wt.\ni\nUpdate \u03bcnew and \u03c3new with, nk = 1.\nJD\n clients. n clients are selected for the training, and we loop\nthrough each client i (line 4) to determine its cluster. We then\ncompute Wt and \u03c3 t according to equations (2) and (3), i,up wi\nrespectively (lines 7). If noc = 0, then it\u2019s the first round, and\nthe first client is assigned to the first cluster (line 9), and\naccordingly, this new cluster\u2019s \u03bcnew and \u03c3new are updated\n(line 10). If noc \u0338= 0, then for each existing cluster plus the\nnew one (line 12), we do the following: first, we compute\np and q (line 13), second, we compute the JD of each\nclient\u2019s p and each cluster\u2019s q (line 14), third, we compute\nthe maximum of the obtained JD set (Maxi ) and decide JD\nthe assigned cluster (line 15) according to this value, and finally append it to the array Maxstored (line 16). Either the\nclient will be assigned to one of the already formed clusters\n(line 17) or it will be assigned to a new cluster (lines 20, 21).\nAfter each FL round, Algorithm 2 (DetectFilter()) is called\nwhich takes input Maxstored (line 25) and returns the filtered JD\nclient updates, fcp. FedAVG(fcp) (defined in Appendix A) algorithm is then performed to aggregate the filtered client updates and finally update the global model.\n5. Experimental Setup\nWe employ the machine learning framework PyTorch to conduct our experiments and use the existing defenses [4], [14], [37], [27], [48], [25], [30] as baseline models to com- paratively analyze the performance of BayBFed. Aligned with previous work on backdoor attacks [1], [3], [30], we\nJD\n"}, {"chunk": " Algorithm 2 Detection and Filter Algorithm, DetectFilter.\n1: 2: 3:\n4: 5: 6: 7: 8: 9:\nTABLE 1: Backdoor Accuracy (BA) and Main Task Ac- curacy (MA) of BayBFed compared to two state-of-the-art attacks. All values are represented as percentages.\n Input: Maxstored containing Maxi JD JD\nvalues, total clients, n Initialize an array to store filtered client updates in each round,\nOutput: Filtered client updates\n Wfiltered =[].\nCompute Maxavg = sum(Maxstored)/n\nBA MA 100.0 22.6 100.0 90.5\n43.0 96.5\n71.0 85.5 100.0 100.0 33.16 88.42\nBA MA 0.0 22.6 0.0 92.2 0.0 96.0 2.0 85.3 0.0 100.0\n4.02 82.82\nAttacks\nConstrain-and-Scale [3]\nEdge-Case [42]\nDataset\nReddit CIFAR-10 MNIST FMNIST IoT-Traffic CIFAR-10\nNo Defense BayBFed\n   JD fori=1tondo\nJD\nthen\n if Maxi not in Maxstored\n  10: W\n.append(W t ) i\n11: 12: 13:\nend if end for\nW\n.append(W t ) i\nJD filtered\nJD\n end if\nif Maxi <Maxavg then\n JD filtered\nJD\nus by Nguyen et al. [29], [30] and Sivanathan et al. [38]. The datasets consist of network traffic of multiple smart home and office settings. Aligned with previous work [30], [35], we converted the network packets into symbols based on their features, such as source and destination ports, protocols, and flags. To simulate a distributed FL setting, we split the dataset into 100 local datasets, each consisting of symbols between 2K and 3K, which were extracted from the network packets. The NN is trained to predict the next probabilities for each possible symbol (network packet). The NN consists of 2 Gated-Recurrent-Unit layers followed by a fully connected linear layer, as defined by Nguyen et al. [29].\nEvaluation metrics. We compute four metrics to estimate\nthe accuracy and precision of BayBFed.\nTrue Positive Rate (TPR): This metric specifies how ac-\ncurately the defense is able to detect the poisoned model\nupdates. The total number of correctly identified poisoned\nupdates are called True Positives (TP) and the number of\npoisoned model updates discerned as benign model updates\nare called False Negatives (FN). Thus, TPR = TP . TP+FN\nTrue Negative Rate (TNR): This metric determines how\naccurately the defense is able to detect the benign model\nupdates. The total number of correctly identified benign\nmodel updates are called True Negatives (TN) and the\nnumber of benign updates discerned as poisoned updates\nare called False Positives (FP). Thus, TNR = TN . TN+FP\nBackdoor Accuracy (BA): This metric is used to measure the accuracy of the model on the triggered inputs. Specifically, it measures the fraction of triggered samples where the model predicts the adversary\u2019s chosen label.\nMain Task Accuracy (MA): This metric is used to measure the accuracy of the model on its benign main task. It represents the fraction of benign inputs for which the model provides correct predictions.\n6. Experimental Results\nNext, we empirically illustrate the effectiveness of BayBFed\nagainst two state-of-the-art attacks [3], [42] and compare its\nefficacy against various state-of-the-art defense mechanisms.\nFurther, we show how Maxi varies for the malicious and JD\nbenign model updates. Finally, we demonstrate the robust- ness of BayBFed for various adversarial attack parameters and sophisticated backdoor injection strategies.\n6.1. Overall Performance\nAttack Strategies. The effectiveness of BayBFed against two state-of-the-art model poisoning attacks, the Constrain-\nReturn Wfiltered\n use the attacks provided by Bagdasaryan et al. [3] and Wang et al. [42] to implement the Constrain-and-Scale and Edge- Case backdoor attacks. Below, we provide the configurations of the different datasets and the accuracy and precision metrics we use to evaluate the performance of BayBFed. Datasets. To show the generality of our results and the representative nature of BayBFed across models/data from different domains, we evaluate the proposed defense mecha- nism by designing two attacks (see Tab. 1) on three popular FL applications: (i) image classification, (ii) word predic- tion, and (iii) IoT network intrusion detection. To facilitate an equitable comparison of BayBFed with state-of-the-art backdoor attack approaches [3], [30], we align the datasets, setups, and NN architectures employed in our comparative evaluation with the ones used by these research efforts. Image Classification (IC): We use the popular benchmark datasets MNIST, FMNIST, and CIFAR-10 in our experi- ments. As these datasets are frequently used for evaluating FL and backdoor attacks and defenses [3], [8], [14], [15], [16], [20], [23], [27], [30], [35], [42], [43], [44], [13], [34], it enables us to perform an equitable comparative analysis of our approach with other state-of-the-art approaches in the literature. All three consist of samples belonging to one out of ten classes, handwritten digits in the case of MNIST, articles of clothing in the case of FMNIST, and objects (airplanes, cars, birds, etc.) in the case of CIFAR-10. The CIFAR-10 dataset consists of 50K training and 10K test images, while MNIST and FMNIST datasets each consist of 60K training and 10K test images. As the NN architecture, a light-weight version of Resnet-18 is used for CIFAR-10 [3], a simple CNN is used for MNIST [8], and a three-layer fully connected NN with relu activations is used for FMNIST. Word Prediction (WP): To evaluate BayBFed for a complex Natural Language Processing (NLP) application such as word prediction, we use the Reddit dataset consisting of all posts from November 2017. Aligned with the work of Bagdasaryan et al., we considered each author\u2019s posts as a local dataset and only the 50K most frequent words. A Long Short-term Memory (LSTM) model is used to predict the next word [3].\nNetwork Intrusion Detection (NIDS): Further, we evaluate BayBFed for the FL-based NIDS D \u0308IoT [29] system using four real-world network traffic datasets, kindly shared with\n  "}, {"chunk": "and-Scale [3] and the Edge-Case backdoor [42] is shown in Tab. 1. As we have assumed that an adversary can fully control the malicious clients (and thus the code on the clients), he is not restricted or constrained in terms of the employed attack strategy. In addition to attacks during training, our adversary can also adopt a runtime strategy to make the attack more stealthy.\nAs can be seen in Tab. 2, BayBFed functions opti- mally against Constrain-and-Scale attacks by filtering out all poisoned updates (BA = 0%). At the same time, the MA remains approximately equal to the benign setting MA. It should be noted that if the MA is less than 100%, misclassifications of the model can be counted in favor of the backdoor, especially if the model wrongly predicts the backdoor target. As already pointed out by Rieger et al. [35], this phenomenon primarily occurs for image scenarios with pixel-based triggers. It causes the BA to be slightly higher than 0% for backdoor-free models. In the case of an Edge- Case attack, the BA before the attack and after BayBFed integration is 11.22% and 4.02%, respectively. However, without defense, the BA achieves 33.16%.\nBaseline Models. We compare BayBFed against seven state-of-the-art defense mechanisms present in the litera- ture: Krum [4], FoolsGold [14], Auror [37], AFA [27], DP [48], Median [25] and FLAME [30]. We implement the Constrain-and-Scale attack against all the defenses and compare the output statistics in terms of the BA and MA. As illustrated in Tab. 2, BayBFed outperforms all these defense mechanisms. These results show that the existing defense mechanisms either lack the precision in removing all the poisoned updates or limit the MA of the global model. Further, these defense mechanisms perform accurately when specific assumptions about the data and attack scenarios are satisfied. For instance, in the case of Krum [4], which selects a single model as an aggregated model, a poisoned model is chosen when an attacker circumvents Krum. Therefore, the aggregated model is entirely replaced by a poisoned model, achieving 100% BA. Similarly, another defense FoolsGold [14], is effective for the highly non-IID Reddit dataset but fails when their clients have similar data. It should be noted that BayBFed achieved a TPR and TNR of 100% in all three scenarios.\nImpact on the MA. For the IC application CIFAR-10 dataset, we observe that the Constrain-and-Scale attack lowers the MA from 92.6% (FedAVG without attack) to 90.5% (FedAVG). Krum, FoolsGold, Auror, DP, and Median techniques achieve a MA of 56.7%, 52.3%, 26.1%, 78.9%, and 50.1%, respectively, which is considerably lower than the benign setting MA. In contrast, BayBFed has a MA of 92.2%, which shows that it works significantly better for IC applications. For the WP application, Krum and DP have a decreased MA of 9.6% and 18.9%, compared to the highest MA of 22.6%. In this case as well, BayBFed performs much better and achieves a MA of 22.6%. For the IoT-Traffic dataset, every defense has decreased MA. In this case, even small drops in MA need to be avoided due to the nature of this application. The reason is due to the high number of network packets in this scenario; even a small number of\nTABLE 2: Backdoor Accuracy (BA) and Main Task Ac- curacy (MA) of BayBFed compared to state-of-the-art de- fenses for the Constrain-and-Scale attack. All values are represented as percentages.\n Defenses\nReddit\nCIFAR-10\nBA MA - 92.6 100.0 90.5 100.0 56.7 100.0 52.3 100.0 26.1 0.0 91.7 0.0 78.9 0.0 50.1 0.0 91.9 0.0 92.2\nIoT-Traffic\nBA MA - 100.0 100.0 100.0 100.0 84.0 100.0 99.2 100.0 96.6 100.0 87.4 14.8 82.3 0.0 87.7 0.0 99.8 0.0 100.0\n BA MA - 22.6 100.0 22.6 100.0 9.6 FoolsGold[14] 0.0 22.5\n Benign Setting No Defense Krum [4]\n    Auror [37]\nAFA [27]\nDP [3]\nMedian [48]\nFLAME [30]\nBayBFed 0.0 22.6\n100.0 22.5 100.0 22.4 14.0 18.9 0.0 22.0 0.0 22.3\n      false alerts will annoy the user, causing them to ignore the alerts. For example, the defense technique FLAME results in a drop of 0.2%, which causes 2 out of every 1000 packets to be misclassified. As a result, when a high amount of network packets is sent, the user will receive a high number of alerts. It should be noted BayBFed recognizes all benign and ma- licious models correctly (TPR = 100% and TNR = 100%) in all three scenarios, thus, comparatively performing better than the other defense mechanisms such as FLAME. For example, FLAME excludes benign models; in the NIDS sce- nario, FLAME wrongly excludes 17 benign models, which might be problematic in the case of highly non-IID data. Backdoor updates removal. Krum and Auror fail to re- move poisoned updates in all three applications, as these defenses exhibit a BA of 100%. FoolsGold eliminates all the poisoned updates in the Reddit dataset (BA = 0.0%). However, it fails to remove them in the CIFAR-10 and IoT- Traffic datasets, as it achieves a BA of 100% in those cases. For the AFA defense, it works accurately for CIFAR-10 (BA = 0.0%) but is ineffective for the Reddit (BA = 0.0%) and IoT-Traffic (BA = 0.0%) datasets. In contrast, BayBFed significantly outperforms these defenses as it can remove poisoned updates (BA = 0.0%) for all the datasets.\nNext, we discuss the impact of two critical experimen-\ntal parameters on each of the considered applications and\ndatasets in this paper: poisoned model rate (PMR) and\ndegree of non-IID data. PMR represents the fraction of nA\nmalicious clients per total clients n. Thus, PMR = nA . non- n\nIID represents the percentage of non-IID data at each client.\nA non-IID value of 0 means that the data is independently\nand identically distributed, non-IID = 1.0 implies that the\ndata of different clients differ significantly and are distin-\nguishable. For the IC application, we simulate experiments\nfor both non-IID degrees and PMR (see Sect. 6.2). However,\nfor the Reddit and the IoT datasets, changing the non-\nIID degree is not meaningful since this type of data has\na natural distribution, as every client obtains data from\ndifferent Reddit users or traffic chunks from different IoT\ndevices. Thus, we only simulate experiments for different\nPMR for these two datasets. We will also show the impact of\nthese two parameters on Maxi for each client (see Sect. 4) JD\nand prove that it differs significantly for the benign and poisoned updates.\n"}, {"chunk": "        Benign Poisoned\n    Benign Poisoned\n        Benign Poisoned\n   555 000\n0 10 20 30 Local Models\n(a) non-IID = 0.0\nFigure 4: Effect of different non-IID rates on the maximum Jensen-Divergence (Maxi ) for CIFAR-10 dataset.\n444\n222\n6.2. BayBFed Statistics for CIFAR-10\nIn this section, we evaluate the impact of non-IID rate and\nPMR on the CIFAR-10 dataset. First, we demonstrate the\ntrend of Maxi for both the malicious and benign clients JD\nwith respect to each of these parameters. Then, we illustrate\nthe impact of non-IID rate and PMR on BayBFed\u2019s perfor-\nmance by quantifying different metrics as stated in Sect. 5\nand also compare it against the no defense scenario.\nJD\nthis setting. As one can observe, we obtain T PR = 100%, indicating BayBFed achieved BA = 0, i.e., all the poisoned models were detected and filtered out before the aggregation. In addition, BayBFed achieved TNR = 100%, indicating it correctly identified all the benign updates, thus getting approximately MA = 92.2% for all the non-IID rates. Effect of different PMR rates. Fig. 6b shows the impact of different PMR rates on BayBFed. We consider PMRs of 0.2, 0.3, 0.4, and 0.5. Hence, nA equals 6, 9, 12, and 15. We use the same metrics that we used for non-IID rates to evaluate BayBFed against different PMRs. In this experiment, we achieve results similar to the ones we obtained for different non-IID rates. This demonstrates that BayBFed is efficient and accurate in eliminating all the poisoned updates for dif- ferent data distributions while keeping the benign accuracy of the model intact.\n6.3. BayBFed Statistics for WP\nThis section evaluates the impact of PMR on the Word\nPrediction application. First, we demonstrate the trend of\nMaxi for both the malicious clients and the benign clients. JD\nThen, we illustrate the impact of PMR on BayBFed\u2019s perfor-\nmance by quantifying different metrics as stated in Sect. 5\nand also compare it against the no defense scenario.\nIllustration of Maxi . In this setting, we also select 30 JD\nclients who can participate in each training round, and\ndemonstrate the impact of varying PMR values (0.2, 0.3, 0.5)\non the clients\u2019 Maxi . As outlined in Fig. 7, the Maxi JD JD\nvalues of malicious and benign client updates differ signifi-\nIllustration of Maxi . The impact of the degree of non-IID JD\ndata and PMR on Maxi for each client is shown in Fig. 4 JD\nand Fig. 5, respectively. We select a total of 30 (n= 30)\nclients for both the non-IID and PMR experimental analysis.\nFor non-IID analysis, we test non-IID \u2208{0.0,0.5,1.0} and\nset PMR = 0.2. Thus, the number of malicious clients equals\n6 (nA = 6). For PMR analysis, we test PMR \u2208 {0.2, 0.3, 0.5},\ni.e., when nA equals 6, 9, and 15 and set non-IID = 0.7. As\nillustrated in Fig. 4 and Fig. 5, the Maxi value for benign JD\nclients differs significantly from that of malicious clients. Hence, BayBFed easily filters out all the malicious client updates, achieving a BA of zero while keeping the MA of the global model intact.\nEffect of the degree of non-IID Data. To study the impact of non-IID data on BayBFed, we conduct experiments for the Constrain-and-Scale attack on the CIFAR-10 dataset. Following recent work [42], [11], [35], [30], we prepare the non-IID data by varying the number of images assigned to a particular class for each client. Precisely, we form 10 groups corresponding to the ten classes of CIFAR-10. Then, clients in each group are allocated a fixed fraction of images, depending on the non-IID degree of that group\u2019s label, while allocating the remaining images to each client randomly. Mainly, for non-IID = 0.0, the samples of all clients followed the same distribution and were chosen randomly from all classes. However, for non-IID = 1.0, the samples of each client were only chosen from the samples belonging to the main class of this client. Fig. 6a compares the impact of the degree of non-IID data in terms of BA and MA for the plain FedAVG without defense (No Defense BA, No Defense MA) and the impact on BayBFed (BA, MA). Fig. 6a also shows the computed TPR and TNR for BayBFed in\n100 100\n50 50\n00 0.0 0.5 1.0\nnon-IID Rate\n(a) non-IID Rate\n0.2 0.3 0.4 0.5 PMR\n(b) PMR\n0 10 20 30 Local Models\n0 10 20 30 Local Models\n(b) non-IID = 0.5\n(c) non-IID = 1.0\n000\n0 10 20 30 0 10 20 30 0 10 20 30\nLocal Models Local Models Local Models\n(a) PMR = 20% (b) PMR = 30% (c) PMR = 50%\nFigure 5: Effect of different PMR rates on the maximum Jensen-Divergence (Maxi ) for the CIFAR dataset.\nJD\nFigure 6: Impact of the poisoned model rate PMR = nA and\nnon-IID rate on BayBFed for the IC application.\nn\n   Benign Poisoned\n Benign\nPoisoned\n Benign Poisoned\n                 BayBFed TPR BayBFed TNR BayBFed BA BayBFed MA No Defense BA No Defense MA\n     BayBFed TPR BayBFed TNR BayBFed BA BayBFed MA No Defense BA No Defense MA\n Value of Metric (%)\nValue of Metric(%)\nMaxJD\nMaxJD\nMaxJD\nMaxJD\nMaxJD\nMaxJD\n"}, {"chunk": "                         Benign\nPoisoned\n   Benign Poisoned\n       Benign Poisoned\n   0.03\n0.00\n0 10 20 30\nLocal Models\n0.1 0.0\n0 10 20 30 Local Models\n0.2 0.1 0.0\n0 10 20 30 Local Models\n(a) PMR= 20%\nFigure 7: Effect of different PMR rates on the maximum Jensen-Divergence (Maxi\n0.2 0.2\n0.2 0.1 0.0\n0.1\n0.0\n0 20 40 60\nLocal Models\n0.1 0.0\n0 20 40 60 Local Models\n0 20 40 60 Local Models\n(a) PMR = 20%\nFigure 8: Effect of different PMR rates on the maximum Jensen-Divergence (Maxi\n(b) PMR = 30% cantly. Thus, BayBFed accurately identified all the poisoned\n(c) PMR = 50%\nupdates, achieving a BA = 0.0% and MA = 22.6%.\nEffect of different PMR rates. Next, we evaluate the effectiveness of BayBFed, compared against no defense BA and MA, for different PMR values (0.2,0.3,0.4,0.5). The results of this experiment are shown in Fig. 9a. These results indicate that BayBFed obtained a T PR = 100% and a T NR = 100%, for all PMR values. Moreover, it successfully identified all the poisoned and benign updates for different PMR values and achieved a BA = 0% and the highest possible MA of benign setting, i.e., MA = 22.6%.\n6.4. BayBFed Statistics for NIDS\nThis section evaluates the impact of different PMR rates on\nthe NIDS application. Here, we randomly select 60 clients\nwho can participate in each training round. It should be\nnoted that since NIDS models have a lesser number of pa-\nrameters, training time is reduced. Thus, we evaluated more\nclients than WP and IC models/applications. However, we\nset the same PMR in all scenarios. Hence, it did not impact\nthe experimental results (except for the experiments where\nwe considered different PMRs). The number of benign and\nmalicious clients varies based on the selected PMR value,\nspecifically, for PMR values 0.2, 0.3, 0.4, and 0.5, nA is 12,\n18, 24, and 30, respectively. First, we demonstrate the trend\nof Maxi for both the malicious and benign clients and then JD\nillustrate the impact of PMR on BayBFed compared to the\nno defense scenario.\n100 50\nBayBFed TPR BayBFed TNR BayBFed BA BayBFed MA No Defense BA No Defense MA\nBayBFed TPR BayBFed TNR BayBFed BA BayBFed MA No Defense BA No Defense MA\n0.2 0.3 0.4 0.5 PMR\nIllustration of Maxi . Fig. 8 illustrates the impact of JD\ndifferent PMR values on Maxi for each client. This plot JD\nillustrates the sequence of Maxi for the poisoned updates, JD\nand one can observe that they are equal and different from benign updates. By employing this pattern of the Maxi ,\nJD BayBFed was accurately able to filter out all the poisoned\nupdates, thus, attaining a BA of 0%.\nEffect of different PMR rates. Next, we compute the T PR, T NR, BA, and MA metrics to evaluate the effec- tiveness of BayBFed compared against the no defense BA and MA, for different PMR values. Results for this set of experiments are shown in Fig. 9b. By using the com-\n(b) PMR= 30%\n(c) PMR= 50%\nJD\n100 50 00\n0.2 0.3 0.4 PMR\n0.5\nJD\n) for the Reddit dataset.\n) for the IoT-Traffic dataset.\n(a) WP\nFigure 9: Impact of the poisoned model rate PMR = n on the evaluation metrics.\nputed maximum Jensen-Divergence values for each client, BayBFed is able to achieve TPR = 100%, TNR = 100%, BA = 0%, and MA = 100%. Hence, BayBFed performs optimally for the NIDS application as well.\n6.5. BayBFed Statistics for FMNIST and MNIST\nFurther, we evaluate the impact of different non-IID and\nPMR rates on the FMNIST and MNIST datasets. We used\nthe same setup that we used for the CIFAR-10 dataset\n(see Sect. 6.2). In all the experiments with FMNIST and\nMNIST, Maxi values of malicious and benign client up- JD\ndates differ significantly, as observed for CIFAR-10. Thus, BayBFed accurately identified all the poisoned updates, achieving a BA of 0%. For detailed FMNIST and MNIST results, please refer to App. D and App. E, respectively.\n6.6. Effect of Other Factors on BayBFed\nNext, we conduct additional experiments with BayBFed by varying four other parameters: (i) number of clients (hence, the number of malicious clients), (ii) backdoor injection strategies, (iii) poisoned data rates (PDR), and (iv) client order. Additionally, we also assess the trade-off between model accuracy and defense evasion for an adaptive attacker. PDR represents the fraction of injected poisoned data in the overall poisoned training dataset. Our goal in conducting these experiments is to show that BayBFed is robust against these factors in detecting backdoor attacks in FL.\nNumber of clients. In this experiment, we evaluate the impact on the performance of BayBFed by varying the\n(b) NIDS\nnA\n     Benign Poisoned\n        Benign Poisoned\n        Benign Poisoned\n        Value of Metric(%)\nValue of Metric(%)\nMaxJD\nMaxJD\nMaxJD\nMaxJD\nMaxJD\nMaxJD\n"}, {"chunk": "     TPR\nTNR\nBA\nMA\nNo Defense BA #clients\nnumber of clients, thus, the PMR. The results are outlined in Fig. 10. In each round, we select a random number of clients ranging from 40 to 90. We conduct this experiment for the IC (Fig. 10a) and NIDS (10b) applications. In both cases, BayBFed achieved a BA of 0%, thereby showing that it is effective in eliminating all the backdoors compared to the no defense scenario.\nDifferent injection strategies. An adversary (A) can inject multiple backdoors at the same time in order to make the backdoor more difficult to detect, thus making the poisoned models harder to distinguish from benign ones in non- IID scenarios. We perform four experiments for the NIDS application, where each client is trained to inject 1 to 4 backdoors. Existing work [35] has shown that the attack efficiency significantly reduces as the number of backdoors increases, and we observed the same pattern during our experiments. Hence, four backdoors were considered a good number (of backdoors) that provided reasonable attack ef- ficiency. Our evaluations show that BayBFed was able to defend against and mitigate all the introduced backdoors effectively, thus achieving a 0% BA.\nDifferent Poisoned Data Rates (PDR). In this experiment, we consider an adversary that is capable of poisoning the data to launch backdoor attacks. We evaluate this attack on the CIFAR-10 and IoT-Traffic dataset for three different values of PDR: 0.05, 0.1, and 0.5, i.e., 5%, 10%, and 50% of the training dataset is poisoned. For the CIFAR-10 dataset, we set n = 30 and PMR = 0.2, and for the IoT- Traffic dataset, we set n = 100 and PMR = 0.3. In both these scenarios, BayBFed is successful in eliminating all the backdoors, obtaining a BA of 0% and achieving an average MA of 92.4% for the CIFAR-10 dataset and 100% for the IoT-Traffic dataset.\nClient Order. To verify that the client updates are ex-\nchangeable, we conducted an experiment for the CIFAR-10\ndataset, where the models were randomly shuffled. However,\nthe shuffling did not affect the results, as we got BA = 0%\nand MA = 92.5%. These results are intuitive because ir-\nrespective of the order in which the client updates arrive\nat the detection module of BayBFed, it does not affect the\ncomputation of Maxi , which is eventually used to identify JD\nthe poisoned updates.\nAdaptive attacks. BayBFed assumes that A knows the backdoor defense deployed at the global server (see Sect. 3). Thus, A can constrain the training process to make Ht inconspicuous, by using its benign data to estimate a benign model and thus, p and Ht. However, A cannot estimate q as this requires knowing parameters that the server calculates on run-time. Thus, an adaptive attacker can only work with Ht to launch backdoor attacks against such defense. In this setting, we conducted experiments for the CIFAR-10, by updating the loss function of A using the base measure for the anomaly evasion loss term [3] according to the equation:\nL = \u03b1Lclass +(1\u2212\u03b1)LBM (8)\nLclass captures both the BA and the MA, and LBM captures the defense mechanism dependency on the base measure. We conducted three experiments with \u03b1 (determines the\n100 100 75 75 50 50 25 25\n00 02468\nRounds\n(a) IC\n(b) NIDS\nFigure 10: Impact of the number of clients on BayBFed vs No Defense for different datasets.\ntrade-off between model accuracy and evasion from defense mechanism) values as 0.0, 0.5, and 1.0. For \u03b1 = 0.0, A sac- rifices the model accuracy to evade the defense mechanism, for \u03b1 = 0.5, A is equally trading off the model accuracy and defense mechanism evasion, while for \u03b1 = 1, A is more con- cerned about the model accuracy than evading the defense mechanism detection. For \u03b1 = 1, BayBFed achieved a BA of 0%, MA of 92.33%, TPR=1 (TP=10 and FN=0), and TNR=0.95 (TN=19 and FP=1). However, as we decreased \u03b1 to 0.5, BayBFed was effective in detecting and filtering an adaptive attacker\u2019s model updates. For \u03b1 = 0.5, BayBFed obtained a BA of 0%, MA of 92.25%, T PR = 1, and TNR = 1. For \u03b1 = 0, BayBFed obtained a BA of 0%, MA of 92.14%, TPR=0 (TP=0 and FN =10), and TNR= 0.85 (T N = 17 and F P = 3). Hence, an adaptive adversary can evade detection at the cost of model accuracy. However, the non-detected models do not have any overall impact on the efficacy of BayBFed as the BA is always zero. In summary, our experiments show that BayBFed is successful in defending against an adaptive adversary who has working knowledge of BayBFed deployed at the global server.\n7. Security Analysis\nThis section provides a security analysis to corroborate that BayBFed can neutralize backdoors by modeling the defense mechanism using BNP modeling concepts. We explain why our defense works and justify its effectiveness. To bypass our defense, an adversarial client (A) has to ensure that BayBFed cannot distinguish between malicious and benign model updates. Below, we present three mechanisms through which A can hide the backdoors from BayBFed. First, A can vary the fraction (PMR) of malicious clients, i.e., A can ei- ther reduce the PMR and make the attack less suspicious, or increase the PMR to keep the attack successful while making the models less suspicious. Second, A can limit the poison data rate (PDR) for each adversarial client, i.e., instead of poisoning the entire dataset, A could partially poison the\nValue of Metric(%)\nNumber of clients\n 100 100 75 75 50 50 25 25\n00\n02468 Rounds\nValue of Metric(%)\nNumber of clients\n    TPR\nTNR\nBA\nMA\nNo Defense BA #clients\n"}, {"chunk": "dataset. Finally, A can utilize an adaptive attack strategy, such as adding regularization terms (i.e., defense evasion) to the objective function of the training process (see Sect. 6.6). A sophisticated A with the working knowledge of BayBFed (has access to the previous round base measure Ht\u22121) could select a sweet spot between the model accuracy and the evasion from BayBFed. As a result, the poisoned models are still similar to the benign models.\nIn all the above cases, we have demonstrated that BayBFed successfully detected all the malicious updates. The reason being BayBFed computes an alternate, more generic representation of the client updates, i.e., a probabilis- tic measure that encompasses all the adjustments made to the client updates due to any local client\u2019s training strategy. Hence, the detection module that takes this probabilistic measure as one of its inputs correctly identifies all the malicious updates without being affected by any local client training strategies. In addition, we also integrate the effect of cos(Wit , Gt \u22121 ) and L2 \u2212 norm (Eq. 2 and Eq. 3) in the clients\u2019 model updates and the computation of error introduced by the client weight. The rationale is that even though A makes sure the distribution of malicious updates does not deviate from benign ones, A cannot fully manipulate the cos(Wit,Gt\u22121) or L2 \u2212norm. The reason being A aims to simulate the global model in the backdoor direction. This ensures that any changes the strategic A makes utilizing advanced hiding techniques cannot bypass BayBFed. We also empirically verified the effectiveness of BayBFed using state-of-the-art (CIFAR-10, MNIST, and FMNIST) and real- world (IoT) datasets and successfully demonstrated that A cannot conduct backdoor attacks while simultaneously bypassing our defense mechanism. Therefore, BayBFed is robust and resilient against backdoor attacks.\n8. Related Works\nDefense mechanisms (against backdoor attacks) in the litera- ture can be broadly classified into two categories: detection- based defense mechanisms [37], [14], [27], [9], [16], [19], [20] and mitigation-based defense mechanisms [48], [15], [33], [40], [43], [44]. Detection-based defenses detect and filter the poisoned updates using similarity measures between the poisoned and benign updates. In contrast, mitigation-based defenses construct aggregation rules or add noise to the updates to mitigate the poisoned updates which are unbeknown to them.\nDetecting backdoors. Detection-based defense mechanisms in the literature include: Auror [37], Krum [4], AFA [27], and FoolsGold [14]. However, these defense mechanisms work only when certain conditions are satisfied. For exam- ple, Auror and Krum only work for benign IID data. In contrast, FoolsGold overcomes this assumption by assum- ing the benign data is non-IID and that the manipulated data is IID. In addition, these defense mechanisms can be bypassed if an adversary restricts the malicious updates within the valid range of benign updates distribution. In summary, these defenses only work when certain condi- tions are satisfied. On the contrary, BayBFed does not as-\nsume anything about the distribution of local client\u2019s data. Thus, it works more effectively against such attacks. Mitigating backdoors. Mitigation-based defenses include rule-based aggregation mechanisms such as coordinate-wise median and coordinate-wise trimmed mean [48], a two- step aggregation algorithm that combines the Krum and trimmed mean mechanisms [15], and RFA [33]. These de- fense mechanisms determine a client update to be benign if it lies within the scope of some aggregation rule. These rules, however, can be easily bypassed if an adversary makes sure its update is within the valid range of these rules. In addition, these rules are computationally intensive. Differ- ential privacy (DP) defense mechanisms [40], [43], [44], [28] have also been designed to protect against backdoor attacks. These defense mechanisms follow clipping of the weights and additive noising [10], to limit the impact of the adversarial updates. However, they also decrease the MA simultaneously. Nguyen et al. [30] designed a defense to limit the impact of noise on MA, however, the outlier de- tection is prone to removing benign models, which reduces the performance in non-IID scenarios. In comparison, the BNP modeling and CRP-Jensen of BayBFed allow us to effectively distinguish between benign and poisoned models.\n9. Conclusion\nThis paper proposes BayBFed, a novel and more generic probabilistic approach to defend against backdoor attacks in Federated Learning. In contrast to existing defenses that mainly consider models as a set of vectors and matrices [4], [14], [26], [27], [30], [37] and operate directly on them, BayBFed first computes a probabilistic measure over the clients\u2019 updates that encompass all the adjustments made in the updates due to any local client training strategy. Then, BayBFed employs a detection algorithm that utilizes this probabilistic measure to detect and filter out malicious up- dates. Thus, it overcomes several shortcomings of previous backdoor defense approaches. BayBFed utilizes two exten- sions of Bayesian non-parametric modeling techniques: the Hierarchical Beta-Bernoulli Process to draw a probabilistic measure given the clients\u2019 model updates (or weights), and a variation of the Chinese Restaurant Process, CRP- Jensen, which is a clustering algorithm that can leverage the probabilistic measure to detect and filter out malicious updates. Our extensive evaluation with benchmark datasets in different domains demonstrates that BayBFed can effec- tively mitigate backdoor attacks in FL while preserving the benign performance of the global model.\nAcknowledgements\nThis work was funded in part by Intel as part of the Private AI center, HMWK within ATHENE project, Huawei as part of the OpenS3 Lab, the Hessian Ministery of Interior and Sport within the F-LION project, as part of the funding guideline for cyber security research and the US NSF under award number 1943351.\n"}, {"chunk": "References\n[1] Sebastien Andreina, Giorgia Azzurra Marson, Helen Mo \u0308llering, and Ghassan Karame. BaFFLe: Backdoor Detection via Feedback-based Federated Learning. In ICDCS, 2021.\n[2] David Baehrens, Timon Schroeter, Stefan Harmeling, Motoaki Kawanabe, Katja Hansen, and Klaus-Robert Mu \u0308ller. How to explain individual classification decisions. The Journal of Machine Learning Research, 11:1803\u20131831, 2010.\n[3] Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and Vitaly Shmatikov. How To Backdoor Federated Learning. In AISTATS, 2020.\n[4] Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, and Julien Stainer. Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent. In NIPS, 2017.\n[5] David M Blei and Peter I Frazier. Distance dependent chinese restaurant processes. In ICML. PMLR, 2010.\n[6] Tamara Broderick, Ashia C Wilson, and Michael I Jordan. Posteriors, conjugacy, and exponential families for completely random measures. Bernoulli, 24(4B):3181\u20133221, 2018.\n[7] Xiaoyu Cao, Minghong Fang, Jia Liu, and Neil Zhenqiang Gong. Fltrust: Byzantine-robust federated learning via trust bootstrapping. In NDSS, 2021.\n[8] Xiaoyu Cao, Jinyuan Jia, and Neil Zhenqiang Gong. Provably secure federated learning against malicious clients. AAAI Conference on Artificial Intelligence, 2021.\n[9] Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Jacob Steinhardt, and Alistair Stewart. Sever: A robust meta-algorithm for stochastic optimization. In ICML. PMLR, 2019.\n[10] CynthiaDwork,AdamSmith,ThomasSteinke,JonathanUllman,and Salil Vadhan. Robust traceability from trace amounts. In FOCS, 2015.\n[11] Minghong Fang, Xiaoyu Cao, Jinyuan Jia, and Neil Gong. Local model poisoning attacks to byzantine-robust federated learning. In USENIX Security, 2020.\n[12] Hossein Fereidooni, Alexandra Dmitrienko, Phillip Rieger, Markus Miettinen, Ahmad-Reza Sadeghi, and Felix Madlener. FedCRI: Federated Mobile Cyber-Risk Intelligence. In NDSS, 2022.\n[13] Hossein Fereidooni, Samuel Marchal, Markus Miettinen, Azalia Mirhoseini, Helen Mo \u0308llering, Thien Duc Nguyen, Phillip Rieger, Ahmad-Reza Sadeghi, Thomas Schneider, Hossein Yalame, et al. Safelearn: Secure aggregation for private federated learning. In IEEE Security and Privacy Workshops (SPW). IEEE, 2021.\n[14] Clement Fung, Chris JM Yoon, and Ivan Beschastnikh. The limita- tions of federated learning in sybil settings. In RAID, 2020.\n[15] Rachid Guerraoui, Se \u0301bastien Rouault, et al. The hidden vulnerability of distributed learning in byzantium. In ICML. PMLR, 2018.\n[16] Youssef Khazbak, Tianxiang Tan, and Guohong Cao. Mlguard: Mitigating poisoning attacks in privacy preserving distributed col- laborative learning. In International Conference on Computer Com- munications and Networks (ICCCN). IEEE, 2020.\n[17] Yongdai Kim. Nonparametric bayesian estimators for counting pro- cesses. Annals of Statistics, pages 562\u2013588, 1999.\n[18] Gu \u0308nter Last and Mathew Penrose. Lectures on the Poisson process, volume 7. Cambridge University Press, 2017.\n[19] Suyi Li, Yong Cheng, Yang Liu, Wei Wang, and Tianjian Chen. Abnormal client behavior detection in federated learning. arXiv preprint arXiv:1910.09933, 2019.\n[20] Suyi Li, Yong Cheng, Wei Wang, Yang Liu, and Tianjian Chen. Learning to detect malicious clients for robust federated learning. arXiv preprint arXiv:2002.00211, 2020.\n[21] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges, methods, and future directions. IEEE Signal Processing Magazine, 37(3):50\u201360, 2020.\n[22] Yuelin Li, Elizabeth Schofield, and Mithat Go \u0308nen. A tutorial on dirichlet process mixture modeling. Journal of mathematical psy- chology, 91:128\u2013144, 2019.\n[23] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Agu \u0308era y Arcas. Communication-Efficient Learning of Deep Networks from Decentralized Data. In AISTATS, 2017.\n[24] Brendan McMahan and Daniel Ramage. Federated learning: Collab- orative Machine Learning without Centralized Training Data. Google AI, 2017.\n[25] Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang. Learning differentially private recurrent language models. arXiv preprint arXiv:1710.06963, 2017.\n[26] Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang. Learning Differentially Private Language Models Without Losing Accuracy. In ICLR, 2018.\n[27] Luis Mun \u0303oz-Gonza \u0301lez, Kenneth T. Co, and Emil C. Lupu. Byzantine- Robust Federated Machine Learning through Adaptive Model Aver- aging. In arXiv preprint:1909.05125, 2019.\n[28] Mohammad Naseri, Jamie Hayes, and Emiliano De Cristofaro. Local and central differential privacy for robustness and privacy in federated learning. NDSS, 2022.\n[29] Thien Duc Nguyen, Samuel Marchal, Markus Miettinen, Hossein Fereidooni, N. Asokan, and Ahmad-Reza Sadeghi. D \u0308IoT: A Federated Self-learning Anomaly Detection System for IoT. In ICDCS, 2019.\n[30] Thien Duc Nguyen, Phillip Rieger, Huili Chen, Hossein Yalame, Helen Mo \u0308llering, Hossein Fereidooni, Samuel Marchal, Markus Miet- tinen, Azalia Mirhoseini, Farinaz Koushanfar, Ahmad-Reza Sadeghi, Thomas Schneider, and Shaza Zeitouni. FLAME: taming backdoors in federated learning. USENIX Security, 2022.\n[31] Thien Duc Nguyen, Phillip Rieger, Markus Miettinen, and Ahmad- Reza Sadeghi. Poisoning Attacks on Federated Learning-Based IoT Intrusion Detection System. In Workshop on Decentralized IoT Systems and Security, 2020.\n[32] John W Paisley, Aimee K Zaas, Christopher W Woods, Geoffrey S Ginsburg, and Lawrence Carin. A stick-breaking construction of the beta process. In ICML, 2010.\n[33] Krishna Pillutla, Sham M Kakade, and Zaid Harchaoui. Robust aggregation for federated learning. IEEE Transactions on Signal Processing, 2022.\n[34] Phillip Rieger, Torsten Krau\u00df, Markus Miettinen, Alexandra Dmitrienko, and Ahmad-Reza Sadeghi. Close the Gate: Detecting Backdoored Models in Federated Learning based on Client-Side Deep Layer Output Analysis. arXiv preprint arXiv:2210.07714, 2022.\n[35] Phillip Rieger, Thien Duc Nguyen, Markus Miettinen, and Ahmad- Reza Sadeghi. Deepsight: Mitigating backdoor attacks in federated learning through deep model inspection. NDSS, 2022.\n[36] Micah Sheller, Anthony Reina, Brandon Edwards, Jason Martin, and Spyridon Bakas. Multi-Institutional Deep Learning Modeling Without Sharing Patient Data: A Feasibility Study on Brain Tumor Segmentation. In Brain Lesion Workshop, 2018.\n[37] Shiqi Shen, Shruti Tople, and Prateek Saxena. Auror: Defending Against Poisoning Attacks in Collaborative Deep Learning Systems. In ACSAC, 2016.\n[38] Arunan Sivanathan, Hassan Habibi Gharakheili, Franco Loi, Adam Radford, Chamith Wijenayake, Arun Vishwanath, and Vijay Sivara- man. Classifying IoT Devices in Smart Environments Using Network Traffic Characteristics. In TMC, 2018.\n[39] Richard Socher, Andrew Maas, and Christopher Manning. Spectral chinese restaurant processes: Nonparametric clustering based on sim- ilarities. In AISTATS. JMLR Workshop and Conference Proceedings, 2011.\n[40] Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, and Brendan McMahan. Can you really backdoor federated learning? arXiv preprint arXiv:1911.07963, 2019.\n"}, {"chunk": "[41] Romain Thibaux and Michael I Jordan. Hierarchical beta processes and the indian buffet process. In AISTATS. PMLR, 2007.\n[42] Hongyi Wang, Kartik Sreenivasan, Shashank Rajput, Harit Vish- wakarma, Saurabh Agarwal, Jy-yong Sohn, Kangwook Lee, and Dimitris Papailiopoulos. Attack of the tails: Yes, you really can backdoor federated learning. In NeurIPS, 2020.\n[43] Chen Wu, Xian Yang, Sencun Zhu, and Prasenjit Mitra. Mit- igating backdoor attacks in federated learning. arXiv preprint arXiv:2011.01767, 2020.\n[44] ChulinXie,MinghaoChen,Pin-YuChen,andBoLi.Crfl:Certifiably robust federated learning against backdoor attacks. In ICML. PMLR, 2021.\n[45] Chulin Xie, Keli Huang, Pin-Yu Chen, and Bo Li. DBA: Distributed Backdoor Attacks against Federated Learning. In ICLR, 2020.\n[46] Jie Xu, Benjamin S Glicksberg, Chang Su, Peter Walker, Jiang Bian, and Fei Wang. Federated learning for healthcare informatics. Journal of Healthcare Informatics Research, 5(1), 2021.\n[47] Timothy Yang, Galen Andrew, Hubert Eichner, Haicheng Sun, Wei Li, Nicholas Kong, Daniel Ramage, and Franc \u0327oise Beaufays. Applied federated learning: Improving google keyboard query suggestions. arXiv preprint arXiv:1812.02903, 2018.\n[48] Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett. Byzantine-robust distributed learning: Towards optimal statistical rates. In ICML. PMLR, 2018.\n[49] MikhailYurochkin,MayankAgarwal,SoumyaGhosh,KristjanGree- newald, Nghia Hoang, and Yasaman Khazaeni. Bayesian nonparamet- ric federated learning of neural networks. In ICML. PMLR, 2019.\nAppendix A. Federated Learning\nFederated learning (FL) collaboratively learns a global model G by iteratively aggregating the local model updates sent by the n clients selected during each training round. In each training round t, the global model server selects a total of n clients and sends them a common aggregated global model, Gt\u22121. Then, each client i \u2208 {1,...,n} locally trains a local model Wit , using its own local dataset Di . After training the local model, each client i, sends the updated model parameters to the global server to compute the next stage global model, Gt . In this paper, we assume the global server aggregates the local updates by utilizing Federated Averaging (FedAVG) function [23], given as:\nnsn Gt=\u2211siWit, wheresi=||Di||ands=\u2211si\ni=1 i=1 FedAVG utilizes each client\u2019s training dataset to com- pute the latest global model. A malicious client (or clients) can take advantage of this requirement by sending the erroneous dataset size [42]. To eliminate this scenario, we assume equal weights (si = 1/n) for all the clients. Such an approach has also been adopted in previous research\nefforts [3], [37], [45], [35].\nAppendix B.\nBackground and Preliminaries\nIn this section, we provide brief technical background knowledge on Bayesian non-parametric modeling and re- lated concepts, which will be critical in understanding the design of BayBFed.\nB.1. Hierarchical Beta-Bernoulli Process (HBBP)\nNext, we describe the concepts of the baseline Beta Process, the Hierarchical Beta Process, and the Bernoulli Process, which are used to compute the probabilistic measure.\nBeta Process (BP). A Beta Process is a random discrete measure on the countable infinitely drawn set of weights, where each weight has a mass in the range (0,1) such that the total mass sums to 1. A Beta Process uses a concentration function c over some space \u03a9 = R and a base measure H to produce some random measure A, i.e., A \u223c BP(c, H ). Given the set \u03a9, informally, a measure is any consistent assignment of sizes to (some of) the subsets of the set. Depending on the application, the size of a subset may be interpreted as either its physical size or the probability that some random process will yield a result within the subset. Formally, a measure is a function \u03bc : \u03a3 7\u2192 [0,\u221e], where \u03a3 is the \u03c3-algebra (collection of subsets) of \u03a9. A concentration function (c) quantitatively characterizes the scatter of the values of a random variable. Thus, it indicates the similarity between the input base measure (H) and the output random measure (A). The base measure H can represent any initial distribution (see Sect. 4). We also call \u03b30 = H(\u03a9) the mass parameter. So, if H is a normal distribution, then \u03b30 is a normal distribution of the complete space \u03a9. Alternatively, A is a discrete measure (discrete weights), represented by A = \u2211 j a j \u03b4w j , where \u03b4 is an indicator function. Thus, in order to draw an infinitely countable set of points (aj,wj) \u2192 [0,1] \u00d7 \u03a9 needs to be drawn. The probabilistic weights {a j }\u221ej=1 are distributed\nby a stick-breaking process: dj \u223c Beta(\u03b30,1), aj = \u220fj dk. k=1\nIn a stick-breaking process [32], there is a stick of length of 1 and aj represents the probabilistic weight taken from the remainder of the stick every time. wj are drawn independently and identically distributed (IID) from the normalized base measure wj \u223c H/H(\u03a9) with domain \u03a9. Here, Beta(\u00b7) represents the beta distribution that is used to model the continuous random variables in the range [0, 1]. This work assumes that \u03a9 is simply a space of weights. The objective here is first to draw a baseline Beta prior (random discrete measure) using a Beta Process and then use this prior (in a Hierarchical Beta Process, as explained next) to draw the corresponding Beta priors for the n entities.\nHierarchical Beta Process (HBP). A Hierarchical Beta\nProcess (HBP) is used to create hierarchies of the baseline\nBeta process when certain conditions are satisfied. Alter-\nnatively, from a pool of countable infinite sets of weights\nof the BP, a subset of weights (under some conditions)\nare drawn for each sub-Beta Process, creating hierarchies.\nWe can employ HBP to draw a discrete random measure\ncorresponding to each of the n entities based on the base-\nline Beta Process prior [41]. Let us consider the following\nrationale for the construction of the HBP. Suppose that\nWPrior is a list of the n entities\u2019 weight vectors, Now, we\nassume that the prior for each entity i, WPrior is generated i\nby including weights, which have a specific cosine angular distance, with respect to some base weight, wb (different for\n"}, {"chunk": "every entity). Thus, each WPrior is generated by including i\nh weights (w) independently with a probability phw specific to the entity i. These probabilities form a discrete measure Ai,h over the space of weights \u03a9, and we put a Beta Process BP(ci,A) prior on Ai,h (Note: Ai,h is the same as Ai defined in Sect. 2 of main paper). In summary, we have the following Hierarchical Beta model:\nThe random measure A, thus, Ai,h, encodes the probability that each entity possesses each particular weight.\nBernoulli Process (BeP). A Bernoulli Process (BeP) is a draw of weights from a space of total weights, given the Beta Process random measure that encodes the probability of selecting the weight in the draw. BeP is employed to draw weights given the Hierarchical Beta priors computed earlier. Thus, the subsets of points in the HBP prior Ai,h are drawn using a BeP with input as the random measure Ai,h . Each subset Wi for entity in i \u2208 {1, ..., n}, having l weights, is characterized by a Bernoulli Process such that Wi |Ai,h \u223c BeP(Ai,h ). Each subset can also be represented by a discrete measure such that the points (bi,l , wl ) \u2192 [0, 1] \u00d7 \u03a9, forms Wi = \u2211l bi,l \u03b4wl , where bi,l is the probabilistic weight (success probability) given to wl, i.e., Pr(bi,l = 1) = phw, if they are included in the subset Wi.\nConjugacy. It has been shown in the literature that the Beta distribution is the conjugate of the Bernoulli distribu- tion [6]. Hence, we do not have to use the computationally intensive Bayes\u2019 rule to compute the posterior distribution of hierarchical random measures. It can be computed as follows: Let Ai,h \u223c BP(ci , A), and let Wi |Ai,h \u223c BeP(Ai,h ). In Wi = {Wi,1 , Wi,2 , ..., Wi,l }, l denotes the independent BeP\nB.2. Mixture modeling: Chinese Restaurant Pro- cess (CRP)\nThe CRP [39], [5], [22] is a discrete-time stochastic process in the probability theory that resembles the situation of seating customers at tables in a Chinese restaurant with an infinite number of circular tables, each with infinite capacity. The first customer that arrives sits at the first table. The following customers can either sit at the already occupied tables or can choose to sit at the new table. This process partitions the customers among tables. The results of this process are exchangeable, meaning that the order in which the customers arrive and sit does not affect the probability of the final distribution. In CRP, we compute two probabil- ities for table (cluster) assignment. The first probability is the probability of the customer entering the restaurant and sitting at the already occupied tables (clusters). The second probability is the predictive probability of how well this new customer fits the mean of already occupied tables (clusters).\nB.3. Jensen-Shannon Divergence\nJensen-Shannon Divergence or Jensen-Divergence is used to realize the distance between two distributions. Specifically, it is computed by estimating the relative entropy between two distributions. The entropy of a random variable X having probability mass function P(x) is given as:\nH(X) = \u2212 \u2211 P(x)logbP(x) (10) x\u2208X\nJensen-Divergence is estimated using the Kullback- Leibler divergence (KL-divergence). KL-divergence also measures the distance between two distributions. However, it is not symmetric and does not satisfy the triangle inequality. Jensen-Divergence is an approach that improves upon the KL-divergence, as it is symmetric and a smoothed version of KL-divergence. KL divergence between two distributions p and q is given as:\nBaseline Beta prior:\nHierarchical Beta prior: Ai,h \u223c BP(ci,A) \u22001 \u2264 i \u2264 n\ndraws over the likelihood function, A\n. By using the results\nA \u223c BP(c,H)\ni,h \u0012p(x)\u0013 i \u2212\u221e\nfor HBP and BeP in [17], the posterior distribution of Ai,h Z\u221e\nafter observing W is still a Beta process with modified DKL(p||q) = p(x)log q(x) dx (11)\nparameters:\nci 1l! Ai,h|Wi \u223cBP ci+l,ci+lH+ci\u00b7l \u2211Wi\nl=1\n(9)\nJensen-Divergence between two distributions p and q is given as:\n1\nJSD(p||q) = 2 (DKL(p||m) + DKL(q||m)) (12)\nAppendix C.\nOverview of Used Symbols\nTable 3 contains an overview of the used symbols.\nAppendix D.\nBayBFed statistics for FMNIST\nIn this section, we evaluate the impact of non-IID rate and PMR on the FMNIST dataset. First, we demonstrate\n Our motivation is to first draw a baseline Beta Process random measure by drawing a countable infinitely set of weights, such that their probabilistic weight sums to 1. Then, we use this baseline Beta Process to form hierarchies of Beta Process for n different entities. We do so by selecting a subset of h weights from the total weights space for each of the n entities. Then, for each of the n entities, we use Bernoulli Process to draw l weights from the corresponding hierarchical Beta Process weights space. Finally, we keep updating the corresponding hierarchical Beta Process for entity n using the conjugacy of the Beta Process and the Bernoulli Process [6].\n"}, {"chunk": "                                                                          10 5 0\n0 10 20 30 Local Models\n  Benign\n Poisoned\n       MaxJD\n 0 10 20 30 Local Models\n0 10 20 30 Local Models\n0 10 20 30 Local Models\n10 10\n55\n00 0 10 20 30\nLocal Models\n0 10 20 30 Local Models\n(a) non-IID = 0.0\nFigure 11: Effect of different non-IID rates on the maximum Jensen-Divergence (Maxi ) for FMNIST dataset.\n(a) PMR = 20% (b) PMR = 30% (c) PMR = 50%\nFigure 12: Effect of different PMR rates on the maximum Jensen-Divergence (Maxi ) for the FMNIST dataset.\n(b) non-IID = 0.5\n(c) non-IID = 1.0\n10 10\n55\n00 0 10 20 30\nLocal Models\nJD\nBenign Poisoned\n0 10 20 30 Local Models\n(a) non-IID = 0.0\nFigure 13: Effect of different non-IID rates on the maximum Jensen-Divergence (Maxi ) for MNIST dataset.\n10 10 10\n(b) non-IID = 0.5\n(c) non-IID = 1.0\n5 Benign 5 Benign 5 Benign Poisoned Poisoned Poisoned\n000\n(a) PMR = 20%\nFigure 14: Effect of different PMR rates on the maximum Jensen-Divergence (Maxi ) for the MNIST dataset.\nthe trend of Maxi for both the malicious and benign JD\nclients with respect to each of these parameters. Then, we illustrate the impact of non-IID rate and PMR on BayBFed\u2019s performance by quantifying different metrics as stated in Sect. 5 and also compare it against the no defense scenario.\nJD\nclient updates, achieving a BA of zero while keeping the\nMA of the global model intact. Appendix E.\nBayBFed statistics for MNIST\nIn this section, we evaluate the impact of non-IID rate and\nPMR on the MNIST dataset. First, we demonstrate the trend of Maxi for both the malicious and benign clients, with\nrespect to each of these parameters. Then, we illustrate the impact of non-IID rate and PMR on BayBFed\u2019s performance by quantifying different metrics as stated in Sect. 5 and also compare it against the no defense scenario.\nIllustration of Maxi . The impact of the degree of non-IID JD\ndata and PMR on Maxi for each client is shown in Fig. 11 JD\nand Fig. 12, respectively. We select a total of 30 (n= 30)\nclients for both the non-IID and PMR experimental analysis.\nFor non-IID analysis, we test non-IID \u2208 {0.0, 0.5, 1.0} and\nset PMR = 0.2. Thus, the number of malicious clients equals\n6 (nA = 6). For PMR analysis, we test PMR \u2208 {0.2, 0.3, 0.5},\ni.e., when nA equals 6, 9, and 15 and set non-IID = 0.7.\nAs illustrated in Fig. 11 and Fig. 12, the Maxi value for JD\nbenign clients differs significantly from that of malicious clients. Hence, BayBFed easily filters out all the malicious\nJD\n(b) PMR = 30%\n(c) PMR = 50%\nJD\nJD\nIllustration of Maxi . Impact of the degree of non-IID JD\ndata and PMR on Maxi for each client is shown in Fig. 13 JD\nand Fig. 14, respectively. We select a total of 30 (n= 30)\n Benign\nPoisoned\n  Benign\n Poisoned\n                 10 10 10\n555\n000\n0 10 20 30 0 10 20 30 0 10 20 30\nLocal Models Local Models Local Models\n   Benign\n Poisoned\n        MaxJD\nMaxJD\nMaxJD\nBenign\nBenign\nPoisoned\nPoisoned\n            10 5 0\n0 10 20 30 Local Models\n  Benign\n Poisoned\n          MaxJD\n   Benign\n Poisoned\n           MaxJD\nMaxJD\nMaxJD MaxJD\nMaxJD\nMaxJD MaxJD\n"}, {"chunk": "Symbol\nBNP HBBP BP HBP BeP CRP\nf\nBet a(\u00b7) Gt\nWt\nn\nnA\nt\nc\n\u03a9(R)\nH\nA\n\u03b30\n\u03b4\nwj\naj\ndj\nW Prior\nW Prior i\nh\nph w\nAi,h or Ai ci\nBP(ci , A) wl\nbi,l\nDKL(p||q)\nJSD(p||q)\nL\nA\nlA\nDA\nN\n\u03bcp\n\u03c3p\nWt i,u p\nMaxi JD\nTABLE 3: Overview of symbols.\nDescription\nBayesian non-parametric\nHierarchical Beta-Bernoulli Process\nBeta Process\nHierarchical Beta Process\nBernouli Process\nChinese Restaurant Process\nNeural Network (NN)\nBeta distribution\nGlobal Model at time t\nLocal Model of client i at time t\nLocal dataset of client i\nNumber of clients\nNumber of malicious clients\nFL training round\nConcentration function\nSpace of weights\nBase measure\nBeta Process random measure\nMass parameter\nIndicator function\nIID weights drawn from \u03a9(R) or from BP\nProbabilistic weight assigned to w j\nA stick-breaking process\nList of the n client weight vectors\nclient i\u2019s weight vector\nclients for both the non-IID and PMR experimental analysis.\nFor non-IID analysis, we test non-IID \u2208{0.0,0.5,1.0} and\nset PMR = 0.2. Thus, number of malicious clients equals 6\n(nA = 6). For PMR analysis, we test PMR \u2208 {0.2, 0.3, 0.5},\ni.e., when nA equals 6, 9, and 15 and set non-IID = 0.7.\nAs illustrated in Fig. 13 and Fig. 14, the Maxi value for JD\nbenign clients differs significantly from that of malicious clients. Hence, BayBFed easily filters out all the malicious client updates, achieving a BA of zero while keeping the MA of the global model intact.\nAppendix F.\nAdditional adaptive attack\nTo implement an adaptive attack in which an adversary makes small changes to client updates to keep the JD divergences small, we vary the Poisoned Data Rate (PDR) to demonstrate the increment in the client updates for the CIFAR-10 dataset. We choose PDR to implement such an adaptive attack because arbitrary increments in PDR will also reflect the random increments in the client updates. Then, we compute the T PR, T NR, BA, and MA metrics to evaluate the effectiveness of BayBFed compared against the no-defense BA and MA, for different PDR values. We conduct experiments for three cases: a) PDR \u2208 (0.1,0.75) with an increment of 0.1, b) PDR \u2208 (0.01,0.1) with an increment of 0.01, and c) PDR \u2208 (0.1,0.2) with an increment of 0.01. Case a) demonstrates the impact of large PDR increments on the metrics mentioned above. The BA with no defense remains at zero for the initial PDR values of 0.01 and 0.1, and after that, it starts to increase. BayBFed easily identified all the poisoned updates, thus filtering out all the poisoned updates, achieving a BA of zero while keeping the MA of the global model intact. As we observed in case a), the no-defense BA remains zero at PDR = 0.1 and starts to increase after that; we conducted two more experiments for PDR \u2208 (0,0.1) and PDR \u2208 (0.1,0.2) to analyze BayBFed\u2019s performance when the PDR increases. Case b) demonstrates the impact of very small increments in PDR, and the no defense BA remains at zero in this case. Nevertheless, BayBFed was correctly able to identify all the poisoned updates. In the case of c), the no defense BA starts to increase from PDR = 0.11, and BayBFed again correctly identified all the poisoned updates, thus achieving a BA of zero while keeping the MA of the global model intact. This experimental analysis demonstrates that even when a shrewd adversary makes small iterative changes to PDR (in consequence, client updates), BayBFed works efficiently by identifying all the poisoned updates.\n          i Di\n                Prior\nProbability with which h weights are drawn from BP\nto be included in WPrior i\nHBP random measure for each client i having weights h client i\u2019s concentration function\nHBP BP(ci,A) prior on Ai,h\nIID weights drawn from HBP\nprobabilistic weight given to wl. Equal to phw\nKL divergence between two distributions p and q\nJensen-Divergence between two distributions p and q\nLabels for samples from domain D\nAdversary\nA chosen labels\ntrigger set of A\nNormal distribution\nMean of the flattened initial Gt\nStandard deviation of the flattened initial Gt\nUpdated client weight at time t\nMaximum Jensen-Divergence\nWeights drawn from BP to be included in Wi\n                 Cosine angular distance between local model Wt cos(Gt\u22121,Wt) i\n dt wi\ni\nand global model Gt\u22121\nL2 \u2212norm between Gt\u22121 and Wt\ni\n  \u03c3wti Wt\nMeasurement error due to the new client\u2019s weight Mean of W t\n i,u p \u03bccl\ni,u p\nMean of the clusters\n  \u03c3cl noc pi qnoc\njsi noc\n\u03bcnew \u03c3new\nnk\n\u03c4k \u03bc0 \u03c40\nVariance of the clusters\nTotal number of clusters formed yet\np distribution of client i\nnoc cluster q distribution\nJensen-Divergence of noc cluster q distribution with\np distribution of client i Updated cluster\u2019s mean\nUpdated cluster\u2019s standard deviation\nNumber of clients update already assigned to a particular cluster\nPrecision of the cluster\nInitial mean for the new cluster\nInitial Precision assumed for the new cluster\nArray of stored Maxi JD\n           Maxstored = [] JD\n "}, {"chunk": "Exploiting Out-of-band Motion Sensor Data to De-anonymize Virtual Reality Users\nMohd Sabra mohd.sabra@utsa.edu University of Texas at San Antonio\nNisha Vinayaga Sureshkanth vsnisha@ieee.org University of Texas at San Antonio\nAri Sharma arisharma2017@gmail.com Liberal Arts and Science Academy\nABSTRACT\nVirtual Reality (VR) is an exciting new consumer technology which offers an immersive audio-visual experience to users through which they can navigate and interact with a digitally represented 3D space (i.e., a virtual world) using a headset device. By (visually) transport- ing users from the real or physical world to exciting and realistic virtual spaces, VR systems can enable true-to-life and more inter- active versions of traditional applications such as gaming, remote conferencing, social networking and virtual tourism. However, as with any new consumer technology, VR applications also present significant user-privacy challenges. This paper studies a new type of privacy attack targeting VR users by connecting their activities visible in the virtual world (enabled by some VR application/service) to their physical state sensed in the real world. Specifically, this paper analyzes the feasibility of carrying out a de-anonymization or identification attack on VR users by correlating visually observed movements of users\u2019 avatars in the virtual world with some auxil- iary data (e.g., motion sensor data from mobile/wearable devices held by users) representing their context/state in the physical world. To enable this attack, this paper proposes a novel framework which first employs a learning-based activity classification approach to translate the disparate visual movement data and motion sensor data into an activity-vector to ease comparison, followed by a fil- tering and identity ranking phase outputting an ordered list of potential identities corresponding to the target visual movement data. Extensive empirical evaluation of the proposed framework, under a comprehensive set of experimental settings, demonstrates the feasibility of such a de-anonymization attack.\n1 INTRODUCTION\nVirtual Reality (VR) is changing the paradigms of human-computer interaction, and has become a ubiquitous consumer technology [4, 6, 8, 9, 15, 16, 20]. Most prevalent VR systems today (e.g., Meta Quest, HP Reverb and Sony PlayStation VR), offer an immersive audio-visual experience where users can navigate around a digitally represented 3D space (i.e., a virtual world) using a VR headset. In most VR systems, users would navigate and interact with this virtual world using on-body (often, handheld) controllers that can track users\u2019 body movements in the real world and execute analogous movements in the virtual world. Reactions from users\u2019 navigation actions and interactions with the virtual world are relayed back to the user by means of video, audio, and haptic (e.g., vibrations) signals perceptible to the user through his/her VR device/headset.\nAnindya Maiti am@ou.edu University of Oklahoma\nMurtuza Jadliwala murtuza.jadliwala@utsa.edu University of Texas at San Antonio\nVR systems enable several novel applications that were previ- ously not possible using traditional desktop and mobile devices, such as immersive gaming [13], remote conferencing [6, 9], virtual tourism [1, 19], social networking [7, 18], visualizing 3D models [4, 15], and large open-world spaces [8, 16]. Unfortunately, at the same time new privacy and security challenges have also emerged in the VR space. For example, password inference from finger move- ments (using motion sensors) when typing a password in the virtual world can become a security problem if the same password is reused by the user in real world [26]. Some VR headsets also include eye- tracking, which can become an additional channel for inference of private data. For instance, it has been shown in recent research efforts that eye tracking or gaze data could be potentially misused to infer a user\u2019s personal information and traits such as gender, age, ethnicity, body weight, personality traits, drug consumption habits, emotional state, skills and abilities, fears, interests, and sexual pref- erences [37]. Personal gait and movement data collected from a VR headset can also be used in conjunction with Deepfake videos to create highly authentic looking fake videos [62], which can be further used to damage personal reputation [10, 55], conduct social engineering attacks [14, 65], and spread misinformation (fake news) [29, 36].\nVR systems and applications can transport users from the real world to a virtual world, wherein the two worlds are seemingly disconnected from each other. In this work, we study the poten- tial of a new type of privacy attack targeting VR users by connect- ing their activities visible in the virtual world (enabled by some VR application/service) to their physical state sensed in the real world. More specifically, we analyze the potential of carrying out a de- anonymization or identification attack on VR users by correlating vi- sually observed movements of users\u2019 anonymous humanoid avatars in the virtual world with auxiliary data representing their con- text/state in the physical world. For such auxiliary information, we specifically focus on data available from motion sensors on-board mobile and wearable devices (e.g., smartphones and smartwatches) that users may be carrying on them while navigating or interacting with virtual worlds in VR applications. Our attack is motivated by the fact that motion sensors on-board modern mobile devices, such as, accelerometers and gyroscopes, are considered to be zero- permission, i.e., any on-device application can record/sample1 data from these sensors without requiring explicit user-permissions.\n1\nAndroid 12+ requires the HIGH_SAMPLING_RATE_SENSORS permission to sample mo- tion sensors beyond 200 \ud835\udc3b\ud835\udc67. However, our correlation framework can operate with a sampling frequency much lower than 200 \ud835\udc3b\ud835\udc67.\n1\narXiv:2301.09041v1 [cs.CR] 22 Jan 2023\n "}, {"chunk": ", , Mohd Sabra, Nisha Vinayaga Sureshkanth, Ari Sharma, Anindya Maiti, and Murtuza Jadliwala\nThis, consequently, enables easy misuse of such motion data by any on-device app, something which has been extensively documented in the security research literature [24, 27, 32, 33, 40, 42, 45, 49, 52, 57, 58]. Moreover, we hypothesize that fine-grained user movement captured by on-body motion sensors (such as those on a user\u2019s wrist in the form of a smartwatch and in a user\u2019s pocket in the form of a smartphone) are strongly correlated with the visual motions observed in the user\u2019s humanoid avatar in the virtual environment of a VR app, and thus can potential be used to de-anonymize users in virtual spaces.\nWe consider an attack scenario where the adversary is trying to de-anonymize a target user in the virtual world by visually tracking the motion of the user\u2019s avatar and then correlating it with labeled motion data streams belonging to a (large) set of users, which also includes motion data from the target user. We refer to this set of labeled motion data streams (belonging to a large set of users) as the target user\u2019s anonymity set. Such an attack scenario could arise in many popular VR services such as Metaverse [8], VRChat [20] and MeetinVR [6] which enable a group of users to organize events, get-togethers and games in some virtual environment. A mobile (smartphone) app of an adversarial service provider can be used to stealthily record motion data of every user in the group for a particular event, while video data corresponding to a target user (in the group) can be captured by the adversary directly from the virtual environment/world, say, by participating or entering the same virtual environment/world as the target user. We propose a novel correlation framework to carry out the de-anonymization in such VR services, and comprehensively evaluate parameters such as effect of different actions/movements and the effect of using having their mobile device in different bodily locations (such as different pockets).\nOur work advances research investigation of how data from the physical world can be used to compromise the privacy of users in the virtual worlds. We believe that this is the first research effort which investigates this issue. Identity protection is key to VR in- novation as otherwise users will be hesitant to participate in the ecosystem [22] in order to protect their privacy, reputation and security. To protect users from the potential de-anonymization at- tack, we also propose novel countermeasures that users can adopt while participating in VR applications. In summary, we make the following main contributions in this paper:\n(1) Contribution1:Aframeworkthattransmutesbothmotionsen- sor data and avatar\u2019s visual movement data in to a comparable activity-vector.\n(2) Contribution2:Acorrelationmodelthatfiltersmismatching activity-vectors, and ranks matching activity vectors from best to worst.\n(3) Contribution3:Testdatacollectionforreal-worldhumanpar- ticipants, and a comprehensive empirical evaluation of the correlation framework under various settings.\n(4) Contribution4:Improvementsandoptimizationsofthecorre- lation framework for a large-scale attack.\n2 RELATED WORK\nResearch efforts in the literature related to our work can be cate- gorized into those that focus on inferring private information by\nmeans of mobile device motion sensors which we discuss first, fol- lowed by those that propose new sensitive information inference vectors for VR systems and applications.\nInformation leakage through mobile device motion sensors: Mobile and wearable device motion sensors such as accelerome- ters and gyroscopes have been heavily scrutinized in the research literature for their potential to be employed as a side-channel for leaking users\u2019 private information. For instance, motion sensor data on smartphones and smartwatches have been utilized to infer keystrokes and passwords [24, 40\u201342, 52, 54], identify lock screen patterns [68], deduce travel routes and location [33, 49, 51], infer speeches [32, 34, 45], infer handwritten text [63], reconstruct 3D models from printer vibrations [58], and estimate demographic in- formation [27, 57]. Application of on-body motion sensors onboard consumer mobile devices such as smartphones and smartwatches for user authentication [39, 64, 67] is another closely related re- search space that has received significant attention in the literature. However, such biometric authentication systems require training data from individual users, which is not available in our adversarial setting.\nInformation leakage in VR systems and applications: Albeit relatively new as a consumer technology, VR has garnered a host of privacy and security concerns. As mentioned earlier, attacks such as password inference from finger movements (using motion sensors) when typing a password in the virtual world can become a security problem if the same password is reused by the user in real world [26]. Some VR headsets include eye-tracking, which can reveal valuable personal information [37]. VR, when used in conjunction with Deepfakes [62], can also become a serious threat as an adversary can potentially utilize personal gait and movement data collected from a VR headset to create a very authentic-looking fake video. These type of attacks can be used to damage personal reputation [10, 55], conduct social engineering attacks [14, 65], and spread misinformation (fake news) [29, 36].\nAuthentication in VR is a closely related research topic [59], wherein authorized sensors on the VR headset or paired on-body controllers are used to authenticate individual users. However, in our attack we focus on out-of-band motion sensor data, which are not paired with the VR system. De-anonymization solely using movements observed in the virtual world is difficult, especially when the anonymity set size is large. In this work, we carry out de-anonymization of users of a VR platform by correlating visually observed movements of the user\u2019s avatar in the virtual world with out-of-band motion data available from users.\nUse of anonymous avatars and identity transformation inside a virtual reality experience [30, 31, 43] is a significant factor contribut- ing to the technology\u2019s popularity. Therefore, identity protection is key to VR innovation as otherwise users will be hesitant to partici- pate in the ecosystem [22] in order to protect their privacy, reputa- tion and security. Previous works on de-anonymization of VR users utilized in-band data (such as sensors on the VR systems and/or movement characteristics of virtual avatars) to infer users\u2019 identity [46, 47], anthropometrics [50], environment [50], device informa- tion [50, 61], and demographics [50]. To the best of our knowledge, our proposed de-anonymization attack using out-of-band motion data has thus far not been analyzed or publicly presented. We also\n2\n"}, {"chunk": "Exploiting Out-of-band Motion Sensor Data to De-anonymize Virtual Reality Users\n, ,\nUser K\nUser J\nUser A\nWears\nVR Headset\nVirtual World Adversary\nAdversary Observes a Set of Virtual Avatars and Composes a Visual Movement Dataset (V)\nMotion Dataset (M)\nMotion Sensor Data (Accelerometer + Gyroscope)\n      Anonymous Virtual Avatar\n   User A Identified\nPhone In Pocket\nSensors\nvi ?mj\nCorrelate Avatars\u2019 Visual Movements\nto Users\u2019 Motion Sensor Data\n   Adversary\u2019s Malicious App\nevaluate the scope of the proposed de-anonymization attack within a small set of users and at a larger scale. To protect users from the proposed attack, we also suggest countermeasures that users can adopt while immersing in a VR experience.\n3 THREAT MODEL\nWe consider an adversary whose goal is to de-anonymize users of a VR ecosystem by correlating visual movements of anonymous virtual world avatars with out-of-band identifiable mobile/wearable motion sensor data from target users. The size of the labeled motion dataset of users in the possession of the adversary, representing the anonymity set of the target VR user or avatar, may vary between a large-scale where the cardinality (of the dataset) may be very high, to a significantly smaller small-scale (e.g., employees of a company or participants of an event). Similarly, the recordings of VR users or avatars will result in a visual movement dataset, which can also range between a global scale where its cardinality may be very high, to a significantly smaller small-scale such as avatars present within a (targeted) virtual room or playing a (targeted) virtual game. As depicted in Figure 1, the goal of the adversary is to de-anonymize a target user (i.e., its avatar) in the VR space by matching an element in the labeled motion dataset to the element (corresponding to the target user or avatar) in the visual movement dataset by utilizing some efficient correlation mechanism, similar to the one we propose in Section 4. This adversarial goal can be easily extended to include de-anonymization of multiple VR users or avatars.\nIn order to compile the visual movement dataset (denoted by \ud835\udc49 = {\ud835\udc631, \ud835\udc632, . . . , \ud835\udc63\ud835\udc5d }, with cardinality \ud835\udc5d), the adversary has to join the virtual world, observe and record each avatar for a baseline duration of time within which a series of movements are likely observed. In case of the VR service provider being the adversary, this process can scale easily. In order to compile the labeled motion dataset (denoted by \ud835\udc40 = {\ud835\udc5a1, \ud835\udc5a2, . . . , \ud835\udc5a\ud835\udc5e }, with cardinality \ud835\udc5e), the adversary installs a malicious data collection app on the mobile/wearable devices of a targeted set of users, which records zero-permission motion (accelerometer and gyroscope) sensor data and reports it back to the adversary. As explained earlier, this targeted set of users can be at a small or large scale. Typically, this can be achieved by means of a trojan app that offers some utility to the users on the front-end (e.g., a game or a social networking service), while surreptitiously recording the motion data on the back-end. We also assume that both datasets (\ud835\udc49 and \ud835\udc40) contains timestamps which are fairly in sync with the standard global time.\nFor popular apps/services that also offer a VR platform, for ex- ample, Meta, such an attack can potentially be scaled globally for both the motion and visual datasets. Nonetheless, such an attack is easier to be carried out at a small-scale, implying that the mali- cious mobile/wearable app has to be popular within a small group of users and/or the VR ecosystem has to be popular within the group. When both \ud835\udc5d and \ud835\udc5e are large, the correlation process to de-anonymize all users grows to be computationally challenging for the adversary. In Section 7 we propose optimization techniques that can significantly reduce the computational complexity, and thus the average runtime, of the proposed correlation framework. Below we present two different scenarios representing our threat model.\nFigure 1: Threat model.\nScenario 1. A large organization (such as Meta) that operates both a popular VR platform (such as Metaverse) and a popular mobile app (such as Facebook, WhatsApp, and Instagram) can collect both the visual movement dataset and motion sensor dataset for respective platforms. Users who do not want to be identified across both of these platforms are susceptible to the proposed de-anonymization attack, even when using anonymous identity and avatar on the VR platform. This scenario represents a large-scale attack where the anonymity set is large.\nScenario 2. A criminal group uses VRChat [20] to anonymously meetup. An undercover police officer present in the meetups is able to record the visual movements of individual (anonymous) avatars of the criminal group. With the help of a popular smartphone app company (such as Google), the police is also able to collect identified motion sensor data from a list of known criminals and suspects. Thereafter, the proposed correlation framework can be used by the police to de-anonymize members of the group on VRChat. This scenario represents a small-scale attack where the anonymity set is small.\n4 CORRELATION FRAMEWORK\nOur correlation framework (Figure 2) is composed of two key com- ponents. The first component converts both the (out-of-band) mo- tion sensor data and the visual movement data in to a comparable format, which we refer to as activity-vector series. The activity- vector series enables us to directly compare and match elements from the two datasets (\ud835\udc49 and \ud835\udc40) using a matching heuristic. The second component in our framework ranks the closest matches across the elements of either dataset, in a fashion such that the high ranked matches are likely associated with the target user (identifiable from \ud835\udc40 ).\n4.1 Activity-Vector Series\nOur motivation behind defining a activity-vector series stems from the fact that the two datasets (motion sensor data from the mo- bile/wearable device and visual movement dataset from the VR app)\n3\n"}, {"chunk": ", , Mohd Sabra, Nisha Vinayaga Sureshkanth, Ari Sharma, Anindya Maiti, and Murtuza Jadliwala\nare not directly comparable to each other. The motion sensor data comprises of samples measuring linear acceleration and orienta- tion changes of a user\u2019s body, whereas the visual movement data consists of a video wherein an anonymous avatar\u2019s movements are recorded as changes in pixels across its frames. Consequently, we define an activity-vector series as a sequence of activities observed (classified by some machine learning or ML model as discussed later), combined with a pairwise sequence of \u201cmagnitudes\u201d for each observed activity from each of the data sources (visual movements and motion sensor). Our magnitude quantification of an observed activity is approximate, but serves as a critical attribute in our correlation framework as detailed in Section 4.5.\nMore precisely, our activity-vector series is composed of the following commonly observed activities: idle, body rotation, head rotation, hand movements, walking, bending, jumping, and \u201cother\u201d. These were the common movements observed in over 2000 hours of activity data collected inside VRChat [20] by us (more details on data collection can be found in Section 5). These activity classifi- cations combined with magnitude calculations form a vector-like representation where each observed activity has a corresponding magnitude information (similar to a vector which consists of direc- tion and magnitude). An activity-vector series from either sources can be depicted as follows:\nwhere \ud835\udc4e\ud835\udc56 \u2208 R+ is the positive real magnitude of an activity time window, such that \ud835\udc4e1 > \ud835\udc4e2 > . . . > \ud835\udc4e10. In order to generate this activity-vector series, we next detail the steps taken to pre- process and utilize supervised machine learning models to classify the activities observed in individual sequences.\n4.2 Pre-Processing\nWe first segment both the physical motion data (obtained from the mobile device motion sensors) and the visual movement data (obtained from the VR apps) into small time windows (of \ud835\udc64 seconds each) and classify each window as one of the eight aforementioned actions. We empirically evaluate the effect of the size of \ud835\udc64 on corre- lation accuracy in Section 6.1 and use the optimal value for rest of the evaluation. For the visual movement data, we further separate individual user\u2019s avatar from the background, so as to better classify the movements of the avatar without any background noise. Paddle- Seg [25], an open-source toolkit that applies image segmentation using different techniques, was used to segment out the individual avatars. More specifically, we used a pre-trained ORCNet model with HRNet backbone that was trained using the Cityscapes dataset [12]. For the motion sensor data, we apply a Savitzky-Golay filter [53] to smooth the signals for noise reduction before classification.\n4.3 Training Data Generation\nIn order to generalize and scale our activity classification for a large-scale attack, we generate training data as an amalgamation of a well-known dataset in the literature and add synthetically gen- erated variations to capture a wide range of bodily variances and anomalies (often caused by imperfections in the VR systems) all of which are otherwise impractical for collection from real human\nVisual Movement Dataset (V)\nAnonymous Motion Sensors Dataset (M)\n6 Activity- Vector Series\nActivity + Magnitude\nActivity + Magnitude\n1 Activity- Vector Series\n4\nFigure 2: Overview of our correlation framework.\nsubjects. Specifically, we generate the training data of our visual movement classifier using the 3D game engine Unity [17] (Figure 3), utilizing the Carnegie Mellon University (CMU MoCap) [2] dataset and synthetically generated variations of motions captured in the CMU MoCap dataset. The CMU MoCap dataset was created using a motion capture system where the subjects wore 41 markers and per- formed various activities. It is a well-known dataset for evaluation of activity recognition frameworks [23, 48, 56], and can be applied to reproduce avatar movements inside Unity using corresponding body keypoints (Figure 13).\nOur synthetically generated movement variations randomized the speed between 0.25\u00d7 and 2\u00d7 of CMU MoCap speeds, and rota- tion angle between \u221210\u00b0 and +10\u00b0 of CMU MoCap rotation angles. In addition to the CMU MoCap model avatar, we also train using another freely available avatar, namely the Futuristic soldier - Scifi character2. As the video movement data is dependent on the view- point of the adversary, we also capture varying camera positions around the virtual avatar in Unity (Figure 3). Specifically, the cam- era position was randomized around the avatar (across all angles for which the avatar is visible), enabling a different visual perspective and thus improving our classifier training. The visual movements of the avatars were recorded using OBS Studio [11].\nAdditionally, in Unity we attached a custom-made virtual motion sensor to the avatar (Figure 3), which is able to capture acceleration and orientation changes of the avatar. This virtual motion sensor closely captures the kinematic forces experienced by the avatar in the same way a smartphone or smartwatch motion sensor on a real person would experience, and it allows us to collectively train a classifier for the motion sensor data alongside the visual movement classifier. The key advantages of using such a virtual sensor for training are the elimination of synchronization errors, and not requiring real human subject participants for data collec- tion (except for the human subject participants who helped in the development of the CMU MoCap dataset). Note that for our experi- mental evaluations (Section 6) with an adversarial standpoint, we compose a realistic test dataset with the help of real human subject participants and also address synchronization errors between the motion sensor and visual movements data (Section 6.3).\n2\nhttps://assetstore.unity.com/packages/3d/characters/humanoids/sci- fi/ futuristic- soldier- scifi- character- 202085\n   Pre-processing\n Pre-processing\n Classification + Magnitude Calculations\n Activity-based Identity Filtering + Magnitude-based Identity Ranking\n Classification + Magnitude Calculations\n   Time Synchronizations\n    Left-front Hip Pocket (Motion Sensor)\n  Activity walking walking idle bending walking walking jumping idle walking jumping\n  Magnitude \ud835\udc4e4 \ud835\udc4e3 \ud835\udc4e1 \ud835\udc4e7 \ud835\udc4e6 \ud835\udc4e10 \ud835\udc4e8 \ud835\udc4e2 \ud835\udc4e5 \ud835\udc4e9\n   "}, {"chunk": "Exploiting Out-of-band Motion Sensor Data to De-anonymize Virtual Reality Users , ,\n positioning for each user\u2019s data, the visually observed magnitude of movement experienced by an avatar\u2019s different body keypoints (Figure 13) is another attribute that should be factored in to improve our correlation model. We consider six usual body positions where the motion sensor is likely to be attached, such as a smartphone in pant pocket or a smartwatch on the wrist: left-front hip pocket, right-front hip pocket, left-back hip pocket, right-back hip pocket, left wrist, and right wrist. As a result, the activity-vector series calculated from the visual movement dataset will consists of six different magnitude sequences (for the same activity sequence) as follows:\n Left-front Hip (Visual)\n  Activity walking walking idle bending walking walking jumping idle idle jumping\n  Magnitude \ud835\udc4e4 \ud835\udc4e3 \ud835\udc4e1 \ud835\udc4e7 \ud835\udc4e6 \u2212 \ud835\udc4e8 \ud835\udc4e2 \ud835\udc4e5 \ud835\udc4e9\n  Right-front Hip (Visual)\n  Activity walking walking idle bending walking walking jumping idle idle jumping\n  Magnitude \ud835\udc4e4 \ud835\udc4e3 \ud835\udc4e2 \ud835\udc4e7 \ud835\udc4e6 \ud835\udc4e10 \ud835\udc4e8 \ud835\udc4e1 \ud835\udc4e5 \ud835\udc4e9\n  Left-back Hip (Visual)\n  Activity walking walking idle bending walking walking jumping idle idle jumping\n  Magnitude \ud835\udc4e4 \ud835\udc4e2 \ud835\udc4e3 \ud835\udc4e7 \ud835\udc4e6 \ud835\udc4e10 \ud835\udc4e8 \ud835\udc4e1 \ud835\udc4e5 \ud835\udc4e9\n  Right-back Hip (Visual)\n  Activity walking walking idle bending walking walking jumping idle idle jumping\n  Magnitude \ud835\udc4e4 \ud835\udc4e3 \ud835\udc4e1 \ud835\udc4e7 \ud835\udc4e6 \ud835\udc4e9 \ud835\udc4e8 \ud835\udc4e2 \ud835\udc4e5 \u2212\n  Left Wrist (Visual)\n  Activity walking walking idle bending walking walking jumping idle idle jumping\n  Magnitude \ud835\udc4e3 \ud835\udc4e4 \ud835\udc4e1 \ud835\udc4e6 \ud835\udc4e7 \ud835\udc4e8 \u2212 \ud835\udc4e2 \ud835\udc4e5 \ud835\udc4e9\n  Right Wrist (Visual)\n  Activity walking walking idle bending walking walking jumping idle idle jumping\n  Magnitude \ud835\udc4e1 \ud835\udc4e3 \ud835\udc4e4 \ud835\udc4e6 \ud835\udc4e7 \ud835\udc4e9 \ud835\udc4e8 \ud835\udc4e2 \ud835\udc4e5 \ud835\udc4e10\n  Figure 3: The training data generation setup inside Unity, de- picting only one camera viewpoint and virtual motion sen- sors attached to the avatar (in red).\n4.4 Activity Classification\n34\nWe collectively utilize Apple\u2019s Core ML and Create ML libraries\nto generate two classification models (each trained separately), one for the video movement training data and another for the motion sensor training data. The Core ML model is already trained by Ap- ple for generic action and activity classification, and can be further customized using transfer learning [44] using the training data gen- erated in Section 4.3. Prior research has already demonstrated the feasibility of such activity recognition using Core ML [38]. More-\n5\nover,Apple\u2019sVisionframework isalreadypre-trainedforkeypoint\ndetection on humans (Figure 13), which can also be utilized with Core ML on humanoid avatars. Applying these trained classification models on test visual movement and motion sensor data split into \ud835\udc64 second windows will result in a sequence of activities observed on the two data sources, which is one of the two sequences in the activity-vector series defined earlier.\n4.5 Activity Magnitude\nIntuitively, when the same classified activity is observed in both data sources (in a given time window), we can improve our identity correlation by ranking smaller magnitude differences above larger magnitude difference. For example, if an anonymous avatar is ob- served to be walking fast in the virtual world (high magnitude), it is likely that their activity magnitude will also be high on the motion sensor data. As mentioned earlier, our magnitude quantification of an observed activity is approximate. For the motion sensor, we calculate magnitude of each \ud835\udc64 second activity window as the aver- age magnitude of acceleration vectors in the motion sensor data. For the visual movement data, we utilize optical flow to compute the average acceleration of areas on the avatar\u2019s body where the motion sensor may be attached. Optical flow estimates the motion of objects between consecutive frames in a video, caused by the relative movement between the object and camera [28, 35].\nHowever, as some activities tend to generate disproportionate levels of motion in various parts of the body, it may result in differ- ent magnitudes of movements for the same activity. Furthermore, as the adversary may not have knowledge of the motion sensor\u2019s\nwhere \u201c\u2013\u201d implies unobservable position for optical flow calcula- tions, all \ud835\udc4e in red depict mismatched magnitude rank with the\n\ud835\udc56\nleft-front hip pocket motion sensor activity-vector series shown inSection4.1,andallgreen\ud835\udc4e implymatchingmagnituderank.\n\ud835\udc56\nMoreover, there is an activity misclassification in this example at the ninth window, highlighted as \ud835\udc56\ud835\udc51\ud835\udc59\ud835\udc52 in red. All of these seven magnitude sequences (one from motion sensor data and six from visual movement data) are utilized in the correlation and identity ranking processes described next.\n4.6 Correlation and Identity Ranking\nThe first intuitive assumption in our correlation framework is that the order of activities conducted by an user (and their avatar) will be unique when observed for a long enough duration. Intuitively, this observation duration can be shorter in a small-scale attack where the anonymity set is smaller. In a large-scale attack, the observation duration has to be longer because with a large anonymity set the occurrence of more than one anonymous user conducting the same sequence of activities within a short observation duration is more probable, thus creating confusion between them. We use this first assumption to filter out unlikely matches from our identity ranking calculations, using the activity sequences in the activity-vector series.\nOur second intuitive assumption is that varying activity magni- tudes caused by disproportional levels of motion in various parts of the body can be utilized to identify closely correlated visual movement and motion sensor sequences. Accordingly, we utilize\n 3 4 5\nhttps://developer.apple.com/documentation/CoreML https://developer.apple.com/documentation/createml https://developer.apple.com/documentation/vision\n5\n"}, {"chunk": ", , Mohd Sabra, Nisha Vinayaga Sureshkanth, Ari Sharma, Anindya Maiti, and Murtuza Jadliwala\nmagnitude correlation rankings to rank known identities (from dataset \ud835\udc40) such that users with motion sensor magnitude sequence closely matching to a visual movement magnitude sequence (best of the six visual positions) are ranked closer to 1.\n4.6.1 Activity-based Filtering. As the activity classification is not perfect, we cannot reliably use the sequence of activities for correlation. Instead, we use a high degree of mismatch between sequences of activities (across visual movement and motion sensor data) to filter out identities whose motion sensor data are objec- tively different from an anonymous avatar being observed. More specifically, we calculate the hamming distance between the mo- tion sensor activity sequence and the visual movement activity sequence (which is the same for all six activity-vector series gener- ated from the visual movement data). Thereafter, we eliminate pairs with distance threshold > \ud835\udc61 from further magnitude-based identity rankings. We empirically evaluate threshold \ud835\udc61 in Section 6.1 as part of our framework parameter optimizations. For example, between the activity-vector series illustrated in Section 4.1 and Section 4.5, this hamming distance is 1 (or 10%) due to the activity mismatch in the ninth time window.\n4.6.2 Magnitude-based Ranking. After filtering, we are left with identities whose motion sensor activity sequences closely matched at least one of the six visual movement activity sequences. We utilize Spearman\u2019s rank correlation coefficient [69] to correlate and rank potential identities based on magnitude sequences, which is computed as follows:\n6P\ud835\udc512 \ud835\udf0c=1\u2212 \ud835\udc56\n\ud835\udc5b(\ud835\udc5b2 \u2212 1)\nwhere \ud835\udc5b is the number of observations (of \ud835\udc64 second windows) in\ntheactivity-vectorseries,and\ud835\udc51 isthedifferenceinthepairedranks \ud835\udc56\nof the two magnitudes (across the visual movement and motion\nsensor data sequences) at the \ud835\udc56\nThe higher the Spearman\u2019s rank correlation coefficient, the more\nlikely the two sequences correlate to each other, and thus the cor- responding identity from \ud835\udc40 would be ranked closer to 1 out of the \ud835\udc5e (minus the identities that did not pass the activity-based filter- ing). As the adversary does not have positioning information of the motion sensor on the users\u2019 body, we compute Spearman\u2019s correla- tion coefficient for the six likely positioning of the motion sensors (Section 4.5), and consider only the maximum for identity ranking. Between the examples shown in Section 4.1 and Section 4.5, magni- tude from the visual data sequence of the left-front hip will have the highest Spearman\u2019s correlation coefficient with the left-front hip pocket motion sensor magnitudes.\nWhen activity-based filtering threshold \ud835\udc61 is set very low (i.e., only tolerance for very minor or no mismatches in the activity sequences), it is also possible that all identities are eliminated from this magnitude-based raking, thus resulting in no identity ranking. The entire correlation procedure is digested in Algorithm 1.\n5 EXPERIMENTAL SETUP\nTo evaluate our proposed correlation framework and training method- ology, we collect test (visual and motion sensor) data from human subject participants using a real VR application. In this section, we outline the details of our data collection procedure.\nTable 1: Legend of camera viewpoints used in Section 6.\n Home Legend\nStatic Camera 1 HC1 Static Camera 2 HC2 Static Camera 3 HC3 Static Camera 4 HC4 Mobile Camera HC5\nCombined HCC\n5.1 Participants\u2019 Task\nBlack Cat\nLegend\n Static Camera 1 BC1 Static Camera 2 BC2 Static Camera 3 BC3 Static Camera 4 BC4 Mobile Camera BC5\nCombined BCC\n  \ud835\udc61h\ntime window.\nOur participants (details in Section 5.3) carry out a set of represen- tative activities in a virtual reality app while carrying a smartphone and smartphone on their body (details in Section 5.4). Table 5 details all the different types of activities that participants were instructed to perform, in addition to other uncontrolled activities that they may perform while navigating inside the virtual world. The con- trolled actions include movement of the head, arms, palms, legs, and also actions that require combination of them. These different actions were chosen to generate a variety of different movements within our limited time with the participants. During the uncon- trolled activity phases, participants were free to interact with the VR app on their own volition, not limited by the aforementioned activities. The average time our participants spent on the virtual reality app, in order to provide us data for our study, was 1 hours and 8 minutes.\n5.2 Adversarial Viewpoints\nWe continuously observe and record the participants\u2019 avatar (Fig- ure 4) in the virtual world by means of five different virtual camera positions, where each camera position represents a different ad- versarial viewpoints. Four of these camera positions are static and positioned at different corners of the virtual room (Figure 4), each of which represents the fixed (or static) position of an adversarial avatar observing the target participant from that position. The fifth camera is mobile, and represents the view of an adversarial avatar moving and navigating in the proximity of the (target) participant\u2019s avatar. We carried out our experiments in two different virtual worlds \u2013 one in a public world (called Black Cat) where other real users\u2019 avatars may be present, and second in a private world (called Home) where access is restricted to a select group of users. We refer to these five adversarial viewpoints in these two worlds by means of a legend outlined in Table 1. In our evaluation (Section 6), we will also analyze the effect of combining these five viewpoints on the accuracy of activity classification (where the viewpoints are referred to as HCC and BCC for Home and Black Cat, respectively).\n5.3 Participants\nBetween August and December of 2022 we recruited 64 participants for test data collection. However, due to various personal, techni- cal, and medical factors, only 35 of them completed the study and whose data is included in our evaluation. Participants aged between 18 and 48, with a median age of 19. Additional demographic and other details about our participants are listed in Table 2. All partici- pants were appropriately compensated for their time and our study\n6\n"}, {"chunk": "Exploiting Out-of-band Motion Sensor Data to De-anonymize Virtual Reality Users , ,\nTable 2: Background details of the 35 participants. Gender\nDominant Hand\neach adversarial perspective into individual video files with times- tamps. The motion sensors were logged in respective devices with timestamps, and later transferred to another desktop for analysis. Analysis Computer. A 2021 MacBook Pro was used to train and classify activities, and also for the activity-based filtering and magnitude- based rankings. It is equipped with 10-Core M1 CPU, 16-Core GPU, 16GB memory, 1TB SSD storage, and 16-core Neural Engine. For\nour large-scale analysis in Section 7, we also used a desktop with Ryzen 5 3600 6-Core 3.6GHz CPU, RTX 3060 12GB GPU, 1TB SSD storage, and 16GB memory, to train and generate large datasets using CTGAN [3, 66].\n6 EVALUATION\nWe next evaluate the proposed correlation framework utilizing the test data collected from participants, which represents a small- scale attack with anonymity set size of 271 (accumulating different motion sensor locations from individual participants). We start with identifying suitable framework parameter values such as the activity window size (\ud835\udc64 ) and activity-based filtering threshold (\ud835\udc61 ). After extensively evaluating the correlation framework in the small- scale setting, we also generate and evaluate a representative dataset for a large-scale correlation in Section 7.\n6.1 Framework Parameters\nOur correlation framework has two key parameters that are critical for the rest of our empirical evaluation. The first parameter is the activity window size (\ud835\udc64 ), which is the time duration used to classify an action. The second parameter is the Hamming distance used as the activity-based filtering threshold (\ud835\udc61), which is the minimum requirement for an activity-vector to be considered in the identity ranking. As the total observation time, and thus the number of observed activity windows, will vary between different target users, the activity-based filtering threshold (\ud835\udc61) is normalized with respect to the number of observed activity windows. No filtering occurs when the filtering threshold is set at 100%, whereas at 0% even one mismatch in the activity sequence will result in that activity-vector being filtered out.\n 14 Female\n2 Left\n21 Male\n33 Right\n  VR Familiarity\n11 Slightly 24 Moderately-Extremely\nPrior VR Experience\n5 Never Used VR Before 30 Used VR Before\nprocedure was approved by our university\u2019s Institutional Review Board (IRB).\n5.4 Data Collection Apparatus\nVR Device and App. We utilize the Meta Quest 2 VR device6 and the popular VRChat [20] app (installed on the Quest 2) for generating and collecting test data from the participants in our study. As of July 2022, VRChat had more than 200,000 daily active users and more than 7 million registered users [21]. Moreover, VRChat was one of the few VR apps which supported full-body avatars (instead of only the upper body) at the time we started our experiments. Although other popular apps later added integration of full-body avatars [5], the fundamental nature of data generation (and collection) does not significantly differ across a majority of the VR apps.\nMotion Sensors. Participants\u2019 body motion was captured at 20 \ud835\udc5a\ud835\udc60 sampling interval on a smartwatch (TicWatch 2) worn by the participants on their wrist and on a smartphone (Moto G7 Play) placed in their pocket. 10 participants chose to wear the smartwatch on their right wrist, while the rest chose to wear it on their left wrist. 23 participants placed the smartphone in one of their front pockets, while the rest place it in one of their back pockets.\nData Logging. The VRChat app was installed on five different desktops to record the viewpoints/perspective of an adversary as described in Section 3, and OBS Studio [11] was used to record the\n   6\nhttps://www.meta.com/quest/products/quest-2\n(a) HC1\n(f) BC1\n     (b) HC2\n(g) BC2\n(c) HC3\n(h) BC3\nFigure 4: Adversarial viewpoints.\n(d) HC4\n(i) BC4\n(e) HC5\n(j) BC5\n     7\n"}, {"chunk": ", , Mohd Sabra, Nisha Vinayaga Sureshkanth, Ari Sharma, Anindya Maiti, and Murtuza Jadliwala\n     (a) \ud835\udc64 = 0.5\ud835\udc60 (b) \ud835\udc64 = 1\ud835\udc60 (c) \ud835\udc64 = 2\ud835\udc60 (d) \ud835\udc64 = 3 (e) \ud835\udc64 = 5\ud835\udc60\nFigure 5: Right smartwatch motion sensor and visual movement data correlated with different \ud835\udc64 and normalized \ud835\udc61 parameters. Accuracy based on top-1 identity in the rankings.\n(a) \ud835\udc64 = 0.5\ud835\udc60 (b) \ud835\udc64 = 1\ud835\udc60 (c) \ud835\udc64 = 2\ud835\udc60 (d) \ud835\udc64 = 3\ud835\udc60 (e) \ud835\udc64 = 5\ud835\udc60\nFigure 6: Front right pocket smartphone motion sensor and visual movement data correlated with different \ud835\udc64 and normalized \ud835\udc61 parameters. Accuracy based on top-1 identity in the rankings.\n       Figures 5 and 6 show the correlation accuracy, where \"None Correlated\" occurs when the activity-based filtering filters all can- didate activity-vectors, \"Incorrectly Correlated\" occurs when the top ranked identity is incorrect, and \"Correctly Correlated\" occurs when the top ranked identity is correct. From these figures we can see an overall trend that as we increase \ud835\udc64 , the percentage of identities that passes the activity-based filtering and then used for identity ranking also grows. Conversely, the percentage of \u201cNone Correlated\u201d is diminished as \ud835\udc64 is increased. This can primarily be attributed to (i) the size of activity sequence in the activity-vector is inversely proportional to \ud835\udc64 for a constant observation time period thereby reducing the number of probable mismatches, and (ii) the activity inference tends to perform more accurately for larger \ud835\udc64 .\nWhile the above observation should compel us to select a larger \ud835\udc64, in Figures 5 and 6 we also observe that there exists a trade-off between \ud835\udc64 and correctly correlated identities for different activity- based filtering thresholds. For instance, when \ud835\udc64 = 5\ud835\udc60 we observe that the percentage of correctly correlated identities starts to de- crease beyond the filtering threshold of 70% in Figure 5e. This is most likely because as the size of activity-vector is reduced with in- creasing \ud835\udc64 , the probability of confusion with another person\u2019s activ- ity magnitudes is increased. This trend was consistent across other experimental variables, such as different adversarial viewpoints, different motion sensors, and different motion sensor positions on the body.\nBased on empirical observations across different experimental vari- ablesweset\ud835\udc64 = 1\ud835\udc60 and\ud835\udc61 = 30%fortherestofouranalyses.On average, these selected values are best suited for maximizing the\npercentage of correctly correlated identities. The average correctly correlated identities using these parameter values within top-1 of the ranking was 16.3%, and 17.0% of the identities were within top-3. In an alternate adversarial model where the motion sensor positions on the body is known to the adversary, more specific (i.e., per target user) \ud835\udc64 and \ud835\udc61 values can be selected to further improve the percentage of correctly correlated identities.\n6.2 Activity Confusions\nThe accuracy of the activity classification models play an important role in the correlation framework\u2019s overall success rate. Activity classification between visual and motion sensor data differs sig- nificantly due to the modality (of input signal), and is potentially subject to different types of noises and interference signals. Differ- ent adversarial viewpoint angles, distances, and occlusion levels affect the visual data classification. For instance, if only half of the avatar is visible due to being behind a coach or another avatar is in front of the target avatar, the chance of a misclassification is significantly increased. On the other hand, the positioning and orientation of the device used to collect motion sensor data also imposes certain limitations on the activity classification accuracy, especially as we assume that the adversary is unaware of the exact position of the motion sensor. For instance, if the motion sensor data is from a smartwatch worn on the right hand, it is very useful to classify activities involving the right hand, but may result in high misclassification of activities not involving the right arm.\nDue to these apparent limitations, we analyze the direct conse- quence of misclassifications, i. e., the confusion of activities between\n8\n"}, {"chunk": "Exploiting Out-of-band Motion Sensor Data to De-anonymize Virtual Reality Users , ,\n  0.01 0.18 0.05 0.03 0.02 0.09 0.00 0.62\n0.00 0.02 0.00 0.01 0.00 0.00 0.91 0.06\n0.01 0.13 0.00 0.01 0.00 0.72 0.00 0.12\n0.00 0.08 0.01 0.01 0.81 0.02 0.00 0.07\n0.03 0.09 0.00 0.75 0.03 0.01 0.00 0.09 0.4 0.26 0.27 0.09 0.16 0.06 0.00 0.03 0.14\n0.01 0.68 0.03 0.11 0.04 0.06 0.00 0.07 0.36 0.00 0.04 0.01 0.58 0.00 0.00 0.00\nIdle Body Head Hand Walk Bend Jump Other Video Action\n0.8\n0.6\n0.2\n0.0\nMotion Sensor Action Idle Body Head Hand Walk Bend Jump Other\n(a) Using right wrist smartwatch.\n(b) Using front right pocket smartphone.\nFigure 7: Activity classification confusion between motion sensor data and visual movements.\nFigure 8: Correctly correlated accuracy (top-1 rank) with ar- tificially introduced misalignment, shown for data from the right wrist.\nthe visual and motion sensor data. In Figure 7, we observe that the idle activity has noticeably low accuracy (36% and 22% for right wrist smartwatch and front right pocket smartphone, respectively),\nand is often confused with other activities. An unexpected, yet clearly discernible, confusion exists between motion sensor idle and visual walking. One possible factor behind this observation is that VR users may be using the VR joystick to walk in the virtual world. As a result, the target user appears idle in the motion sensor data, while their virtual avatar is visually walking. Another note- worthy observation is that head movements had high confusion due to the fact that placement of motion sensors around hip and wrist areas is not suitable for capturing the target user\u2019s head movements, where as a head-mounted VR device is accurately able to capture head movements and apply them to the avatar in the virtual world.\nIn light of these insights, we further optimize our framework as follows. Rather than considering all the classified actions, we only utilize activities with less than 60% of confusion \u2013 body, hand, walk, bend, jump, and others \u2013 for our activity-based filtering. Remaining activities in the activity-vector are ignored from the Hamming distance calculations. The average correctly correlated identities after this optimization within top-1 of the ranking was 37.3%, while 38.7% of the identities were within top-3.\n6.3 Time Alignment\nBoth the visual and motion sensor data are collected with device timestamps for synchronization. Although most modern smart- phones and smartwatches are by default periodically updated against internet-based time servers, motion sensor data collection in the wild may contain time drift errors and thus misaligned with the visual movements. Misaligned data sources will likely cause con- fusion between classified activities, resulting in a high failure rate in satisfying the activity-based filter threshold. As shown in Fig- ure 8, misaligned data can drop a 62.1% correctly correlated result down to 0% in the presence of only 2.4 seconds (of artificially in- troduced) misalignment. The adversary can potentially detect and overcome such misalignments by offsetting the (motion sensor) data in increments, and selecting a time offset (\u00b1\ud835\udeff) that results in the minimum Hamming distance in the activity-based filtering. Realistic assumptions must be made on the bounds of \ud835\udeff in order to keep the computational time practical.\n6.4 Different Motion Sensors and Camera Locations\nWe next detail how different positions of the motion sensor on the (human) body and different adversarial viewpoints affect the correct correlation of our proposed framework. Overall, smartwatch (motion sensor) on left or right wrist performed better than the smartphone in the hip pockets (Figure 9). For example, for the Home world, the smartwatch yielded about 41% and 68% correct correlations (top-1 rank), for left and right wrists, respectively. In contrast, the front left-front pocket smartphone data resulted in about 9.1% correct correlations, while other smartphone locations are in a similar range. Intuitively, one of the main factors behind this observation is the inability of smartphone motion sensors to pick up hand and head movements when they are located in the hip area pockets. This causes higher confusion between activities (Figure 7), resulting in the activity-vector of the target user being filtered out with high likelihood.\n  0.04 0.15 0.11 0.07 0.04 0.06 0.01 0.51\n0.00 0.00 0.00 0.03 0.00 0.00 0.95 0.02\n0.00 0.04 0.01 0.00 0.02 0.87 0.02 0.03\n0.00 0.10 0.06 0.02 0.79 0.02 0.00 0.01\n0.15 0.27 0.01 0.34 0.13 0.01 0.04 0.05\n0.72 0.02 0.10 0.01 0.00 0.00 0.07 0.07\n0.06 0.53 0.08 0.17 0.10 0.00 0.00 0.07\n0.22 0.08 0.14 0.14 0.38 0.00 0.00 0.03\nIdle Body Head Hand Walk Bend Jump Other Video Action\n0.8\n0.6\n0.4\n0.2\n0.0\nMotion Sensor Action Idle Body Head Hand Walk Bend Jump Other\n 9\n"}, {"chunk": ", ,\nMohd Sabra, Nisha Vinayaga Sureshkanth, Ari Sharma, Anindya Maiti, and Murtuza Jadliwala\n   (a) Motion sensor in back left pocket\n(d) Motion sensor in front right pocket.\n(b) Motion sensor in back right pocket. (c) Motion sensor in front left pocket.\n(e) Motion sensor on right wrist. (f) Motion sensor on left wrist.\n    Figure 9: Accuracy for different cameras positions and motion sensors locations of devices during the free-movement phase. Accuracy based on top-1 identity in the rankings.\n  As far as the impact of different adversarial viewpoints on the correlation accuracy of our framework is concerned, we can see from Figure 9 that, except for BC1, all other camera locations (or adversarial viewpoints) yielded comparable results within each of the motion sensor locations. The reason behind BC1 performing particularly poor is that its location was near the entrance point of the Black Cat world and most participants eventually moved away from the field-of-view of this camera during the data collection experiments. In summary, combining multiple viewpoints and the availability of wrist-based motion sensor data are the most favorable conditions for the adversary.\n6.5 Conflicting Activity Sequences\nThere can be cases, especially in a large-scale attack, where mul- tiple target users perform a similar or even an identical sequence of activities. In such cases, the magnitude-based ranking should ideally still rank the real identity higher than others. In this part of our analysis, we study the extent to which our magnitude-based ranking is able to do so, by comparing correlation accuracy when participants (and their avatars) performed the same sequence of activities. In Figure 10b, we observe 16.5% correct correlation for motion data from the right wrist in top-1 of identity rankings and 50.1% correct correlation within the top-3 ranks. This demonstrates that to an extent the magnitude-based ranking is in fact able to discern the difference between identities based on the magnitude of movements.\n7 OPTIMIZING FOR LARGE-SCALE ATTACKS\nAn adversary trying to correlate thousands or millions of anony- mous avatars with identified motion sensors data is presented with a very significant computational task. In this section, we analyze\n(a) Front left pocket motion data\n(b) Right wrist motion data\n10\nFigure 10: Identity correlation for conflicting activity se- quences.\nthe computational complexity of this task and propose related opti- mizations to our correlation framework.\nSynthetic Data Generation To test the scalability of our frame- work, we must first generate a very large synthetic dataset utilizing real participant data collected in Section 5. While it was not feasible for us to collect real-world data from thousands or millions of par- ticipants, due to the time and resources required for systematic data collection per participant, we still want to test using a dataset that has resemblance to the small-scale dataset instead of generating completely random activity-vectors. The activity classification and magnitude calculation tasks take constant time, and will grow lin- early with the size of each dataset (\ud835\udc5d and \ud835\udc5e, for visual movement and motion sensor datasets, respectively). For large \ud835\udc5d and \ud835\udc5e, the more complex task is that of calculating the correlation of all \ud835\udc5e identities against all \ud835\udc5d anonymous avatars. However, as seen in Section 6, the activity-based filtering is very effective in reducing the complexity of the magnitude-based identity rankings. Therefore, for large \ud835\udc5d and \ud835\udc5e the most computationally complex task in the entire framework comes down to the activity-based filtering. Accordingly, we gener- ate our large-scale dataset to test the scalability of our activity-based\n"}, {"chunk": "Exploiting Out-of-band Motion Sensor Data to De-anonymize Virtual Reality Users , ,\nTable 3: Computational time and correlation accuracy for GAN generated datasets, for default and optimized activity-based filtering. Tested for \ud835\udc58 = 5 with \ud835\udc61 = 2, and \ud835\udc58 = 10 with \ud835\udc61 = 3. Entries marked as \u201c\u2013\u201d did not finish.\n GAN Generated\nMotion \u00d7 Video 100 \u00d7 100\n500 \u00d7 500 1000 \u00d7 1000 10000 \u00d7 10000 100000 \u00d7 100000 1000000 \u00d7 1000000\nTime (ms) Default Hash 3/5\n22 7 586 36 2415 80 267293 1020\n31481325 9617 - 99304\nAverage Correctly Correlated (%)\n Hash 7/10\n29 177 386 4714 54736 644596\nDefault Hash 3/5\n47.00 41.00 44.00 43.00 45.80 39.40 51.30 42.60 39.10 31.10\n- 30.90\nHash 7/10\n44.00 41.00 40.10 34.70 21.50 21.90\n  Table 4: Correlation accuracy for permutation generated datasets, for default and optimized activity-based filtering. Testedfor\ud835\udc58 = 5with\ud835\udc61 = 2,and\ud835\udc58 = 10with\ud835\udc61 = 3.Entries marked as \u201c\u2013\u201d did not finish.\nhash values (i.e., the keys in a hash table), we design a larger hash table that allows for some degree of mismatch. Specifically, we populate a hash table with keys based on permutations of the \ud835\udc5e activity sequences in \ud835\udc40 (each of length \ud835\udc58) from the motion sensors data, accounting for possible errors allowable within the Hamming distance threshold (\ud835\udc61 ). Let us assume that the numbers 0 to 7 denotes 1 of the eight activities we classify. If \ud835\udc58 = 5, an example of the activity string would be \u27e847634\u27e9. If our hamming distance threshold is \ud835\udc61 = 2, then any two activities can be mismatched and still pass the threshold. Now, assume the character \u2217 as a wildcard activity that may or may not be a match. To populate the hash table exhaustively, we compute every possible permutation of each activity sequences in \ud835\udc40 including up to two \u2217. For our previous example, \u27e847634\u27e9, some of the permutations generated would be \u27e8\u2217 \u2217 634\u27e9, \u27e84 \u2217 6 \u2217 4\u27e9, and \u27e847 \u2217 3\u2217\u27e9. All these permutations are then used as the key in our hash table, while the corresponding value is the identity of users from the motion sensor data (\ud835\udc40). Thereafter, during the correlation process, each activity sequence from the video dataset also undergoes permutations with up to two \u2217, and then queried against the above hash table for a match. If a matching key exists, the corresponding identity and activity-vector has satisfied the activity-based filtering and is included in the identity ranking. Optimized Performance Analysis. The number of permutations per activity-vector does not scale with the size of datasets and thus can be treated as \ud835\udc42(1) time complexity. Similarly, hash table search and insertion is \ud835\udc42 (1) time complexity. Therefore, with the use of our hash table, the new time complexity becomes \ud835\udc42(\ud835\udc5d + \ud835\udc5e), where \ud835\udc42(\ud835\udc5e) time is required to create the hash table, and \ud835\udc42(\ud835\udc5d) time is require to iterate through \ud835\udc49 for filtering. Our empirical results (Tables 3 and 4) show that with the optimization, the activity-filtering is significantly faster. For instance with \ud835\udc5d = \ud835\udc5e = 100000, \ud835\udc58 = 10, and \ud835\udc61 = 3, using the optimization technique was 575 times faster than the default activity-based filter.\n8 DISCUSSION\nNext, we highlight some interesting observations that we made during our experiments, which may need to be considered by an adversary carrying out the above de-anonymization attack. Further, we also list some additional adversarial optimizations that could be applied to the proposed framework and identify potential mitigation strategies against this threat.\nObject Spawning. During out experiments, we observed random objects, for example, a tent (Figure 11b) and a meteoroid (Figure 11a),\n Permutation Generated\nMotion \u00d7 Video 100 \u00d7 100\n500 \u00d7 500 1000 \u00d7 1000 10000 \u00d7 10000 100000 \u00d7 100000 1000000 \u00d7 1000000\nAverage Correctly Correlated (%)\n Default Hash 3/5\n54.00 49.00 55.00 42.00 48.90 41.10 53.20 40.90 51.70 36.60\n- 38.70\nHash 7/10\n49.00 40.00 43.10 36.20 29.80 24.50\n  filtering, which only requires activity sequences as input. Our first large-scale dataset was generated using a modern tabular Genera- tive Adversarial Network (GAN) technique [3], called CTGAN [66], which is trained using activity sequences from real participants, as outlined in Section 5. Our second large-scale dataset was generated using random permutations of our activity sequences from Sec- tion 5. Each of these large-scale datasets contained 1 million activity sequences for the motion sensor and 1 million activity sequences for the visual movements.\nActivity-based Filtering Without Optimizations. Without any optimizations, the activity-based filtering has a time complexity of\n2\n\ud835\udc42(\ud835\udc5d\ud835\udc5e\ud835\udc58 ), where \ud835\udc5d is the number of unique avatars from the visual\nmovement data, \ud835\udc5e is the number of different identities from the\nmotion sensor data, and \ud835\udc58 is the size of the activity sequences. As\nsuch, we can further assume that increasing the size of \ud835\udc58 would have\ndiminishing returns (computationally), making it less attractive\nfor an adversary to record each target for too long. Therefore, we\nassume \ud835\udc58 would not be scaled, unlike \ud835\udc5d and \ud835\udc5e, and treat \ud835\udc58 as constant,\nthus resulting with a complexity of \ud835\udc42(\ud835\udc5d\ud835\udc5e). As shown in Table 3,\nour setup takes 2.2 \u2217 101 ms to finish activity-based filtering when 5\n\ud835\udc5d=\ud835\udc5e=100.However,whenwescaleupto\ud835\udc5d=\ud835\udc5e=10 ,itrequires 3.15 \u2217 107 ms (or about 8 hours) to finish activity-based filtering.\n6\nWe estimate that for \ud835\udc5d = \ud835\udc5e = 10 , it will take approximately 30 days\n7\nto finish, and about 3000 days when \ud835\udc5d = \ud835\udc5e = 10 , which is not very\nscalable.\nOptimization. We propose the use of a hash table to store our activity sequence data in order to reduce the time complexity of activity matching and filtering. However, as even a single mismatch between two activity sequences will result in completely different\n11\n"}, {"chunk": ", , Mohd Sabra, Nisha Vinayaga Sureshkanth, Ari Sharma, Anindya Maiti, and Murtuza Jadliwala\nbeing spawned arbitrarily and at random locations within the VR- Chat worlds. While the reason for these arbitrary objects appearing was unclear, depending on their location, they could interfere with the adversary\u2019s viewpoint by blocking his (visual) line-of-sight to the target. In addition to randomly appearing stationary objects, we have also sometimes observed arbitrary appearances of mov- ing non-playable characters which can also impact the adversary\u2019s view of the target. In summary, an adversary should plan for such arbitrary obstructions during visual data collection, and perhaps employ multiple viewpoints (or perspectives) to the target user in order to overcome this issue, similar to what we do in our experi- ments.\ninactive avatars, and avatars who misuse VRChat terms of services\nand kicks them out or bans them from the service. During our experiments, we did observe that some of our adversarial avatars, especially stationary avatars, were kicked out of the room (being monitored) or even banned altogether from VRChat. Although the\nmain reasons (could be the anti-cheat software or other users re-\nporting our adversarial avatars) behind such kick-outs or bans are\nunclear to us, we believe this could present a significant obstacle\nto an adversary attempting to accomplish the proposed attack. In\norder to continue collecting visual data in the presence of such\nroom kick-outs and bans, an adversary would need to find ways\nto circumvent such \u201canti-cheat\" measures or be ready to deploy\nbackup avatars, similar to what we did during our experiments. Additional Optimization. In addition to the optimizations we presented earlier in Section 7, an adversary can carry out additional optimizations as part of the framework to improve the overall accu-\nracy by further reducing the number of incorrect correlations. For example, suppose that an adversary has collected visual and motion\ndata over multiple sessions/days. It is highly unlikely that a corre-\nlation between motion data of two (or more) unique people/users\nto a target avatar will repeat over a span of multiple independent observed virtual reality sessions. To utilize this factor, the adver-\nsary has to first increase the activity-based filtering threshold (\ud835\udc61 ) for\nall the observed sessions/days. With a higher allowable mismatch between the activity sequences, the adversary is more likely to\ninclude the target user\u2019s identity in the rankings across all of the sessions. Thereafter, with elimination of identities not present in rankings of all the sessions, the combined ranking/search set will\nreduce drastically, increasing the probability of correct correlation.\nActive Mitigation Measures. The best mitigation for the de-anonymization attack presented in this work is to fully decouple the visual and\nmotion sensor data by not making the motion data available to the adversary when users are in virtual environments. This can be accomplished through various means such as increasing user aware- ness of such threats, not wearing/carrying smart mobile devices (with in-built motion sensors) while using VR services or through appropriate user-notifications at the beginning of VR sessions. If the smart mobile device(s) is synced with the VR device, access to the mobile device motion sensor could also be automatically and appropriately regulated while the user is in a virtual reality session. Alternatively, another option to protect against such attacks would be to use non-humanoid avatars or a humanoid avatar with adver- sarial patches [60]. Adversarial patches typically overlay an image patch on a target image object (in our case, an avatar), causing some pre-trained machine learning or deep learning classifier into misclassifying the object. An appropriate adversarial patch on the user\u2019s chosen avatar would prevent recognition of the humanoid character in our framework, thus preventing accurate generation of the activity-vector series required for correlation.\n9 CONCLUSION\nWe proposed a novel framework to correlate anonymous avatars in virtual worlds with identified out-of-band motion sensor data.\n  (a) Meteoroid\nFigure 11: Examples of object spawning.\nImage & Link Injections. Another challenge an adversary could face in the virtual world (especially, public worlds) while collecting visual data (corresponding to the target) is random and uniniti- ated interactions with other VR users. During our experiments, we observed random users positioning themselves in front of our adversary (and its view), thus blocking his line-of-sight (to the tar- get) and impacting the attack. While a mobile adversary may be able to adjust his position (within the virtual room) to regain view of the target, a stationary adversary may be unable to do it and thus unable to record useful visual data for the attack. Other forms of interactions (by other users with our adversary) could include sharing of images and links, which could also disrupt the visual data recording by the adversary. For instance, during our experi- ments we observed that when an image is shared (see Figure 12a) by a VRChat user (with our adversary), it overlays a transparent image on top of the adversary\u2019s viewpoint, rendering the visual data collected by him ineffective during that period. Similarly, we also observed that sharing of links can also have undesirable effects on the adversary\u2019s avatar (Figure 12b), rendering it ineffective in collecting useful visual data.\n(a) Injected image.\nFigure 12: Examples of image/link injection.\nDetecting and Ousting Suspicious Avatars. The VRChat ser- vice employs an anti-cheat software which attempts to detect bots,\n(b) Tent\n  (b) Injected link.\n12\n"}, {"chunk": "Exploiting Out-of-band Motion Sensor Data to De-anonymize Virtual Reality Users , ,\nOur work highlights a newfound privacy risk to users of the grow- ing VR ecosystem. Specifically, VR users can be vulnerable to de- anonymization attack if they carry a smartphone or wear a smart- watch while using a VR system. Our evaluation of the proposed framework is a step towards demonstrating the feasibility of such an attack, utilizing real-world data from human participants. Through our empirical analyses, we were able to optimize framework pa- rameters, improve scalability, and identified current limitations and potential for further improvements.\nREFERENCES\n[1] Online; accessed 01-Nov-2022. 7 Great Virtual Reality Travel Experiences. https: //www.lifewire.com/virtual-reality-tourism-4129394. (Online; accessed 01-Nov- 2022).\n[2] Online; accessed 01-Nov-2022. CMU Graphics Lab Motion Capture Database. http://mocap.cs.cmu.edu. (Online; accessed 01-Nov-2022).\n[3] Online; accessed 01-Nov-2022. GAN-for-tabular-data. https://github.com/ Diyago/GAN-for-tabular-data. (Online; accessed 01-Nov-2022).\n[4] Online; accessed 01-Nov-2022. Google Blocks. https://arvr.google.com/blocks. (Online; accessed 01-Nov-2022).\n[5] Online; accessed 01-Nov-2022. Legs are finally coming to Mark Zucker- berg\u2019s metaverse. https://www.vox.com/recode/2022/10/11/23399439/ metaverse- mark- zuckerberg- connect- avatar- legs- meta- microsoft- apple- vr- ar. (Online; accessed 01-Nov-2022).\n[6] Online; accessed 01-Nov-2022. MeetinVR. https://www.meetinvr.com. (Online; accessed 01-Nov-2022).\n[7] Online; accessed 01-Nov-2022. Meta Horizon. https://www.oculus.com/ FacebookHorizon. (Online; accessed 01-Nov-2022).\n[8] Online; accessed 01-Nov-2022. Metaverse. https://about.meta.com/metaverse. (Online; accessed 01-Nov-2022).\n[9] Online; accessed 01-Nov-2022. Mozilla Hubs. https://hubs.mozilla.com. (Online; accessed 01-Nov-2022).\n[10] Online; accessed 01-Nov-2022. MrDeepFakes. https://mrdeepfakes.com. (Online; accessed 01-Nov-2022).\n[11] Online; accessed 01-Nov-2022. OBS Studio. https://obsproject.com. (Online; accessed 01-Nov-2022).\n[12] Online; accessed 01-Nov-2022. ocrnet-hrnet-w48-paddle. https://docs.openvino. ai/latest/omz_models_model_ocrnet_hrnet_w48_paddle.html. (Online; accessed 01-Nov-2022).\n[13] Online; accessed 01-Nov-2022. Oculus Store. https://www.oculus.com/ experiences/quest/. (Online; accessed 01-Nov-2022).\n[14] Online; accessed 01-Nov-2022. See No Evil, Hear No Evil: The Use of Deepfakes in Social Engineering Attacks. https://www.tripwire.com/state-of-security/ use-of-deepfakes-in-social-engineering-attacks. (Online; accessed 01-Nov- 2022).\n[15] Online; accessed 01-Nov-2022. Sketchfab. https://sketchfab.com. (Online; ac- cessed 01-Nov-2022).\n[16] Online; accessed 01-Nov-2022. Spatial. https://www.spatial.io. (Online; accessed 01-Nov-2022).\n[17] Online; accessed 01-Nov-2022. Unity Real-Time Development Platform. https: //unity.com. (Online; accessed 01-Nov-2022).\n[18] Online; accessed 01-Nov-2022. Virtual Reality in Social Net- works - What is This Phenomenon? https://servreality.com/blog/ virtual- reality- in- social- networks- what- is- this- phenomenon/. (Online; accessed 01-Nov-2022).\n[19] Online; accessed 01-Nov-2022. VR for Tourism. https://immersionvr.co.uk/ about-360vr/vr-for-tourism/. (Online; accessed 01-Nov-2022).\n[20] Online; accessed 01-Nov-2022. VRChat. https://hello.vrchat.com/. (Online; accessed 01-Nov-2022).\n[21] Online; accessed 01-Nov-2022. VRChat. https://mmostats.com/game/vrchat. (Online; accessed 01-Nov-2022).\n[22] Devon Adams, Alseny Bah, Catherine Barwulor, Nureli Musaby, Kadeem Pitkin, and Elissa M Redmiles. 2018. Ethics emerging: the story of privacy and security perceptions in virtual reality. In Fourteenth Symposium on Usable Privacy and Security (SOUPS 2018). 427\u2013442.\n[23] Mathieu Barnachon, Sai\u0308da Bouakaz, Boubakeur Boufama, and Erwan Guillou. 2014. Ongoing human action recognition with motion capture. Pattern Recogni- tion 47, 1 (2014), 238\u2013247.\n[24] Liang Cai and Hao Chen. 2011. {TouchLogger}: Inferring Keystrokes on Touch Screen from Smartphone Motion. In 6th USENIX Workshop on Hot Topics in Security (HotSec 11).\n[25] PaddlePaddle Contributors. 2019. PaddleSeg, End-to-end image segmentation kit based on PaddlePaddle. https://github.com/PaddlePaddle/PaddleSeg. (2019).\n[26] Anupam Das, Joseph Bonneau, Matthew Caesar, Nikita Borisov, and XiaoFeng Wang. 2014. The tangled web of password reuse.. In NDSS, Vol. 14. 23\u201326.\n[27] Erhan Davarci, Betul Soysal, Imran Erguler, Sabri Orhun Aydin, Onur Dincer,\nand Emin Anarim. 2017. Age group detection using smartphone motion sensors.\nIn 2017 25th European Signal Processing Conference (EUSIPCO). IEEE, 2201\u20132205.\n[28] Douglas DeCarlo and Dimitris Metaxas. The integration of optical flow and deformable models with applications to human face shape and motion estimation. In Proceedings CVPR IEEE Computer Society Conference on Computer Vision and\nPattern Recognition. IEEE, 231\u2013238.\n[29] Nicholas Diakopoulos and Deborah Johnson. 2021. Anticipating and addressing\nthe ethical implications of deepfakes in the context of elections. New Media &\nSociety 23, 7 (2021), 2072\u20132098.\n[30] Guo Freeman, Samaneh Zamanifard, Divine Maloney, and Alexandra Adkins.\n2020. My body, my avatar: How people perceive their avatars in social virtual reality. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u20138.\n[31] Saumya Gupta, Theresa Jean Tanenbaum, Meena Devii Muralikumar, and Apara- jita S Marathe. 2020. Investigating roleplaying and identity transformation in a virtual reality narrative experience. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201313.\n[32] Jun Han, Albert Jin Chung, and Patrick Tague. 2017. Pitchln: eavesdropping via intelligible speech reconstruction using non-acoustic sensor fusion. In Proceed- ings of the 16th ACM/IEEE International Conference on Information Processing in Sensor Networks. 181\u2013192.\n[33] Jun Han, Emmanuel Owusu, Le T Nguyen, Adrian Perrig, and Joy Zhang. 2012. Accomplice: Location inference using accelerometers on smartphones. In 2012 Fourth International Conference on Communication Systems and Networks (COM- SNETS 2012). IEEE, 1\u20139.\n[34] Duncan Hodges and Oliver Buckley. 2018. Reconstructing what you said: Text inference using smartphone motion. IEEE Transactions on Mobile Computing 18, 4 (2018), 947\u2013959.\n[35] Berthold KP Horn and Brian G Schunck. 1981. Determining optical flow. Artificial intelligence 17, 1-3 (1981), 185\u2013203.\n[36] Stamatis Karnouskos. 2020. Artificial intelligence in digital media: The era of deepfakes. IEEE Transactions on Technology and Society 1, 3 (2020), 138\u2013147.\n[37] Jacob Leon Kro\u0308ger, Otto Hans-Martin Lutz, and Florian Mu\u0308ller. 2019. What does your gaze reveal about you? On the privacy implications of eye tracking. In IFIP International Summer School on Privacy and Identity Management. Springer, 226\u2013241.\n[38] Amit Kumar, Kristina Yordanova, Thomas Kirste, and Mohit Kumar. 2018. Com- bining off-the-shelf image classifiers with transfer learning for activity recogni- tion. In Proceedings of the 5th international Workshop on Sensor-based Activity Recognition and Interaction. 1\u20139.\n[39] Gen Li and Hiroyuki Sato. 2020. Handwritten signature authentication using smartwatch motion sensors. In 2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC). IEEE, 1589\u20131596.\n[40] Xiangyu Liu, Zhe Zhou, Wenrui Diao, Zhou Li, and Kehuan Zhang. 2015. When good becomes evil: Keystroke inference with smartwatch. In Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security. 1273\u20131285.\n[41] Chris Xiaoxuan Lu, Bowen Du, Hongkai Wen, Sen Wang, Andrew Markham, Ivan Martinovic, Yiran Shen, and Niki Trigoni. 2018. Snoopy: Sniffing your smartwatch passwords via deep sequence learning. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 1, 4 (2018), 1\u201329.\n[42] Anindya Maiti, Oscar Armbruster, Murtuza Jadliwala, and Jibo He. 2016. Smartwatch-based keystroke inference attacks and context-aware protection mechanisms. In Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security. 795\u2013806.\n[43] Divine Maloney, Samaneh Zamanifard, and Guo Freeman. 2020. Anonymity vs. familiarity: Self-disclosure and privacy in social virtual reality. In 26th ACM Symposium on Virtual Reality Software and Technology. 1\u20139.\n[44] Oge Marques. 2020. Machine Learning with Core ML. In Image Processing and Computer Vision in iOS. Springer, 29\u201340.\n[45] Yan Michalevsky, Dan Boneh, and Gabi Nakibly. 2014. Gyrophone: Recognizing speech from gyroscope signals. In 23rd USENIX Security Symposium (USENIX Security 14). 1053\u20131067.\n[46] Mark Roman Miller, Fernanda Herrera, Hanseul Jun, James A Landay, and Jeremy N Bailenson. 2020. Personal identifiability of user tracking data during observation of 360-degree VR video. Scientific Reports 10, 1 (2020), 1\u201310.\n[47] Robert Miller, Natasha Kholgade Banerjee, and Sean Banerjee. 2022. Combining Real-World Constraints on User Behavior with Deep Neural Networks for Virtual Reality (VR) Biometrics. In 2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR). IEEE, 409\u2013418.\n[48] Clinton Mo, Kun Hu, Shaohui Mei, Zebin Chen, and Zhiyong Wang. 2021. Keyframe extraction from motion capture sequences with graph based deep reinforcement learning. In Proceedings of the 29th ACM International Conference on Multimedia. 5194\u20135202.\n13\n"}, {"chunk": ", ,\nMohd Sabra, Nisha Vinayaga Sureshkanth, Ari Sharma, Anindya Maiti, and Murtuza Jadliwala\n[49]\n[50]\n[51]\n[52]\n[53]\n[54]\n[55] [56]\n[57]\n[58]\n[59]\n[60]\n[61]\n[62]\n[63]\n[64]\n[65]\n[66]\n[67]\n[68]\n[69]\nArsalan Mosenia, Xiaoliang Dai, Prateek Mittal, and Niraj K Jha. 2017. Pinme: Tracking a smartphone user around the world. IEEE Transactions on Multi-Scale Computing Systems 4, 3 (2017), 420\u2013435.\nVivek Nair, Gonzalo Munilla Garrido, and Dawn Song. 2022. Exploring the Unprecedented Privacy Risks of the Metaverse. arXiv preprint arXiv:2207.13176 (2022).\nSashank Narain, Triet D Vo-Huu, Kenneth Block, and Guevara Noubir. 2016. Inferring user routes and locations using zero-permission mobile sensors. In 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 397\u2013413.\nEmmanuel Owusu, Jun Han, Sauvik Das, Adrian Perrig, and Joy Zhang. 2012. Accessory: password inference using accelerometers on smartphones. In pro- ceedings of the twelfth workshop on mobile computing systems & applications. 1\u20136.\nWilliam H Press and Saul A Teukolsky. 1990. Savitzky-Golay smoothing filters. Computers in Physics 4, 6 (1990), 669\u2013672.\nAllen Sarkisyan, Ryan Debbiny, and Ani Nahapetian. 2015. WristSnoop: Smart- phone PINs prediction using smartwatch motion sensors. In 2015 IEEE interna- tional workshop on information forensics and security (WIFS). IEEE, 1\u20136. Homeland Security. Increasing Threat of DeepFake Identities. (????).\nLeonid Sigal, Alexandru O Balan, and Michael J Black. 2010. Humaneva: Synchro- nized video and motion capture dataset and baseline algorithm for evaluation of articulated human motion. International journal of computer vision 87, 1 (2010), 4\u201327.\nShirish Singh, Devu Manikantan Shila, and Gail Kaiser. 2019. Side channel attack on smartphone sensors to infer gender of the user. In Proceedings of the 17th Conference on Embedded Networked Sensor Systems. 436\u2013437.\nChen Song, Feng Lin, Zhongjie Ba, Kui Ren, Chi Zhou, and Wenyao Xu. 2016. My smartphone knows what you print: Exploring smartphone-based side-channel attacks against 3d printers. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. 895\u2013907.\nSophie Stephenson, Bijeeta Pal, Stephen Fan, Earlence Fernandes, Yuhang Zhao, and Rahul Chatterjee. 2022. SoK: Authentication in Augmented and Virtual Reality. In 2022 IEEE Symposium on Security and Privacy (SP). IEEE Computer Society, 1552\u20131552.\nSimen Thys, Wiebe Van Ranst, and Toon Goedeme\u0301. 2019. Fooling automated surveillance cameras: adversarial patches to attack person detection. In Pro- ceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops. 0\u20130.\nRahmadi Trimananda, Hieu Le, Hao Cui, Janice Tran Ho, Anastasia Shuba, and Athina Markopoulou. 2022. {OVRseen}: Auditing Network Traffic and Privacy Policies in Oculus {VR}. In 31st USENIX security symposium (USENIX security 22). 3789\u20133806.\nMika Westerlund. 2019. The emergence of deepfake technology: A review. Technology Innovation Management Review 9, 11 (2019).\nRaveen Wijewickrama, Anindya Maiti, and Murtuza Jadliwala. 2019. deWristified: handwriting inference using wrist-based motion sensors revisited. In Proceedings of the 12th Conference on Security and Privacy in Wireless and Mobile Networks. 49\u201359.\nRaveen Wijewickrama, Anindya Maiti, and Murtuza Jadliwala. 2021. Write to know: on the feasibility of wrist motion based user-authentication from handwriting. In Proceedings of the 14th ACM Conference on Security and Privacy in Wireless and Mobile Networks. 335\u2013346.\nJohn Wojewidka. 2020. The deepfake threat to face biometrics. Biometric Tech- nology Today 2020, 2 (2020), 5\u20137.\nLei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, and Kalyan Veeramacha- neni. 2019. Modeling tabular data using conditional GAN. Advances in Neural Information Processing Systems 32 (2019).\nWeitao Xu, Girish Revadigar, Chengwen Luo, Neil Bergmann, and Wen Hu. 2016. Walkie-talkie: Motion-assisted automatic key generation for secure on- body device communication. In 2016 15th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN). IEEE, 1\u201312.\nZhi Xu, Kun Bai, and Sencun Zhu. 2012. Taplogger: Inferring user inputs on smartphone touchscreens using on-board motion sensors. In Proceedings of the fifth ACM conference on Security and Privacy in Wireless and Mobile Networks. 113\u2013124.\nJerrold H Zar. 1972. Significance testing of the Spearman rank correlation coefficient. J. Amer. Statist. Assoc. 67, 339 (1972), 578\u2013580.\nA FRAMEWORK DETAILS\nFigure 13: Keypoints on a human user or humanoid avatar.\nAlgorithm 1 Correlation Algorithm.\n   1: 2: 3: 4: 5: 6:\n7: 8: 9:\n10: 11: 12: 13: 14: 15: 16: 17: 18: 19: 20: 21: 22: 23:\n24: 25:\nInput:\n\ud835\udc63\ud835\udc56\ud835\udc51\ud835\udc52\ud835\udc5c[] \ud835\udc5a\ud835\udc5c\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b[] \ud835\udc61\nOutput:\n\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc58\ud835\udc52\ud835\udc51[]\nmaximum Spearman\u2019s rank correlation coefficient procedureCorrelate\n\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc5f\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc51[] \u22b2 Maps motion indexes to correlated video indexes\n\ud835\udc62\ud835\udc5b\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc58\ud835\udc52\ud835\udc51[] \u22b2 Unranked list of correlated motion/video indexes with maximum Spearman\u2019s rank correlation coefficient\nfor \ud835\udc56 in range(\ud835\udc63\ud835\udc56\ud835\udc51\ud835\udc52\ud835\udc5c.\ud835\udc60\ud835\udc56\ud835\udc67\ud835\udc52() \u2212 1) do\nfor \ud835\udc57inrange(\ud835\udc5a\ud835\udc5c\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b.\ud835\udc60\ud835\udc56\ud835\udc67\ud835\udc52()\u22121)do\nif \ud835\udc3b\ud835\udc4e\ud835\udc5a\ud835\udc5a\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc37\ud835\udc56\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5b\ud835\udc50\ud835\udc52(\ud835\udc63\ud835\udc56\ud835\udc51\ud835\udc52\ud835\udc5c[\ud835\udc56],\ud835\udc5a\ud835\udc5c\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b[\ud835\udc57]) < \ud835\udc61 then \ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc5f\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc51[\ud835\udc56].\ud835\udc4e\ud835\udc5d\ud835\udc5d\ud835\udc52\ud835\udc5b\ud835\udc51(\ud835\udc57)\nend if end for\nend for\nfor \ud835\udc56 in range(\ud835\udc63\ud835\udc56\ud835\udc51\ud835\udc52\ud835\udc5c.\ud835\udc60\ud835\udc56\ud835\udc67\ud835\udc52() \u2212 1) do\nfor \ud835\udc57 in range(\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc5f\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc51[\ud835\udc56].\ud835\udc60\ud835\udc56\ud835\udc67\ud835\udc52() \u2212 1) do\n\ud835\udc5a\ud835\udc56\ud835\udc51\ud835\udc65 =\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc5f\ud835\udc52\ud835\udc59\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc51[\ud835\udc56][\ud835\udc57]\n\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc46\ud835\udc5d\ud835\udc52\ud835\udc4e\ud835\udc5f\ud835\udc5a\ud835\udc4e\ud835\udc5b = \ud835\udc5a\ud835\udc4e\ud835\udc65(\ud835\udc46\ud835\udc5d\ud835\udc52\ud835\udc4e\ud835\udc5f\ud835\udc5a\ud835\udc4e\ud835\udc5b(\ud835\udc63\ud835\udc56\ud835\udc51\ud835\udc52\ud835\udc5c[\ud835\udc56],\ud835\udc5a\ud835\udc5c\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b[\ud835\udc5a \ud835\udc62\ud835\udc5b\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc58\ud835\udc52\ud835\udc51[\ud835\udc56].\ud835\udc4e\ud835\udc5d\ud835\udc5d\ud835\udc52\ud835\udc5b\ud835\udc51({\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc46\ud835\udc5d\ud835\udc52\ud835\udc4e\ud835\udc5f\ud835\udc5a\ud835\udc4e\ud835\udc5b,\ud835\udc5a\ud835\udc56\ud835\udc51\ud835\udc65 })\nend for\n\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc58\ud835\udc52\ud835\udc51[\ud835\udc56] = \ud835\udc62\ud835\udc5b\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc58\ud835\udc52\ud835\udc51[\ud835\udc56].\ud835\udc60\ud835\udc5c\ud835\udc5f\ud835\udc61() Spearman\u2019s rank correlation coefficient\nend for endprocedure\n\u22b2 sorted based on\n\u22b2 Video\u2019s activity-vectors series \u22b2 Motion\u2019s activity-vectors series \u22b2 Filtering Threshold\n\u22b2 Ranked list of correlated motion/video indexes with\n\u22b2motionindex \ud835\udc56\ud835\udc51\ud835\udc65\n]))\n 14\n"}, {"chunk": "Exploiting Out-of-band Motion Sensor Data to De-anonymize Virtual Reality Users\n, ,\nB CONTROLLED ACTIVITY SETS IN DATA COLLECTION\nTable 5: List of controlled actions performed by participants in the real and virtual reality worlds.\n Action Types\nHead-based\nArm-based\nPalm-based\nLeg-based\nCombination-based\nAction Description\nLooking [left, right, up, down]\nRotating the head in [clockwise, anti-clockwise] directions\nRaising [left, right, both] arms in [forward, upward, sideward] directions Rotating [left, right, both] arms in [clockwise, anti-clockwise] directions Stretching arms [forward, upward, sideward]\nHandshaking with [left, right, both] arms\nWaving with [left, right, both] arms in [forward, upward] directions\nThumbs up and down with [left, right, both] arms forward\nClapping with hands forward\nStepping along [left, right, forward, backward] directions\nWalking diagonally towards [left, right, forward, backward] directions Raising [left, right] knee\n[Twisting hip, turning body around] in [clockwise, anti-clockwise] directions Crouching or squatting, Jumping up and down\nSitting on the [floor, chair]\nExploring [public, private] instances\n[Walking, running] in [straight, zig-zag] paths\n[Talking, browsing] smartphone in [portrait, landscape] modes\nFiddling with an object\nPicking up objects placed on the [floor, table]\n  15\n"}, {"chunk": "SCALAR POLYNOMIAL CURVATURE INVARIANTS IN THE CONTEXT OF THE CARTAN-KARLHEDE ALGORITHM\nD. A. BROOKS1, D. D. MCNUTT1,3, J. P. SIMARD2, AND N. K. MUSOKE1,4\n1DEPARTMENT OF MATHEMATICS AND STATISTICS, DALHOUSIE UNIVERSITY, HALIFAX, NOVA SCOTIA,\nCANADA B3H 3J5\n2 DEPARTMENT OF MATHEMATICS AND STATISTICS, UNIVERSITY OF NEW BRUNSWICK, FREDERICTON, NEW BRUNSWICK CANADA, E3B 5A3\n3 FACULTY OF SCIENCE AND TECHNOLOGY, UNIVERSITY OF STAVANGER, N-4036 STAVANGER, NORWAY\n4 UNIVERSITY OF AUCKLAND,\nAUCKLAND, NEW ZEALAND 1142\nAbstract. We employ the Cartan-Karlhede algorithm in order to completely characterize the class of G \u0308odel-like spacetimes for three-dimensional gravity. By examining the permitted Segre types (or P-types) for the Ricci tensor we present the results of the Cartan-Karlhede algorithm for each subclass in terms of the algebraically independent Cartan invariants at each order. Using this smaller subset of Cartan invariants we express the scalar polynomial curvature invariants for the Go \u0308del-like spacetimes in terms of this subset of Cartan in- variants and generate a minimal set of scalar polynomial curvature invariants that uniquely characterize metrics in the class of G \u0308odel-like spacetimes and identify the subclasses in terms of the P-types of the Ricci tensor.\n1. Introduction\nThe question of when two spacetimes in general relativity can be transformed from one to another by a change of coordinates is known as the equivalence problem. This is an important issue for solutions to the Einstein field equations, as one would like to know when two solutions are related and hence describe the same gravitational field. It can also be difficult to determine whether an effect derived from the metric is due to the coordinates chosen or is of a real physical nature. The solution to the equivalence problem concerns itself with obtaining an invariant characterization of the local geometry of the spacetime, and provides a framework from which the answers to these and other questions can be obtained [1, 2]. In general, having an invariant description of a metric can be quite applicable and has far-reaching consequences [3, 4, 5].\nMathematically, interest in the equivalence problem goes back to the time of Gauss [3]. Christoffel was the first to investigate this problem for n-dimensional Riemannian manifolds admitting no symmetries, and his work implied that for\nDate: September 6, 2018.\n1\narXiv:1506.03415v2 [gr-qc] 5 Sep 2018\n "}, {"chunk": "2 Brooks et al.\nn = 4 the twentieth covariant derivative of the curvature tensor was required for complete classification [6]. Cartan applied his method of moving frames in 1946 to the classification of Lie pseudo-groups, and extended this approach to metrics ad- mitting symmetries. In general, this approach required comparing the components of the curvature tensor and its covariant derivatives up to n(n + 1)/2-th order [3, 7]. Sternberg completed Cartan\u2019s approach in the 1960\u2019s, and with the development of computer algebra systems Karlhede gave Cartan\u2019s approach a true algorithmic form and adapted it specifically for general relativity in 1980 [8, 9]. Algorithms using the algebraic classification of the irreducible parts of the curvature spinor and the Newman-Penrose spinor formalism have also been developed and implemented for various computer algebra suites [10, 11, 12].\nTo determine if two spacetimes are equivalent we must construct a set of invari- ants that are necessary and sufficient to characterize uniquely each spacetime. In practice, there are two major approaches used to generate invariants: the Cartan- Karlhede (C.K.) algorithm and scalar polynomial invariants (SPIs). Implementing the C.K. algorithm for three-dimensional (3D) solutions requires knowledge of the coframe formalism and the effect of frame transformations on the Ricci tensor and its higher order derivatives. In comparison the computation of SPIs is straightfor- ward, one merely takes the copies of the curvature tensor and its covariant deriva- tives, and contract the indices to produce scalars. This procedure will give the same result regardless of the choice of basis. Admittedly, the set of all SPIs, I, is not sufficient to uniquely characterize all spacetimes. It has been shown that if a spacetime is not uniquely characterized by I, it is either locally homogeneous or it belongs to the class of degenerate Kundt metrics [13, 14, 15, 16].\nFor the class of spacetimes uniquely characterized by I, there are several unan- swered questions relating to the minimal number of SPIs to compute, and the highest order covariant derivative of the curvature tensor needed to completely classify a spacetime. In four dimensions (4D) considerable effort has been focused on studying the zeroth order scalar curvature invariants in order to determine the minimal basis of algebraically independent invariants needed to generate any other scalar curvature invariant [17]. However, less is known about the higher order SPIs involving the covariant derivatives of the curvature tensor [18, 19].\nMotivated by the results of [20] where the C.K. algorithm was employed to pro- duce a minimal set of algebraically independent SPIs required for the 3D Szekeres cosmological spacetimes using a 3D analogue of the Newman Penrose spinor for- malism [2]. In this paper, we will use the 3D G \u0308odel-like spacetimes as an example to argue that a set of SPIs chosen using the C.K. algorithm is sufficient to uniquely characterize a spacetime. In section 2, we introduce the quantities required for the coframe formalism in the G \u0308odel-like spacetimes. In section 3, we outline the C.K. algorithm and present a lemma detailing the Segre types (or P-types in the notation of [2]) for the Ricci tensor with corresponding constraints on the metric functions. In section 4, for each P-type we present a summary of the ensuing iterations of the C.K. algorithm. In Section 5, we identify the subset of algebraically independent Cartan invariants and use them to generate a minimal set of SPIs that uniquely characterize each subcase of the G \u0308odel-like spacetimes. In section 6 we conclude the paper and discuss future work.\n "}, {"chunk": "Scalar Polynomial Curvature Invariants in the Context of the C.K. Algorithm 3\n2. The Coframe Formalism The 3D G \u0308odel-like metric is defined as [1]\nds2 = \u2212[dt + H(r)d\u03c6]2 + D2(r)d\u03c62 + dr2. Using the formalism in [2], with\n(1) F\u00b1 = H \u00b1 D,\nthe coframe {\u03b8a} may be written in compact form:\n01\n\u2212n\u03bc= \u03b8\u03bc =\u2212\u221a2(dt+F\u2212d\u03c6),\n   (2) m\u03bc= \u03b81\u03bc =\u221a2dr, 21\n \u2212l\u03bc= \u03b8\u03bc =\u2212\u221a2(dt+F+d\u03c6).\n  Here, greek indices will be used for the coordinate basis and the indices a,b,c... denote the (co)frame basis. We will denote the frame basis by e\u03bc0 = l\u03bc,e\u03bc2 = m\u03bc a n d e \u03bc2 = n \u03bc .\nThe connection one-forms, \u03c9ab = \u0393acb\u03b8c, which arise from the first Cartan struc- ture equation and satisfy \u03c9ab = \u2212\u03c9ba, are then:\nF+\u2032 0 D\u2032 2 \u03c901 = 2\u221a2D\u03b8\u22122\u221a2D\u03b8,\nH\u2032 1 \u03c902 = 2\u221a2D\u03b8,\nD\u2032 0 F\u2212\u2032 2 \u03c912 = 2\u221a2D\u03b8+2\u221a2D\u03b8,\nwhere primes denote differentiation with respect to r. Using the second Cartan\nstructure equation, we can compute the Ricci tensor, Rab, and compute the quan-\ntities defined in [2] for the trace-free part of the Ricci tensor Sab = Rab \u2212 R gab we\n           3 find that \u03a81 = S10 = 0, \u03a83 = S12 = 0 and the non-zero components are:\n1 \"D\u2032\u2032 \u0012H\u2032 \u00132 \u0012H\u2032 \u0013\u2032# \u03a80=S00=\u22122 D\u2212 D \u2212 D\n\u03a82 =S11 =S02 =\u22121\"D\u2032\u2032 \u2212\u0012H\u2032\u00132# 6DD\n       (3)\nTo normalize the components of the Ricci tensor we must use the frame transfor- mations to bring the components in agreement with table 1 of [2]. To summarize the frame freedoms we have a boost:\n \u03030 \u221a 0  \u03031 1  \u03032 1 2 (4) \u03b8= A\u03b8,\u03b8=\u03b8,\u03b8=\u221aA\u03b8,\n\" \u2032\u2032 \u0012 \u2032\u00132 \u0012 \u2032\u0013\u2032# \u03a84=S22=\u22121 D \u2212 H + H\n    2DDD R=\u22121\"4D\u2032\u2032 \u2212\u0012H\u2032\u00132#.\n   2DD\n   "}, {"chunk": "4 Brooks et al. and null rotations about n\u03bc and l\u03bc respectively:\n(5) \u03b8 \u03030=\u03b80, \u03b8 \u03031=\u03b81+B\u03b80, \u03b8 \u03032=\u03b82+B\u03b81+B2\u03b80, 2\n(6) \u03b8 \u03030=\u03b80+C\u03b81+C2\u03b82, \u03b8 \u03031=\u03b81+C\u03b82, \u03b8 \u03032=\u03b82, 2\nWhile we will work primarily with these Lorentz transformations, at times it will be helpful to express the null coframe as an orthonormal coframe {t\u03bc, x\u03bc, m\u03bc} and rotate the spatial one-forms x\u03bc and m\u03bc.\n3. The Zeroth iteration of the C.K. Algorithm: Segre types for the Go \u0308del-like Spacetimes\nTo put the Segre types into context, we reiterate the five steps of the Karlhede algorithm for the zeroth iteration, q = 0, for each P-type:\n(1) Calculate the set Rq, the components of the derivatives of the curvature up to the q-th order.\n(2) Fix the frame as much as possible by putting the elements of Rq into a canonical form.\n(3) Find the frame freedom given by the isotropy group Hq of transforma- tions which leave the canonical form (also known as normal form) of Rq unchanged.\n(4) Find the number tq of functionally independent functions of spacetime co- ordinates in the elements of Rq.\n(5) For q > 0, if the isotropy group Hq is the same as Hq\u22121 and the number of functionally independent functions tq is equal to tq\u22121 , then let q = p + 1 and stop. Otherwise set q = q + 1 and repeat steps 1-5 until the algorithm stops.\nBy studying the effect of the frame transformations which do change the form of the Ricci tensor, we may use the frame transformations to fix the coframe and determine all possible Segre types. For example, in the general case of the G \u0308odel- like spacetimes with Ricci tensor of Segre type [11,1], SO(1, 2) acting as the frame transformation group may be entirely fixed to put the tensor into the canonical form for P-type I (or IZZ) defined below. Contrast this with the opposite extreme, when the Ricci tensor is of Segre type [(11,1)] and all of the frame transformations leaves the Ricci tensor unchanged.\nNoting that for the G \u0308odel-like spacetimes \u03a81 = \u03a83 = 0, we have the following distinct subclasses.\nLemma 3.1. The G \u0308odel-like spacetimes admit the following Segre types for the Ricci tensor, which gives constraints on the metric functions D(r) and H(r) and a canonical form for the Ricci tensor:\n\u2022 [11,1] (P- type I or IZZ) if D(r) and H(r) satisfy D\u2032\u2032 \u0012H\u2032 \u00132\nD\u2212 D =f,\nwhere f is an arbitrary non-vanishing function with f < 0 for P-type I and f > 0 for P-type IZZ.\nApplying a boost (4), the components of the Ricci spinor are:\n\u03a8 \u0303 0 = \u03a8 \u0303 4 = p | \u03a8 0 \u03a8 4 | , \u03a8 \u0303 2 = \u03a8 2 , R \u0303 = R ,\n      "}, {"chunk": "Scalar Polynomial Curvature Invariants in the Context of the C.K. Algorithm 5 where the original components are defined in equation (3)\n \u2022 [1zz \u0304] (P- type IZ) if for an arbitrary function f(r) with f\u2032 \u0338= 0: H\u2032 =f(r), D\u2032\u2032 \u2212f2 =0.\nThe components of the Ricci tensor are:\n\u03a80 =\u2212\u03a84 = 1f\u2032, \u03a82 =0, R=\u22123f. 22\n  DD\n  \u2022 [12] (P-type IIZ), if for an arbitrary function f(r) with f\u2032 \u0338= 0: H\u2032=f(r), D\u2032\u2032\u2212f2+f\u2032=0.\n  DD\nApplying a boost (4), the components of the Ricci tensor are: \u03a8 \u03030 = 1, \u03a8 \u03034 = 0, \u03a8 \u03032 = f\u2032 , R \u0303 = \u22121[3f2 + 4f\u2032].\n  \u2022 [(11), 1] (P-type DZ) if\nThe components of the Ricci tensor are:\n62 H\u2032=CD, C\u2208R.\n\u03a80 =\u03a84 =3\u03a82 =\u22121\u0014D\u2032\u2032 \u2212C2\u0015, R=\u22121\u00144D\u2032\u2032 \u2212C2\u0015. 2D 2D\n\u2022 [(11, 1)] (P-type O) if\nH\u2032 = CD, D\u2032\u2032 \u2212 C2D = 0, C \u2208 R.\nThe components of the Ricci tensor are:\n3C2 \u03a80 = \u03a84 = 3\u03a82 = 0, R = \u2212 2 .\nFor each P-type of the Ricci tensor, we have a separate instance of the C.K. algorithm. We can use the components of the Ricci tensor in normal form to produce simpler invariants, and as they are all functions of r we have at most one functionally independent function allowing us to identify t0 for each case. The dimension of the isotropy group, H0, of the Ricci tensor (R0) is found by counting the remaining frame freedom; for all P-types except P-type DZ the dimension is dim(H0) = 0, while P-type DZ has dim(H0) = 1. To continue, we set q = 1 and evaluate the covariant derivative of the Ricci tensor to compute R1.\nIn general, to distinguish a 3D G \u0308odel-like spacetime from another 3D spacetime, the C.K. algorithm requires the form of the Ricci tensor and its covariant derivatives up to appropriate order relative to a fixed coframe. However, we are interested in uniquely characterizing spacetimes within the G \u0308odel-like spacetimes, we will only focus on the algebraically independent invariants. For the class of G \u0308odel-like spacetimes, the form of these invariants will be sufficient to determine if two G \u0308odel- like spacetimes are distinct or not, since all other components of the Ricci tensor and its covariant derivatives will be expressed in terms of the algebraic independent invariants in a generic manner.\n     "}, {"chunk": "6 Brooks et al.\n4. The first iteration of the Cartan-Karlhede algorithm\nThe next iteration of the C.K. algorithm requires that we must compute the covariant derivative of the Ricci tensor, or equivalently covariant derivatives of the Ricci spinor, although we will focus on tensors due to the simplicity of the metric. It is here, where the frame derivatives of the Ricci tensor and the spin-coefficients are introduced as potential invariants. This can be seen by using the formula for the covariant derivative:\n(7) R =\u2207R =R \u2212R \u0393d \u2212R \u0393d . ab;c c ab ab,c db ca ad cb\nWe will repeat the analysis of the C.K. algorithm for those G \u0308odel-like spacetimes admitting a Ricci tensor with each P-type listed above.\n4.1. P-type I or IZZ. According to Lemma (3.1) at zeroth order the set of func- tions {R,\u03a82,\u03a80} are all non-constant invariants. With some algebra, these give\nrise to a simpler but algebraically equivalent set \u001a(H\u2032 )2, D\u2032\u2032 , \u0010H\u2032 \u0011\u2032\u001b ; the num- DDD\nber of functionally independent invariants is t0 = 1 as these are all functions of r alone. We have fixed all of the isotropy at first order (dim(H0) = 0) and produced one functionally independent invariant and two essential algebraically independent classifying functions,\n(\u0012H\u2032 \u00132 D\u2032\u2032 \u0012H\u2032 \u0013\u2032) {I0,I1,I2}= D , D, D .\nWe proceed to the next iteration of the algorithm to show that the algorithm must terminate, since dim(H1) = 0 and t1 = 1, and more importantly, to collect all essential classifying functions. As all isotropy has been fixed, the metric coframe is an invariant coframe, and so the frame derivatives of all zeroth order invariants are now invariants as well. Using this fact we may solve for the frame derivatives of the Ricci tensor components \u03a80, \u03a82 and R and the spin-coefficients [2] from the components of the covariant derivative of the Ricci tensor:\nAF+\u2032 D\u2032 \u03ba= 2\u221a2D, \u03c3=0, \u03c4 = 2\u221a2D,\nH\u2032 e1(A)\n(8) o\u0328=0, 2\u03b1=2\u221a2D + A , \u03b3=0,\nD\u2032 F\u2212\u2032 \u03c0=\u22122\u221a2D, \u03bb=0,\u03bd=2\u221a2AD,\nwhere the boost parameter in (4) is defined as A = q\u03a80 . \u03a84\nThere are four algebraically in\u221adependent invariants appearing at first order. From the spin-coefficients we find 2 2\u03c4 = (lnD)\u2032 and \u03b1 from which we can solve for the sign of H\u2032/D. Taking linear combinations of the frame derivatives of \u03a82 and R we have two algebraically independent invariants, namely e2(I1) and e2(I2). Thus the list of algebraically independent invariants required to classify the spacetime is\n(9) {I0,I1,I2;I3,I4,I5,I6} = \u001a\u0010H\u2032 \u00112 , D\u2032\u2032 ,\u0010H\u2032 \u0011\u2032 ; D\u2032 ,\u0010D\u2032\u2032 \u0011\u2032 ,\u0010H\u2032 \u0011\u2032\u2032 ,sign\u0010H\u2032 \u0011\u001b. DDDDDD D\n                            "}, {"chunk": "Scalar Polynomial Curvature Invariants in the Context of the C.K. Algorithm 7\n4.2. P-type IZ. According to Lemma (3.1), at zeroth order the set of functions {R, \u03a80} are the only non-constant invariants, which give rise to the simpler set of invariants:\n{I0,I1,I2} = \bf2,f2,f\u2032 .\nThe number of functionally independent invariants is t0 = 1 as these are all func- tions of r alone. We have fixed all of the isotropy at first order (dim(H0) = 0) and produced one functionally independent invariant and one algebraically independent essential classifying function.\nThe algorithm stops at first order since dim(H1) = 0 and t1 = 1. The metric coframe is an invariant coframe, and so we may separate the spin-coefficients and the frame derivatives of the Ricci tensor components [2] from the components of the covariant derivative of the Ricci tensor. Comparing with (9), the number of algebraically independent invariants has been reduced:\n\u001aD\u2032 \u001b (10) {I0, I1, I2; I3, I4, I5, I6} = f2, f2, f\u2032; D , 2f\u2032f, f\u2032\u2032, sign(f) .\n4.3. P-type IIZ. From Lemma (3.1), at zeroth order the set of functions {R, \u03a82} are non-constant invariants, from which we have the following set of invariants \bf2, f\u2032 . The number of functionally independent invariants is t0 = 1, and we have fixed all of the isotropy at zeroth order, yielding the following set of invariants\n{I0,I1,I2}=\bf2,f2\u2212f\u2032,f\u2032 .\nYet again, the frame is an invariant coframe and we can isolate the invariants in (9) from the components of the covariant derivative of the Ricci tensor to completely classify this spacetime:\n\u001aD\u2032 \u001b (11) {I0,I1,I2;I3,I4,I5,I6} = f2,f2 \u2212f\u2032,f\u2032; D ,2f\u2032f \u2212f\u2032\u2032,f\u2032\u2032,sign(f) .\nAs in the previous case, the number of algebraically independent Cartan invariants has been reduced.\n4.4. P-type DZ. Lemma (3.1) indicates that at zeroth order the set of functions {R, \u03a82} are the only distinct non-constant invariants. The number of functionally independent invariants is t0 = 1. Thus, we have fixed most of the isotropy at first order except spatial rotations, i.e., dim(H0) = 1, and the reduced Cartan invariants are\n{I0,I1,I2} = \u001aC2, D\u2032\u2032 ,0\u001b. D\nAt the first iteration the metric coframe is not yet an invariant coframe, and so we must be careful with taking frame derivatives of invariants until an invariant coframe is determined. To entirely fix the frame, we consider the transformation rules for the spin-coefficients under an element of SO(2):\n(l+n)\u2032 =LHS, (l\u2212n\u00b12im)\u2032 =e\u2213it \u0303(l\u2212n\u00b12im).\n    "}, {"chunk": "8 Brooks et al.\nThis produces the following transformation rules for the spin-coefficients and cur- vature components [2]:\n(\u03b3+\u03c3\u2212o\u0328\u2212\u03bb)\u2032 =LHS,\n(4\u03b1+\u03ba\u2212\u03c0+\u03bd\u2212\u03c4)\u2032 =LHS,\n(2(\u03b3+o\u0328)\u00b1i(\u03ba\u2212\u03c0+\u03c4\u2212\u03bd))\u2032 =e\u00b1it \u0303LHS,\n (4\u03b1+\u03c0\u2212\u03ba+\u03c4\u2212\u03bd+\u00b12i(o\u0328\u2212\u03b3+\u03c3\u2212\u03bb))\u2032 =e\u00b12it \u0303LHS, \u2032\u00b1it \u0303  \u0303i \u0303 \u0303\n(\u03bb+\u03c3\u2212\u03b3\u2212o\u0328+\u00b1i(\u03c0\u2212\u03c4)) =e (LHS\u2212\u03b4t\u2213 2(Dt\u2212\u2206t)), \u2032 \u0303 \u0303\n (\u03ba+\u03c0+\u03bd+\u03c4) =LHS\u2212(Dt+\u2206t),\n(\u03a80 + 2\u03a82 + \u03a84)\u2032 = LHS,\n(\u03a80 \u2212 \u03a84 \u00b1 2i(\u03a81 + \u03a83))\u2032 = e\u2213it \u0303LHS,\n(|P si0 \u2212 6\u03a82 + \u03a84 \u00b1 4i(\u03a81 \u2212 \u03a83))\u2032 = e\u22132it \u0303LHS.\nSubstituting the non-zero spin-coefficients and curvature components (8) we find the simpler transformation rules for the G \u0308odel-like spacetimes:\n2\u03b3\u2032 =0, \u03c3\u2032 \u2212\u03bb\u2032 =0, 8\u03b1\u2032 =8\u03b1, \u03bd\u2032 =2\u03b1\u2032 +\u03c4\u2032, \u03ba\u2032 =2\u03b1\u2212\u03c4\u2032,\n\u2032 \u2032  \u0303  \u0303 \u2032 \u2032 \u2032 \u00b1it \u0303  \u0303 Dt \u0303 \u2206t \u0303\n2[\u03c0 +\u03c4 ]=\u2212Dt\u2212\u2206t, 2\u03c3 \u00b1i(\u03c0 \u2212\u03c4 )=e [\u2212\u03b4t\u2213i(2\u03c4\u2212 2 + 2 )]\n  Comparing with the spin-coefficients of original frame (with A = 1): \u03c4 = \u2212\u03c0, \u03ba = 2\u03b1 + \u03c4, and \u03bd = 2\u03b1 \u2212 \u03c4; we conclude that setting the rotation parameter t \u0303 to zero is the best choice. Any other choice of t \u0303 \u0338= 0 would cause \u03c3 \u0338= 0, \u03c4 \u0338= \u03c0, and the frame derivatives of any scalar with respect to e0 and e2 to be non-zero; effectively increasing the number of invariants instead of decreasing the number.\nFixing t \u0303 = 0, and simplifying the components of covariant derivative of the Ricci tensor, one finds the first order invariants are e1(\u03a82),e1(R), and the spin coefficients. Of the spin-coefficients, the only algebraically independent invariant appears in \u03b1, since \u03c4 = \u2212\u03c0 does not appear in the first covariant derivative of the Ricci tensor. Noting that C \u2212 4\u221a2\u03b1 = 0, \u03b1 provides a useful discrete invariant as the sign of the constant C. Returning to the frame derivatives, we have one algebraically independent invariant appearing: e1(I2). Thus the list of invariants required to classify the spacetime is:\n{I0,I1,I2;I4,I5,I6} = (C2, D\u2032\u2032 ,0;\u0012D\u2032\u2032 \u0013\u2032 ,0,sign(C)). DD\n4.4.1. The second iteration of the Cartan-Karlhede algorithm: P-type DZ. Apply- ing the frame derivatives to the first order invariants, we produce two new alge- braically independent classifying function:\n   (12)\n{I0, I1, I2;I4, I5, I6; I3I4, I7} =\n\u001a 2 D\u2032\u2032 \u0012D\u2032\u2032 \u0013\u2032 D\u2032 \u0012D\u2032\u2032 \u0013\u2032 \u0012D\u2032\u2032 \u0013\u2032\u2032\u001b C , D ,0; D ,0,sign(C); D D , D .\n     "}, {"chunk": "Scalar Polynomial Curvature Invariants in the Context of the C.K. Algorithm 9\nWe note that, if I4 \u0338= 0 then we can isolate I3. However, for the P-type DZ spacetimes, if I4 = 0 then all appearances of I3 vanish within the components of the second covariant derivative of the Ricci tensor.\n4.5. P-type O. As all components of the Ricci tensor are constant, using Lemma (3.1) and the form of the spin-coefficients (8), one may show that the covariant derivative of the Ricci tensor is zero. We conclude that these are locally homoge- neous spaces which are fully determined at zeroth order by the constant C2. In fact, the P-type O G \u0308odel-like spacetimes are all isometric to the 3D anti-de Sitter spacetime.\n5. Characterization of the Go \u0308del-like spacetimes using Scalar polynomial invariants\nTo begin, we consider the Cartan invariants of the P-type I (or IZZ) 3D G \u0308odel- like metric and compare them to the SPIs given in [19]. In section 4.1 we found that the algebraically independent invariants required for classification of the P-type I metrics are\n{I0,I1, I2; I3, I4, I5, I6} =\n(13) (\u0012H\u2032 \u00132 D\u2032\u2032 \u0012H\u2032 \u0013\u2032 D\u2032 \u0012D\u2032\u2032 \u0013\u2032 \u0012H\u2032 \u0013\u2032\u2032 \u0012H\u2032 \u0013)\nD ,D, D ;D, D , D ,sign D .\nCalculating the SPIs and making the substitutions for the zeroth order Cartan invariants:\n         (14) (15) (16)\nH\u2032 \u221a\nD = I6 I0,\nD\u2032\u2032\nD = I1,\n  \u0012H\u2032 \u0013\u2032 D=D\u2212D+D\n\u0012H\u2032 \u0013\u2032\nH\u2032\u2032 \u0012H\u2032\u2032 H\u2032 D\u2032\u0013 \u0012H\u2032\u0013\u2032 \u221a\nH\u2032\u2032 H\u2032\u2032\n= D\u2212 D\u2212DD + D = I0I6I3+I2.\n          The\n(17) R0 = Ra =\u22121/2 D2 =\u22122I1+1/2I0,\n(19)\nabc 3 2 2 2 3 R2 = R Ra Rbc\u221a=\u22122I1 +3I1 I0\u22123/2I1I0 +3/4I1I2 +1/8I0 ,\nthree zeroth order SPIs in [19] are:\na 4 (D)D\u2032\u2032 \u2212H\u20322\n (18) R1 = RabRab =2I12 \u22122I1I0 +3/4I02 \u22121/2I22,\n which are polynomials in I0, I1, I2.\nAt the next order, we make the similar substitutions to express nine of the first\norder SPIs in terms of the Cartan invariants. Here we give only five; all three of the case [1, 1] and two of the case [1, 1, 1, 1] in the categorization of [19]:\n (20) (21)\n;a \u0010\u221a \u00112 R3=R R;a = I0I6I2\u22122I4 ,\n\u221a\nR4 =R Rbc;d =\u2212I0 +2I4 \u22121/2I5 \u2212I1 I0 +2I1I0 +I1 I0I5\nbc;d 3 2 2 2 2\n3/2 \u221a \u221a 3/2\n   \u2212I3I0 I2 \u22125 I0I2I4 +I1I3 I0I6I2 \u2212I0 I5\n23\n+4I0I2 \u22121/2I3I2,\n222\n "}, {"chunk": "10\n(22)\n(23) (24)\nBrooks et al.\nbc;d 3/2 \u221a922 R5 =R Rbd;c =1/2I0 I3I2\u22121/2I1I3 I0I2+8I0I2 +I4\n   322\u221a +1/2I0 +1/2I1 I0 \u2212I1I0 \u22121/2I1 I0I5\n\u221a\n\u2212 3/2 I0I6I2I4 + 1/2 F2I5I2 + 1/2 I0\n 3/2\n I5, R6 = R;cRce;f R;eR;f = \u0010\u221aI0I6I2 \u2212 2 I4\u00113 \u0010\u221aI0I6I2 \u2212 I4\u0011 ,\n    R7 =R\n;ab;cd 1\u0010\u221a \u00112\u00102\u221a 2\u0011 Ra Rc ;bR;d =8 I0I6I2\u22122I4 9I0I2 \u221216 I0I6I2I4+8I4 .\n The other SPIs give more expressions of the same form: they are polynomials in \b\u221aI0, I1, I2; I3, I4, I5, I6 .\nWhile we have only considered P-type I, the SPIs we have listed above may be adapted to the G \u0308odel-like spacetimes of P-type IZ, and IIZ. These two P-type is can be identified by the following syzygies between the zeroth order SPIs, which are unique to their P-type:\n P-type IZ (25) P-type IIZ (26)\nR1R0 +R2 = 16R0; 9\nR \u2212RR +2R3= 1(6R +2R2)3. 2 1 0 9 0 36 1 0 2\n    The reduction in the number of algebraically independent Cartan invariants chang- ing from P-type I to IZ or IIZ is also reflected in the set of algebraically independent SPIs.\nIn the case of P-type DZ and O, the different structure of the algebraically independent Cartan invariants:\n{I0, I1, I2;I4, I5, I6; I3I4, I7} =\n\u001a 2 D\u2032\u2032 \u0012D\u2032\u2032 \u0013\u2032 D\u2032 \u0012D\u2032\u2032 \u0013\u2032 \u0012D\u2032\u2032 \u0013\u2032\u2032\u001b\nC , D ,0; D ,0,sign(C); D D , D ,\nis reflected in the set of SPIs. Since the Cartan invariants I2 and I5 vanish, this eliminates I3 from the set of SPIs (17)- (19) and (20)-(24). While P-type O is easily identified from the SPIs, P-type DZ can be determined by checking the following two syzygies for the first order SPIs:\n(27) R42 = 2R6, and R42 = 4R7\nIn this case we must introduce two second order SPIs to recover the Cartan invari-\nants I3 and I7. Two possibilities are: \u221a\n(28) and\n(29)\n     R8 = R3;aR3;a =\nR9 = SabScdSab;cd = 1I04 \u2212 I03I1 \u2212 2I02I7 \u2212 2I02I3I4 + I02I12\n 24I4I7 399\n   + 4I0I1I7 + 4I0I1I3I4 \u2212 1I13I0 \u2212 2I12I7 \u2212 2I12I3I4. 99399\n     Including these two SPIs we now have a set containing all of the algebraically in- dependent Cartan invariants. This set will characterize the P-type DZ spacetimes.\n"}, {"chunk": "Scalar Polynomial Curvature Invariants in the Context of the C.K. Algorithm11\nWe have found that a representative sample of the SPIs can be expressed as polynomials in (the square root of) the Cartan invariants. As any combination of invariants is an invariant, this suggests that an appropriate choice of the above ten SPIs may be sufficient to classify all G \u0308odel-like metrics, as long as one is concerned with functional dependence.\n6. Conclusion\nIn this paper we have applied the Cartan-Karlhede algorithm to the 3D G \u0308odel- like spacetimes to generate a sequence of algebraically independent Cartan invari- ants that fully characterize each subclass of these spacetimes. Beyond the ability of the Cartan invariants to classify all spacetimes, including the locally homogeneous spacetimes and the degenerate Kundt spacetimes [13, 14, 15, 16], the invariants arising from the C.K. algorithm provide a helpful framework to study SPIs for spacetimes which are characterized by I. While the invariants in each sequence can only be considered as an invariant relative to the choice of a particular coframe; in theory, working with such a coframe is not a hindrance [4]. However, in some applications choosing this frame may not be possible, such as in higher dimensions and in numerical GR. In these circumstances, SPIs are better suited as invariants.\nAs the G \u0308odel-like spacetimes are characterized by I, we have examined the set of SPIs formed from the Ricci tensor, and its covariant derivatives up to second order. By comparing with the results of the C.K. algorithm we have identified a minimal subset of SPIs which uniquely characterize these spacetimes, and identify the various subcases relative to P-type in terms of additional syzygies between the SPIs. This work is meant to be a continuation of [20], where a minimal basis of algebraically independent SPIs were determined for the Szekeres cosmological spacetimes using the C.K. algorithm. Unlike the G \u0308odel-like spacetimes, the Szekeres spacetime does not contain subcases of differing P-type and did not illustrate the ability of the chosen SPIs to distinguish P-type.\nWe believe this approach will be helpful for identifying a minimal set of SPIs (up to the appropriate order) needed to uniquely characterize a spacetime. While the Newman-Penrose formalism is already employed in 4D for the zeroth order invariants [17], the C.K. algorithm allows for a reduction of the number of non- zero independent components of the covariant derivatives of the curvature tensor. It has been shown that partial knowledge of the Cartan invariants allows for the manipulation of first order SPIs [5, 21, 22], this suggests we can potentially simplify the form of any higher order SPIs using the C.K. algorithm. In future work we will explore the implications of the C.K. algorithm for general spacetimes of fixed P-type using the 3D spinor formalism, and extend this procedure to higher dimensions [5].\nAcknowledgements\nThis work was supported in part through the Research Council of Norway, Topp- forsk grant no. 250367: Pseudo-Riemannian Geometry and Polynomial Curvature Invariants: Classification, Characterisation and Applications (D.M.) and by the Natural Sciences and Engineering Research Council of Canada (N.K.M). Research at Perimeter Institute is supported by the Government of Canada through Indus- try Canada and by the Province of Ontario through the Ministry of Research and Innovation.\n "}, {"chunk": "12 Brooks et al.\nReferences\n[1] J.B. Fonseca F.C. Sousa and C. Romero. Equivalence of three dimensional spacetimes. Class Quant Grav, 2008. arXiv:0705.0758 [gr-qc].\n[2] R. Milson and L. Wylleman. Three-dimensional spacetimes of maximal order. Class. Quant. Grav. arXiv:1210.6920 [gr-qc].\n[3] P. J. Olver. Equivalence, Invariants and Symmetry. Cambridge University Press, 1995.\n[4] M. A. H. MacCallum. Spacetime invariants and their uses. arXiv:1504.06857 [gr-qc].\n[5] D. Brooks, P. C. Chavy-Waddy, A. A. Coley, A. Forget, D. Gregoris, M. A. H. MacCallum, and D. D. McNutt. Cartan invariants and event horizon detection. General Relativity and Gravitation. arXiv:1709.03362 [gr-qc].\n[6] J. Ehlers. Christoffel\u2019s Work on the Equivalence Problem for Riemannian Spaces and its Importance for Modern Field Theory of Physics, Edited by P. L. Butzer and R. F. Feher. Basel, Birkh \u0308auser-Verlag, 1981.\n[7] E. Cartan. Le \u0327cons sur la Geo \u0301m \u0301etrie des Espaces de Riemann (English trans- lation by J. Glazebrook). Math. Sci. Press, Brookline, 1983.\n[8] A. Karlhede. A review of the geometrical equivalence of metrics in general relativity. Gen. Rel. Grav., 12, 1980.\n[9] A. Karlhede. The Equivalence Problem. Gen. Rel. Grav, 38.\n[10] T. Morgan G.S. Hall and Z. Perjes. Three-Dimensional Space-times. Gen. Rel.\nGrav., 19, 1987.\n[11] A.N. Alieve and Y. Nutku. Spinor Formulation of Topologically Massive Grav-\nity. Class. Quant. Grav., 12, 1995.\n[12] R. Penrose and W. Rindler. Spinors and Spacetime, vol. 1 & 2. Cambridge,\nCambridge University Press, 1984.\n[13] S. Hervik A. A. Coley and N. Pelavas. On Spacetimes with Constant Scalar\nInvariants . Class. Quant. Grav., 23:3053, 2006. arXiv:0509113 [gr-qc].\n[14] A. Coley, S. Hervik, and N. Pelavas. Lorentzian spacetimes with constant curvature invariants in four dimensions. Classical and Quantum Gravity,\n26(12):125011, 2009. arXiv:0904.4877 [gr-qc].\n[15] A. Coley, S. Hervik, and N. Pelavas. Lorentzian spacetimes with constant\ncurvature invariants in three dimensions. Classical and Quantum Gravity,\n25(2):025008, 2008. arXiv:0710.3903 [gr-qc].\n[16] A. Coley, S. Hervik, G. Papadopoulos, and N. Pelavas. Kundt spacetimes.\nClassical and Quantum Gravity, 26(10):105016, 2009. arXiv:0901.0394 [gr-qc].\n[17] J. Carminati and R.G. McLenaghan. Algebraic invariants of the Riemann\ntensor in a four-dimensional Lorentzian space. J. Math. Phys., 32, 1991.\n[18] M. MacCallum C. Hoenselaers H. Stephani, D. Kramer and E. Herlt. Exact\nSolutions of Einstein\u2019s Field Equations 2nd Edition. 2003.\n[19] A. A. Coley, A. MacDougall, and D. D. McNutt. Basis for scalar curvature\ninvariants in three dimensions. Class. Quant. Grav. arXiv:1409.1185 [gr-qc].\n[20] N. K. Musoke, D. D. McNutt, A. A. Coley, and D. A. Brooks. On scalar curvature invariants in three dimensional spacetimes. Gen. Rel. Grav.\narXiv:1511.01435 [gr-qc].\n[21] D. D. McNutt and D. N. Page. Scalar polynomial curvature invariant vanishing\non the event horizon of any black hole metric conformal to a static spherical metric. Phys Rev. D, 95(8):084044, 2017. arXiv:1704.02461 [gr-qc].\n "}, {"chunk": "Scalar Polynomial Curvature Invariants in the Context of the C.K. Algorithm13\n[22] D. D. McNutt. Curvature invariant characterization of event horizons of four- dimensional black holes conformal to stationary black holes. Phys. Rev. D, 96(10):104022, 2017. arXiv:1706.00995 [gr-qc].\n "}, {"chunk": "   Noname manuscript No.\n(will be inserted by the editor)\n  Cartan Invariants and Event Horizon Detection\nD. D. McNutt \u00b7 M.A.H. MacCallum \u00b7 D. Gregoris \u00b7 A. Forget \u00b7 A. A. Coley \u00b7 P. C. Chavy-Waddy \u00b7 D. Brooks\nAbstract We show that it is possible to locate the event horizons of a black hole (in arbitrary dimensions) as the zeros of certain Cartan invariants. This approach accounts for the recent results on the detection of stationary horizons using scalar polynomial curvature invariants, and improves upon them since the proposed method is computationally less expensive. As an application, we produce Cartan invariants that locate the event horizons for various exact four- dimensional and five-dimensional stationary, asymptotically flat (or (anti) de Sitter) black hole solutions and compare the Cartan invariants with the corresponding scalar curvature invariants that detect the event horizon. In particular, for each of the four-dimensional examples we express the scalar polynomial curvature invariants introduced by Abdelqader and Lake in terms of the Cartan invariants and show a direct relationship between the scalar polynomial curvature invariants and the Cartan invariants that detect the horizon.\n1 Introduction\nGeneral Relativity predicts the existence of singularities hidden by a horizon (Misner et al. 1973). Remarkably, this was noticed a year after the appearance of the Einstein field equations when Schwarzschild published a solution describing an isolated non-rotating massive object. Additional exact solutions to Einstein field equations have been found which exhibit this property (Stephani et al. 2003). Improvements in astrophysical observations have allowed black holes to be distinguished from other highly massive objects like neutron stars in our universe suggesting the physical relevance of such general relativistic metrics (Abbott et al. 2016, 2017; Gillessen et al. 2009; Celotti et al. 1999).\nNaively speaking one can regard a black hole as a region of spacetime from which nothing can escape, i.e., after crossing the horizon towards the singularity, a photon can never escape to asymptotic infinity. While this captures the basic property of black holes it is clearly unsatisfactory in general relativity, which was constructed as a local theory, and the definition of an event horizon requires global information on the entire spacetime (Choquet-Bruhat et al. 1982; Choquet-Bruhat 2000). Due to the contradictory nature of these two facts it is desirable to find alternative definitions or characterizations of black hole horizons that are quasi-local. For example, a local characterization of the horizon of a black hole is necessary in the numerical study of the evolution of configurations of many black holes.\nAt this time, only approximate localizations are possible, such as considering the event horizon as a marginally outer trapped surface, a minimal surface, a Killing horizon or an apparent horizon (Ashtekar and Krishnan 2004; Booth 2005) which are also foliation dependent. Recently it was shown that specific combinations of the scalar polynomial curvature invariants (SPIs) (see next sections for their definition) vanish on the horizon of a stationary black hole. This provides a local technique for the localization of the event horizon, and an extension of Paiva et al. (1993) allowing for the extraction of information about the mass, angular momentum and electric charge of a black hole (Abdelqader and Lake 2015; Page and Shoom 2015).\nIn this paper we will show that it is possible to locate the horizon of any stationary asymptotically flat (or (anti) de Sitter) black hole using Cartan invariants. While both the SPIs and Cartan invariants are foliation independent, the Cartan invariants have two important advantages over SPIs: they are linear in terms of the components of the curvature\nD. D. McNutt\nFaculty of Science and Technology, University of Stavanger, N-4036 Stavanger, Norway E-mail: david.d.mcnutt@uis.no\nM. A. H. MacCallum\nSchool of Mathematical Sciences, Queen Mary University of London, Mile End Road, London E1 4NS E-mail: m.a.h.maccallum@qmul.ac.uk\nD. Brooks \u00b7 P. C. Chavy-Waddy \u00b7 A. A. Coley \u00b7 A. Forget \u00b7 D. Gregoris\nDepartment of Mathematics and Statistics, Dalhousie University, Halifax, Nova Scotia, Canada B3H 3J5 E-mail: dario.a.brooks@dal.ca, pl859327@dal.ca, aac@mathstat.dal.ca, Adam.AL.Forget@dal.ca, danielegregoris@libero.it\narXiv:1709.03362v3 [gr-qc] 10 Jan 2020\n "}, {"chunk": "2 D. D. McNutt et al.\n tensor instead of quadratic or higher degree terms, and it is possible to construct from the Cartan invariants suitable invariants that vanish on the horizon and nowhere else, eliminating the problem of SPIs detecting surfaces outside of the horizon.\nUsing the Cartan-Karlhede algorithm (known as the Karlhede algorithm in 4D) (Collins et al. 1990; Collins and d\u2019Inverno 1993; McNutt et al. 2017) we briefly discuss the classification of metrics as a necessary step for the computation of the Cartan invariants. We apply our method to four-dimensional (4D) black hole solutions and the less studied five di- mensional (5D) black hole solutions (Polchinski 2005; Zwiebach 2009). Finally, we compute SPIs for the 4D and 5D examples using the results of Page and Shoom (2015), and in 4D we show how the Cartan invariants are related to the SPIs: thereby the rather complicated expressions used for the SPIs in previous work are shown to have simpler forms.\n2 Horizon Detection with Scalar Polynomial Curvature invariants\nIn this section we will review some basic properties of the SPIs that will be useful in the applications discussed in this paper. In 1869, Christoffel showed that any scalar function on a n-dimensional Riemannian (or pseudo-Riemannian) manifold (M,gab) constructed from the metric gab must be a function of Rabcd,Rabcd;e and higher order covariant derivatives (MacCallum 2015). Due to the nature of SPIs, they are one of the conceptually simplest of such scalar functions. The SPIs of a given spacetime metric, gab, are the set of functions generated by operations on (contractions of) the curvature tensors, and their covariant derivatives, such as\nRabRab, CabcdCabef Cefcd, Rab;cRab;c, Cabcd;eCabcd;e. (2.1) We denote by I = {R,RabRab,CabcdCabcd,...} the set of SPIs of M. Some basic examples, denoted by I1,...,I7\n(Abdelqader and Lake 2015; Page and Shoom 2015), are the following:\nI1 = CabcdCabcd, I2 = C\u2217abcdCabcd, I3 = Cabcd;eCabcd;e,\nI4 = C\u2217abcd;eCabcd;e, I5 = (I1);a(I1);a, I6 = (I2);a(I2);a, I7 = (I1);a(I2);a,\n(2.2)\nwhere Cabcd is the Weyl tensor and Ca\u2217bcd is its dual and a semicolon denotes covariant differentiation.\nWe stress that the maximum number of functionally independent and maximum algebraically independent SPIs are in general different, the former being at most n, while the latter is\nN (n, p) = (0\nn[(n+1)][(n+p)!] \u2212\n2n!p!\nif p = 0 or 1 (2.3) (n+p+1)! + n if p \u2265 2\n(n\u22121)!(p+1)!\n  where p denotes the order of differentiation of the metric tensor components.\nBlack hole horizon detection was remarked upon by Karlhede et al. (1982), where the invariant Rabcd;eRabcd;e was\nshown to detect horizons for several type D solutions. However in the case of the Kerr horizon, it detected the stationary limit, and not the outer horizon itself. This was first noted by Skea in his doctoral thesis (Skea 1986) where it was observed that Rabcd;eRabcd;e did not provide an adequate test for horizons. More recently Abdelqader and Lake (2015) examined a collection of invariants from which they determined physical properties of spacetimes around rotating black holes, including the detection of the horizons. These invariants are constructed from SPIs (note that being in vacuum we do not distinguish between Riemann and Weyl tensors):\n(I12 \u2212 I2)(I5 \u2212 I6) + 4I1I2I7 Q1 = \u221a 2 2 9\n, Q2 =\nI5I6 \u2212 I72 I5 + I6\n2 2 5 , Q3 = \u221a 2 2 5 , (2.4)\n27(I1 +I2)2 6 3(I1 +I2)4\n     3 3(I1 +I2)4\n   where I1 to I7 are given by (2.2). From the dimensionless invariants Q1, Q2 and Q3 one can read off the physical properties of the Kerr metric since they locate the horizon and ergosurface in an algebraic manner. With this information two approaches were provided to compute the angular momentum and mass of the black hole, one global and the other local. To determine the mass and angular momentum in the global approach, the area of the horizon and of the ergosurface must be calculated, requiring that these two surfaces must be located. The local method, which makes use of (2.2) alone, does not require knowledge of the location of the black hole or its event horizon. By knowing the forms of the invariants I1,...,I7 the mass and angular momentum can be expressed as functions in terms of these invariants. The derivation outlined by Abdelqader and Lake (2015) is not unique, and the authors noted that the presented approach was the simplest found through experimentation.\nThe relationship between (2.4) and (2.2) has been expanded by Page and Shoom (2015) in which the authors introduce a general approach to determine the location of the event horizon and ergosurface for the Kerr metric. More generally, this method will give the exact location of any horizon for a stationary black hole, although it is believed\n"}, {"chunk": "Cartan Invariants and Event Horizon Detection 3\n that it will be able to determine the approximate location for any nearly stationary horizon. This technique relies on the fact that the squared norm of the wedge product of n gradients of functionally independent local smooth curvature invariants will always vanish on the horizon of any stationary black hole, where n is the local cohomogeneity of the metric, which is defined as the codimension of the maximal dimensional orbits of the isometry group of the local metric. Their results can be summarized by the following theorem:\nTheorem 1. For a spacetime of local cohomogeneity n that contains a stationary horizon (a null hypersurface that is orthogonal to a Killing vector field that is null there and hence lies within the hypersurface and is its null generator) and which has n independent SPIs S(i) whose gradients are well-defined there, the n-form wedge product\nW = dS(1) \u2227 ... \u2227 dS(n)\n||W||2 = 1\u03b4\u03b11,...,\u03b1ng\u03b21\u03b31...g\u03b2n\u03b3n \u00d7S(1)...S(n)S(1)...S(n) =0,\nhas zero squared norm on the horizon,\nn! \u03b21,...,\u03b2n ;\u03b11 ;\u03b1n ;\u03b31 ;\u03b3n\nwhere the permutation tensor \u03b4\u03b11,...,\u03b1n is +1 or \u22121 if \u03b11, ..., \u03b1n is an even or odd permutation of \u03b21, ..., \u03b2n respectively, and\n \u03b21 ,...,\u03b2n\nIn general the set I is not sufficient to locally distinguish the manifold M as it is possible that two different metrics can have the same set I. In the particular case in which it is fully characterized by its SPIs the spacetime is said to be I-non-degenerate (Coley et al. 2009). If a spacetime metric is of Ricci type I, Weyl type I, or Riemann type I/G (relative to the alignment classification, which is reviewed in section 3.1), then the metric is I-non-degenerate. Moreover, in the case that the metric is not I-non-degenerate, then it is necessarily contained in the Kundt class or is locally homogeneous (Coley et al. 2009). We note that all of the black hole metrics considered in this paper are I-non-degenerate.\n3 The Cartan-Karlhede Method for Determining Local Equivalence of Spacetimes\nThe method for testing geometric equivalence due to E \u0301lie Cartan (Stephani et al. 2003) was developed with the aim of determining the equivalence of geometric objects under a diffeomorphism. The method we employ in our paper is a spe- cialized form applicable to sets of differential forms defined on differentiable manifolds under appropriate transformation groups. In Riemannian geometry, the formal statement of this problem is:\nLet (M, g) and (M \u0304 , g \u0304) be two m-dimensional Riemannian manifolds. We say that g and g \u0304 are equivalent as Riemannian metrics if\n\u03a6\u2217(g \u0304) = g,\nfor a locally-defined diffeomorphism \u03a6 : M \u2192 M \u0304 . When does such a diffeomorphism exist?\nTo relate two apparently different metrics, we look to the coordinate neighbourhoods defined on the manifold at each point and examine the frame bundle on the manifold. If the metrics on two neighbourhoods are equivalent, the frame bundles derived from them are (locally) identical. Now, the frame bundle on each manifold possesses uniquely-defined one-form fields {\u03c9a, \u0393ab} such that\n\u0393ab =\u0393abc\u03c9c, \u0393abc =\u27e8\u03c9a,\u2207ceb\u27e9,\nwhere {ea} is the corresponding basis of tangent vectors and {\u03c9a} the basis of one-forms. In local coordinates {x1, . . . , xm},\ne a = e ia \u2202 , \u03c9 a = \u03c9 ia d x i . \u2202xi\nThus, the basis one-form fields on the frame bundle (\u0393,\u03c9) defined on each frame bundle must also be identical for equivalent metrics. In the case of spacetimes, the Cartan structure equations imply:\nd \u03c9 a = \u2212 \u0393 ab \u2227 \u03c9 b , ( 3 . 1 ) d\u0393ab+\u0393ac\u2227\u0393cb=\u0398ab, \u0398ab=Rabcd\u03c9c\u2227\u03c9d. (3.2)\nHence the Cartan structure equations show that the above implies the components of the curvature on the frame bundle must also be equatable.\nHowever, the equability of (3.1) and (3.2) on the two neighbourhoods are necessary conditions, and not sufficient for the local identification of differentiable manifolds. Cartan showed that sufficient conditions are obtained by taking repeated exterior derivatives, starting with d\u0393ab, until no new functionally independent quantity arises; if at any step of differentiation no such quantity arises, the process terminates, as any further derivatives depend on the quantities\nis zero otherwise.\n "}, {"chunk": "4 D. D. McNutt et al.\n previously obtained. Consequently, the relations between dependent and independent invariants must be the same in coordinate neighbourhoods of points in both manifolds in order for them to be equivalent. The number of k functionally independent quantities obtained (called the rank) is at most the dimension m of the manifold, and so the process necessarily terminates in a finite number of steps; if it turns out that k < m this is due to the presence of symmetries.\nIn the case of spacetimes, the equation\ndRabcd = Rabcd;e\u03c9e + Rebcd\u0393 ea + Raecd\u0393 eb + Rabed\u0393 ec + Rabce\u0393 ed\nshows that repeated exterior differentiation is equivalent to repeatedly taking covariant derivatives of the Riemann tensor Rabcd. A metric can consequently be uniquely (locally) characterized by its Riemann tensor and a finite number of its covariant derivatives, regarded as functions on the frame bundle of the manifold. If we use Rq to denote the set {Rabcd,Rabcd;f ...,Rabcd;f1f2...fq } of the components of the Riemann tensor and its covariant derivatives up to the qth order, then if p is the last derivative at which a new functionally independent quantity arises (the order), we must compute Rp+1. If k is the number of functionally independent invariants on the frame bundle in a maximal set, we denote the invariants by I\u03b1, \u03b1 = 1,...,k.\nThe main idea of this method is to reduce the frame bundle to the smallest possible dimension at each step by casting the curvature and its covariant derivatives into a canonical form and only permitting those frame changes which preserve that canonical form. The frames we will employ in 4D are the so-called null tetrads, i.e. a set of four complex vectors {la,na,ma,m \u0304a} such that lala = nana = mama = m \u0304am \u0304a = 0 and lana = 1 = mam \u0304a and where a bar denotes complex conjugate. In terms of this complex null tetrad the metric is\nd s 2 = \u2212 2 l ( a n b ) + 2 m ( a m \u0304 b ) , ( 3 . 3 )\nwhere round parentheses denote symmetrization.\nSince there are many solutions to Einstein\u2019s equations describing vacuum spacetimes and few which admit confor-\nmally flat geometries, we usually begin by putting the Weyl tensor into the appropriate normal form (See Stephani et al. (2003) section 4.2, table 4.2.), and then using any residual frame freedom to put the Ricci tensor Rab = Rcacb into canon- ical form, if possible. The curvature components in this tetrad are the first set of invariants required. We then calculate the first (covariant) derivatives of the curvature and use them to further fix the tetrad, if necessary. This is repeated for higher derivatives until the stopping conditions are met for the algorithm, which will be discussed below.\nThe Cartan-Karlhede algorithm that we will use in the next section is (MacCallum 1986):\n1. Set the order of differentiation q to 0.\n2. Calculate the derivatives of the Riemann tensor up to the qth order.\n3. Find the canonical form of the Riemann tensor and its covariant derivatives.\n4. Fix the frame as much as possible using this canonical form, and note the residual frame freedom (the group of\nallowed transformations is the linear isotropy group Hq). The dimension of Hq is the dimension of the remaining\nvertical freedom of the frame bundle.\n5. Find the number tq of independent functions of space-time position in the components of the Riemann tensor and\nits covariant derivatives, in the canonical form. This tells us the remaining horizontal freedom.\n6. If the isotropy group and number of independent functions are the same as in the previous step, let p + 1 = q, and\nthe algorithm terminates; if they differ (or if q = 0), increase q by 1 and go to step 2.\nThe nonzero components of Rabcd and its covariant derivatives are referred to as Cartan invariants: a statement of\nthe minimal set required, taking Bianchi and Ricci identities into account, was given by MacCallum and  \u030aAman (1986). We will refer to the invariants constructed from, or equal to, Cartan invariants of any order as extended invariants. Thus for sufficiently smooth metrics, a result of the test of equivalence gives sets of scalars providing a unique local geometric characterization, as the D-dimensional space-time is then characterized by the canonical form used, the two discrete sequences arising from the successive isotropy groups and the independent function counts, and the values of the (nonzero) Cartan invariants. As there are tp essential space-time coordinates, the remaining D \u2212 tp are ignorable, and so the dimension of the isotropy group of the space-time will be s = dim(Hp), and the isometry group has dimension r = s + D \u2212 tp.\nTheorem 1 can be readily generalized to the set of Cartan invariants arising from the Cartan-Karlhede algorithm:\nTheorem 2. For a spacetime of local cohomogeneity n that contains a stationary horizon and which has n independent Cartan invariants C(i) whose gradients are well-defined there, the n-form wedge product\nW = dC(1) \u2227 ... \u2227 dC(n)\n||W||2 = 1\u03b4\u03b11,...,\u03b1ng\u03b21\u03b31...g\u03b2n\u03b3n \u00d7C(1)...C(n)C(1)...C(n) =0,\nhas zero squared norm on the horizon,\nn! \u03b21,...,\u03b2n ;\u03b11 ;\u03b1n ;\u03b31 ;\u03b3n\n where the permutation tensor \u03b4\u03b11,...,\u03b1n is +1 or \u22121 if \u03b11, ..., \u03b1n is an even or odd permutation of \u03b21, ..., \u03b2n respectively, and\nis zero otherwise.\n\u03b21 ,...,\u03b2n\n"}, {"chunk": "Cartan Invariants and Event Horizon Detection 5\n Proof. The number of functionally independent invariants at the end of the algorithm, tp, is directly related to the dimension of the local cohomogeneity. To see this, we note that the dimension of the isometry group is given by r = D \u2212 tp + dim(Hp) where Hp is the dimension of the isotropy group of the curvature tensor and all its covariant derivatives. However, the maximal dimensional orbits of the isometry group will be given by r \u2212 dim(Hp) = D \u2212 tp, since this is the quotient of the Lie group of Killing vectors by the isotropy group, and therefore n = D \u2212 r + dim(Hp) = tp. Using n functionally independent Cartan invariants, the proof carries forward in a similar manner to the proof of theorem 1 in Page and Shoom (2015).\nAlternatively, we can use the first order Cartan invariants (those arising from the covariant derivative of the Riemann tensor) to produce new invariants that detect the stationary horizons. These invariants will be much simpler than the SPIs.\n3.1 The Cartan-Karlhede Algorithm in Five Dimensions\nWe would like to apply the Cartan-Karlhede algorithm to determine a set of Cartan invariants which detect the stationary horizon for the 5D black hole metrics. This can be achieved in arbitrary dimension by examining the qth covariant derivative of the Weyl and Ricci tensor at iteration, q, and using the frame transformations to transform the qth covariant derivative of the Weyl tensor and Ricci tensor into some canonical form, if possible.\nIn 5D, relative to the half-null frame with nala = 1, nana = lala = 0 and m(i)m(j) = \u03b4ij in terms of which the ab\nmetric can be written as g = 2l n + \u03b4jm(i)m(j), the local Lorentz transformations are generated by combining the ab (a b) i a b\n    following frame transformations (Coley et al. 2004; Milson et al. 2005): 1. Null rotations about l:\n 2. Null rotations about n:\n3. Spins:\n4. Boost:\n\u02c6l=l, n\u02c6=n+zimi\u22121zizil, m\u02c6i=mi\u2212zil 2\n\u02c6l=l+yimi\u22121yiyin, n\u02c6=n, m\u02c6i=mi\u2212yin 2\n\u02c6l=l, n\u02c6=n, m\u02c6i=Xijmj \u02c6l=\u03bbl, n\u02c6=\u03bb\u22121n, m\u02c6i=mi,\n(3.4a)\n(3.4b)\n(3.4c)\n(3.4d)\n where Xij denotes the usual rotation matrices for rotations about the axes m2, m3, m4 respectively. We stress that the quantities zi = zi(xa), \u03b8 = \u03b8(xa) and \u03bb = \u03bb(xa) depend on the coordinates. We also note that the Lorentz transformations in 5D have 10 parameters.\nFor dimension D > 4, we no longer have the usual spinor approach to simplify calculations, and the 4D algebraic classifications of the Weyl and Ricci tensors are no longer applicable. Instead, we consider the boost weight decomposition (Coley and Hervik 2010; Ortaggio et al. 2011; Coley et al. 2012) to classify the curvature tensor. Relative to the basis {\u03b8a} = {n, l, mi}, the components of an arbitrary tensor of rank p transform under the boost (3.4d) by:\np\nT\u2032 =\u03bbba1a2...apTa a ...a , ba a ...a =X(\u03b4 \u2212\u03b4 ) (3.5)\na1a2...ap 12 p 12 p ai0 ai1 i=1\nwhere \u03b4ab denotes the Kronecker delta symbol. This quantity is called the boost weight (b.w) of the frame component Ta1 a2 ...ap . This approach, called the alignment classification, relies on the fact that the frame basis written as a null basis transforms in a simple manner under a boost given by (3.4d) and that this identifies null directions relative to which the Weyl tensor has components of a particular b.w. configuration, called Weyl aligned null directions (WANDs). Typically, we must use null rotations to identify the WANDs for a given tensor.\nWe define the boost order of Ta1a2...ap as the maximal b.w. of its non-vanishing components relative to the frame. As this integer is invariant under the group of Lorentz transformations that fix the null direction [l], it is a function of [l] only, and will be denoted by bT ([l]). We introduce another integer, BT = maxl bT ([l]), which is entirely dependent on the form of the tensor. For a generic l the Weyl and Ricci tensors have boost order bR([l]) = bC([l]) = 2, and so BR = BC = 2. If a null direction [l] exists for which bT ([l]) \u2264 BT \u22121, it is said to be a T aligned null direction of alignment\n"}, {"chunk": "6 D. D. McNutt et al.\n order: BT \u2212 1 \u2212 bT ([l]). As an example, for a WAND, the alignment order can be 0, 1, 2, 3. The alignment order can be related to another integer invariant,\n\u03b6 \u2261 min bC ([l]), l\nwhich is a pointwise invariant of the spacetime defining the (Weyl) primary or principal alignment type 2 \u2212 \u03b6 at p. If \u03b6 = 2, 1, 0, 1 or \u22122 this type is denoted by G, I, II, III or N respectively. If there is more than one WAND in the type II case, then this is denoted as D. This classification can also be applied to the Ricci tensor since BC = BR = 2.\nThis classification reproduces the Petrov and Segre classifications in 4D, and also leads to a coarse classification in higher dimensions; for example, an algebraic classification of all higher dimensional Kundt metrics (Podolsky \u0301 and Svarc 2013). In 5D this classification can be made finer by considering the spin group which is isomorphic to O(3) and acts on the null frame according to (3.4). The details of this approach are expanded upon in Coley et al. (2012). There is a fundamental difficulty with applying the alignment classification, as it relies on solving degree four multivariate polynomials, with more than two variables, to determine the WANDs. The exact solutions to such polynomial equations are difficult to compute and hence the ability to determine the WANDs in dimension higher than four is not always feasible in practice. Assuming a theory of approximate equivalence could be developed, numerical root solving could be implemented to resolve this issue.\n4 Applications in 4D\nIn this section we apply the Cartan equivalence method for the classification of 4D solutions of the Einstein equations describing stationary, asymptotically flat (or (anti) de Sitter) black holes to compute Cartan invariants that are capable of identifying the horizons which correspond to the positive b.w. components of the covariant derivatives of the Weyl and Ricci tensor; this follows in 4D from the fact that a Killing horizon is a special case of a weakly isolated horizon (Coley et al. 2017; Coley and McNutt 2017a). We will then relate these Cartan invariants to the SPIs using the Newman- Penrose (NP) formalism. Due to the relationship between the SPIs I1 and I2 and the Cartan invariant \u03a82 each of the SPIs generated by Theorem 1 may be considered as extended Cartan invariants produced by Theorem 2.\nWe note that some of the examples we consider here will be contained as special cases in others. For example, the Kerr solution is a special case of the Kerr-NUT-(Anti)-de Sitter solution and the Kerr-Newman solution, and similarly the Reissner-Nordstr \u0308om solution is contained in the Kerr-Newman solution. Our intention in giving these as separate cases is to provide examples in different coordinate systems and illustrate the structure of the Cartan invariants.\n4.1 Kerr metric\nThe 4D Kerr metric in Boyer-Lindquist coordinates is given by the line element\n2 Q \u2212 a2 sin2 \u03b8 2 2a sin2 \u03b8(r2 + a2 \u2212 Q) ((r2 + a2)2 \u2212 Qa2 sin2 \u03b8) sin2 \u03b8 ds = \u2212 R2 dt \u2212 R2 dtd\u03c6 + R2\nQ(r)=r2+a2\u22122Mr, R(r,\u03b8)=pr2+a2cos2\u03b8. To start the Cartan-Karlhede algorithm, we employ the following null coframe:\n2 R2 2 2 2 d\u03c6 + Q dr + R d\u03b8 ,\n(4.1)\n(4.2)\n(4.3) (4.4) (4.5)\n\u0013dt\u2212\u0012\nTo calculate the Riemann tensor at zeroth order we will use the NP formalism. We find the only non-vanishing curvature\nscalar at zeroth order to be:\n\u03a82 = iM . (4.7) (a cos \u03b8 + ir)3\nAny null rotation will ruin the form of the Riemann tensor, while spins and boosts do not effect \u03a82, and thus leave the Weyl tensor invariant. The dimension of the isotropy group has been reduced from six to two at zeroth order. From \u03a82,\n     l = dt + \u0012 R2 \u0013 dr + a sin2 \u03b8d\u03c6, Q\nn=\u0012 Q \u0013dt\u22121dr+\u0012asin2\u03b8Q\u0013d\u03c6,\n2R2 2 2R2\n\u0013d\u03b8+\u0012i\u221a2(a2 +r2)sin\u03b8\u0013d\u03c6, 2 (r + ia cos \u03b8)\n    m = \u0012\u2212 i\u221a2asin\u03b8\n2 (r + ia cos \u03b8)\n\u0013dt+\u0012\n\u221a2R2\n2 (r + ia cos \u03b8)\n\u0013d\u03b8+\u0012i\u221a2(a2 +r2)sin\u03b8\u0013d\u03c6. 2 (ia cos \u03b8 \u2212 r)\n      m = \u0012\u2212 i\u221a2asin\u03b8\n2 (ia cos \u03b8 \u2212 r)\n\u221a2R2\n2 (ia cos \u03b8 \u2212 r)\n(4.6)\n        "}, {"chunk": "Cartan Invariants and Event Horizon Detection 7\n \u0010 \u00111\nwe obtain an even simpler invariant C0 = i 1 3 ; the real and imaginary parts define two functionally independent\n  \u03a82\nzeroth order invariants:\nThe zeroth iteration of the Cartan-Karlhede algorithm concludes with dim(H0) = 2, t0 = 2.\nTo begin the first iteration of the Cartan-Karlhede algorithm, we compute the first covariant derivative of the Weyl tensor (or the Weyl spinor here, as we have chosen to work with the spinor formalism (Stephani et al. 2003)). From the\nsymmetrized first covariant derivative of the Weyl spinor has the following components:\n\u2207\u03a820\u2032 =3(D\u03a82+2\u03c1\u03a82)/5, \u2207\u03a821\u2032 =3(\u03b4\u03a82+2\u03c4\u03a82)/5, \u2207\u03a830\u2032 =3(\u03b4 \u0304\u03a82\u22122\u03c0\u03a82)/5, \u2207\u03a831\u2032 =3(\u2206\u03a82\u22122\u03bc\u03a82)/5. (4.9)\nSince we have that \u03c1, \u03bc, \u03c4, and \u03c0 are all non-vanishing, the Kerr metric belongs to the family of type D vacuum spacetimes in the third case identified by Collins et al. (1990); we thus may fix the boost and spin to some desired value. We employ the canonical choice for such a Petrov type D metric, \u2207\u03a831\u2032 = \u2212\u2207\u03a820\u2032 , implying that \u03c1 = \u03bc and additionally impose that \u03c4 = \u03c0 using the remaining spin:\n\u03c1=\u03bc=\u221a i\u221aQ , (4.10) 2R(ir+a cos \u03b8)\n\u2212ia sin \u03b8 . (4.11) 2R(ir+a cos \u03b8)\nNo new functionally independent invariants have been introduced at this iteration. The first iteration of the Cartan- Karlhede algorithm therefore concludes with dim(H1) = 0 and t1 = 2. Although t0 = t1 = 2, we have that 2 = dim(H0) \u0338= dim(H1) = 0 and so we must continue the algorithm.\nThe second iteration of the Cartan-Karlhede algorithm begins by computing the second covariant derivative of the Weyl spinor. While this can be computed in compact form using the GHP formalism and the formulae (4.3a\u2032)\u2212(4.3i\u2032) of (Collins et al. 1990), we will omit the details. No functionally independent invariants appear from the second covariant derivative. Thus, t1 = t2 = 2 and dim(H1) = dim(H2) = 0; the Cartan-Karlhede algorithm terminates after the second iteration, in agreement with  \u030aAman (1984). In the subsequent examples, we will omit details of the final iteration of the Cartan-Karlhede algorithm for brevity.\nUsing the Cartan invariants we can construct scalar invariants that can be used to detect both the horizon and the ergosurface. For vacuum Petrov type D metrics the Bianchi identities give\nRe(C)=acos\u03b8, Im(C0)= r . 011\n(4.8)\n  M3 M3\n     \u03c4=\u03c0=\u221a\n  D\u03a82 = 3\u03c1\u03a82, \u2206\u03a82 = \u22123\u03bc\u03a82, \u03b4\u03a82 = 3\u03c4\u03a82, \u03b4 \u0304\u03a82 = \u22123\u03c0\u03a82.\nApplying the Bianchi identities to (4.9), the extended Cartan invariant\n\u2207\u03a820\u2032 \u221d \u03c1, \u03a82\n(4.12)\n(4.13)\n will vanish on the horizon, and nowhere else due to its coordinate expression (4.10). This invariant is relevant due to its geometric meaning as noted by MacCallum (2006), but it is not unique, since one could use another combination of Cartan invariants up to first order. Noting that Q1 detects the ergosurface, we would like a corresponding Cartan invariant that will do so. Consider the following extended Cartan invariant:\n\u03c12\u2212\u03c42= \u2212(Q\u2212a2sin2\u03b8), (4.14) 2R2(ir + a cos \u03b8)2\ncomparing with the gtt component of (4.1) shows that this will detect the ergosurface.\nIt is important to stress that this approach requires a particular invariantly defined choice of coframe, and that \u03c1\nand \u03c12 \u2212 \u03c42 can be regarded as invariants only in the form they take relative to the canonical frame. However, it is possible to implement Theorem 2 to generate an extended Cartan invariant that detects the event horizon and make the choice of frame irrelevant. Working with \u03a82 and its complex conjugate we find the following invariant:\n| | d \u03a8 2 \u2227 d \u03a8 \u0304 2 | | 2 = \u2212 3 4 2 3 Q 2 a 2 M 4 s i n 2 \u03b8 . ( 4 . 1 5 ) R20\n  "}, {"chunk": "8 D. D. McNutt et al.\n 4.2 Reissner-Nordstr \u0308om-(Anti)-de Sitter metric\nIn this section we consider the Cartan invariants arising from the Cartan-Karlhede algorithm for the 4D Reissner- Nordstr \u0308om-(Anti)-de Sitter metric describing a static but electrically charged black hole in presence of a cosmological constant (Stephani et al. 2003). In the system of coordinates (t, r, \u03b8, \u03c6) the metric is\n2 2dr22222\nds =\u2212f(r)dt + f(r) +r (d\u03b8 +sin \u03b8d\u03c6 ) (4.16)\n\u0010 2M q2 \u039br2\u0011\nwhere f(r) = 1 \u2212 r + r2 \u2212 3 , and M and q denote respectively the mass and the electric charge of the black hole\nand \u039b the cosmological constant.\nTo begin the Cartan-Karlhede algorithm for the Reissner-Nordstr \u0308om-(anti)-de Sitter metric, we introduce the or-\n    thonormal frame:\n1 r2Mq2\u039br2 1 1 e0=q \u2202t, e1= 1\u2212 + 2\u2212 \u2202r, e3= \u2202\u03b8, e4= \u2202\u03c6,\n(4.17)\n(4.18)\n(4.19)\n(4.20)\n(4.21) (4.22)\n       1\u22122M+q2 \u2212\u039br2 r r 3 r rsin\u03b8 r r2 3\n    in terms of which we construct the null tetrad: 1111\nl=\u221a2(e1+e2), n=\u221a2(e1\u2212e2), m=\u221a2(e3+ie4), m \u0304=\u221a2(e3\u2212ie4). The nonzero curvature scalars are\n        q2 q2 \u2212Mr \u039b \u03a611 = 2r4, \u03a82 = r4 , \u039bNP = 6,\nwhere R is the Ricci scalar.\nCalculating the first covariant derivative of the Weyl and Ricci spinors are given by (4.9) and\n   where\n\u2207\u03a611\u2032 =4(D\u03a611+(\u03c1+\u03c1 \u0304)\u03a611)/9, \u2207\u03a612\u2032 =4(\u03b4\u03a611+(\u03c4\u2212\u03c0 \u0304)\u03a611)/9, \u2207\u03a622\u2032 = 4(\u2206\u03a611 \u2212 (\u03bc + \u03bc \u0304)\u03a611)/9,\n2 1\u00102Mq2 \u039br2\u00111\n \u03c1=\u03bc=\u2212\u221a2r 1\u2212 r +r2 \u2212 3 ,\n     \u03c4 = \u03c0 = 0.\nAt first order we still have one functionally independent component and the boost is no longer in the isotropy group;\nthus t1 = 1 and dim(H1)=1. The nonzero components are expressed in terms of the frame derivatives of \u03a82, the nonzero Ricci spinor components, and the spin-coefficients \u03bc, \u03c1, \u03c0 and \u03c4 . As the Cartan-Karlhede algorithm stops at second order ( \u030aAman 1984), we can now refer to these quantities as Cartan invariants.\nFor Petrov type D metrics in which \u03a611 is the only nonzero matter term, the Bianchi identities give\nD\u03a82 = 3\u03c1\u03a82 + 2\u03c1\u03a611, \u2206\u03a82 = \u22123\u03bc\u03a82 \u2212 2\u03bc\u03a611,\n\u03b4\u03a82 = 3\u03c4 \u03a82 \u2212 2\u03c4 \u03a611, \u03b4 \u0304\u03a82 = \u22123\u03c0\u03a82 + 2\u03c0\u03a611,\nD\u03a611 = 2(\u03c1 + \u03c1 \u0304)\u03a611, \u03b4\u03a611 = 2(\u03c4 \u2212 \u03c0 \u0304)\u03a611, \u2206\u03a611 = \u22122(\u03bc + \u03bc \u0304)\u03a611.\nApplying the Bianchi identities to (4.9), we find that the extended Cartan invariant\n\u2207\u03a820\u2032 \u221d \u03c1, \u03a82\n(4.23)\n(4.24)\n will vanish on the horizon, and nowhere else, due to (4.10).\nPreviously it was noted that I3 = Rabcd;eRabcd;e detects the horizon for the Reissner-Nordstr \u0308om solution (Karlhede et al.\n1982), which can be seen by direct calculation:\nI3 = Rabcd;eRabcd;e = \u221216(15M2r2 \u2212 36Mq2r + 22q4)f(r). (4.25)\nr10\nAlternatively, we can apply Theorem 2 to generate an extended Cartan invariant that will detect the horizon. As the\ncohomogeneity of this solution is n = 1, we may consider the norm of the exterior derivative of \u03a82:\n||d\u03a82||2 = (3Mr \u2212 4q2)2f(r). (4.26) r10\n  "}, {"chunk": "Cartan Invariants and Event Horizon Detection 9\n 4.3 Kerr-Newman metric\nIt is worthwhile to ask if the invariants Q1,Q2 and Q3 from (2.4) detect the event horizon and ergosurface for more general type D metrics, as for a non-vacuum solution. To check this we consider the Kerr-Newman solution given by the line element:\n2 Q 2 2 R2 2 2 2 (r2+a2)2sin2(\u03b8)\u0010 a \u00112\nds = R2(dt\u2212asin (\u03b8)d\u03c6) \u2212 Q dr \u2212R d\u03b8 \u2212 R2 d\u03c6\u2212 r2 +a2dt (4.27)\nwhere \u039b denotes the cosmological constant and q denotes the electric charge, and the functions Q and R are:\nQ=r2 \u22122Mr+q2 +a2, R=pr2 +a2cos2(\u03b8). (4.28)\nThe location of event horizons may be calculated from the zeros of Q. In the limit q \u2192 0 we recover the line element for the Kerr metric.\nThe expressions for the invariants Q1,Q2 and Q3 are considerably larger and we will show in section 5 that Q1 no longer detects the ergosurface for the Kerr Newman solution. While it is still possible to apply Theorem 1 from Page and Shoom (2015) to generate a SPI that will detect the horizon, relative to the coordinates, the calculation of this invariant will be lengthy.\nWe would like to see if a simpler invariant can be built out of first order Cartan invariants. We begin the Cartan- Karlhede algorithm by computing the Weyl and Ricci spinors using the NP formalism. We define our orthonormal coframe:\n     \u221aQ \u221aQa sin(\u03b8) R (x2+a2) sin(\u03b8)\na sin(\u03b8) R\n  Qdr, e2 =Rd\u03b8, e3 = R d\u03c6\u2212 e0=Rdt\u2212 R d\u03c6,e1=\u221a\ndt,\n(4.29)\n(4.30)\n(4.31)\n(4.32)\n      in terms of which the full tetrad reads: 1111\nl= \u221a2(e0 \u2212e1), n= \u221a2(e0 +e1), m= \u221a2(e2 +ie3), m= \u221a2(e2 \u2212ie3). The nonzero curvature scalars are:\n         q2 i \u0000Ma cos \u03b8 \u2212 iMr + iq2\u0001 \u03a611=2(r2+a2cos2\u03b8)2, \u03a82=(acos\u03b8\u2212ir)(acos\u03b8+ir)3.\n  Using \u03a611 and (the magnitude of) \u03a82, we construct the functionally independent invariants: M2a2 cos2 \u03b8 + M2r2 \u2212 2Mrq2 + q4 r2 + a2 cos2 \u03b8\nC0= q4 , C1= q .\n  Thus, t0 = 2. In addition, null rotations alter the form of \u03a82 and \u03a611, while boosts and spins leave both unchanged. We have therefore reduced the isotropy group from six dimensions to two at zeroth order, i.e. dim(H0) = 2.\nWe can now proceed to the first iteration of the Cartan-Karlhede algorithm, by calculating the first covariant derivative of the Weyl and Ricci spinors (Collins et al. 1990; Collins and d\u2019Inverno 1993), these are given by (4.9) and (4.20) where we may apply a boost and spin to set:\n\u03c1=\u03bc=\u221a \u2212i\u221aQ , 2R(ir+a cos \u03b8)\n\u2212ia sin \u03b8 . 2R(ir+a cos \u03b8)\n(4.33) (4.34)\n   \u03c4=\u03c0=\u221a\n  No new functionally independent Cartan invariants appear at first order. The remaining isotropy freedom is used up at first order by fixing both boosts and spins to be identity. It is known already ( \u030aAman 1984) that the Cartan-Karlhede algorithm concludes at the second iteration, since no new functionally independent invariants appear; t1 = t2 = 2 and dim (H1) = dim (H2) = 0.\nAs an aside, we use components of the Weyl spinor and its first covariant derivative to construct the Cartan invariants that will detect the horizon and ergosurface. Applying the Bianchi identities (4.23) to (4.9), the same extended Cartan invariant,\n\u2207\u03a820\u2032 \u221d \u03c1, (4.35) \u03a82\nwill vanish on the horizon, and nowhere else due to (4.10). Unlike Q1 the extended Cartan invariant that detects the ergosurface is applicable to the Kerr-Newman solution since\n "}, {"chunk": "10 D. D. McNutt et al.\n \u03c12\u2212\u03c42 = \u2212(Q\u2212a2sin2\u03b8) (4.36) 2R2(ir + a cos \u03b8)2\nand comparing with the gtt component of (4.27) shows that this will detect the ergosurface.\nAs an alternative, we apply Theorem 2 using the zeroth order Cartan invariants \u03a82 and \u03a8 \u03042, which gives the following\n extended Cartan invariant that will detect the horizon:\n \u0304 2 \u2212a2Q sin2(\u03b8)(9M2 cos2(\u03b8)a2 + 9r2M2 \u2212 18rMq2 + 8q4)2\nW = ||d\u03a82 \u2227 d\u03a82|| = 2(r2 + a2 cos2(\u03b8))12 . (4.37) 4.4 Kerr-NUT-(Anti)-de Sitter metric\n The 4D Kerr-NUT-AdS metric is given by the line element (Pleban \u0301ski and Demian \u0301ski 1976; Stephani et al. 2003; Griffiths and Podolsky \u0301 2007)\nds2 =\u0012P\u2212Q\u0013dt2+\u0012Qp2+Pq2\u0013(dt\u2297dr+dr\u2297dt) p2 + q2 p2 + q2\n+ \u0012Pq4 \u2212Qp4\u0013dr2 +\u0012p2 +q2\u0013dp2 +\u0012p2 +q2\u0013dq2, (4.38) p2 + q2 P Q\nwhere P \u2261 P (p) and Q \u2261 Q(q) are fourth-degree polynomials in p and q, containing the parameters a, l, m and \u039b:\nP = (a2 \u2212(p\u2212l)2)\u00121+ 1(p\u2212l)(p+3l)\u039b\u0013, (4.39)\n3\nQ = a2 \u2212 l2 \u2212 2mq + q2 \u2212 1 h3l2(a2 \u2212 l2) + (a2 + 6l2)q2 + q4i \u039b. (4.40) 3\nWe note that we have chosen a0 = 1 (Griffiths and Podolsky \u0301 2007), but there are other choices for the coefficients that will provide simpler expressions for P and Q. The locations of the event horizon for this solution are denoted by the roots of Q(q). To see if the invariants Q1, Q2 and Q3 detect the horizons, one could pick particular values for a, l, m, and \u039b to determine the roots of Q and test to see if the invariants share these roots. The expressions for the Q invariants are very large polynomials in p and q, and it is not clear that they can be factorized into irreducible polynomials. Cartan invariants consequently allow for the construction of simpler candidates for detection of the horizon.\n       We define our null frame:\n\u221a2r Q \u221a22r Q \u221a2rp2+q2 l= 2 p2+q2dt\u2212 2 p p2+q2dr\u2212 2 Q dq,\n\u221a2r Q \u221a22r Q \u221a2rp2+q2 n= 2 p2+q2dt\u2212 2 p p2+q2dr+ 2 Q dq,\n\u221a2r P \u221a22r P i\u221a2rp2+q2 m= 2 p2+q2dt+ 2q p2+q2dr\u2212 2 P dp,\n\u221a2r P \u221a22r P i\u221a2rp2+q2 m= 2 p2+q2dt+ 2q p2+q2dr+ 2 P dp.\n(4.41) (4.42) (4.43) (4.44)\n(4.45)\n                                                 The only nonzero NP curvature scalars are \u039b and\n\u03a82 = 1\u039ba2l\u22124\u039bl3 +3im+3l.\n3 (p + iq)3\n  At zeroth order of the Cartan-Karlhede algorithm, we obtain as our Cartan invariants the real and imaginary parts of \u03a82, which are functionally independent, and so t0 = 2. The zeroth order isotropy group consists of boost and spins, and so dim (H0) = 2. At the first iteration of the algorithm the components of the covariant derivative of the Weyl spinor are (4.9). Relative to this coordinate system we have\n\u221aQ(iq\u2212p) \u03c1=\u03bc=\u2212\u221a 2 23,\n2(p +q )2\n\u221aP (iq\u2212p) \u03c4=\u03c0=\u2212\u221a 3.\n2(p2+q2)2\n(4.46) (4.47)\n        "}, {"chunk": "Cartan Invariants and Event Horizon Detection 11\n and so the boosts and spins have already been fixed to the canonical form, implying dim (H1) = 0. No new functionally independent invariants appear at first order, so that t1 = 2. It is known already ( \u030aAman 1984) that the Cartan-Karlhede algorithm concludes at the second iteration, since no new functionally independent invariants appear t1 = t2 = 2 and dim (H1) = dim (H2) = 0.\nWe would like to compute an extended Cartan invariant that detects the event horizon. As before applying the Bianchi identities to (4.9) gives the usual extended Cartan invariant\n\u2207\u03a820\u2032 \u221d \u03c1. (4.48) \u03a82\nComputing the roots of Q(q) for arbitrary a,l,m and \u039b is not a pleasant task. However, for this extended Cartan invariant we do not need to compute them, as it is clear that the zeros of \u03c1 are exactly the zeros of Q(q). As in the Kerr case, the following extended Cartan invariant\n2 2 (Q \u2212 P )(iq \u2212 p)2\n\u03c1 \u2212\u03c4 = 2(p2+q2)3 , (4.49)\nwill detect the ergosurface.\nOf course, it is possible to implement Theorem (2) to generate an extended Cartan invariant that detects the event\nhorizon, and make the choice of frame irrelevant. Working with the real and imaginary of \u03a82 we find the following invariant:\n   \u0304 2 34QP|\u03a82|2 |d\u03a82 \u2227 d\u03a82| = \u2212 2(q2 + p2)4 .\nThisinvariantdetectsthehorizons;however,italsovanishesatp=l\u00b1aandp=\u2212\u2212\u039bl\u00b1\u221a4\u039b2l2\u22123\u039b aswell. \u039b\n5 Scalar Polynomial Invariants in Terms of Cartan Invariants in 4D\n(4.50)\n   For the stationary, asymptotically flat (or (anti) de Sitter) 4D black holes we have considered, the SPIs, I1, ..., I7 from (2.2) may be expressed in terms of the zeroth order Cartan invariants:\n\u03a8 2 , \u03a8 \u0304 2 , \u03a6 1 1 , and the nonzero first order extended Cartan invariants:\nD\u03a82, \u2206\u03a82, \u03b4\u03a82, \u03b4 \u0304\u03a82,D\u03a611, \u2206\u03a611, \u03b4\u03a611, \u03b4 \u0304\u03a611, \u03c1, \u03c0, \u03c4, \u03bc.\nThis follows by computing the SPIs relative to the coframe determined by the Cartan-Karlhede algorithm. To relate\nthe SPIs to the Cartan invariants we first note that (Abdelqader and Lake 2015) I1 + iI2 = 48\u03a822.\nSince \u03a82 is therefore expressible in terms of SPIs, its gradient \u2207\u03a82 (which for scalars is the same as a covariant derivative) can also be used to form SPIs. From the definitions (2.2), it is immediately obvious that I5, I6 and I7 can be expressed using \u03a82 and \u2207\u03a82 and their complex conjugates, and the same follows for I3 and I4 using Page and Shoom\u2019s equation (9). Writing \u2207A.\u2207B for A,\u03bcB,\u03bc, we find that\n(96\u03a82)2(\u2207\u03a82.\u2207\u03a82) = 12 \u00b7 48(\u03a82)2(I3 + iI4)/5, so I3 and I4 are the real and imaginary parts of 160(\u2207\u03a82.\u2207\u03a82). We also find\nI5 = (96)2[(\u03a82)2(\u2207\u03a82.\u2207\u03a82) + cc + 2\u03a82\u03a8 \u03042(\u2207\u03a82.\u2207\u03a8 \u03042)]/4, I6 = (96)2[\u2212(\u03a82)2(\u2207\u03a82.\u2207\u03a82) \u2212 cc + 2\u03a82\u03a8 \u03042(\u2207\u03a82.\u2207\u03a8 \u03042)]/4, I7 = (96)2[(\u03a82)2(\u2207\u03a82.\u2207\u03a82) \u2212 cc]/4,\n(5.1)\n(5.2) (5.3) (5.4)\nwhere cc means the complex conjugate of the preceding expression. Using the Bianchi identities, these expressions may be simplified\n"}, {"chunk": "12\nD. D. McNutt et al.\n We can now easily compute the Qi which are\nQ1 = 2R[(\u03a8 \u03042(\u2207\u03a82.\u2207\u03a82)], 9 ( \u03a8 2 \u03a8 \u0304 2 ) 5 / 2\n\u22122||\u2207\u03a8 \u03042 \u2227 \u2207\u03a82||2 Q2 = 182(\u03a82\u03a8 \u03042)3 ,\nQ3= \u2207\u03a82.\u2207\u03a8 \u03042 , 1 8 ( \u03a8 2 \u03a8 \u0304 2 ) 3 / 2\n(5.5) (5.6) (5.7)\n   where R denotes the real part. We note that while the original formula (2.4) for Q2 is more complicated, it is in fact a dimensionless version of our proposed invariant W = ||d\u03a82 \u2227 d\u03a8 \u03042||2.\n\u2013 Kerr-NUT-(Anti)-de Sitter Metric\nFor the Kerr-NUT-(Anti)-de Sitter metric we have, using (4.12) and evaluating in the canonical frame: \u2207\u03a82.\u2207\u03a82 = 18\u03a822(\u03c12 \u2212 \u03c42),\n\u2207\u03a82.\u2207\u03a8 \u03042 = 18\u03a82\u03a8 \u03042(|\u03c1|2 + |\u03c4|2). Therefore, the invariants Q1,Q2 and Q3 take the form:\n(5.8) (5.9)\n(5.10) (5.11) (5.12)\n(5.13) (5.14)\n(5.15)\n(5.16)\n(5.17)\nQ1 = (\u03c12 \u2212\u03c42)+cc, ( \u03a8 2 \u03a8 \u0304 2 ) 1 / 2\n2 ( \u03c1 \u03c4 \u0304 + \u03c1 \u0304 \u03c4 ) 2 Q2 = |\u03a82|2 ,\nQ3 = (|\u03c1|2 +|\u03c4|2). |\u03a82 |\n   \u2013 Kerr-Newman Metric\nFor Kerr-Newman, using (4.23) and evaluating in the canonical frame we find: \u2207\u03a82.\u2207\u03a82 = 8(\u03c12 \u2212 \u03c42)\u03a6211 + 24(\u03c42 + \u03c12)\u03a82\u03a611 + 18\u03a822(\u03c12 \u2212 \u03c42),\n\u2207\u03a82.\u2207\u03a8 \u03042 = 8(|\u03c1|2 + |\u03c4|2)\u03a6211 + (12(|\u03c1|2 \u2212 |\u03c4|2)\u03a8 \u03042 + cc)\u03a611 + 18\u03a82\u03a8 \u03042(|\u03c1|2 + |\u03c4|2). Using these identities, we find that Q1, Q2 and Q3 are now polynomials in terms of \u03a611.\nQ1 = 8 (R[\u03a8 \u03042(\u03c12 \u2212 \u03c42)])\u03a6211 + 8 R[(\u03c12 + \u03c42)\u03a8 \u03042]\u03a611 + 2R[\u03c12 \u2212 \u03c42], 9 |\u03a82|5 3 |\u03a82|4 |\u03a82|\nQ2 = 4 (\u03c4 \u0304\u03c1 + \u03c4\u03c1 \u0304)2\u03a6411 + 32 R[\u03a82(\u03c4\u03c1 \u0304\u2212 \u03c1\u03c4 \u0304)(\u03c4 \u0304\u03c1 + \u03c1 \u0304\u03c4)\u03a6311 81 |\u03a82|6 27 |\u03a82|6\n+16 [|\u03a82|2R[(\u03c1\u03c4 \u0304)2] + R[\u03a82(\u03c4 \u0304\u03c1 \u2212 \u03c1 \u0304\u03c4)2]]\u03a6211 9 |\u03a82|6\n8 ( \u03c1 \u03c4 \u0304 + \u03c1 \u0304 \u03c4 ) ( R [ \u03a8 2 ( \u03c4 \u0304 \u03c1 \u2212 \u03c1 \u0304 \u03c4 ) ] ) \u03a6 1 1 2 ( \u03c1 \u03c4 \u0304 + \u03c1 \u0304 \u03c4 ) 2 +3 |\u03a82|4 + |\u03a82|2 ,\nQ3 = 4 (|\u03c1|2 + |\u03c4|2)\u03a6211 + 4 R[\u03a82(|\u03c1|2 \u2212 |\u03c4|2)]\u03a611 + (|\u03c1|2 + |\u03c4|2). 9 |\u03a82|3 3 |\u03a82|3 |\u03a82|\nDue to the \u03a611 linear term in Q1, it no longer detects the ergosurface. \u2013 Reissner-Nordstr \u0308om-(Anti)-de Sitter Metric\n                   This is just a special case of the Kerr-Newman solution where \u03c4 = \u03c0 = 0, \u03c1 \u0304 = \u03c1 and \u03a8 \u03042 = \u03a82, implying that Q2 = 0 and\n8 \u03c1 2 \u03a6 21 1 Q1 = 2Q3 = 3 9\u03a82\n+\n8 \u03c1 2 \u03a6 1 1\n2 3\u03a82\n2 \u03c1 2\n+ . (5.18)\n\u03a82\n   Unsurprisingly Q1 \u221d ||d\u03a82||2 due to (5.5).\n"}, {"chunk": "Cartan Invariants and Event Horizon Detection 13\n 6 Examples in 5D\nIn this section we will apply the Cartan-Karlhede algorithm to 5D analogues of the black hole metrics studied in the previous section. In particular, we will show how the Cartan invariants are a more viable tool for locating the horizons than the corresponding SPIs generated by Theorem 1. While we have not included the invariants, we note that Theorem 2 will generate smaller extended Cartan invariants using the non-constant zeroth order Cartan invariants for each of these examples.\nAs in the 4D examples, some of these solutions are special cases of the others. For example, the Tangherlini metric is a special case of the Reissner-Nordstr \u0308om-(Anti)-de Sitter metric. The Tangherlini metric is also a special case of the simply rotating Myers-Perry metric which is in turn a special case of the Kerr-NUT-Anti-de Sitter metric.\n6.1 Tangherlini Metric\nThe 5D pseudo-Riemannian analogue of the Schwarzschild metric is given by Tangherlini (1963)\n\u0012 r2\u0013 \u0012 r2\u0013\u22121 \u0010 \u0011 ds2=\u2212 1\u2212 s dt2+ 1\u2212 s dr2+r2 d\u03b82+sin2\u03b8d\u03c62+sin2\u03b8sin2\u03c6d\u03c92 ,\n(6.1)\n  r2 r2\nwhere rs2 = 2M is the Schwarzschild radius. In order to try to detect the event horizon using Cartan invariants, we\nemploy the higher-dimensional analogue of the NP Formalism (Milson et al. 2005). Defining an orthonormal frame by\nr s2 s \u0012 r s2 \u0013 \u2212 1\ne0 =r1\u2212 r2dt, e1 = 1\u2212 r2 dr, e2 =rd\u03b8, e3 =rsin\u03b8d\u03c6, e4 =rsin\u03b8sin\u03c6d\u03c9, (6.2)\n    we produce the half-null frame\nl= \u221a2, n= \u221a2, m=e2,m=e3, m=e4. (6.3)\ne1 \u2212 e0 e0 + e1 2 3 4\nFor the zeroth iteration of the Cartan-Karlhede algorithm, we obtain seven nonzero components of the Weyl tensor.\n    However, these components are algebraically dependent on the following components1 (Coley et al. 2012): 1 6rs2\nC0101 = 3 C0i1i = \u2212 2r4 , (6.4)\n  At zeroth order, only null rotations alter the form of the Riemann tensor. The elements of the invariance group at\nzeroth order H0 consists of rotations and boosts, and hence is four-dimensional. We write the sole linearly independent\ncomponent as C0 = \u2212 rs r4\nAt first order, the invariance group H1 is the group of spatial rotations specified by three parameters. The one- dimensional subgroup of boosts alters the form of the first covariant derivative of the Riemann tensor, using this we have fixed the boosts by setting the component C0101;1 = 1:\n C0101;1 = 3C0i1i;1 = \u22123Cijij;1 = 3C011i;i = 6C1iij;j = 1, (6.5) 72(r2 \u2212 rs2)rs2\nC0101;0 = 3C0i1i;0 = \u22123Cijij;0 = 3C010i;i = \u22126C0iij;j = r12 , (6.6)\n To complete the algorithm one must compute the second covariant derivative of the Weyl tensor, revealing that t1 = t2 = 1 and dim(H1) = dim(H2) = 3, thus the algorithm stops at second order.\nNotice that all positive b.w. terms detect the horizon at first order. In fact, for all higher order derivatives of the Weyl and Ricci tensors, the positive b.w. terms will vanish on the horizon, suggesting that the geometric horizon conjecture for weakly isolated horizons is valid in higher dimensions (Coley et al. 2017; Coley and McNutt 2017a). At first order the SPI I3 vanishes on the horizon r = rs\nI3 = Rabcd;eRabcd;e = 2633rs4(rs2 \u2212 r2). (6.7) r12\nAlternatively, since the cohomogeneity of the Tangherlini metric is n = 1, we can compute the norm of the exterior\n derivative of which yields:\nabcd 72rs4 I1=R Rabcd=r8,\n||dI1||2 = 21234rs8(rs2 \u2212 r2) . r20\n (6.8)\n  1 To display components here and in the following subsections we will repeat indices; this will not indicate summation, unless indicated by a repeated index being raised.\n"}, {"chunk": "14\nD. D. McNutt et al.\n 6.2 5D Reissner-Nordstr \u0308om-(Anti)-de Sitter Metric From Konoplya and Zhidenko (2008), the metric is\n2 2 dr2 2\nds =\u2212f(r)dt +f(r)+rdS3,\n2M \u039br2 Q2 f(r)=1\u2212 r2 \u2212 6 +r4,\n(6.9)\n(6.10)\n(6.11)\n(6.12) (6.13)\n    where dS3 is the line element for the unit 3-sphere. We use the following orthonormal frame:\ne0 = pf(r)dt, e1 = r 1 dr, e2 = rd\u03b8, e3 = r sin(\u03b8)d\u03c6, e4 = r sin(\u03b8) sin(\u03c6)d\u03c9.\n11\nl=\u221a2(e1\u2212e0), n=\u221a2(e0+e1), m2=e2, m3=e3, m4=e4.\nIn this frame, l and n are WANDs; to see this we compute the components of the Weyl and Ricci tensor: R = 2(\u039br6\u22126Q2), R = 2(\u039br6+3Q2), i \u2208 [2,4] ,\n01 3r6 ii 3r6\n3 4Mr2\u22125Q2\n   f(r) From which we build the half-null frame:\n      C0101 = 3C0i1i = 2 r6 ,\nwith the remaining nonzero components Cijij i,j \u2208 [2,4],i \u0338= j algebraically dependent on C0101. That is, relative to\n  this frame, the only nonzero components are the b.w. zero terms.\nAt zeroth order, it can be shown that the isotropy group of the Weyl and Ricci tensor consists of boosts and any\nspatial rotation; hence dim (H0) = 4. The number of functionally independent invariants is t0 = 1. Continuing the Cartan-Karlhede algorithm, we compute the covariant derivative of the Weyl and Ricci tensor:\n8Q2\nR01;1 = \u22124R1i;i = \u22122Rjj;1 = 8Mr2 \u2212 15Q2 ,\n36(8Mr2 \u2212 15Q2)f(r)Q2 R01;0 = \u22124R0i;i = \u22122Rjj;0 = \u2212 r14 ,\n(6.14) (6.15) (6.16)\n(6.17)\n(6.18)\n  C0101;1 = 3C0i1i;1 = \u22123Cijij;1 = 1,\nC0101;0 = 3C0i1i;0 = \u22123Cijij;0 = \u2212 2 r14 ,\n9 (8Mr2 \u2212 15Q2)2f(r) C011i;i = 2C1iij;j = 3 8Mr2 \u2212 15Q2 ,\n  2 4Mr2\u22125Q2\nC100i;i = 2C0iij;j = 3(8Mr2 \u2212 15Q2)f(r)(4Mr2 \u2212 5Q2).\n   r14\nHere we have fixed the boosts by setting the component C0101;1 = 1. Through direct inspection, it is clear that spatial rotations have no effect on the first order Cartan invariants, hence dim (H1) = 3. The number of functionally independent invariants remains t1 = 1. The Cartan-Karlhede algorithm continues for one more iteration since t1 = t2 = 1 and dim (H1) = dim (H2) = 3.\nAs in the Tangherlini metric, all positive b.w. terms detect the horizon at first order. Since the cohomogeneity is n = 1, we may produce a SPI that detects the horizon using I1 = CabcdCabdc:\n||dI1||2 = 26(4Mr2 \u2212 5Q2)2(8Mr2 \u2212 15Q2)2f(r). r26\nThis invariant will vanish at r2 = 5Q2 and r2 = 15Q2 as well.\n6.3 5D Simply Rotating Myers-Perry Metric\n(6.19)\n   4M\n8M\nThe simply rotating Myers-Perry metric is a 5D analogue of the Kerr metric (Myers and Perry 1986; Pravda and Pravdov \u0301a 2005). The metric is:\n21\u2212x\u221a2R2 22 ds = \u22121\u2212y(dt+R \u03bd(1+y)d\u03c8) + (x\u2212y)2[(x\u22121)((1\u2212y )(1\u2212\u03bdy)d\u03c8\ndy22dx2 2\n+ (1+y)(1\u2212\u03bdy))+(1\u2212y) ((1\u2212x2)(1\u2212\u03bdx) +(1+x)(1\u2212\u03bdx)d\u03c6 )].\n(6.20)\n     We first define a non-orthogonal half-null frame {L+,L\u2212,\u2202\u03c6,\u2202y,\u2202\u03c8} where:\n"}, {"chunk": "Cartan Invariants and Event Horizon Detection\n15\n L\u00b1 = 1 \u0012\u03bdyx\u2212y+\u03bdx+1\u22122\u03bdyR\u2202t \u2212\u221a\u03bd\u2202\u03c8\u0013\u00b1r (x2 \u22121)(\u03bdy\u22121) x\u2212y\n\u03bdx\u22121 (x\u2212y)(y\u22121)\n\u0012\u2202x + y2 \u22121\u2202y\u0013. (6.21) x2 \u22121\n      Pravda and Pravdov \u0301a (2005) suggest using a half-null frame {l, n, m2, m3, m4} with l \u221d L+ and n \u221d L\u2212, since in this frame the only nonzero components of the Weyl tensor are those with boost weight zero (i.e. l and n are the WANDs of the simply rotating Myers-Perry metric). We thus start with {L+,L\u2212,\u2202\u03c6,\u2202y,\u2202\u03c8}, normalize L+ and L\u2212, and then use the Gram-Schmidt procedure to obtain {l, n, m2, m3, m4}.\nFor the zeroth iteration of the Cartan-Karlhede algorithm, we obtain 10 nonzero components of the Weyl tensor. However, these components are functionally dependent on any two components (say, for example, C0101 and C0212); thus t0 = 2. As expected, only components with zero boost weight show up, therefore the Weyl tensor is invariant under a boost. Spatial rotations about m4 do not change the components of the Weyl tensor. To see why, consider the matrices defined in Table 1 in Coley et al. (2012):\n\uf8eb Aij = C01ij = \uf8ec\n0\n\u221a(1\u2212\u03bdx)(\u03bd)(x+1)(x\u2212y)2 \uf8f6 (y\u22121)2R2 0\nC0101 = (x \u2212 y)2(4\u03bdx + \u03bd \u2212 3), 4(y \u2212 1)2R2\n1 \u221a(1\u2212\u03bdx)(\u03bd)(x+1)(x\u2212y)2 \u22122 (y\u22121)2R2\n1 (x\u2212y)2(2\u03bdx+\u03bd\u22121)\n(6.22)\n\uf8f6\n0\n0 \uf8f7,\n  \uf8eb 1 (x\u2212y)2(2\u03bdx+\u03bd\u22121) 4 (y\u22121)2R2\n    Mij = C0i1j = \uf8ec1 \u221a(1\u2212\u03bdx)(\u03bd)(x+1)(x\u2212y)2 \uf8ed2 (y\u22121)2R2\n(6.23)\n(6.24)\n     4\n\u221a(1\u2212\u03bdx)(\u03bd)(x+1)(x\u2212y)2 \uf8f7 . (y\u22121)2R2 0 0\uf8f8\n0\n(y\u22121)2R2 0\n\u22121 (x\u2212y)2(\u03bd+1) 4 (y\u22121)2R2\n\uf8f8\n     \uf8ed\u2212\n000\n Since Aij = o\u0328ijkwk, rotations about m4 do not change Aij. And from the form of Mij, it follows that Mij is unaffected by spatial rotations about m4. Therefore dim(H0) = 2.\nAt first order of the Cartan-Karlhede algorithm, there are several nonzero components of the first covariant derivative of the Weyl tensor. No new functionally independent invariants appear, and the remaining isotropy may be fixed by applying a boost to set C0101;1 = 1 and C0101;3 = 0; therefore, t1 = 2 and dim(H1) = 0. The algorithm would carry on for one more iteration, since t1 = t2 = 2 and dim (H1) = dim (H2) = 0, we will omit these details.\nWe note that the following component at first order detects the horizon which is located at x = y = 1/\u03bd:\nC0101;0 = 9 (x \u2212 y)5(2\u03bdx + \u03bd \u2212 1)2(\u03bdx \u2212 1)(\u03bdy \u2212 1)(x \u2212 1). (6.25)\n8 (y \u2212 1)6R6(\u03bd + 1)\nIn fact, all positive b.w. components of the covariant derivative of the Weyl tensor vanish, and similarly for all higher order derivatives.\n  As an alternative using SPIs, define I1 = CabcdCabdc and J1 = CabcdCabef Ccdef , and applying Theorem 1: 2 \u22122434\u03bd2(1+y)(x+1)(x\u22121)2(1\u2212\u03bdx)(1\u2212\u03bdy)(x\u2212y)22(\u03bd+1)4(8\u03bd2x2+8\u03bd2x+3\u03bd2\u22128\u03bdx\u22122\u03bd+3)2\n||dI1 \u2227 dJ1|| = (y\u22121)24R24 , which will vanish on the horizon.\n 6.4 5D Kerr-NUT-Anti-de Sitter Metric\nFor the 5D Kerr-NUT-Anti-de Sitter solution, we will use the metric relative to the coordinate system given by equations (22)-(23) in Chen et al. (2006):\nds2 = dx21 + dx2 + Q1 \u0010d\u03c80 + x2d\u03c81\u00112 + Q2 \u0010d\u03c80 + x21d\u03c81\u00112 \u2212 c0 \u0010d\u03c80 + \u0010x21 + x2\u0011 d\u03c81 + x21x2d\u03c82\u00112 Q 1 Q 2 x 21 x 2 2\nwhere\n(6.26)\n(6.27)\n   Q1=X1,Q2=\u2212X2,U=x2\u2212x21, X1=c1x21+c2x41+c0 \u22122b1,andX2=c1x2+c2x42+c0 \u22122b2. UU x21 x2\n    "}, {"chunk": "16 D. D. McNutt et al.\n The constants c0,c1,c2,b1,b2 are free parameters, which are related to the rotation parameters a1, a2, the mass and NUT charge M1,M2, and the cosmological constant \u039b as follows:\n22 \u039b222\u039b12222\u039b2\nc0 =a1a2, c1 =1\u2212 4 (a1 +a2), c2 = 4, b\u03bc = 2(a1 +a2 \u2212a1a2 4 )\u2212M\u03bc, \u03bc=1,2. (6.28)\nThis metric has been Wick rotated and so it no longer has a Lorentzian signature. This will lead to complex null vectors relative to this coordinate system. However, relative to the original coordinates in Chen et al. (2006) they will be real.\n    We first define an orthonormal frame:\ndx1 dx2 e0=\u221aQ1, e1=\u221aQ2,\nQ2 \u0000d\u03c80 + x21d\u03c81\u0001 , e4 = \u221a\u2212c0 \u0000d\u03c80 + \u0000x21 + x2\u0001 d\u03c81 + x21x2d\u03c82\u0001 . x1 x2\nl=\u221ai (e1+ie3), n=\u2212irQ2(e1\u2212ie3), m2=e0, m3=e2, m4=e4. (6.31) 2Q2 2\nUsing the WANDs in this half-null frame, it may be shown that any of the components are functionally dependent on the choice of two components at zeroth order. Thus t0 = 2. All components are of b.w. zero and they do not change under a rotation about m4. To see why, we express the Weyl tensor components as the following matrices as defined by Table 1 in (Coley et al. 2012):\n(6.29)\n    e2 = \u221a\nThen, according to Hamamotoa et al. (2007) and Pravda et al. (2007), the WANDs are simply the null vectors n and l\nQ1\u0000d\u03c80+x2d\u03c81\u0001, e3=\u221a in the following half-null frame:\n(6.30)\n        C0101 =\u22122(x21+3x2)(b1\u2212b2), U3\n(6.32)\n(6.33)\n(6.34)\n \uf8eb\u22122(x21+x2)(b1\u2212b2) U3\nU3 0\n0 \uf8f6\n\uf8ec 4ix1x2(b1\u2212b2)\n2(x2+x2)(b1\u2212b2) 1 2\nMij =C0i1j =\uf8ed \u2212\nAij = C01ij = \uf8ed\u22128ix1x2(b1\u2212b2) 0 0\uf8f8.\n\uf8f7 \uf8f8,\n4ix1x2(b1\u2212b2) U3\nU3 0\n000\n  \u2212\n0\n  \u2212\u22122(b1\u2212b2) U2\n \uf8eb 0 U3\n8ix1x2(b1\u2212b2) 0\uf8f6 U3\n  We note that this is a vacuum solution and so Rij = \u039bgij. Since Aij = o\u0328ijkwk, rotations about m4 do not change Aij. And from the form of Mij, it follows that Mij is unaffected by spatial rotations about m4. Thus dim(H0) = 2.\nAt first iteration, we have several non-trivial components, but they are all functionally dependent on the two functionally independent invariants at zeroth order, t1 = 2. We can fix the remaining isotropy by applying a boost to set C0101;1 = 1: a rotation about m4 is not needed as our frame already gives the canonical choice C0101;3 = 0. Therefore, dim(H1) = 0. The algorithm would carry on for one more iteration, since t1 = t2 = 2 and dim (H1) = dim (H2) = 0; however, we will omit these details. Instead of listing components of the covariant derivative of the Weyl tensor, we note that the following components at first order detect the horizon, which occurs when the function X2 = 0:\nC0101;0 = 25 \u00b7 32(x21 + x2)2(b1 \u2212 b2)2x2Q2 (6.35) U8\n To determine the location of the event horizon, we may compute the expansion of the trivially-boosted2 l (Pravda et al. 2007),\u03b8 =1habl ,whereh =g \u2212l n :\n(l) 3 (a;b) ab ab (a b)\n\u03b8(l) = 4(x21 \u2212 3x2)(x21 + x2)Q2(b1 \u2212 b2). (6.36)\n  U5\nAs in the previous example, all of the positive b.w. components of the covariant derivative of the Weyl tensor vanish on the horizon, and similarly for all higher order derivatives of the Weyl tensor. Applying Theorem 1, we may produce a SPI that detects the horizon using I1 = CabcdCabdc and J1 = CabcdCabef Ccd ef :\n2 23734(3x41 + 2x21x2 + 3x42)2x21x2X1X2(b1 \u2212 b2)10\n||dI1 \u2227 dJ1|| = (x1 \u2212 x2)30(x1 + x2)30 . (6.37)\nAlternatively, we could use Theorem 2 to produce an extended Cartan invariant from the non-constant zeroth order Cartan invariants that will detect the horizon and will be of lower order than the above SPI.\n2 The boost parameter used was chosen to simplify calculations. We note that this parameter is not well-defined for the original purpose of the Cartan-Karlhede algorithm\n  "}, {"chunk": "Cartan Invariants and Event Horizon Detection 17\n 7 Conclusion\nWe have shown that it is possible to locate the event horizon of any stationary, asymptotically flat (or (anti) de Sitter) black hole from the zeros of Cartan invariants. Our work complements the related results on the detection of stationary horizons using SPIs (Abdelqader and Lake 2015; Page and Shoom 2015). Our approach has a notable advantage in that it is computationally less expensive compared to the related SPIs. In the reviewed examples we have also computed extended Cartan invariants whose zeros only occur on the surface of the stationary horizons, and the related SPIs (Page and Shoom 2015) are computed for each solution as a comparison. In 4D, we employ the NP formalism relative to the frame arising from the Cartan-Karlhede algorithm to demonstrate the relationship between the SPIs and the Cartan invariants.\nWhile we have only considered stationary horizons with spherical topology, in higher dimensions other topologies are permitted for the horizon. For example, the 5D black rings have horizon topology S1 \u00d7 S2. For the rotating and supersymmetric black rings, it has been shown that the approach based on Cartan invariants will detect the horizon (Coley and McNutt 2017b). Furthermore, the results of Coley and McNutt (2017b) show that the Cartan-Karlhede algorithm can be implemented to produce Cartan invariants that detect the horizon even when WANDs are not known. This indicates that the Cartan-Karlhede algorithm can be implemented in dimensions D \u2265 5 and that the resulting invariants will be easier to compute than the related SPIs.\nIn future work we will consider the horizons of solutions containing more than one black hole, including the analytical example of the Kastor-Traschen solution (Kastor and Traschen 1993). This dynamical extension may allow us to follow the formation of the event horizon during the merger of two black holes, during the phase of collapse of a star into a single black hole (Penrose 1969), and perhaps even the disappearance of the horizon during the evaporation of a single black hole (Hawking 1974). We will also extend our method to the study of evolving event horizons for time dependent metrics, including metrics currently used for cosmological modelling. We hope that these results will play an important role in numerical relativity in which configurations of many black holes are evolved in time (Baumgarte and Shapiro 2010), and a sharp localization of the event horizons is required.\nAcknowledgements\nThe authors would like to thank Jan  \u030aAman and Sebastian Jan Szybka for checking the calculations in the paper. The work was supported by NSERC of Canada (A.A.C, A.F., D.B.) and AARMS (D.G.) and through the Research Council of Norway, Toppforsk grant no. 250367: Pseudo-Riemannian Geometry and Polynomial Curvature Invariants: Classification, Characterisation and Applications (D.M.). We are also grateful to the authors of the free software GRtensorII, Reduce and Sheep used in checking our calculations.\nReferences\nBenjamin P Abbott, Richard Abbott, TD Abbott, MR Abernathy, Fausto Acernese, Kendall Ackley, Carl Adams, Thomas Adams, Paolo Addesso, RX Adhikari, et al. Observation of gravitational waves from a binary black hole merger. Physical review letters, 116(6): 061102, 2016.\nBP Abbott, R Abbott, TD Abbott, F Acernese, K Ackley, C Adams, T Adams, P Addesso, RX Adhikari, et al. Gw170104: Observation of a 50-solar-mass binary black hole coalescence at redshift 0.2. Physical Review Letters, 118(22):221101, 2017.\nM. Abdelqader and K. Lake. Invariant characterization of the Kerr spacetime: Locating the horizon and measuring the mass and spin of rotating black holes using curvature invariants. Phys. Rev. D, 91:084017, 2015.\nJ. E.  \u030aAman. Computer-aided classification of geometries in general relativity; example: The Petrov type D vacuum metrics. In W. B. Bon- nor, J. N. Islam, and M. A. H. MacCallum, editors, Classical general relativity., pages 1\u20134. Cambridge University Press, Cambridge, 1984.\nA. Ashtekar and B. Krishnan. Isolated and dynamical horizons and their applications. Liv. Rev. Rel., 7:10, 2004.\nT. W. Baumgarte and S. L. Shapiro. Numerical Relativity: Solving Einstein\u2019s Equations on the Computer. Cambridge University Press,\nCambridge, 2010.\nI. Booth. Black hole boundaries. Can J. Phys., 83:1073\u20131099, 2005.\nAnnalisa Celotti, John C Miller, and Dennis W Sciama. Astrophysical evidence for the existence of black holes. Classical and Quantum\nGravity, 16(12A):A3, 1999.\nW. Chen, H. Lu \u0308, and C. N. Pope. General Kerr-NUT-AdS metrics in all dimensions. Class. Quantum Grav., 23:5323\u20135340, 2006.\nY. Choquet-Bruhat. General Relativity and the Einstein Equations. Oxford Mathematical Monographs. Oxford University Press, Oxford,\n2000.\nY. Choquet-Bruhat, C. DeWitt-Morette, and M. Dillard-Bleick. Analysis, Manifolds and Physics: Part I: Basics (Revised Edition).\nNorth Holland, Amsterdam, 1982.\nA. Coley and S. Hervik. Higher dimensional bivectors and classification of the Weyl operator. Class. Quantum Grav., 27(1):015002, 2010. A. Coley, R. Milson, V. Pravda, and A. Pravdova \u0301. Classification of the Weyl tensor in higher dimensions. Class. Quantum Grav., 21:35,\n2004.\nA. Coley, S. Hervik, and N. Pelavas. Spacetimes characterized by their scalar curvature invariants. Class. Quantum Grav., 26:025013,\n2009.\n"}, {"chunk": "18 D. D. McNutt et al.\n A. Coley, S. Hervik, M. Ortaggio, and L. Wylleman. Refinements of the Weyl tensor classification in five dimensions. Class. Quantum Grav., 29(15):155061, 2012.\nA. A. Coley and D. D. McNutt. Identification of black hole horizons using discriminating scalar curvature invariants. Class. Quant. Grav., 35(2):025013, 2017a.\nA. A. Coley and D. D. McNutt. Horizon detection and higher dimensional black rings. Class. Quantum Grav., 34:035008, 2017b.\nA. A. Coley, A. A. Shoom, and D. D. McNutt. Geometric horizons. Physics Letters B, 771:131\u2013135, 2017.\nJ. M. Collins and R. A. d\u2019Inverno. The Karlhede classification of type-D nonvacuum spacetimes. Class. Quant. Grav., 10(2):343\u201351,\n1993.\nJ. M. Collins, R. A. d\u2019Inverno, and J. A. Vickers. The Karlhede classification of type D vacuum spacetimes. Class. Quant. Grav., 7:\n2005\u20132015, 1990.\nStefan Gillessen, F Eisenhauer, S Trippe, T Alexander, R Genzel, F Martins, and T Ott. Monitoring stellar orbits around the massive\nblack hole in the galactic center. The Astrophysical Journal, 692(2):1075, 2009.\nJ. B. Griffiths and J. Podolsky \u0301. On the parameters of the Kerr NUT (anti)-de Sitter spacetime. Class. Quantum Grav., 24:1687\u20131689,\n2007.\nN. Hamamotoa, T. Houri, T. Oota, and Y. Yasui. Kerr-NUT-de Sitter curvature in all dimensions. J. Phys. A, 40:F177, 2007.\nS. W. Hawking. Black hole explosions? Nature, 248(5443):30\u201331, 1974.\nA. Karlhede, U. Lindstr \u0308om, and J. E.  \u030aAman. A note on a local effect at the Schwarzschild sphere. Gen. Rel. Grav., 14:569\u2013572, 1982. D. Kastor and J. Traschen. Cosmological multi-black-hole solutions. Phys. Rev. D, 47:5370, 1993.\nR. A. Konoplya and Z. Zhidenko. Stability of higher dimensional Reissner-Nordstr \u0308om-anti-de Sitter black holes. Phys. Rev. D, 78:104017,\n2008.\nM. A. H. MacCallum. Computer-aided classification of exact solutions in general relativity. In H. Sato and T. Nakamura, editors,\nGravitational Collapse and Relativity (Proceedings of the XIV Yamada conference), pages 127\u2013140. World Scientific, Singapore,\n1986.\nM. A. H. MacCallum. On singularities, horizons, invariants, and the results of Antoci, Liebscher and Mihich (GRG 38, 15 (2006) and\nearlier). Gen. Rel. Grav., 38:1887\u20131899, 2006.\nM. A. H. MacCallum. Spacetime invariants and their uses. In M. Sharif, editor, Proceedings of the International Conference on Relativistic\nAstrophysics, Lahore, February 2015, pages 122\u2013128. Punjab University Press, Lahore, 2015. The complete proceedings are available\nfor downloading at http://icra.pu.edu.pk/ProceedingsFinal.pdf.\nM. A. H. MacCallum and J. E.  \u030aAman. Algebraically independent n-th derivatives of the Riemannian curvature spinor in a general\nspacetime. Class. Quant. Grav., 3(6):1133\u201341, 1986.\nD. D. McNutt, A. A. Coley, and A. Forget. The Cartan algorithm in five dimensions. J. Math. Phys., 58:032502, 2017.\nR. Milson, A. Coley, V. Pravda, and A. Pravdova \u0301. Alignment and algebraically special tensors in Lorentzian geometry. Int. J. Geom.\nMeth. Mod. Phys., 2:41, 2005.\nC. W. Misner, K. S. Thorne, and J. A. Wheeler. Gravitation. Freeman, San Francisco, 1973.\nRobert C Myers and Michael J Perry. Black holes in higher dimensional space-times. Annals of Physics, 172(2):304\u2013347, 1986.\nM. Ortaggio, V. Pravda, and A. Pravdova \u0301. Algebraic classification of higher-dimensional spacetimes based on null alignment. Class.\nQuantum Grav., 30(1):013001, 2011.\nD. N. Page and A. A. Shoom. Local invariants vanishing on stationary horizons: A diagnostic for locating black holes. Phys. Rev. Lett.,\n114:141102, 2015.\nF. M. Paiva, M. J. Rebou \u0327cas, and M. A. H. MacCallum. On limits of spacetimes \u2013 a coordinate-free approach. Class. Quant. Grav., 10:\n1165\u20131178, 1993.\nR. Penrose. Gravitational collapse: the role of general relativity. Rivista del Nuovo Cimento, Numero Speziale, I:252, 1969. Reprinted as\nGolden Oldie 26 in Gen. Relativ. Gravit. 34, no 7, 1141 (2002), with editorial note by Andrzej Kr \u0301olak and biography by W. Israel,\npp. 1135-1140.\nJ. F. Pleban \u0301ski and M. Demian \u0301ski. Rotating, charged and uniformly accelerated mass in general relativity. Ann. Phys. (USA), 98:98,\n1976.\nJ. Podolsky \u0301 and R. Svarc. Explicit algebraic classification of kundt geometries in any dimension. Class. Quantum Grav., 30:125007, 2013. J. Polchinski. String Theory (2 volumes). Cambridge University Press, Cambridge, 2005.\nV. Pravda and A. Pravdova \u0301. WANDs of the black ring. Gen. Relativ. Gravit., 37:1277, 2005.\nV. Pravda, A. Pravdova \u0301, and M. Ortaggio. Type D Einstein spacetimes in higher dimensions. Class. Quantum Grav., 24:4407, 2007.\nJ. E. F. Skea. Anisotropic cosmologies and curvature invariants. PhD thesis, University of Sussex, 1986.\nH. Stephani, D. Kramer, M. A. H. MacCallum, C. A. Hoenselaers, and E. Herlt. Exact solutions of Einstein\u2019s field equations, 2nd edition.\nCambridge University Press, Cambridge, 2003. Corrected Paperback edition, 2009.\nF. R. Tangherlini. Schwarzschild field inn dimensions and the dimensionality of space problem. Il Nuovo Cimento, 27:636\u2013651, February\n1963. doi: 10.1007/BF02784569.\nB. Zwiebach. A First Course in String Theory. Cambridge University Press, Cambridge, 2009.\n"}, {"chunk": "On the role of theory and modeling in neuroscience\nDaniel Levenstein1,19, Veronica A. Alvarez2, Asohan Amarasingham14, Habiba Azab3, Zhe S. Chen18, Richard C. Gerkin4, Andrea Hasenstaub5, Ramakrishnan Iyer6, Renaud B. Jolivet7, Sarah Marzen12, Joseph D. Monaco8, Astrid A. Prinz13, Salma Quraishi, Fidel Santamaria9, Sabyasachi Shivkumar15, Matthew F. Singh10, Roger Traub11, Horacio G. Rotstein16,*, Farzan Nadim16,*, A. David Redish17,*\n 1 Montreal Neurological Institute, McGill University, Montreal, QC, Canada\n 2 Laboratory on Neurobiology of Compulsive Behaviors, National Institute on Alcohol Abuse and Alcoholism, NIH. Bethesda, MD\n 3 Department of Neuroscience, Center for Magnetic Resonance Research, University of Minnesota, Minneapolis, MN\n 4 School of Life Sciences, Arizona State University, Tempe, AZ\n 5 Department of Otolaryngology - Head and Neck Surgery, University of California San Francisco, San Francisco, CA\n 6 Allen Institute for Brain Science, Seattle, WA\n 7 Maastricht Centre for Systems Biology (MaCSBio), Maastricht University, Maastricht, Netherlands\n 8 Department of Biomedical Engineering, Johns Hopkins University School of Medicine, Baltimore, MD\n 9 Department of Biology, University of Texas at San Antonio, San Antonio, TX\n10 Department of Psychological & Brain Sciences, Department of Electrical & Systems Engineering, Washington University in St.\n  Louis, St. Louis, MO\n 11 IBM T.J. Watson Research Center, AI Foundations, Yorktown Heights, NY\n 12 W. M. Keck Science Department, Pitzer, Scripps, and Claremont McKenna Colleges, Claremont, CA\n 13 Department of Biology, Emory University, Atlanta, GA\n14 Department of Mathematics, City College of New York; Departments of Biology, Computer Science, and Psychology, The\n  Graduate Center; City University of New York\n 15 Brain and Cognitive Sciences, University of Rochester, Rochester, New York, United States of America\n16 Federated Department of Biological Sciences, New Jersey Institute of Technology and Rutgers University & Institute for Brain and\n  Neuroscience Research, New Jersey Institute of Technology, Newark, NJ\n 17 Department of Neuroscience, University of Minnesota, Minneapolis MN\n 18 Department of Psychiatry, Neuroscience & Physiology, New York University School of Medicine\n 19 Mila - Quebec AI Institute, Montreal, QC, Canada\n *Co-senior author\nAbstract\nIn recent years, the field of neuroscience has gone through rapid experimental advances and a significant increase in the use of quantitative and computational methods. This growth has created a need for clearer analyses of the theory and modeling approaches used in the field. This issue is particularly complex in neuroscience because the field studies phenomena that cross a wide range of scales and often require consideration at varying degrees of abstraction, from precise biophysical interactions to the computations they implement. We argue that a pragmatic perspective of science, in which descriptive, mechanistic, and normative models and theories each play a distinct role in defining and bridging levels of abstraction will facilitate neuroscientific practice. This analysis leads to methodological suggestions, including selecting a level of abstraction that is appropriate for a given problem, identifying transfer functions to connect models and data, and the use of models themselves as a form of experiment.\n Correspondence: daniel.levenstein@mcgill.ca, horacio@njit.edu, farzan@njit.edu, redish@umn.edu\n    "}, {"chunk": "Introduction\nRecent technological advances in neuroscience have prompted the growth of new experimental approaches and subfields that investigate phenomena from single neurons to social behavior. However, rapid growth has also revealed a need to develop new theoretical frameworks (Phillips 2015) that integrate the growing quantities of data and to establish relationships between their underlying processes. While neuroscience has a strong history of interactions between experimental and theoretical approaches (Marr 1991; Hodgkin and Huxley 1952; O\u2019Keefe and Nadel 1978), there is still disagreement as to the nature of theory and its role in neuroscience, including how it should be developed, used, and evaluated by the community (Goldstein 2018; Bialek 2018).\nWe argue that an idealized view of scientific progress, in which science is a problem-solving enterprise that strives to explain phenomena, is well-suited to inform scientific practice. In neuroscience, the phenomena of interest are those that pertain to neurons, the nervous system, and its contribution to cognition and behavior. Because these phenomena span a wide range of spatiotemporal scales, their explanations often require a \u201cmulti-level\u201d approach that combines data from dramatically different modalities. Descriptive, mechanistic, and normative explanations each play distinct roles in building a multi-level account of neural phenomena \u2014 descriptive explanations delineate an abstract characterization of a phenomenon, while mechanistic and normative explanations bridge abstractions of different levels. Collectively, these operations unify scientific theories across disparate experimental approaches and fields. We show how this view facilitates the bidirectional interaction between theory and experimentation as well as theory development.\nWhat is a theory and what is it good for?\nTheories are the primary tools by which scientists make sense of observations and make predictions. Given this central role, it is surprising how little methodological attention is given in scientific training to the general nature of theories. Traditional descriptions of science tend to be based on the processes of theory identification and falsification, in which theories are proposed as universal truths about the world, tested, provisionally accepted if found to be compatible with experimental data, and rejected when found to be incompatible (Popper 1959). According to these traditional descriptions, when theories are incompatible with experimental data, the conceptual framework on which they are based is called into question and a new framework is found that can better account for the data (Popper 1959; Kuhn 2012; Lakatos 1980). However, historical, philosophical, and sociological analyses argue that these views do not account for how theory is used in practice (Lakatos 1980; Firestein 2015; Godfrey-Smith 2003; Feyerabend 1993; Ben-Ari 2011; Kaiser 2014; Laplane et al. 2019). For example, theories are rarely, if ever, decisively testable, scientists can have a variety of attitudes towards a theory rather than to simply accept or reject it (Lakatos 1978; van Fraassen 1980; Mermin 1989; Ben-Ari 2011; Kaiser 2014), and although new discoveries can provide answers to open questions, the new questions they prompt may be more consequential (Firestein 2012).\nA pragmatic view: science as problem-solving\nWe propose that a pragmatic view of the scientific enterprise (James 1907; Ben-Ari 2011; Laudan 1978; Douglas 2014) is better suited to inform scientific practice. In this view, science is a process through which we solve empirical problems and answer questions about observable phenomena (Laudan 1978; Douglas 2014; Firestein 2015; A. D. Redish et al. 2018; Haig 1987; Nickles 1981). Empirical problems can range from matters of basic scientific interest (for example, \u201cHow does the brain process visual signals?\u201d or \u201cHow does an animal select between alternative choices?\u201d), to those with more obvious applications (such as \u201cWhich brain functions are disrupted in schizophrenia?\u201d). Like any other problem, a\nLevenstein et al. - On the role of theory and modeling in neuroscience | 2\n"}, {"chunk": "scientific problem can be seen as a search to achieve a desired goal, which is specified by the statement of the problem (Newell and Simon 1972). However, scientific problems are often ill-defined (Bechtel and Richardson 2010), in part because the search space and solution criteria are not always explicitly stated and in part because they evolve with additional discoveries (Firestein 2012). For example, the discovery of multiple memory and decision-making systems raises further questions of how those systems interact (Balleine and Dickinson 1998; O\u2019Keefe and Nadel 1978; Daw, Niv, and Dayan 2005; A. David Redish 2013; Scoville and Milner 1957; Squire 1987; Nadel 1994; Schacter 2001), while the question \u201cHow does the pineal gland generate consciousness?\u201d (Descartes 1637) is now considered outdated. Further, scientific problems are never definitively solved, but are only deemed \"adequately solved\" by a research community. What is seen as an adequate solution in one socio-historical context may not be in another \u2014 as new data become available, standards change, or alternative solutions are presented. While a continuously evolving landscape of problems and proposed solutions might seem to counter a notion of progress in science, scientific theories have been used to explain and control progressively more phenomena over the course of the scientific record (Laudan 1978; Douglas 2014). According to the pragmatic view, this progress results from community-maintained standards of explanation, under an overarching drive to better predict and control natural phenomena of potential relevance to society (Hacking 1983; Douglas 2014).\nWe can thus define a scientific explanation (Hempel and Oppenheim 1948; Woodward 2019) as a proposed solution to an empirical problem, and scientific theories to be the ideas we use to form explanations. Where traditional views have tried to specify the form theories take, the pragmatic view sees theory structure as closely tied to its function and context. As a result, a theory can include a wide and complex range of structural elements, including those that are not formalized (Winther 2021). While theories may be spelled out in the scientific literature, they are more often used implicitly in the explanation of phenomena and design of experiments. By shifting theories from \u201cproposals of truth to be falsified\u201d to \u201cproposed problem-solving tools\u201d, the pragmatic view prompts us to assess a theory by its utility: what empirical problems it can solve, how easily it can be used to solve them, and how good its solutions are. It also requires criteria to evaluate the quality of solutions to a problem and a set of standards by which we measure the utility of the theory such as accuracy, simplicity, falsifiability, generalizability, and reproducibility (Chang 2007b, 2011; van Fraassen 1980; Laudan 1978; Schindler 2018). Through competition to solve empirical problems, theories become more precise, provide clearer and more concise explanations, can be used to make more reliable and accurate predictions, and can be applied to larger domains.\nConceptual frameworks provide constructs and constraints\nAssessing scientific explanations inevitably involves considerations that are not directly related to solution quality, but are instead constraints on the form solutions can take. These constraints constitute a conceptual framework (Table 1): a language within which explanations are proposed. In effect, a conceptual framework is a set of foundational theories that provide a conceptual structure on which further theories within that program are built (Lakatos 1978; Laudan 1978; Kuhn 2012).\nThe stability of such a framework allows its component theories to change without rebuilding their conceptual foundations. For example, under the modern framework of neuropsychiatry, psychiatric disorders are framed in terms of biophysical dysfunctions in neural structure. Current debates about the underpinnings of schizophrenia include hypotheses of dysfunction within dopaminergic or glutamatergic systems, dysfunctional pruning of dendrites, and dysfunctional oscillatory dynamics (Moghaddam and Javitt 2012; Glausier and Lewis 2013; Uhlhaas and Singer 2015; Howes et al. 2017). However, they all lie within a general framework of biophysical changes in neural processes. The consistency of this founding idea allows us to modify theories without disrupting the foundational premise, which allows them to be directly compared and contrasted.\nLevenstein et al. - On the role of theory and modeling in neuroscience | 3\n"}, {"chunk": "While explanations are naturally comparable within a framework, theories under different frameworks are composed of fundamentally different objects and describe the world in different terms, which makes them difficult to compare. For example, explanations under the traditional psychoanalytic framework (Luyten et al. 2015) are fundamentally different from those under the modern neuropsychiatry framework (World Health Organization 2021; American Psychiatric Association 2013; Cuthbert and Insel 2013; Insel and Cuthbert 2015). The two frameworks are composed of fundamentally different objects and are described in different terms: in contrast to the neuropsychiatric framework, psychoanalytic explanations for schizophrenia invoke unconscious conflicts and/or distorted ego functions as the key factors underlying psychosis (Luyten et al. 2015). Even the categorizations of psychiatric phenomena are different under these frameworks, making direct comparisons of explanations for the same phenomena across frameworks difficult (Feyerabend 1993).\nDespite the difficulties in directly comparing theories across frameworks, all frameworks are not equivalent. One can compare conceptual frameworks by asking how well their theories allow us to predict and control our environment (Lakatos 1978). This is not to say that all research requires a direct application, but rather that consideration of practical components is necessary for a complete understanding of scientific progress (Laudan 1978; Douglas 2014). For example, the psychoanalytic framework implies treatment based analytic therapy, while the modern neuropsychiatry framework suggests medication as a key component. Furthermore, under the new framework known as computational psychiatry, psychiatric disorders are attributed to computational \u201cvulnerabilities\u201d in the systems architecture of the brain (A. D. Redish 2004; A. D. Redish, Jensen, and Johnson 2008; Montague et al. 2012; A. D. Redish and Gordon 2016; Huys, Maia, and Frank 2016). Theories in this new framework suggest that such disorders would be treatable by changing information processing \u2013 by modifying the physical substrate (e.g. through electrical stimulation or pharmacological changes), enhancing compensation processes (e.g. through cognitive training), or changing the environment (e.g. by giving a student with ADHD extra time on a test). The pragmatic view suggests that the ultimate adoption (or not) of this framework will come down to how successfully it can be applied to unsolved problems.\nModels as the interface between theories and phenomena\nWhile \u201ctheoretical\" work may appear further from \u201capplied\u201d science than its experimental counterpart, models can act as an interface between theory and phenomena. A model consists of a structure and an interpretation of how that structure relates to its target phenomena ((Frigg and Hartmann 2006), also known as the model's \u201cconstrual\u201d (Weisberg 2013)). For example, the equation \ud835\udf0f\ud835\udc51\ud835\udc49/\ud835\udc51\ud835\udc61 \udbff\udc00 \udbff\udc01\ud835\udc49 \udbff\udc02 \ud835\udc49\udbff\udc03\udbff\udc04\udbff\udc05\udbff\udc06 is a mathematical structure that is interpreted to represent the temporal dynamics of the membrane potential, \ud835\udc49, of a passive cell with time constant, \ud835\udf0f, and resting potential, \ud835\udc49\udbff\udc03\udbff\udc04\udbff\udc05\udbff\udc06 (Hille 2001; Hodgkin and Huxley 1952; Koch and Segev 1989; Rall 1992; Gerstner et al. 2014). Models whose structure consists of mathematical equations or computational processes are amenable to simulation and analytical treatment. Models can be constructed from many different kinds of interpreted structures, such as physical structures that are interpreted to represent the double helix of DNA (Watson and Crick 1953) or diagrammatic structures that are interpreted to represent protein interactions involved in signaling cascades (Alon 2006). Many \u201canimal models\u201d used in experimental neuroscience are physical structures interpreted to represent other phenomena, such as the 6-OHDA rat or the MPTP monkey, which are interpreted to represent the pathology of Parkinson\u2019s disease (Dorval and Grill 2014; Schultz et al. 1989).\nIn creating a model, a researcher has to make foundational assumptions in the terms they use, the form those terms take, and the relationships between them. These assumptions instantiate aspects of a theory in an explicit expression with a well-defined form. The voltage equation above instantiates the theory that a neuron\u2019s electrical properties arise from a semipermeable membrane (Hodgkin and Huxley 1952; Rall\nLevenstein et al. - On the role of theory and modeling in neuroscience | 4\n"}, {"chunk": "1992), while the 6-OHDA model instantiates the theory that Parkinson\u2019s disease arises from dopaminergic dysfunction (Langston and Palfreman 2013). This explicit formulation of theories can force us to confront hidden assumptions (Marder 2000), and provide useful insights for the design of experiments or potential engineering applications.\nFurther, in selecting some aspects of a phenomenon to include, and others to ignore, creating a model abstracts a multi-faceted phenomenon into a concise, but inevitably simplified, representation. Thus, models simultaneously act as an instantiation of a theory and an abstraction of a phenomenon (Rosenblueth and Wiener 1945; Stafford 2009). This dual role of models is the foundation of their use in explanation (Cartwright 1997).\n[TABLE 1 NEAR HERE]\nDescriptive, mechanistic, and normative explanation\nThe terms \u201cdescriptive\u201d, \u201cmechanistic\u201d, and \u201cnormative\u201d are widely used in neuroscience to describe various models. A pragmatic view prompts us to consider how these terms relate to the type of problem they are used to solve (Kording et al. 2020). In doing so, we find that these labels correspond to three different explanatory approaches in neuroscience, which are used to solve three different types of problems: \u201cwhat\u201d problems, \u201chow\u201d problems, and \u201cwhy\u201d problems (Dayan and Abbott 2001). (See Figure 1).\n[FIGURE 1 NEAR HERE]\nDescriptive explanations\nThe first problem often encountered in scientific research is: What is the phenomenon? Phenomena are not divided into discrete entities a priori, but instead appear as a continuous multifaceted stream with many possible methods of observation and many aspects that could be observed. Thus, the set of characteristics that define a phenomenon are often unclear. This problem is addressed with a descriptive explanation (David M. Kaplan and Bechtel 2011). For example, to explain the spikes observed from a hippocampal neuron we could use a theory of \u201cplace cells\u201d (O\u2019Keefe and Nadel 1978): a collection of ideas that defines the relationship between neural activity in the hippocampus and an animal\u2019s position in an environment, which can be instantiated in a model that specifies that relationship in an equation (O\u2019Keefe and Nadel 1978; A. D. Redish 1999; Laura Lee Colgin 2020). Descriptive models are founded on basic assumptions of which variables to observe and how to relate them. At its heart, a descriptive explanation is simply a selective account of phenomenological data; indeed descriptive models are often called phenomenological models (Craver 2007; David Michael Kaplan 2011) or, when they are well-established, phenomenological laws (Cartwright 1997).\nMechanistic explanations\nAfter addressing the \u201cwhat\u201d question, one might ask: How does the phenomenon arise? This problem is addressed with a mechanistic explanation, which explains a phenomenon in terms of its component parts and their interactions (Machamer, Darden, and Craver 2000; Craver 2007; Bechtel and Richardson 2010). For example, to explain the activity of place cells, we can create explanations based on afferent information from other structures, internal connectivity patterns, and intra-neuronal processing, which can be instantiated in a model that specifies how they interact to produce neural firing (A. D. Redish 1999;\nLevenstein et al. - On the role of theory and modeling in neuroscience | 5\n"}, {"chunk": "Hartley et al. 2000; Barry et al. 2006; Solstad, Moser, and Einevoll 2006; Fuhs and Touretzky 2006; Giocomo, Moser, and Moser 2011; Sanders et al. 2015). A mechanistic model is founded on an assumption of which parts and processes are relevant, and illustrates how their interaction can produce a phenomenon or, equivalently, how the phenomenon can emerge from these parts. Often these parts are considered to be causally relevant to the phenomenon, and a mechanistic explanation is often also referred to as a causal explanation (Machamer, Darden, and Craver 2000; Craver 2007; Bechtel and Richardson 2010).\nMathematical mechanistic models in neuroscience often take the form of a dynamical system (Koch and Segev 1989; Ellner and Guckenheimer 2006; Izhikevich 2007; Ermentrout and Terman 2010; Gabbiani and Cox 2017; Gerstner et al. 2014; Bo\u0308rgers 2017), in which a set of variables represent the temporal evolution of component processes or their equilibrium conditions. For example, the classic Hodgkin- Huxley model uses a set of four coupled differential equations to represent the dynamics of membrane potential and voltage-dependent conductances, and shows how an action potential can emerge from their interaction by producing a precise prediction of the progression of the membrane potential in time (Hodgkin and Huxley 1952). However, qualitative mechanistic models, in which complex processes are summarized in schematic or conceptual structures that represent general properties of components and their interactions, are also commonly used in neuroscience. For example, Hebb considered a conceptualization of neural processing in which coincident firing of synaptically connected neurons strengthened the coupling between them. From this model, Hebb was able to propose how memories could be retrieved by the completion of partial patterns and how these processes could emerge from synaptic plasticity, as cells that were coactive during a particular stimulus or event would form assemblies with the ability to complete partially-activated patterns (Hebb 1949).\nMechanistic models represent the (assumed) underlying processes that produce the phenomenon (Craver 2007; David M. Kaplan and Bechtel 2011). They can be used to make predictions about situations where the same processes are presumed to operate (Ellner and Guckenheimer 2006). This includes the effects of manipulations to component parts, and circumstances beyond the scope of data used to calibrate the model.\nNormative explanations\nIn addition to the mechanistic question of \u201chow\u201d, we can also ask the question: Why does the phenomenon exist? This kind of problem is addressed with a normative explanation, which is used to explain a phenomenon in terms of its function (Barlow 1961; Kording, Tenenbaum, and Shadmehr 2007; Bialek 2012). A normative explanation of place cells would appeal to an animal\u2019s need to accurately encode its location, and could instantiate that need in a model of a navigation task (O\u2019Keefe and Nadel 1978; A. D. Redish 1999; McNaughton and Nadel 1990; Zilli and Hasselmo 2008). Appealing to a system\u2019s function serves as a guiding concept that can be a powerful heuristic to explain its behavior based on what it ought to do to perform its function (Dennett 1989). This kind of explanation has a long history in the form of teleological explanation, which explains a thing by its \u201cpurpose\u201d (Aristotle, n.d.), and is often used implicitly in biological sciences \u2014 for example, stating that the visual system is \u201cfor\u201d processing visual information. In neuroscience, functions often come in the form of cognitive, computational, or behavioral goals.\nWhen quantified, normative models formalize the goal of the phenomenon in an objective function (also known as a utility or cost function), which defines what it means for a system to perform \u201cwell\u201d. These models are founded on an assumed statement of a goal and the constraints under which the system operates. For example, models of retinal function formalize the goal of visual processing using equations that represent the ability to reconstruct a sensory signal from neural responses, under the constraints of sensory degradation and a limited number of noisy neurons (Rieke et al. 1997; Field and Rieke 2002; Doi\nLevenstein et al. - On the role of theory and modeling in neuroscience | 6\n"}, {"chunk": "and Lewicki 2014). Such an approach also relies on an assumption of an underlying optimization process. This assumption is often justified by appealing to evolution, which might be expected to optimize systems (Parker and Smith 1990; Barlow 1961; Bialek and Setayeshgar 2008). However, evolution does not guarantee optimality due to limitations of genetic search (Gould 1983; Gould and Lewontin 1979). Moreover, there are numerous processes in physical, biological, neurological, and social systems that can drive phenomena towards a state that maximizes or minimizes some objective function; however, these processes each also have their own unique limitations. For example, physical processes that minimize surface-to-volume ratio create hexagonal tessellations in beehives, but this process is limited by the physical properties of construction (Thompson 1992; Smith, Napp, and Petersen 2021). Economic markets might be expected to optimize the balance between offer and selling price, but are limited by imperfect and unbalanced information and the limited decision-making abilities of agents (Kahneman, Knetsch, and Thaler 1991; Gigerenzer and Gaissmaier 2011; Fox 2009; Shleifer 2000; Akerlof 1978). Similarly, supervised learning might be expected to optimize object discrimination, but its implementation in the brain would be limited by constraints such as synaptic locality and the availability of credit signals and training data (Hunt et al. 2021; Hamrick et al. 2020; Ha\u0308usser and Mel 2003; Richards et al. 2019; Takeuchi, Duszkiewicz, and Morris 2014; McNaughton, Douglas, and Goddard 1978). Where each of these processes might be expected to bring systems toward an optimal solution, the constraints under which they operate may themselves impose distinct signatures on the systems they optimize.\nThe descriptive / mechanistic / normative classification depends on context\nTheories and models do not exist in isolation, but are embedded in scientific practice. As the descriptive/mechanistic/normative categorization reflects the problem being solved, it can be applied to both theories and models depending on the context, i.e., kind of explanation, in which they are being used. In general, this categorization is independent of whether an explanation is accepted by the scientific community. For instance, a mechanistic explanation does not cease to be mechanistic if it is not adopted, e.g., because some of its predictions are not experimentally corroborated. Further, models with the same structure can be used for different purposes, and can thus be assigned to a different category in different contexts. For example, the integrate-and-fire model can be used as a descriptive model for membrane potential dynamics, or as a mechanistic model for the neuronal input-output transformation; and while the Hodgkin-Huxley model was discussed above as a mechanistic model for the problem of spike generation, it was originally proposed to be \u201can empirical description of the time course of the changes in permeability to sodium and potassium\u201d (Hodgkin and Huxley 1952). In fact, theories often start as an effort to solve one class of problem, and over time develop aspects to address related problems of different classes \u2014 resulting in a theory with descriptive, mechanistic, and normative aspects.\nLevels of abstraction\nIn selecting some aspects of a phenomenon to include, and others to ignore, a model abstracts a multi- faceted phenomenon into a more concise, but inevitably simplified, representation. That is, in making a model we replace a part of the universe with a simpler structure with arguably similar properties (Rosenblueth and Wiener 1945; Weisberg 2013). It could be argued that abstraction is detrimental to model accuracy (i.e. that \u201cThe best material model for a cat is another, or preferably the same cat\u201d), and is only necessary in light of practical and cognitive limitations (Rosenblueth and Wiener 1945). However, abstraction is important in scientific practice, and its role extends beyond addressing those limitations (Potochnik 2017).\nLevenstein et al. - On the role of theory and modeling in neuroscience | 7\n"}, {"chunk": "Descriptive models define abstractions at different levels\nAbstraction is most obvious when we consider the construction of descriptive explanations. First, abstractions are made when researchers decide which aspects of a phenomenon not to include. For example, the cable equation which describes the relationship between axonal conductance and membrane potential (Rinzel and Ermentrout 1989; Rall 1992; Gerstner et al. 2014) does not include details about intracellular organelles, the dynamics of individual ion channels, or the impact of nearby neurons on the extracellular potential. Importantly, these models do not include many larger scale effects (such as the neuron\u2019s embedding in a circuit, or the social dynamics of the agent) as well as smaller scale factors (Vinogradov, Hamid, and Redish 2022). The process of abstraction thus applies to both phenomena at smaller scales (organelles) and at larger scales (social interactions of the agent) that are hypothesized to be unnecessary to address the question at hand. Each of these factors are abstracted away, leaving only the features chosen to be represented in a model\u2019s structure.\nSecond, the aspects that are included must be represented in an idealized form. For instance, ionic flux through the cell membrane is not a strictly linear current function of voltage and conductance, but we often idealize it as such for tractability (Rall 1992; Koch and Segev 1989; Hille 2001). These idealizations are assumptions about a phenomenon which are, strictly speaking, false, but are used because they serve some purpose in creating the model (Potochnik 2017).\nClassic accounts of neuroscience emphasize analysis at different levels of abstraction (Churchland and Sejnowski 1994; Craver 2007; Marr 1982; Shepherd 1994; Sejnowski, Koch, and Churchland 1988; Wimsatt 1976) (Box 1). However, despite the ubiquity of level-based views of neuroscience and a number of proposed schemes, no consensus can be found on what the relevant levels of abstraction are, or even what defines a level (Guttinger and Love 2019). Suggestions of different level schemes range from those of computational abstraction (Colburn and Shute 2007; Wing 2008), which simplifies a process to be independent of its specific implementation or physical substrate, to levels of conceptual abstraction, which delineate the degree of idealization vs relatability to data (O\u2019Leary, Sutton, and Marder 2015), and levels of physical abstraction, which are used to deal with different spatiotemporal scales (Churchland and Sejnowski 1994). However, recent analyses suggest that natural phenomena are not organized into levels in a universally coherent manner (Potochnik and McGill 2012; Potochnik 2017, 2020). From a pragmatic view, levels of abstraction need not reflect discrete \u201clevels\u201d in nature, but are indicative of our problem-solving strategies and constraints. Because different abstractions can facilitate different research aims (Potochnik 2017), multiple descriptive models are needed to represent the same phenomenon that abstract different features to different degrees.\n[BOX 1 NEAR HERE]\nMechanistic and normative models connect levels of abstraction\nWithout links between them, we would be left with a hodgepodge of different descriptions. However, unification has been noted as a strong desideratum for scientific theories (Schindler 2018; Keas 2018). The relationship between different descriptions of the same phenomena can often be expressed in terms of a mechanistic explanation. For example, we might describe single-neuron activity in terms of membrane currents, or by listing a set of spike times: a natural reduction in the dimensionality that can result from many possible combinations of currents (Golowasch et al. 2002; Prinz, Bucher, and Marder 2004). A mechanistic model (e.g., (Hodgkin and Huxley 1952)) that demonstrates how spike times emerge from currents connects the descriptions at the two levels and, in addition, does so asymmetrically, as it does not claim to be a mechanism by which currents emerge from spike times. By bridging descriptions that each abstract different features to different degrees, mechanistic explanations create a multi-level \u2018mosaic unity\u2019 in neuroscience (Craver 2007), in which descriptions are grounded\nLevenstein et al. - On the role of theory and modeling in neuroscience | 8\n"}, {"chunk": "through their interconnections, and more abstract features are grounded in their emergence from less abstract counterparts (Craver 2007; David M. Kaplan and Bechtel 2011; Bechtel 2008; Craver 2002; Oppenheim and Putnam 1958).\nIn contrast, a normative explanation connects descriptions by appealing to the ability of less abstract features to satisfy a description of more abstract goals. For example, the mammalian hypothalamus could be described as maintaining body temperature like a thermostat (Tan and Knight 2018; Morrison and Nakamura 2011) or as a circuit of interconnected neurons. A normative model connects the two descriptions by explaining the negative feedback loop in the circuit through its ability to achieve those thermostatic functions. Because functions exist over a range of levels, from cellular to behavioral or computational, we could imagine a \u201cmulti-level\u201d approach to understanding the mammalian hypothalamus that in turn uses the goal of a negative feedback loop to explain the developmental processes that establish hypothalamic connectivity. Like their mechanistic counterparts, normative explanations establish links between descriptions which each have their own utility for different problems, by virtue of their unique abstractions.\nThus, the three-fold division of explanatory labor in neuroscience falls naturally into the different roles a model can play in terms of levels of abstraction. Descriptive explanations define abstractions of phenomena at different levels, while mechanistic and normative explanations bridge levels of abstraction. Descriptive models, rather than \u201cmere\u201d descriptions of phenomena (as they\u2019re sometimes dismissed), are the necessary foundation of both normative and mechanistic models. In turn, mechanistic and normative explanations connect a description at a \u201csource\u201d level to a description at a higher or lower \u201ctarget\u201d level (Figure 2). Each of the terms that represent the components of mechanistic models and the constraints of normative models are descriptive models at a lower level of abstraction, while those that represent the emergent properties of mechanistic models and the goals of normative models are descriptive models at a higher level of abstraction. Given their multi-level nature, a dialogue between descriptive, normative, and mechanistic models is needed for a theoretical account of any neuroscientific phenomenon.\n[FIGURE 2 NEAR HERE]\nAt what level of abstraction should a model be built?\nAs different abstractions trade-off advantages and disadvantages, the selection of which abstraction to use is highly dependent on the problem at hand (Herz et al. 2006). Current neuroscientific practice generally attempts two approaches for selecting the appropriate level of abstraction, which serve different purposes. The first approach is to try to find as low a level as possible that still includes experimentally- supported details and accounts for the phenomenon. For example, one might explain the phenomenon of associative memories using compartmental models of pyramidal cell networks, including specific active conductances, dendritic compartments, pharmacological effects on different inputs arriving at different compartments and identifying the consequences for learning and recall (Hasselmo 1993). The multiplicity of parameters and variables used in this approach provides many details that can be matched to observable features of a phenomenon and can capture unexpected properties that emerge from their interaction. However, these details need to be extensively calibrated to ensure the model is accurate, and can be very sensitive to missing, degenerate, or improperly tuned parameters (Traub, Jefferys, and Whittington 1999; Traub et al. 1991). The second approach is to try to find the most abstract level that can still account for the phenomenon. For example, we might instead appeal to the classic Hopfield network, in which units are binary (+1, -1), connections are symmetrical, and are updated using a very simple asynchronous rule (Hopfield 1982; Hertz, Krogh, and Palmer 1991). While more abstract models sacrifice the ability to make predictions about lower level details, their insights are often more robust to specific (e.g. unobserved) physiological details, and by reducing a complicated system to a small number\nLevenstein et al. - On the role of theory and modeling in neuroscience | 9\n"}, {"chunk": "of effective parameters, they allow for powerful analysis on the influences to the system properties. Further, abstract models can provide conceptual benefits such as intuition for how the system works and the ability to generalize to other systems that can be similarly abstracted (Gilead, Trope, and Liberman 2019; Gilead, Liberman, and Maril 2012; O\u2019Leary, Sutton, and Marder 2015).\nAnother important consideration is the ability of models at different levels to interface with different experimental modalities or scientific fields. Every measurement is itself an abstraction, in that it is a reduced description of the part of the universe corresponding to the measurement (Chang 2007b). For example, fMRI measures blood flow across wide swaths of cortex, but abstracts away the interactions between individual neurons, while silicon probes measure extracellular voltage but abstract away intracellular processes, and calcium imaging measures neuronal calcium levels, but abstracts away the electrophysiology of neuronal spiking. All of these are discussed as \u201cneural activity\u201d, but they likely reflect different aspects of learning, performance, and dynamics. Moreover, subsequent processing abstracts these signals even further, such as correlation (functional connectomics) in fMRI, sorting voltage signals into putative cell \u201cspiking\u201d from silicon probes, and treating calcium transients as \u201cevents\u201d from calcium imaging. The abstraction made by one measurement device might lend itself to explanations at a given level, but not others, and the measurements available are important considerations when selecting which abstractions to make in our models.\nSimilarly, models at different levels are often used by distinct scientific fields or communities. The existence of a literature with a rich body of relevant work can provide details and support for components of a model outside of the immediate problem of interest. Integrating theories and models across these different fields can be particularly beneficial for scientific progress (Wu, Wang, and Evans 2019; Grim et al. 2013); however, crossing levels can be a sociological problem as well as a methodological one because different fields of study often use different languages and operate under different conceptual frameworks.\nIn general, it is important that researchers spell out the abstractions being made in their models, including their purposes as well as their limitations. By being concrete about the abstractions made, researchers can increase the reliability of their theories. Importantly, as noted above, it is useful to acknowledge not only the simplifications made about smaller-scale phenomena, but also the simplifications made as to larger-scale interactions that have been abstracted away from a theory.\nTheory development and experimentation\nTraditional views emphasize the use of experiments to test proposed theories (Popper 1959), and even consider an interplay in which theories suggest new experiments and unexpected experimental results reveal the need for new theories (Firestein 2015; Laudan 1978). However, theories do not arise fully- formed, but are developed over time through an interaction with experimentation (Bechtel 2013; Laudan 1978; Hacking 1983; Douglas 2014; Firestein 2015). We now consider two crucial pieces of that dialogue: the domain of a theory, or phenomena it is intended to pertain to, and a translation function, which specifies how it should relate to phenomena in its domain. Experimentation plays two key roles in relation to theory: 1) grounding model assumptions and 2) assessing the quality of model-based explanations. We then discuss an often underappreciated form of experimentation, in which models themselves are the experimental subjects. These modeling experiments allow us to explore the (sometimes hidden or unexpected) implications of a theory itself, identify its underlying inconsistencies, and can be used to predict novel phenomena. Together, this reveals a picture in which theory development is not relegated to simply proposing theories-to-be-tested, but instead entails a complex experimental paradigm in which models play an active role in the simultaneous development, assessment, and utilization of theories within explicit conceptual frameworks.\nLevenstein et al. - On the role of theory and modeling in neuroscience | 10\n"}, {"chunk": "Linking Theory and Phenomena\nThe domain of a theory is the set of phenomena that it purports to explain (Kuhn 2011, 2012; Mitchell, Keller, and Kedar-Cabelli 1986; A. D. Redish 1997). The domain is therefore a set of data-imposed constraints, and the theory should provide an explanation consistent with those constraints. Theoretical studies should be explicit about what phenomena do and do not lie in their intended domain. In practice, nascent theories are often evaluated not only by their ability to explain data in their proposed domain (Feyerabend 1993; Laudan 1978) but also by their potential to expand beyond the initial domain with further development (Lakatos 1978). For example, the theory that action potentials arise from voltage- dependent changes in ionic permeability (Hodgkin and Huxley 1952; Goldman and Morad 1977; Katz 1993; Hille 2001) should apply to the domain of all action potentials in all neurons. Early theories of action potential function identified voltage-gated sodium currents as the primary depolarizing component and formalized their action in models that developed into the Hodgkin-Huxley framework (Hodgkin and Huxley 1952). When some action potentials were later found to be independent of sodium concentrations, it was straightforward to incorporate other voltage-gated channels within the same framework (Hille 2001; Koch and Segev 1989; Gerstner et al. 2014).\nBy instantiating a theory in a specific structure (Rosenblueth and Wiener 1945; Stafford 2009), models play a key role in connecting a theory to phenomena in its domain. However, no model is directly comparable to experimental data by virtue of its structure alone. As noted above, a model also consists of an interpretation of how that structure relates to its target phenomena (Weisberg 2013). This interpretation is specified by a translation function: a statement of how the model\u2019s components map onto its target phenomena. A translation function may be as straightforward as \u201cvariable V represents the membrane potential in millivolts\u201d, but it can also be less constrained, e.g., \u201cvariable V describes the slow changes in the membrane potential and ignores all spiking activity\u201d. In other cases, the translation function can be complex, as parts of the model can have a loose correspondence to general features of large classes of data, and can represent highly abstract effective parameters or qualitative behaviors. For example, the units in Hopfield\u2019s attractor network models (Hopfield 1982; Hopfield and Tank 1985; Hertz, Krogh, and Palmer 1991) are not meant to directly correspond to measurable properties of biological neurons, but are instead intended to reflect qualitative features, namely that neural populations are \u201cactive\u201d or not. In effect, the translation function spells out the abstractions made by the model. Specifying the translation function of a model is as important as defining its structure (Weisberg 2013). While these descriptions are often provided for highly abstract models, models that describe finer spatio-temporal scales (such as detailed compartmental models of neurons) are often considered to be \u201cbiologically realistic\u201d and assume a simple or obvious translation function. However, it is important to remember that these models are also abstractions, albeit at a different level, and a proper description of the abstractions made will help clarify both the uses and the limitations of such models. By specifying the intended correspondence between model terms and phenomena, the translation function operationalizes the concepts associated with those terms in the theory (Bridgman 1927; Chang 2007a).\n[FIGURE 3 NEAR HERE]\nExperiments ground model assumptions\nWith a well-defined translation function in hand, we can now consider the ways in which models are informed by experimental data. As outlined above, the components of descriptive, mechanistic, and normative models are each based on a different set of foundational assumptions. These assumptions are not generally arbitrary, but are informed by experimental observations and results.\nDescriptive models are founded on an assumed relationship between variables, which is generally formulated to capture an observed regularity in experimental data. These initial observations often rely on \u201cexploratory\u201d experiments, which attempt to identify empirical regularities and the constructs with which to\nLevenstein et al. - On the role of theory and modeling in neuroscience | 11\n"}, {"chunk": "describe them (Steinle 1997). In specifying the characteristic properties of a phenomenon, descriptive explanations delineate the attributes that are expected to be replicable in future experiments and play a foundational role in subsequent mechanistic and normative models. This is extremely important for the current replication controversy (Baker 2016; Goodman, Fanelli, and Ioannidis 2016; Fanelli 2018; A. D. Redish et al. 2018). A recent National Academy report (National Academies of Sciences and Medicine 2019) characterizes replicability as the ability to obtain consistent results across multiple studies, and contrasts it with reproducibility, defined as the ability to get the same results when applying the same analyses to the same data. Several authors have suggested that the replication crisis is in fact a crisis of theory development, as it is the scientific claims (not data) that should be replicable (drugmonkey 2018; A. D. Redish et al. 2018; Smaldino 2019). We suggest that this crisis stems from three sources: 1) a failure to define domains correctly, assuming that limited observations correspond to a much larger range of phenomena than they actually do, 2) a failure to formalize observations in adequate descriptive models (e.g., an overreliance on correlation, or assumed simple relationships), and 3) a failure to connect those descriptive models with mechanistic or normative models that integrate descriptions at different levels of abstraction.\nMechanistic models are founded on a set of parts and interactions that are assumed to be relevant to a target phenomenon. The existence of candidate parts/interactions can be informed by experimental observations, and their relevance (or irrelevance) to a given target phenomenon is often derived from experimental or natural interventions (Pearl 2009). Once the decision is made to include a part/interaction in a mechanistic model, its corresponding terms can be parameterized by virtue of the descriptive models at their source level of abstraction. For example, when trying to explain the phenomenon of burst spiking in thalamocortical neurons, we might observe the presence of a hyperpolarization-activated current (Ih) which, when blocked, disrupts burst spiking (McCormick and Pape 1990). We can then calibrate the parameters used to model Ih with values acquired through slice experiments.\nExperimental data can also inform the founding assumptions (goal/constraints) of normative models. For example, when trying to explain the responses of visual neurons, we might parameterize the constraints of an efficient coding model with data from retinal photoreceptors (Field and Rieke 2002). As with mechanistic models, normative parameters rely on the descriptive models we have for photoreceptor properties. However, grounding an assumed function (e.g. \u201cvision\u201d) in experimental data can be more challenging. This arises from a notable asymmetry between mechanistic and normative approaches: while the founding assumptions of a mechanistic model (parts/interactions) are less abstract than their target phenomena, the founding assumptions of normative approaches (a function/goal) are generally more abstract than the phenomenon they are used to explain. This often results in normative approaches being termed \u201ctop-down\u201d, in contrast to \u201cbottom-up\u201d mechanistic modeling. In practice, functions are often operationalized via performance on a specified task, rendering them groundable in experimental data. For example, the assumed goal of primate facial recognition areas is grounded in the change in facial recognition abilities when those neural systems are manipulated or absent, neural responses to facial stimuli, and in the coupling of those areas with sensory and motor areas providing a behavioral circuit (Gross, Bender, and Rocha-Miranda 1969; Tsao et al. 2006; Moeller et al. 2017; Grimaldi, Saleem, and Tsao 2016).\nExperiments assess solution quality\nAs has been noted by many previous authors, we cannot definitively \u201cconfirm\u201d theories (Popper 1959), nor can we definitively test/falsify the validity of a theory in isolation (Duhem 1991; Lakatos 1980). However, a theory\u2019s utility does not require absolute confidence in its validity, but only a track record of solving problems in its domain. By instantiating theories in a model with a well-defined translation function, we can assess the quality of solutions proposed with a given theory by comparing the behavior of those models to experimental observations.\nLevenstein et al. - On the role of theory and modeling in neuroscience | 12\n"}, {"chunk": "In the case of descriptive models, model fitting can estimate confidence intervals and goodness-of-fit for the best-fitting parameter values, and can even be used to quantitatively compare candidate models to determine which can best explain experimental data with the fewest parameters. A researcher might build a mechanistic model with terms that correspond to the proposed parts to see if they are able to reproduce features of the data, or test the model\u2019s ability to predict the effect of experimental manipulations. Alternatively, a researcher can hypothesize that the system is performing some function, make a normative model that instantiates the goal, and see if properties of the data match those expected from a system optimizing that goal. In these \u201cconfirmatory\u201d (theory-driven/hypothesis-testing) experiments, models are used to apply existing theories to account for observed phenomena, compare possible instantiations of a theory, or even compare theories with overlapping domains to see which better accounts for the phenomenon. In each case, the assumptions of the model act as a hypothesis and the degree of similarity between model and experimental data is used to assess the sufficiency of a theory (and its specific model instantiation) to account for a phenomenon.\nHowever, the value of modeling is often in its ability to show insufficiency of a theory/model to account for experimental data. Rather than invalidating the theory, this can often prompt updates to the theory or a search for yet-unobserved relevant phenomena. For example, early models of head-direction tuning found that a mechanism based on attractor networks required recurrent connections not supported by anatomical data (A. D. Redish, Elga, and Touretzky 1996). This incompatibility led to subsequent analyses which found that the tuning curves were more complicated than originally described, matching those seen in the model without the recurrent connections (Blair, Lipscomb, and Sharp 1997). Similarly, the usefulness of normative models often lies in their ability to identify when a system is performing suboptimally (Parker and Smith 1990). Such a finding can provide additional information about unexpected functions or constraints. When there is a mismatch between a normative model and observed phenomena, one could hypothesize that the agent is optimizing a different goal (Fehr and Schmidt 1999; Binmore 2005), new constraints that limit the processes available (Simon 1972; Mullainathan 2002), historical processes that could limit the optimization itself (Gould and Lewontin 1979; Gould 1983), or computational processes that limit the calculations available to the system (A. David Redish 2013; Nadel 1994; Schacter 2001; Webb, Glimcher, and Louie 2021). For instance, several studies have found that foraging subjects tend to remain at reward sites longer than needed (Nonacs 2001; Camerer 1997; Carter and Redish 2016) and accept longer-delay offers than would be expected to maximize total reward (Wikenheiser, Stephens, and Redish 2013; Sweis et al. 2018; Schmidt, Duin, and Redish 2019; Sweis, Thomas, and Redish 2018). However, optimality could be restored by assuming an additional factor in the cost function (Simon 1972) subsequently characterized as \u201cregret\u201d: an increased cost of making a mistake of one\u2019s own agency compared to equivalently poor outcomes that were not due to recognizable mistakes (Wikenheiser, Stephens, and Redish 2013; Steiner and Redish 2014; Sweis, Thomas, and Redish 2018; Zeelenberg et al. 2000; Coricelli et al. 2005). Similarly, Fehr and colleagues have found that normative explanations of behavior in a multi-player game require an additional component with information about one\u2019s companion\u2019s success in addition to one\u2019s own, in order to account for the observed behavior (Fehr and Krajbich 2014; Fehr and Schmidt 1999; Binmore 2005).\nModeling experiments explore theory implications\nConfirmatory experiments can even be carried out without direct comparison to data, as phenomena at both the target and source levels of abstraction can be pure theoretical entities. Similar to their benchtop counterparts, we can treat different parameters or model instantiations as independent variables in the experiment, and test their sufficiency to account for different aspects of the phenomenon as the dependent variables (Omar, Aldrich, and Gerkin 2014; Gerkin, Jarvis, and Crook 2018). One can use these models as experiments to test the feasibility of theoretical claims in tractable idealized systems. For example, Hopfield\u2019s attractor network models (Hopfield 1982; Hopfield and Tank 1985) provided strong support for Hebb\u2019s theory (Hebb 1949) that increased connectivity from co-active firing could create\nLevenstein et al. - On the role of theory and modeling in neuroscience | 13\n"}, {"chunk": "associative memory, by showing that strong connections between simple neuron-like entities were sufficient to produce cell assemblies that could be accessed through a pattern-completion process (Hertz, Krogh, and Palmer 1991).\nLike their physical analogues (e.g. the 6-OHDA rat or the MPTP monkey), models can be used for exploratory experiments as well. Exploration of the Hopfield model (Hopfield 1982; Hopfield and Tank 1985; Kohonen 1984, 1980) revealed novel properties of categorization, tuning curves, and pattern completion in the neuron-like entities, which were later identified experimentally (K. Obermayer, Blasdel, and Schulten 1992; Klaus Obermayer et al. 2001; Swindale and Bauer 1998; Swindale 2004; de Villers- Sidani and Merzenich 2011; Nahum, Lee, and Merzenich 2013; Freedman et al. 2001, 2003; Lakoff 1990; Rosch 1983; Wills et al. 2005; L. L. Colgin et al. 2010; Yang and Shadlen 2007; Jezek et al. 2011; Kelemen and Fenton 2016). Exploratory modeling experiments can instantiate idealized aspects of a theory to help build intuition for the theory itself. Hopfield\u2019s model and its subsequent derivatives have provided researchers with a deeper understanding of how memories can be accessed by content through pattern-completion processes and given rise to concepts such as \u201cbasins of attraction\u201d (Hopfield 1982; Hertz, Krogh, and Palmer 1991). These computational discoveries can help build understanding of the theory, and lead to predictions and ideas for new experiments.\nModeling experiments are especially useful in the context of theory development (Guest and Martin 2020). When a phenomenon cannot be readily explained using an existing theory, assumptions can be made as the basis of a modeling experiment. The behavior of this model can then be used to evaluate the sufficiency of these assumptions to account for the phenomenon. Often, these modeling experiments precede a well-formed theory, and a theorist will perform numerous experiments with different models in the process of developing a theory (van Rooij and Baggio 2020). Over time, specific successful model formulations can become closely associated with the theory and develop into its canonical instantiations that make the theory applicable to a wider range of problems and give more precise solutions.\n[BOX 2 NEAR HERE]\nConclusions\nA scientific theory is a thinking tool: a set of ideas used to solve specific problems. We can think of theoretical neuroscience as a field which approaches problems in neuroscience with the following problem-solving methodology: theories exist within conceptual frameworks and are instantiated in models which, by virtue of a translation function, can be used to assess a theory\u2019s ability to account for phenomena in the theory\u2019s domain or explore its further implications. (See Figure 3.)\nWe identified three kinds of explanations that play distinct roles in this process: those in which descriptive theories and models are used to define the abstractions by which we describe a phenomenon; those in which mechanistic theories and models are used to explain phenomena in terms of lower-level parts and their interactions; and those in which normative theories and models are used to explain phenomena in terms of a function at a higher level of abstraction.\nThese considerations lead to a more concrete view of theory in neuroscience under the pragmatic view: a theory is a set of assumptions available to be instantiated in models, whose adequacy for problems in their domain has been vetted via experimentation, and with a well-established translation function that defines their connection to phenomena. Over time and through the development of canonical model formulations, theories become more rigorous, such that researchers agree on how they should be implemented to explain specific domains. A theory in this sense is not a formal set of laws, but a continuously developing body of canonical models and model-phenomenon correspondences, bound together partly by history and partly by shared problem-solving methods and standards (Bechtel 1993).\nLevenstein et al. - On the role of theory and modeling in neuroscience | 14\n"}, {"chunk": "What recommendations can we take away from this perspective? First and foremost, that scientists should be explicit about the underlying components of their theory. Reliability of theoretical work depends on being explicit about the domain that the theory purports to cover, the abstractions used (what has been ignored and left out), and the translation function to connect the theory to actual measurements. Furthermore, thinking of the pragmatic aspects suggests being explicit about what problems the work proposes to solve, what conceptual frameworks the theory fits in, and what the founding assumptions of the models are.\nFinally, it is interesting to consider that we might apply our taxonomy to our own framework. The concept that \u2018the ultimate goal of a theory is to provide tools that allow one to better explain and control one\u2019s environment\u2019 is a normative theory of the goal of scientific theories; the concept that \u2018models instantiate theories and allow one to test their viability and their relationship to phenomena\u2019 is a mechanistic theory of how those theories achieve that goal; and the concept that \u2018theories live within a framework that a community applies to them\u2019 is a descriptive theory of theories. One could imagine a metascientific research program which studies the available phenomena - for example, the scientific literature - to test and further develop those theories, and even the use of models of the scientific process itself (e.g. (Devezer et al. 2019)). The benefits of such a research program could prove as impactful for scientific practice as other theories have proven for manipulation of phenomena in their domain.\nLevenstein et al. - On the role of theory and modeling in neuroscience | 15\n"}, {"chunk": "Figure captions\nFigure 1: The three explanatory processes that underlie scientific explanations. Descriptive theories address the question of \u201cwhat is the phenomenon?\u201d and identify the repeatable characteristics of that phenomenon. Mechanistic theories address the question of \u201chow does the phenomenon arise?\u201d and explains the phenomenon in terms of the parts and interactions of other phenomena at lower levels of abstraction. Normative theories address the question of \u201cwhy do the phenomena exist?\u201d and allow a comparison of the phenomenon to an identified function or goal. Normative theories allow the determination of whether a process is achieving its goal \u2014 inadequacies generally imply an incomplete understanding of the limitations engendered by processes at a lower level of abstraction.\nFigure 2: Interactions between three explanatory processes and levels of abstraction. Descriptive explanations define an idealized abstraction of specific aspects of a phenomenon for discussion, measurement, and repeatability. Mechanistic explanations account for properties of a phenomenon by their emergence from less abstract phenomena, while normative explanations account for those properties by appealing to their ability to perform more abstract goals.\nFigure 3: How the various components discussed in this manuscript interact. The domain of a theory is the set of phenomena which it purports to explain. Theories are instantiated in models, which are an abstraction of phenomena in the domain, as specified by a translation function. By constraining the form solutions can take, a conceptual framework defines a way of looking at a problem, within which models and theories can be proposed. Note that a given model can instantiate more than one theory and a theory can be instantiated by more than one model.\nTable captions\nTable 1: Terminology used in this manuscript. Three neuroscience examples.\nBox captions\nBox 1: Levels of abstraction\nBox 2: What makes a good neuroscientific theory? What makes a good model?\nLevenstein et al. - On the role of theory and modeling in neuroscience | 16\n"}, {"chunk": "Acknowledgments\nThis paper is the result of discussions as part of the workshop \u201cTheoretical and Future Theoretical Frameworks in Neuroscience\u201d (San Antonio, TX, Feb 4-8, 2019) supported by the NSF grants DBI- 1820631 (HGR) and IOS-1516648 (FS). The authors acknowledge support from the grants NIH T90DA043219 and The Samuel J. and Joan B. Williamson Fellowship (DL),\nNSF CRCNS-DMS-1608077, NSF-IOS 2002863 (HGR), NIH MH060605 (FN), NIH MH080318, MH119569,\nand MH112688 (ADR).\nThe authors further acknowledge the University of Texas at San Antonio (UTSA) Neuroscience Institute and the New Jersey Institute of Technology (NJIT) Department of Biological Sciences and Institute for Brain and Neuroscience Research for technical support in the organization of the workshop, as well as all of the participants in the workshop. We thank Erich Kummerfeld, Hal Greenwald, Kathryn McClain, Simo\u0301n(e) Sun, and Gyo\u0308rgy Buzsa\u0301ki for comments on parts of the manuscript, and Matt Chafee and Sophia Vinogradov for help with citations.\n DDIR Innovation Award, NIH (VA), MH118928 (ZSC), NINDS 1U19NS112953, NIDCD 1R01DC018455,\nIRP-NIH ZIA-AA000421 and\n  NIMH 1R01MH106674, NIBIB 1R01EB021711 (RCG), NIDCD R01DC014101, Hearing Research\n Incorporated, Sandler Foundation (AH), H2020 GAMMA-MRI (964644) and H2020 IN-FET (862882)\n (RBJ), NINDS 1R03NS109923 and NSF/NCS-FO 1835279 (JDM), NIMH-NIBIB BRAIN Theories\n 1R01EB026939 (FS), IBM Exploratory Research Councils (RT), DOD ARO W911F-15-1-0426 (AA),\nLevenstein et al. - On the role of theory and modeling in neuroscience | 17\n"}, {"chunk": "References\nAkerlof, George A. 1978. \u201cThe Market for \u2018lemons\u2019: Quality Uncertainty and the Market Mechanism.\u201d In Uncertainty in Economics, 235\u201351. Elsevier.\nAlon, Uri. 2006. An Introduction to Systems Biology: Design Principles of Biological Circuits. Chapman and Hall/CRC.\nAmerican Psychiatric Association. 2013. Diagnostic and Statistical Manual of Mental Disorders (DSM-5\u00ae). American Psychiatric\nPub.\nAristotle. n.d. Physics. Translated by R. P. Hardie and R. K. Gaye. Internet Classics Archive.\nBaker, Monya. 2016. \u201c1,500 Scientists Lift the Lid on Reproducibility.\u201d Nature 533 (7604): 452\u201354.\nBalleine, B. W., and A. Dickinson. 1998. \u201cGoal-Directed Instrumental Action: Contingency and Incentive Learning and Their Cortical\nSubstrates.\u201d Neuropharmacology 37 (4-5): 407\u201319.\nBarlow, Horace B. 1961. \u201cPossible Principles Underlying the Transformation of Sensory Messages.\u201d Sensory Communication 1:\n217\u201334.\nBarry, C., C. Lever, R. Hayman, T. Hartley, S. Burton, J. O\u2019Keefe, K. Jeffery, and N. Burgess. 2006. \u201cThe Boundary Vector Cell\nModel of Place Cell Firing and Spatial Memory.\u201d Reviews in the Neurosciences 17 (1-2): 71\u201397.\nBechtel, William. 1993. \u201cIntegrating Sciences by Creating New Disciplines: The Case of Cell Biology.\u201d Biology and Philosophy 8 (3):\n277\u201399.\n\u2014\u2014\u2014. 2008. \u201cMechanisms in Cognitive Psychology: What Are the Operations?\u201d Philosophy of Science 75 (5): 983\u201394. \u2014\u2014\u2014. 2013. Philosophy of Science: An Overview for Cognitive Science. Psychology Press.\nBechtel, William, and Robert C. Richardson. 2010. Discovering Complexity: Decomposition and Localization as Strategies in\nScientific Research. MIT Press.\nBen-Ari, Moti. 2011. Just A Theory: Exploring The Nature Of Science. Prometheus Books.\nBialek, William. 2012. Biophysics: Searching for Principles. Princeton University Press.\n\u2014\u2014\u2014. 2018. \u201cPerspectives on Theory at the Interface of Physics and Biology.\u201d Reports on Progress in Physics 81 (1): 012601. Bialek, William, and Sima Setayeshgar. 2008. \u201cCooperativity, Sensitivity, and Noise in Biochemical Signaling.\u201d Physical Review\nLetters 100 (25): 258101.\nBinmore, Ken. 2005. Natural Justice. Oxford University Press.\nBlair, H. T., B. W. Lipscomb, and P. E. Sharp. 1997. \u201cAnticipatory Time Intervals of Head-Direction Cells in the Anterior Thalamus of\nthe Rat, Implications for Path Integration in the Head-Direction Circuit.\u201d Journal of Neurophysiology 78 (1): 145\u201359. Bo\u0308rgers, Christoph. 2017. An Introduction to Modeling Neuronal Dynamics. Springer International Publishing. Bridgman, Percy W. 1927. \u201cThe Logic of Modern Physics.\u201d New York.\nCamerer, Colin F. 1997. \u201cTaxi Drivers and Beauty Contests.\u201d Engineering and Science 60 (1): 10\u201319.\nCarter, Evan C., and A. David Redish. 2016. \u201cRats Value Time Differently on Equivalent Foraging and Delay-Discounting Tasks.\u201d Journal of Experimental Psychology. General 145 (9): 1093\u20131101.\nCartwright, Nancy. 1997. \u201cModels: The Blueprints for Laws.\u201d Philosophy of Science 64 (December): S292\u2013303.\nChang, Hasok. 2007a. Inventing Temperature: Measurement and Scientific Progress. Oxford University Press.\n\u2014\u2014\u2014. 2007b. \u201cScientific Progress: Beyond Foundationalism and Coherentism 1.\u201d Royal Institute of Philosophy Supplements 61: 1\u2013\n20.\n\u2014\u2014\u2014. 2011. \u201cThe Persistence of Epistemic Objects Through Scientific Change.\u201d Erkenntnis. An International Journal of Analytic\nPhilosophy 75 (3): 413\u201329.\nChurchland, P., and T. J. Sejnowski. 1994. The Computational Brain. MIT Press.\nColburn, Timothy, and Gary Shute. 2007. \u201cAbstraction in Computer Science.\u201d Minds and Machines 17 (2): 169\u201384. Colgin, Laura Lee. 2020. \u201cFive Decades of Hippocampal Place Cells and EEG Rhythms in Behaving Rats.\u201d The Journal of\nNeuroscience. https://doi.org/10.1523/jneurosci.0741-19.2019.\nColgin, L. L., S. Leutgeb, K. Jezek, J. K. Leutgeb, E. I. Moser, B. L. McNaughton, and M-B Moser. 2010. \u201cAttractor-Map Versus\nAutoassociation Based Attractor Dynamics in the Hippocampal Network.\u201d Journal of Neurophysiology.\nCoricelli, Giorgio, Hugo D. Critchley, Mateus Joffily, John P. O\u2019Doherty, Angela Sirigu, and Raymond J. Dolan. 2005. \u201cRegret and Its\nAvoidance: A Neuroimaging Study of Choice Behavior.\u201d Nature Neuroscience 8: 1255\u201362.\nCraver, Carl F. 2002. \u201cInterlevel Experiments and Multilevel Mechanisms in the Neuroscience of Memory.\u201d Philosophy of Science 69\n(S3): S83\u201397.\n\u2014\u2014\u2014. 2007. Explaining the Brain: Mechanisms and the Mosaic Unity of Neuroscience. Clarendon Press.\nCuthbert, Bruce N., and Thomas R. Insel. 2013. \u201cToward the Future of Psychiatric Diagnosis: The Seven Pillars of RDoC.\u201d BMC\nMedicine 11 (May): 126.\nDaw, Nathaniel D., Yael Niv, and Peter Dayan. 2005. \u201cUncertainty-Based Competition between Prefrontal and Dorsolateral Striatal\nSystems for Behavioral Control.\u201d Nature Neuroscience 8: 1704\u201311.\nDayan, P., and L. F. Abbott. 2001. Theoretical Neuroscience. MIT Press.\nDennett, Daniel Clement. 1989. The Intentional Stance. MIT Press.\nDescartes, Rene\u0301. 1637. Discours de La Me\u0301thode Pour Bien Conduire Sa Raison, et Chercher La Ve\u0301rite\u0301 Dans Les Sciences. Destexhe, Alain, and Terrence J. Sejnowski. 2009. \u201cThe Wilson\u2013Cowan Model, 36 Years Later.\u201d Biological Cybernetics 101 (1): 1\u20132. Devezer, Berna, Luis G. Nardin, Bert Baumgaertner, and Erkan Ozge Buzbas. 2019. \u201cScientific Discovery in a Model-Centric\nFramework: Reproducibility, Innovation, and Epistemic Diversity.\u201d PloS One 14 (5): e0216125.\nDoi, E., and M. Lewicki. 2014. \u201cOptimal Retinal Population Coding Predicts Inhomogeneous Light Adaptation and Contrast\nSensitivity across the Visual Field.\u201d Journal of Vision. https://doi.org/10.1167/14.10.1188.\nDorval, Alan D., and Warren M. Grill. 2014. \u201cDeep Brain Stimulation of the Subthalamic Nucleus Reestablishes Neuronal Information\nTransmission in the 6-OHDA Rat Model of Parkinsonism.\u201d Journal of Neurophysiology 111: 1949\u201359.\nDouglas, Heather. 2014. \u201cPure Science and the Problem of Progress.\u201d Studies in History and Philosophy of Science 46 (June): 55\u2013\n63.\ndrugmonkey. 2018. \u201cGeneralization, Not \u2018reproducibility.\u2019\u201d Drugmonkey. February 27, 2018.\nhttps://drugmonkey.scientopia.org/2018/02/26/generalization-not-reproducibility/.\nDuhem, Pierre Maurice Marie. 1991. The Aim and Structure of Physical Theory. Princeton University Press.\nLevenstein et al. - On the role of theory and modeling in neuroscience | 18\n"}, {"chunk": "Ellner, Stephen P., and John Guckenheimer. 2006. Dynamic Models in Biology. Princeton University Press.\nErmentrout, G. Bard, and David H. Terman. 2010. Mathematical Foundations of Neuroscience. Springer Science & Business Media. Eronen, Markus I., and Daniel Stephen Brooks. 2018. \u201cLevels of Organization in Biology.\u201d In The Stanford Encyclopedia of\nPhilosophy, edited by Edward N. Zalta, Spring 2018. Metaphysics Research Lab, Stanford University.\nhttps://plato.stanford.edu/archives/spr2018/entries/levels-org-biology/.\nFanelli, Daniele. 2018. \u201cOpinion: Is Science Really Facing a Reproducibility Crisis, and Do We Need It To?\u201d Proceedings of the\nNational Academy of Sciences of the United States of America 115 (11): 2628\u201331.\nFehr, Ernst, and Ian Krajbich. 2014. \u201cSocial Preferences and the Brain.\u201d In Neuroeconomics (Second Edition), 193\u2013218. Elsevier. Fehr, Ernst, and Klaus M. Schmidt. 1999. \u201cA Theory of Fairness, Competition, and Cooperation.\u201d The Quarterly Journal of\nEconomics 114 (3): 817\u201368.\nFeyerabend, Paul. 1993. Against Method. Verso.\nField, Greg D., and Fred Rieke. 2002. \u201cNonlinear Signal Transfer from Mouse Rods to Bipolar Cells and Implications for Visual\nSensitivity.\u201d Neuron 34 (5): 773\u201385.\nFirestein, Stuart. 2012. Ignorance: How It Drives Science. Oxford University Press, USA.\n\u2014\u2014\u2014. 2015. Failure: Why Science Is So Successful. Oxford University Press.\nFox, J. 2009. The Myth of the Rational Market: A History of Risk, Reward, and Delusion on Wall Street. HarperCollins e-books. Fraassen, B. C. van. 1980. The Scientific Image. Clarendon Press.\nFreedman, David J., Maximilian Riesenhuber, Tomaso Poggio, and Earl K. Miller. 2001. \u201cCategorical Representation of Visual\nStimuli in the Primate Prefrontal Cortex.\u201d Science 291 (5502): 312\u201316.\n\u2014\u2014\u2014. 2003. \u201cA Comparison of Primate Prefrontal and Inferior Temporal Cortices during Visual Categorization.\u201d The Journal of\nNeuroscience: The Official Journal of the Society for Neuroscience 23 (12): 5235\u201346.\nFrigg, Roman, and Stephan Hartmann. 2006. \u201cModels in Science.\u201d https://seop.illc.uva.nl/entries/models-science/.\nFuhs, Mark C., and David S. Touretzky. 2006. \u201cA Spin Glass Model of Path Integration in Rat Medial Entorhinal Cortex.\u201d The Journal\nof Neuroscience: The Official Journal of the Society for Neuroscience 26 (16): 4266\u201376.\nGabbiani, Fabrizio, and Steven James Cox. 2017. Mathematics for Neuroscientists. Academic Press.\nGerkin, Richard C., Russell J. Jarvis, and Sharon M. Crook. 2018. \u201cTowards Systematic, Data-Driven Validation of a Collaborative,\nMulti-Scale Model of Caenorhabditis Elegans.\u201d Philosophical Transactions of the Royal Society of London. Series B, Biological\nSciences 373 (1758). https://doi.org/10.1098/rstb.2017.0381.\nGerstner, Wulfram, Werner M. Kistler, Richard Naud, and Liam Paninski. 2014. Neuronal Dynamics: From Single Neurons to\nNetworks and Models of Cognition. Cambridge University Press.\nGigerenzer, Gerd, and Wolfgang Gaissmaier. 2011. \u201cHeuristic Decision Making.\u201d Annual Review of Psychology 62: 451\u201382. Gilead, Michael, Nira Liberman, and Anat Maril. 2012. \u201cConstruing Counterfactual Worlds: The Role of Abstraction.\u201d European\nJournal of Social Psychology. https://doi.org/10.1002/ejsp.1862.\nGilead, Michael, Yaacov Trope, and Nira Liberman. 2019. \u201cAbove and Beyond the Concrete: The Diverse Representational\nSubstrates of the Predictive Brain.\u201d The Behavioral and Brain Sciences, July, 1\u201363.\nGiocomo, Lisa M., May-Britt Moser, and Edvard I. Moser. 2011. \u201cComputational Models of Grid Cells.\u201d Neuron 71 (4): 589\u2013603. Glausier, J. R., and D. A. Lewis. 2013. \u201cDendritic Spine Pathology in Schizophrenia.\u201d Neuroscience 251 (October): 90\u2013107. Godfrey-Smith, Peter. 2003. \u201cAn Introduction to the Philosophy of Science: Theory and Reality.\u201d Chicago: University of Chicago\nPress.\nGoldman, Y., and M. Morad. 1977. \u201cIonic Membrane Conductance during the Time Course of the Cardiac Action Potential.\u201d The\nJournal of Physiology 268 (3): 655\u201395.\nGoldstein, Raymond E. 2018. \u201cAre Theoretical Results \u2018Results\u2019?\u201d eLife 7 (July). https://doi.org/10.7554/eLife.40018. Golowasch, J., M. S. Goldman, L. F. Abbott, and E. Marder. 2002. \u201cFailure of Averaging in the Construction of a Conductance-\nBased Neuron Model.\u201d Journal of Neurophysiology 87: 1129\u201331.\nGoodman, Steven N., Daniele Fanelli, and John P. A. Ioannidis. 2016. \u201cWhat Does Research Reproducibility Mean?\u201d Science\nTranslational Medicine 8 (341): 341ps12.\nGould, S. J. 1983. Hen\u2019s Teeth and Horse's Toes. Norton.\nGould, S. J., and R. C. Lewontin. 1979. \u201cThe Spandrels of San Marco and the Panglossian Paradigm: A Critique of the Adaptationist\nProgramme.\u201d Proceedings of the Royal Society of London. Series B, Containing Papers of a Biological Character. Royal\nSociety 205 (1161): 581\u201398.\nGrimaldi, Piercesare, Kadharbatcha S. Saleem, and Doris Tsao. 2016. \u201cAnatomical Connections of the Functionally Defined \u2018Face\nPatches\u2019 in the Macaque Monkey.\u201d Neuron 90 (6): 1325\u201342.\nGrim, Patrick, Daniel J. Singer, Steven Fisher, Aaron Bramson, William J. Berger, Christopher Reade, Carissa Flocken, and Adam\nSales. 2013. \u201cScientific Networks on Data Landscapes: Question Difficulty, Epistemic Success, and Convergence.\u201d Episteme\n10 (4): 441\u201364.\nGross, C. G., D. B. Bender, and C. E. Rocha-Miranda. 1969. \u201cVisual Receptive Fields of Neurons in Inferotemporal Cortex of the\nMonkey.\u201d Science 166 (3910): 1303\u20136.\nGuest, Olivia, and Andrea E. Martin. 2020. \u201cHow Computational Modeling Can Force Theory Building in Psychological Science.\u201d\nhttps://doi.org/10.31234/osf.io/rybh9.\nGutenkunst, Ryan N., Joshua J. Waterfall, Fergal P. Casey, Kevin S. Brown, Christopher R. Myers, and James P. Sethna. 2007.\n\u201cUniversally Sloppy Parameter Sensitivities in Systems Biology Models.\u201d PLoS Computational Biology 3 (10): 1871\u201378. Guttinger, Stephan, and Alan C. Love. 2019. \u201cCharacterizing Scientific Failure: Putting the Replication Crisis in Context.\u201d EMBO\nReports 20 (9): e48765.\nHacking, Ian. 1983. Representing and Intervening: Introductory Topics in the Philosophy of Natural Science. Cambridge University\nPress.\nHaig, Brian D. 1987. \u201cScientific Problems and the Conduct of Research.\u201d Educational Philosophy and Theory 19 (2): 22\u201332. Hamrick, Jessica B., Abram L. Friesen, Feryal Behbahani, Arthur Guez, Fabio Viola, Sims Witherspoon, Thomas Anthony, Lars\nBuesing, Petar Velic\u030ckovic\u0301, and The\u0301ophane Weber. 2020. \u201cOn the Role of Planning in Model-Based Deep Reinforcement\nLearning.\u201d arXiv [cs.AI]. arXiv. http://arxiv.org/abs/2011.04021.\nHartley, T., N. Burgess, C. Lever, F. Cacucci, and J. O\u2019Keefe. 2000. \u201cModeling Place Fields in Terms of the Cortical Inputs to the\nHippocampus.\u201d Hippocampus 10: 369\u201379.\nHasselmo, M. E. 1993. \u201cAcetylcholine and Learning in a Cortical Associative Memory.\u201d Neural Computation 5: 32\u201344.\nLevenstein et al. - On the role of theory and modeling in neuroscience | 19\n"}, {"chunk": "Ha\u0308usser, Michael, and Bartlett Mel. 2003. \u201cDendrites: Bug or Feature?\u201d Current Opinion in Neurobiology 13 (3): 372\u201383. Hebb, D. O. 1949. The Organization of Behavior. New York: Wiley.\nHempel, Carl G., and Paul Oppenheim. 1948. \u201cStudies in the Logic of Explanation.\u201d Philosophy of Science 15 (2): 135\u201375. Hertz, J., A. Krogh, and R. G. Palmer. 1991. Introduction to the Theory of Neural Computation. Reading MA: Addison-Wesley. Herz, Andreas V. M., Tim Gollisch, Christian K. Machens, and Dieter Jaeger. 2006. \u201cModeling Single-Neuron Dynamics and\nComputations: A Balance of Detail and Abstraction.\u201d Science 314 (5796): 80\u201385.\nHille, Bertil. 2001. Ion Channels of Excitable Membranes. Sinauer.\nHodgkin, A. L., and A. F. Huxley. 1952. \u201cA Quantitative Description of Membrane Current and Its Application to Conduction and\nExcitation in Nerve.\u201d The Journal of Physiology 117: 500\u2013544.\nHopfield, J. J. 1982. \u201cNeural Networks and Physical Systems with Emergent Collective Computational Abilities.\u201d Proceedings of the\nNational Academy of Sciences of the United States of America 79: 2554\u201358.\nHopfield, J. J., and D. Tank. 1985. \u201c``Neural\u2019' Computation of Decisions in Optimization Problems.\u201d Biological Cybernetics 52: 141\u2013\n52.\nHowes, Oliver D., Robert McCutcheon, Michael J. Owen, and Robin M. Murray. 2017. \u201cThe Role of Genes, Stress, and Dopamine in\nthe Development of Schizophrenia.\u201d Biological Psychiatry 81 (1): 9\u201320.\nHunt, L. T., N. D. Daw, P. Kaanders, M. A. MacIver, U. Mugan, E. Procyk, A. D. Redish, et al. 2021. \u201cFormalizing Planning and\nInformation Search in Naturalistic Decision-Making.\u201d Nature Neuroscience. https://doi.org/10.1038/s41593-021-00866-w. Huys, Quentin J. M., Tiago V. Maia, and Michael J. Frank. 2016. \u201cComputational Psychiatry as a Bridge from Neuroscience to\nClinical Applications.\u201d Nature Neuroscience 19 (3): 404\u201313.\nInsel, Thomas R., and Bruce N. Cuthbert. 2015. \u201cMedicine. Brain Disorders? Precisely.\u201d Science 348 (6234): 499\u2013500. Izhikevich, Eugene M. 2007. Dynamical Systems in Neuroscience. MIT Press.\nJalics, J., M. Krupa, and H. G. Rotstein. 2010. \u201cA Novel Mechanism for Mixed-Mode Oscillations in a Neuronal Model.\u201d Dynamical\nSystems: An International Journal iFirst, 1\u201338.\nJames, William. 1907. \u201cPragmatism: A New Name for Some Old Ways of Thinking.\u201d https://doi.org/10.1037/10851-000.\nJezek, K., E. J. Henriksen, A. Treves, E. I. Moser, and M. B. Moser. 2011. \u201cTheta-Paced Flickering between Place-Cell Maps in the\nHippocampus.\u201d Nature 478 (7368): 246\u201349.\nKahneman, Daniel, Jack L. Knetsch, and Richard H. Thaler. 1991. \u201cThe Endowment Effect, Loss Aversion, and Status Quo Bias.\u201d\nThe Journal of Economic Perspectives: A Journal of the American Economic Association 5 (1): 193\u2013206.\nKaiser, David. 2014. \u201cHistory: Shut up and Calculate!\u201d Nature 505 (7482): 153\u201355.\nKaplan, David M., and William Bechtel. 2011. \u201cDynamical Models: An Alternative or Complement to Mechanistic Explanations?\u201d\nTopics in Cognitive Science.\nKaplan, David Michael. 2011. \u201cExplanation and Description in Computational Neuroscience.\u201d Synthese 183 (3): 339.\nKatz, A. M. 1993. \u201cCardiac Ion Channels.\u201d The New England Journal of Medicine 328 (17): 1244\u201351.\nKeas, Michael N. 2018. \u201cSystematizing the Theoretical Virtues.\u201d Synthese 195 (6): 2761\u201393.\nKelemen, Eduard, and Andre\u0301 A. Fenton. 2016. \u201cCoordinating Different Representations in the Hippocampus.\u201d Neurobiology of\nLearning and Memory 129 (March): 50\u201359.\nKoch, C., and I. Segev, eds. 1989. Methods in Neuronal Modeling. MIT Press.\nKohonen, T. 1980. Content-Addressable Memories. New York: Springer.\n\u2014\u2014\u2014. 1984. Self-Organization and Associative Memory. New York: Springer-Verlag.\nKording, Konrad P., Gunnar Blohm, Paul Schrater, and Kendrick Kay. 2020. \u201cAppreciating the Variety of Goals in Computational\nNeuroscience.\u201d arXiv [q-bio.NC]. arXiv. http://arxiv.org/abs/2002.03211.\nKording, Konrad P., Joshua B. Tenenbaum, and Reza Shadmehr. 2007. \u201cThe Dynamics of Memory as a Consequence of Optimal\nAdaptation to a Changing Body.\u201d Nature Neuroscience 10 (6): 779\u201386.\nKuhn, Thomas S. 2011. The Essential Tension. University of Chicago Press.\n\u2014\u2014\u2014. 2012. The Structure of Scientific Revolutions: 50th Anniversary Edition. University of Chicago Press.\nLakatos, Imre. 1978. \u201cScience and Pseudoscience.\u201d Philosophical Papers 1: 1\u20137.\n\u2014\u2014\u2014. 1980. The Methodology of Scientific Research Programmes: Volume 1: Philosophical Papers. Cambridge University Press. Lakoff, G. 1990. Women, Fire, and Dangerous Things. Chicago: University of Chicago Press.\nLangston, J. W., and J. Palfreman. 2013. The Case of the Frozen Addicts: How the Solution of a Medical Mystery Revolutionized\nthe Understanding of Parkinson\u2019s Disease. IOS Press.\nLaplane, Lucie, Paolo Mantovani, Ralph Adolphs, Hasok Chang, Alberto Mantovani, Margaret McFall-Ngai, Carlo Rovelli, Elliott\nSober, and Thomas Pradeu. 2019. \u201cWhy Science Needs Philosophy.\u201d Proceedings of the National Academy of Sciences 116\n(10): 3948\u201352.\nLaudan, Larry. 1978. Progress and Its Problems: Towards a Theory of Scientific Growth. University of California Press.\nLuyten, Patrick, Linda C. Mayes, Peter Fonagy, Mary Target, and Sidney J. Blatt. 2015. Handbook of Psychodynamic Approaches\nto Psychopathology. Guilford Publications.\nMachamer, Peter, Lindley Darden, and Carl F. Craver. 2000. \u201cThinking about Mechanisms.\u201d Philosophy of Science 67 (1): 1\u201325. Machta, Benjamin B., Ricky Chachra, Mark K. Transtrum, and James P. Sethna. 2013. \u201cParameter Space Compression Underlies\nEmergent Theories and Predictive Models.\u201d Science 342 (6158): 604\u20137.\nMarder, Eve. 2000. \u201cModels Identify Hidden Assumptions.\u201d Nature Neuroscience. https://doi.org/10.1038/81477.\nMarr, D. 1982. Vision. New York: W. H. Freeman and Co.\n\u2014\u2014\u2014. 1991. From the Retina to the Neocortex: SElected Papers of David Marr. Boston: Edited by L. M. Vaina. Birkha\u0308user. McCormick, D. A., and H. C. Pape. 1990. \u201cProperties of a Hyperpolarization-Activated Cation Current and Its Role in Rhythmic\nOscillation in Thalamic Relay Neurones.\u201d The Journal of Physiology 431 (December): 291\u2013318.\nMcNaughton, B. L., R. M. Douglas, and G. V. Goddard. 1978. \u201cSynaptic Enhancement in Fascia Dentata: Cooperativity among\nCoactive Afferents.\u201d Brain Research 157 (2): 277\u201393.\nMcNaughton, B. L., and L. Nadel. 1990. \u201cHebb-Marr Networks and the Neurobiological Representation of Action in Space.\u201d In\nNeuroscience and Connectionist Theory, edited by M. A. Gluck and D. E. Rumelhart, 1\u201363. Hillsdale NJ: Erlbaum. Mermin, N. David. 1989. \u201cWhat\u2019s Wrong with This Pillow?\u201d Physics Today 42 (4): 9\u201311.\nMitchell, Tom M., Richard M. Keller, and Smadar T. Kedar-Cabelli. 1986. \u201cMachine Learning.\u201d\nhttps://doi.org/10.1023/a:1022691120807.\nMoeller, Sebastian, Trinity Crapse, Le Chang, and Doris Y. Tsao. 2017. \u201cThe Effect of Face Patch Microstimulation on Perception of\nLevenstein et al. - On the role of theory and modeling in neuroscience | 20\n"}, {"chunk": "Faces and Objects.\u201d Nature Neuroscience 20 (5): 743\u201352.\nMoghaddam, Bita, and Daniel Javitt. 2012. \u201cFrom Revolution to Evolution: The Glutamate Hypothesis of Schizophrenia and Its\nImplication for Treatment.\u201d Neuropsychopharmacology: Official Publication of the American College of\nNeuropsychopharmacology 37 (1): 4\u201315.\nMontague, P. Read, Raymond J. Dolan, Karl J. Friston, and Peter Dayan. 2012. \u201cComputational Psychiatry.\u201d Trends in Cognitive\nSciences 16 (1): 72\u201380.\nMorrison, Shaun F., and Kazuhiro Nakamura. 2011. \u201cCentral Neural Pathways for Thermoregulation.\u201d Frontiers in Bioscience 16\n(January): 74\u2013104.\nMullainathan, S. 2002. \u201cA Memory-Based Model of Bounded Rationality.\u201d The Quarterly Journal of Economics 117 (3): 735\u201374. Nadel, L. 1994. \u201cMultiple Memory Systems: WHat and WHy, an Update.\u201d In Memory Systems 1994, edited by D. L. Schacter and E.\nTulving, 39\u201364. Cambridge MA: MIT Press.\nNahum, Mor, Hyunkyu Lee, and Michael M. Merzenich. 2013. \u201cPrinciples of Neuroplasticity-Based Rehabilitation.\u201d Progress in Brain\nResearch 207: 141\u201371.\nNational Academies of Sciences, and Medicine. 2019. Reproducibility and Replicability in Science. Washington, DC: The National\nAcademies Press.\nNewell, Allen, and Herbert Alexander Simon. 1972. Human Problem Solving. Prentice-Hall.\nNickles, Thomas. 1981. \u201cWhat Is a Problem That We May Solve It?\u201d Synthese 47 (1): 85\u2013118.\nNonacs, P. 2001. \u201cState Dependent Patch Use and the Marginal Value Theorem.\u201d Behavioral Ecology: Official Journal of the\nInternational Society for Behavioral Ecology 12: 71\u201383.\nObermayer, K., G. G. Blasdel, and K. Schulten. 1992. \u201cStatistical-Mechanical Analysis of Self-Organization and Pattern Formation\nduring the Development of Visual Maps.\u201d Physical Review. A 45 (10): 7568\u201388.\nObermayer, Klaus, Terrence Joseph Sejnowski, Howard Hughes Medical Institute Computational Neurobiology Laboratory Terrence\nJ Sejnowski, and Tomaso A. Poggio. 2001. Self-Organizing Map Formation: Foundations of Neural Computation. MIT Press. O\u2019Keefe, J., and L. Nadel. 1978. The Hippocampus as a Cognitive Map. Oxford: Clarendon Press.\nO\u2019Leary, Timothy, Alexander C. Sutton, and Eve Marder. 2015. \u201cComputational Models in the Age of Large Datasets.\u201d Current\nOpinion in Neurobiology 32 (June): 87\u201394.\nOmar, C., J. Aldrich, and R. C. Gerkin. 2014. \u201cCollaborative Infrastructure for Test-Driven Scientific Model Validation.\u201d Of the 36th\nInternational Conference on .... https://dl.acm.org/doi/abs/10.1145/2591062.2591129?casa_token=rLQqfjvROA0AAAAA:S4oo17Qzxm- YfjZk3ZMam1bDWiW4hBE5ASK9H3uV_0yju_lhB24Zz_DIlc6dymiQ_Cr_Q2q3X7ro.\nOppenheim, Paul, and Hilary Putnam. 1958. \u201cUnity of Science as a Working Hypothesis.\u201d Minnesota Studies in the Philosophy of Science 2: 3\u201336.\nPanas, Dagmara, Hayder Amin, Alessandro Maccione, Oliver Muthmann, Mark van Rossum, Luca Berdondini, and Matthias H. Hennig. 2015. \u201cSloppiness in Spontaneously Active Neuronal Networks.\u201d The Journal of Neuroscience: The Official Journal of the Society for Neuroscience 35 (22): 8480\u201392.\nParker, G. A., and J. Maynard Smith. 1990. \u201cOptimality Theory in Evolutionary Biology.\u201d Nature 348 (6296): 27\u201333.\nPearl, Judea. 2009. Causality: Models, Reasoning and Inference. Cambridge University Press.\nPhillips, Rob. 2015. \u201cTheory in Biology: Figure 1 or Figure 7?\u201d Trends in Cell Biology 25 (12): 723\u201329.\nPinto, D. J., J. C. Brumberg, D. J. Simons, and G. B. Ermentrout. 1996. \u201cA Quantitative Population Model of Whisker Barrels: Re-\nExamining the WIlson-COwan Equations.\u201d Journal of Computational Neuroscience 3 (3): 247\u201364. Popper, Karl R. 1959. \u201cThe Logic of Scientific Discovery New York.\u201d Science.\nPotochnik, Angela. 2017. Idealization and the Aims of Science. University of Chicago Press.\n\u2014\u2014\u2014. 2020. \u201cIdealization and Many Aims.\u201d Philosophy of Science 87 (5): 933\u201343.\nPotochnik, Angela, and Brian McGill. 2012. \u201cThe Limitations of Hierarchical Organization.\u201d Philosophy of Science 79 (1): 120\u201340. Prinz, Astrid A., Dirk Bucher, and Eve Marder. 2004. \u201cSimilar Network Activity from Disparate Circuit Parameters.\u201d Nature\nNeuroscience 7 (12): 1345\u201352.\nPylyshyn, Zenon W. 1984. Computation and Cognition: Toward a Foundation for Cognitive Science. MIT Press.\nRall, W. 1992. \u201cCable Theory for Dendritic Neurons.\u201d In Methods in Neuronal Modeling, edited by C. Koch and I. Segev, 9\u201362. MIT\nPress.\nRedish, A. D. 1997. \u201cBeyond the Cognitive Map: Contributions to a Computational Neuroscience Theory of Rodent Navigation.\u201d\nEdited by David S. Touretzky. Ann Arbor, United States: Carnegie Mellon University. http://login.ezproxy.lib.umn.edu/login?url=https://www.proquest.com/dissertations-theses/beyond-cognitive-map-contributions- computational/docview/304366785/se-2.\n\u2014\u2014\u2014. 1999. Beyond the Cognitive Map: From Place Cells to Episodic Memory. Cambridge MA: MIT Press.\n\u2014\u2014\u2014. 2004. \u201cAddiction as a Computational Process Gone Awry.\u201d Science 306 (5703): 1944\u201347.\nRedish, A. David. 2013. The Mind within the Brain: How We Make Decisions and How Those Decisions Go Wrong. Oxford. Redish, A. D., A. N. Elga, and D. S. Touretzky. 1996. \u201cA Coupled Attractor Model of the Rodent Head Direction System.\u201d Network:\nComputation in Neural Systems 7 (4): 671\u201385.\nRedish, A. D., and J. A. Gordon, eds. 2016. Computational Psychiatry: New Perspectives on Mental Illness. Stru\u0308ngmann Forum\nReports. Cambridge MA: MIT Press.\nRedish, A. D., S. Jensen, and A. Johnson. 2008. \u201cA Unified Framework for Addiction: Vulnerabilities in the Decision Process.\u201d The\nBehavioral and Brain Sciences 31: 415\u201387.\nRedish, A. D., E. Kummerfeld, R. L. Morris, and A. C. Love. 2018. \u201cOpinion: Reproducibility Failures Are Essential to Scientific\nInquiry.\u201d Proceedings of the National Academy of Sciences of the United States of America 115 (20): 5042\u201346.\nRichards, Blake A., Timothy P. Lillicrap, Philippe Beaudoin, Yoshua Bengio, Rafal Bogacz, Amelia Christensen, Claudia Clopath, et\nal. 2019. \u201cA Deep Learning Framework for Neuroscience.\u201d Nature Neuroscience 22 (11): 1761\u201370.\nRieke, F., D. Warland, R. de Ruyter van Steveninck, and W. Bialek. 1997. Spikes. Cambridge MA: MIT Press.\nRinzel, J., and G. B. Ermentrout. 1989. \u201cAnalysis of Neural Excitability and Oscillations.\u201d In Methods in Neuronal Modeling, edited by\nC. Koch and I. Segev, 135\u201369. MIT Press.\nRooij, Iris van, and Giosue\u0300 Baggio. 2020. \u201cTheory before the Test: How to Build High-Verisimilitude Explanatory Theories in\nPsychological Science.\u201d https://psyarxiv.com/7qbpr/download?format=pdf.\nRosch, E. 1983. \u201cPrototype Classification and Logical Classification: The Two Systems.\u201d New Trends in Conceptual Representation:\nLevenstein et al. - On the role of theory and modeling in neuroscience | 21\n"}, {"chunk": "Challenges.\nRosenblueth, Arturo, and Norbert Wiener. 1945. \u201cThe Role of Models in Science.\u201d Philosophy of Science 12 (4): 316\u201321. Rotstein, Horacio G., Tim Oppermann, John A. White, and Nancy Kopell. 2006. \u201cA Reduced Model for Medial Entorhinal Cortex\nStellate Cells: Subthreshold Oscillations, Spiking and Synchronization.\u201d Journal of Computational Neuroscience 21: 271\u201392. Sanders, Honi, Ce\u0301sar Renno\u0301-Costa, Marco Idiart, and John Lisman. 2015. \u201cGrid Cells and Place Cells: An Integrated View of Their\nNavigational and Memory Function.\u201d Trends in Neurosciences 38 (12): 763\u201375.\nSchacter, D. L. 2001. The Seven Sins of Memory. Houghton Mifflin.\nSchindler, Samuel. 2018. Theoretical Virtues in Science: Uncovering Reality through Theory. Cambridge University Press. Schmidt, Brandy, Anneke A. Duin, and A. David Redish. 2019. \u201cDisrupting the Medial Prefrontal Cortex Alters Hippocampal\nSequences during Deliberative Decision Making.\u201d Journal of Neurophysiology 121 (6): 1981\u20132000.\nSchultz, W., A. Studer, R. Romo, E. Sundstrom, G. Jonsson, and E. Scarnati. 1989. \u201cDeficits in Reaction Times and Movement\nTimes as Correlates of Hypokinesia in Monkeys with MPTP-Induced Striatal Dopamine Depletion.\u201d Journal of Neurophysiology\n61 (3): 651\u201368.\nScoville, W. B., and B. Milner. 1957. \u201cLoss of Recent Memory after Bilateral Hippocampal Lesions.\u201d Journal of Neurology,\nNeurosurgery, and Psychiatry 20: 11\u201321.\nSejnowski, T., C. Koch, and P. Churchland. 1988. \u201cComputational Neuroscience.\u201d Science. https://doi.org/10.1126/science.3045969. Shepherd, Gordon M. 1994. Neurobiology. Oxford University Press.\nShleifer, Andrei. 2000. Inefficient Markets:An Introduction to Behavioral Finance: An Introduction to Behavioral Finance. OUP\nOxford.\nSimon, Herbert A. 1972. \u201cTheories of Bounded Rationality.\u201d Decision and Organization 1 (1): 161\u201376.\nSmaldino, Paul. 2019. \u201cBetter Methods Can\u2019t Make up for Mediocre Theory.\u201d Nature.\nSmith, Michael L., Nils Napp, and Kirstin H. Petersen. 2021. \u201cImperfect Comb Construction Reveals the Architectural Abilities of\nHoneybees.\u201d Proceedings of the National Academy of Sciences of the United States of America 118 (31).\nhttps://doi.org/10.1073/pnas.2103605118.\nSolstad, T., E. I. Moser, and G. T. Einevoll. 2006. \u201cFrom Grid Cells to Place Cells: A Mathematical Model.\u201d Hippocampus 16 (12):\n1026\u201331.\nSquire, L. R. 1987. Memory and Brain. New York: Oxford University Press.\nStafford, Tom. 2009. \u201cWhat Use Are Computational Models of Cognitive Processes?\u201d In Connectionist Models of Behaviour and\nCognition II: Proceedings of the 11th Neural Computation and Psychology Workshop, edited by Mayor, J., Ruh, N., Plunkett, K.\nWorld Scientific. http://tomstafford.staff.shef.ac.uk/docs/stafford09_ncpw.pdf.\nSteiner, Adam P., and A. David Redish. 2014. \u201cBehavioral and Neurophysiological Correlates of Regret in Rat Decision-Making on a\nNeuroeconomic Task.\u201d Nature Neuroscience 17 (7): 995\u20131002.\nSteinle, Friedrich. 1997. \u201cEntering New Fields: Exploratory Uses of Experimentation.\u201d Philosophy of Science 64: S65\u201374.\nSweis, Brian M., Samantha V. Abram, Brandy J. Schmidt, Kelsey D. Seeland, Angus W. MacDonald, Mark J. Thomas, and A. David\nRedish. 2018. \u201cSensitivity to \u2018sunk Costs\u2019 in Mice, Rats, and Humans.\u201d Science 361 (6398): 178\u201381.\nSweis, Brian M., Mark J. Thomas, and A. David Redish. 2018. \u201cMice Learn to Avoid Regret.\u201d PLoS Biology 16 (6): e2005853. Swindale, N. V. 2004. \u201cHow Different Feature Spaces May Be Represented in Cortical Maps.\u201d Network 15 (4): 217\u201342. Swindale, N. V., and H-U Bauer. 1998. \u201cApplication of KOhonen\u2019s Self-Organizing Feature Map Algorithm to Cortical Maps of\nOrientation and Direction Preference.\u201d Proceedings of the Royal Society of London. Series B, Containing Papers of a Biological\nCharacter. Royal Society 265: 827\u201338.\nTakeuchi, Tomonori, Adrian J. Duszkiewicz, and Richard G. M. Morris. 2014. \u201cThe Synaptic Plasticity and Memory Hypothesis:\nEncoding, Storage and Persistence.\u201d Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences\n369 (1633): 20130288.\nTan, Chan Lek, and Zachary A. Knight. 2018. \u201cRegulation of Body Temperature by the Nervous System.\u201d Neuron 98 (1): 31\u201348. Thompson, D\u2019arcy Wentworth. 1992. On Growth and Form. Courier Corporation.\nTranstrum, Mark K., Benjamin B. Machta, Kevin S. Brown, Bryan C. Daniels, Christopher R. Myers, and James P. Sethna. 2015.\n\u201cPerspective: Sloppiness and Emergent Theories in Physics, Biology, and beyond.\u201d The Journal of Chemical Physics 143 (1):\n010901.\nTraub, R. D., J. G. R. Jefferys, and M. A. Whittington. 1999. Fast Oscillations in Cortical Circuits. Cambridge MA: MIT Press. Traub, R. D., R. K. Wong, R. Miles, and H. Michelson. 1991. \u201cA Model of a CA3 Hippocampal Pyramidal Neuron Incorporating\nVoltage-Clamp Data on Intrinsic Conductances.\u201d Journal of Neurophysiology 66 (2): 635\u201350.\nTsao, Doris Y., Winrich A. Freiwald, Roger B. H. Tootell, and Margaret S. Livingstone. 2006. \u201cA Cortical Region Consisting Entirely\nof Face-Selective Cells.\u201d Science 311 (5761): 670\u201374.\nUhlhaas, Peter J., and Wolf Singer. 2015. \u201cOscillations and Neuronal Dynamics in Schizophrenia: The Search for Basic Symptoms\nand Translational Opportunities.\u201d Biological Psychiatry. https://doi.org/10.1016/j.biopsych.2014.11.019.\nVillers-Sidani, Etienne de, and Michael M. Merzenich. 2011. \u201cLifelong Plasticity in the Rat Auditory Cortex: Basic Mechanisms and\nRole of Sensory Experience.\u201d Progress in Brain Research 191: 119\u201331.\nVinogradov, Sophia, Arif A. Hamid, and A. David Redish. 2022. \u201cEtiopathogenic Models of Psychosis Spectrum Illnesses Must\nResolve Four Key Features.\u201d Biological Psychiatry 92 (6): 514\u201322.\nWatson, J. D., and F. H. Crick. 1953. \u201cMolecular Structure of Nucleic Acids; a Structure for Deoxyribose Nucleic Acid.\u201d Nature 171\n(4356): 737\u201338.\nWebb, Ryan, Paul W. Glimcher, and Kenway Louie. 2021. \u201cThe Normalization of Consumer Valuations: Context-Dependent\nPreferences from Neurobiological Constraints.\u201d Management Science 67 (1): 93\u2013125.\nWeisberg, Michael. 2013. Simulation and Similarity: Using Models to Understand the World. OUP USA.\nWikenheiser, Andrew, David W. Stephens, and A. David Redish. 2013. \u201cSubjective Costs Drive Overly-Patient Foraging Strategies\nin Rats on an Intertemporal Foraging Task.\u201d Proceedings of the National Academy of Sciences of the United States of America\n110 (20): 8308\u201313.\nWills, Tom J., Colin Lever, Francesca Cacucci, Neil Burgess, and John O\u2019Keefe. 2005. \u201cAttractor Dynamics in the Hippocampal\nRepresentation of the Local Environment.\u201d Science 308 (5723): 873\u201376.\nWilson, H. R., and J. D. Cowan. 1973. \u201cA Mathematical Theory of the Functional Dynamics of Cortical and Thalamic Tissue.\u201d\nKybernetik 13: 55\u201380.\nWimsatt, William C. 1976. \u201cReductionism, Levels of Organization, and the Mind-Body Problem.\u201d In Consciousness and the Brain: A\nLevenstein et al. - On the role of theory and modeling in neuroscience | 22\n"}, {"chunk": "Scientific and Philosophical Inquiry, edited by Gordon G. Globus, Grover Maxwell, and Irwin Savodnik, 205\u201367. Boston, MA:\nSpringer US.\nWing, Jeannette M. 2008. \u201cComputational Thinking and Thinking about Computing.\u201d Philosophical Transactions. Series A,\nMathematical, Physical, and Engineering Sciences 366 (1881): 3717\u201325.\nWinther, Rasmus Gr\u00f8nfeldt. 2021. \u201cThe Structure of Scientific Theories.\u201d In The Stanford Encyclopedia of Philosophy, edited by\nEdward N. Zalta, Winter 2016. Metaphysics Research Lab, Stanford University. https://plato.stanford.edu/entries/structure-\nscientific-theories/.\nWoodward, James. 2019. \u201cScientific Explanation.\u201d In The Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta.\nWorld Health Organization. 2021. International Classification of Diseases, Eleventh Revision (ICD-11).\nWu, Lingfei, Dashun Wang, and James A. Evans. 2019. \u201cLarge Teams Develop and Small Teams Disrupt Science and Technology.\u201d\nNature, February 13, 2019.\nYang, T., and M. N. Shadlen. 2007. \u201cProbabilistic Reasoning by Neurons.\u201d Nature 447: 1075\u201380.\nZeelenberg, Marcel, Wilco W. Van Dijk, Antony S. R. Manstead, and Joop vanr de Pligt. 2000. \u201cOn Bad Decisions and Disconfirmed\nExpectancies: The Psychology of Regret and Disappointment.\u201d Cognition & Emotion 14 (4): 521\u201341.\nZilli, Eric A., and Michael E. Hasselmo. 2008. \u201cModeling the Role of Working Memory and Episodic Memory in Behavioral Tasks.\u201d\nHippocampus 18 (2): 193\u2013209.\nLevenstein et al. - On the role of theory and modeling in neuroscience | 23\n"}, {"chunk": "Table 1\nTerminology used in this manuscript. Three neuroscience examples.\n               Framework\nA general description about the structure of the world, providing a language and a conceptual basis for developing theories.\nTheory\nA set of ideas that can be used to explain a set of phenomena (the domain of the theory).\nModel\nAn instantiation of aspects of a theory in an (often mathematical) structure, which is interpreted to represent aspects of a phenomenon.\nCellular\nExplanations for differences in neural functional properties can be appropriately described in terms of differences in the electrochemical properties of membranes and proteins.\nSpecific voltage gated ion channels enable excitable properties of neurons such as the action potential.\nThe Hodgkin-Huxley equations represent the voltage- dependent conductances that underlie the action potential.\nExamples\nSystems\nExplanations of the production of movement by skeletal muscle contractions can be appropriately described in terms of patterns of action potentials in the central nervous system.\nMany movements are generated by central pattern generators that are primarily driven by internal oscillatory dynamics.\nHalf-center oscillators represent neural circuits in the notochord that underlie swimming processes in the lamprey.\nDisease\nExplanations of neurodegenerative diseases can be appropriately described in terms of dysfunction in cellular processes.\nParkinson\u2019s disease is due to loss of dopaminergic function in the substantia nigra.\nDopaminergic loss caused by 6-OHDA in rodents and MPTP in non-human primates represent similar losses in Parkinson\u2019s disease that underlies behaviors such as bradykinesia and tremors.\n                   "}, {"chunk": "Box 1: Levels of abstraction\nAn illustrative example of levels of abstraction comes from computer science (Colburn and Shute 2007; Wing 2008), in which higher-level languages abstract the details specified in lower-level languages by concealing detailed code in a single function that provides the same relationship. Computational abstraction simplifies a process, such that it is independent of its component processes or even its physical substrate. For example, there are many algorithms that sort a list of numbers, but any computational sort command produces the same output regardless of the algorithm used. Computational abstraction is used in neuroscience, for example, when we simplify the molecular process of synaptic transmission in a more abstract model that represents its net effect as an increased firing rate of a postsynaptic neuron. This simplification is akin to conceptual abstraction (O\u2019Leary, Sutton, and Marder 2015), by which more abstract, or idealized, models aim to capture general properties of a process rather than the specific details of any one event or dataset. In neuroscience, computational abstraction is often discussed in terms of David Marr\u2019s three levels of analysis (Marr 1982; Pylyshyn 1984): the implementational level is a low-level, concrete statement of a phenomenon, the algorithmic level is an abstraction of the implementational level, explaining the process by which the phenomenon occurs, and the computational level is a high-level (normative) statement of the goal of the process.\nDistinct levels of abstraction also arise in neuroscience when considering problems at different spatiotemporal scales (Churchland and Sejnowski 1994). For example, we might consider synaptic transmission in terms of the interactions of various proteins at nanometer to micrometer scales, or we might consider a more abstract model in which neural activity is propagated across the cortex at scales of millimeters or centimeters. When we model phenomena at a given spatiotemporal scale, we make an abstraction that prioritizes organizational details at that scale (e.g., cellular), while further simplifying details at others (e.g., subcellular and network) (Eronen and Brooks 2018). One promising perspective on the emergence of spatiotemporal levels suggests that models at higher levels of abstraction arise from their lower level counterparts via a natural dimensionality reduction of the parameter space (Machta et al. 2013; Transtrum et al. 2015). Such a reduction is possible because models of complex systems are \u201csloppy\u201d: they have a large number of dimensions in parameter space along which model parameters can vary without affecting relevant macroscopic observables (i.e. the microscopic parameters are degenerate with respect to macroscopic behavior (Gutenkunst et al. 2007); for examples in neuroscience, see e.g., (Prinz, Bucher, and Marder 2004; Panas et al. 2015). Thus, abstraction from lower to higher spatio- temporal scales can be seen as a reduction of the lower level parameter space that removes sloppy dimensions, but preserves \u201cstiff\u201d dimensions that have strong influence on observable properties at the higher level. The appropriate dimensionality reduction could be as simple as taking the mean or asymptote of some parameter over a population (Wilson and Cowan 1973; Pinto et al. 1996; Destexhe and Sejnowski 2009), or the set of microscopic parameters needed to produce the same macroscopic behavior might be nonlinear and complex (Prinz, Bucher, and Marder 2004; Transtrum et al. 2015; Jalics, Krupa, and Rotstein 2010; Rotstein et al. 2006)\n"}, {"chunk": "Box 2: What makes a good neuroscientific theory? What makes a good model?\nBe specific. A theory should be specific, particularly in terms of what the theory is attempting to explain and the strategies for doing so. The theory should define what problems it is trying to solve, and provide the criteria for an adequate solution. It is important to define the descriptive, mechanistic, and normative components of the theory and the rationale behind their selection.\nIdentify the domain. The theory should define the set of questions and problems that it is trying to solve. Importantly, this definition should be a reasonable space of phenomena such that it is easy for someone to determine if a new experiment falls within the domain of the theory or not.\nSpecify which aspects of the theory are instantiated in each model, and how. As shown in Table 1, models instantiate theories, enabling them to be compared with data. It is important to specify which aspects of the theory are instantiated in the model and how those aspects are instanted. It is also important to identify how those aspects were chosen, whether from experimental measurements, theoretical assumptions, or best-fit solutions (or arbitrarily).\nSpecify the translation function for all models. All models require translation to be compared to data. While sometimes those translations will be straight-forward, they usually are not. However, even in situations where the translation is straight-forward, being explicit about the translation function will make clear what data it explains and what experimental predictions it makes.\nIdentify the abstractions. Models at all levels can be useful, but in order to be useful, one must identify what aspects of the world are being abstracted away. It is important to include both abstractions of low- level phenomena and what additional (potentially higher-level) complexities are being ignored.\nDefine which aspects of the research are exploratory and which are confirmatory. The fact that models are a form of experiment creates a way forward for theoretical grant proposals. For example, a researcher can propose to build a model that crosses levels in order to address the question of theoretical viability. Such a proposal may have preliminary data to show that one can build models at each level, even if the researcher has not yet put those levels together. Similarly, a grant proposal can define the domain even if the literature review is incomplete. One can also identify how one is going to explore the parameter space of a set of models to determine how those parameters affect phenomena across levels.\nBy being explicit about the scientific question being addressed, about the assumptions of the theory, the domain the theory is purporting to address, and the process of building and testing models underlying that theory, grant proposals could be viable even if the theory itself remains incomplete. We call on funding agencies and reviewers to recognize that theory is the foundation of any science, and that construction of rigorous theory and systematic computational modeling are time-consuming processes that require dedicated personnel with extensive training. Our hope is that the framework and associated language outlined in this document can be used to specify deliverables that can be understood by both funders and investigators.\n"}, {"chunk": " "}, {"chunk": " "}, {"chunk": " "}, {"chunk": "Development of theoretical frameworks in neuroscience: a pressing need in a sea of data\nHoracio G. Rotstein1 and Fidel Santamaria2\n1 Federated Department of Biological Sciences, New Jersey Institute of Technology and Rutgers University, Newark, NJ 07102 horacio@njit.edu\n2 Department of Neuroscience, Developmental and Regenerative Biology and Brain Health Consortium, The University of Texas at San Antonio, San Antonio, TX 78249 fidel.santamaria@utsa.edu\nAbstract\nNeuroscience is undergoing dramatic progress because of the vast data streams derived from the new technologies product of the BRAIN initiative and other enterprises. As any other scientific field, neuroscience benefits from having clear definitions of its theoretical components and their interactions. This allows generating theories that integrate knowledge, provide mechanistic insights, and predict results under new experimental conditions. However, theoretical neuroscience is a heterogeneous field that has not yet agreed on how to build theories or whether it is desirable to have an overarching theory or whether theories are simply tools to understand the brain. Here we advocate for the need of developing theoretical frameworks as a basis of generating common theoretical structures. We enumerate the elements of theoretical frameworks we deem necessary for any theory in neuroscience. In particular, we address the notions of paradigms, models, and scales of organizations. We then identify areas with pressing needs to develop brain theories: integration of statistical and dynamic approaches; multi-scale integration; coding; and interpretability in the context of Artificial Intelligence. We also point out that future theoretical frameworks would benefit from the incorporation of the principles of Evolution as a fundamental structure rather than purely mathematical or engineering principles. Rather than providing definite answers, the objective of this paper is to serve as an initial and succinct presentation of these topics to encourage discussion and further in depth development of each topic.\n"}, {"chunk": "Introduction\nThere are three primary objectives of theoretical neuroscience: to provide quantitative testable predictions of brain function, to explain neuronal mechanisms in healthy and diseased brains and to abstract computational strategies to develop better engineering tools 1-4. Achieving these goals requires developing theoretical approaches that encompass the shared assumptions of models developed for different species and scales 5-8. If this were in fact possible, then experimental neuroscience would benefit from having access to theories that can take experimental data points obtained at one scale of organization and species and apply them to other scales and species. Thus, it is necessary to examine the present existing theoretical frameworks and determine whether they point to one or several theoretical approaches, what new frameworks need to be developed, and how to link them. It is no less important to clarify what is a theoretical framework, how frameworks are different from theories and models, and how different integrated modeling approaches produce a cohesive body of knowledge. These frameworks should build on the existing conceptual structure of the field and should not be compartmentalized, but must span across scales (e.g. spatial, temporal), levels of organization (e.g. subcellular, cellular, microcircuit, complex networks; systems; species), and theoretical sub-disciplines 9.\nTraditionally, models and theories in neuroscience address a specific problem or data set 5,10. In addition, theories have been founded on using metaphors (e.g., brain computation, the neural code)11 and more metaphors to address these \u201cprimary\u201d ones (e.g., brain-as-a-computer, information processing, and trajectories in the phase-space diagrams)12,13. However, the field would benefit from theories and models that integrate the vast data streams derived from the new technologies product of the BRAIN initiative to provide a mechanistic link between the activity of the nervous system and behavior 14. Furthermore, theoretical frameworks need not only to integrate spatial and temporal scales, but also across biological scales of organization 15- 18. In order to achieve this, models and theories require a mathematical foundation for generalization and translation 19. Generalization allows addressing larger problems or data sets. Translation refers to the ability of a theory developed at one scale, system, function, and species to be applied to another.\nWe have been involved in a number of activities whose goals are to bring together the theoretical neuroscience community and discuss the structure of the state-of-the-art, and identify fields within neuroscience that could benefit from developing frameworks that cross scales and established disciplines 20,21. Some of these activities have resulted in publications on specific topics21. However, we believe there is a need to provide a succinct overview of the properties of neuroscience theories and areas to focus with a vision to the future. As such, the first part of this manuscript presents definitions of theoretical frameworks, paradigms, models, and scales of organization. We believe that there is a need to clarify each of these elements to develop and compare complementary or competing theories, such as in a more extensive\n"}, {"chunk": "recent paper. In the second part of the paper, we discuss five areas that require attention. In one of those topics, we emphasize that the theory of evolution should be included in the theoretical frameworks of neuroscience.\nTheoretical frameworks and their properties applied to neuroscience\nWe make use of the concept of theoretical frameworks to provide a parsimonious way to communicate and develop neuroscience theories. We identify the basic parts of theoretical frameworks applicable to any neuroscience field. In particular, we pay attention to the concept of scales of integration, which are taking more importance as large streams of data sets become available because of the technologies developed by the BRAIN initiative. Our objective in this section is to be succinct and to provide an initial introduction of the issues to promote conversation in the field and further development of these ideas.\nFrameworks\nIn a recent paper that resulted from our previous organizational efforts21, a theoretical framework is a \u201clanguage within which explanations are proposed.\u201d From this point of view, a framework is a set of theories believed to be fundamental that support a research program, creating a conceptual structure from which more theories are developed. Some other disciplines are keen in defining theoretical frameworks22-26. While there are variations, a summary of such proposals say that a theoretical framework consists of a theory or theories; their paradigms, both theoretical and experimental; and the fundamental concepts that identify them. A framework also includes the relationships and interactions among all these elements 27. As mentioned before, it is not our intention on arguing on how to define theoretical frameworks for theoretical neuroscience. However, any definition should be useful to develop theories that integrate information across scales and across species. In this section, we will briefly discuss, what we argue, are the fundamental theoretical frameworks in neuroscience.\nA first one is dynamics. In this case, computations are trajectories in phase-plane diagrams of neuronal activity (state) variables, such as membrane potential or firing rate. Coding is the transformation of a stimulus, static or dynamic, discrete or continuous, into a particular trajectory. Learning and memory are processes that shape these trajectories28-30.\nA second framework is statistics. In this case, neurons are stochastic agents that encode noisy signals. Memory, learning, and plasticity, take place in, mostly, a Bayesian inference setting, including causality, where there are priors of expected statistical models of the environment. The neuronal code is noisy and in need of networks that average or poll the responses of the system31.\nEngineering and machine learning concepts constitute a third framework. On one side of this group, there is an intrinsic assumption of a von Neumann type of arrangement of brain computation where there are modules that algorithmically parse and process information. Each module has a main task, which could interact with other modules depending on environmental\n"}, {"chunk": "conditions or learning5,32. The process is mostly hierarchical, providing higher levels of abstraction from the stimulus. Computational psychiatry is a good example of this approach33,34. In contrast, there is the non-von Neumann approach using neural networks35,36. However, hierarchical or deep neural networks theories have similarities with the compartmentalized approach37,38.\nWhile all these conceptual ideas on the structure of neuroscience theories are of importance, we could also adopt a different approach to move the field forward. Along these lines, a recent paper, the result of one of our previous organizational activities, took the pragmatic view to describe the function of theory and models in neuroscience 21. Instead of proposing an overarching theory, it proposed to organize knowledge in terms of context-dependent frameworks, theories, and models, and to use three categories for each of them: descriptive, mechanistic, and normative. The descriptive category consists of phenomenological approaches to neuronal processes; mechanistic theories aim to describe the interactions of a number of components of the nervous systems; and normative theories use the biological function of a system under the constraints of an objective function.\nClearly, our discussion and classification of the different frameworks is a simplification and it is possible to find works that span these different perceptual approaches. However, it is important to identify and spell out their fundamental assumptions in order to be able to identify areas to develop. In addition, different framework approaches are not necessarily mutually exclusive, and can in fact be complementary.\nParadigms\nTheoretical frameworks allow organizing high-level problems by assuming relations among different components of neuroscience. It is at this level where we can use a set of paradigms, within a framework, to study the nervous system. A paradigm is a conceptual general view that consists of theories, classic experiments, and trusted methods 39. The neuron as the basic block of the nervous system, synaptic plasticity as a cellular mechanism of learning and memory, the nervous system complexity supports its flexibility, are a few of these paradigms. These paradigms have been extremely useful in simplifying the study of the brain and allowing us to gain insight into neuronal function. However, how are the large multi-scale data expected from the technological advancements of the BRAIN initiative affect those paradigms?\nModels\nWhile a paradigm is a statement of fundamental properties, a model is an abstraction (see discussion in 40). Models are tools that contribute to our understanding of a problem and the interpretation of data, and their level of complexity satisfies these goals 41. However, in many cases, the roles are reversed, and models distortedly became the foundation of a theory (e.g., the leaky integrate-and-fire model). Basing theory on oversimplified models distracts from advancing actual theory and forces researchers to design experiments constrained by the models. Model-based theory also results in producing theories that correspond to a specific\n"}, {"chunk": "spatial or temporal scale, a specific level of organization, or a specific experimental situation. The collection of such theories results in difficult-to-integrate higher order, more inclusive theories. In this respect, it is important to question if efforts should be devoted to this type of integrated frameworks or, alternatively, develop frameworks for the development of the necessary theories across scales.\nScales of organization\nThe influence of physics and engineering in neuroscience has shaped the compartmentalized focus of theories 42-45. As such, theories aim to explain brain phenomena at separable physical or temporal scales. For example, the impulse-response strategy to characterize everything, from the opening of an ion channel to mapping the motor cortex in primates, assumes that it is enough to characterize the response of the system to a short stimulus to understand the embedding macro-systems 46,47. Building a theory on only this type of oversimplified assumptions proves to be of limited predictive value when, for example, the stimulus is longer, is presented in different contexts, or the response is affected by nonlinearities 48. At this point, it is relevant to bring into the discussion the concept of biological scales of organization49. These levels of organization are not just separable physical or temporal scales, but describe interactions among elements and make relationships to their isolated forms (networks vs single neurons)50,51. Integrated frameworks should include mechanisms of looking at specific levels of organization by considering the effect of their sub- and supra-levels in ways that are consistent across scales and their biological function. Here, the use of Artificial Intelligence (AI) for automatic detection of complex behavior, together with electrophysiology and modeling, and additional tools to resolve degeneracies could provide the experimental foundation to determine biological scales by function and behavior 52.\nAreas of neuroscience that require theoretical development\nHere we present an initial discussion of different topics that, we believe, will be of importance in the near future. As in the previous section, it is not our intention to have an exhaustive discussion of each one of them, but instead to present them in a succinct form to inspire debate.\nIntegration of dynamics, statistics and other mathematical\napproaches\nThe dynamical and statistical neuroscience communities have approached problem solving and the generation of theories and models from different perspectives, using different tools and different languages 53-56. While there are overlaps between the different approaches a conceptual separation between the ways the two fields address theoretical neuroscience questions remains prominent. For example, the leaky integrate-and-fire model and the generalized linear model are largely considered to be equivalent. How do the equivalences\n"}, {"chunk": "between primarily dynamics and statistical models extend to more complex systems? Statistical tools are often calibrated or validated by using the so-called ground truth models. Can this approach be extended to provide interpretability to the results of using these tools in combination with experimental/observational data? How can a mathematical integrated approach further incorporate other fields of mathematics that are becoming increasingly useful in theoretical neuroscience such as topology and geometry? Finally, how these combined approaches can contribute to develop tools to establish causal effects among neuronal processes, understand biophysical and dynamic mechanisms, and resolve degeneracies present in neuronal systems?\nMulti-scale challenges\nFrom the beginning of modern neuroscience, it has been necessary to break down the tasks of the nervous system into elements tractable by the experimental and theoretical tools available at the time. Thus, there was no pressing need for a multi-scale approach. In this context, the mean-field assumption is a widely used approach to study the effects of other scales on a specific problem. The fundamental assumption of this process is that the activity that is being averaged out can be represented as a homogenous population 57-61. The assumptions of what constitutes a homogeneous population have to be carefully understood before simplifying their description. Novel approaches are needed to consider the effects discussed above of the sub- and supra-levels of organization with respect to the one considered in ways that are consistent across scales and preserve the necessary details to ensure the dynamics across scales are preserved.\nCoding\nThere is no single definition of coding 62-66. From a correlative point of view, coding, by either spike timing or firing rate strategies, is a static process characterized by mutual information. A second form of coding is by the biophysical decoding properties of the downstream receivers. Changes in neuronal excitability due to neuromodulatory or intrinsic processes requires the recalculation of the mutual information. This neuron-centric approach creates conundrums in which it is not possible to know for a receiver when a pre-synaptic neuron has changed coding strategies. Thus, it is necessary to define coding and establish how different notions of coding interact at multiple scales, from synapse to system.\nMechanistic interpretability of artificial intelligence and machine\nlearning in neuroscience\nExperimental and computational neuroscientists are increasingly using artificial intelligence (AI), particularly machine learning (ML) tools, to analyze large data sets with for a number of purposes, including data processing, understanding relationships between variables, uncovering hidden structure of neuronal activity, data classification, data clustering, and hypothesis testing67,68 69-71. Complemented with additional tools, these primarily data-driven approaches can\n"}, {"chunk": "be functional for hypothesis generation, hypothesis testing and certain aspects of mechanistic interpretation of the data. However, the process of automatic discovery of neuronal mechanisms using AI, a concept known as explainable AI or XAI 71,72, as well as the dynamic properties of the systems that underlie neuronal processes is still underdeveloped. Overcoming these issues is crucial for the field to move forward and to produce theories that are not only interpretable, but also generalizable beyond the limits of the data sets used to produce them. Moving forward requires the development of novel conceptual ideas and algorithms, and platforms that allow these ideas to be implemented. For example, by taking inspiration from the shortcomings in other fields73, we could use XAI for the testing and developing of frameworks, theories and models. Since we are at the beginning of incorporating these technologies to research workflows, it is important to train a new generation of investigators that experience this as the standard approach.\nEvolution as a framework of theoretical neuroscience\nThe brain is the result of evolution. However, there are multiple ways of using Evolution to study the brain. In possibly the most common form, Evolution studies how the shapes and structures of the nervous system relate among organisms. A second branch aims to understand brain function in relation to behavior, mainly mating and survival, at evolutionary scales. But, Evolution is also an engineering metaphor to develop training and learning strategies that could explain the diversity of the brain\u2019s computational strategies.\nIn contrast to the more common uses, we propose using Evolution to study the principles of brain computation. We could use the evolutionary basic concepts of allopatric, sympatric, adaptive radiation, hybrid zones, and the Hardy-Weinberg principle of equilibrium to study not only brain evolution but also neuronal computation74,75. We could do this at two scales. The first one is the study of behavior across species using evolution to develop computational theories of the brain. A fascinating example is on the evolution of vocal communication and speech. Recent work provides strong evidence that vocal communication can be described with all the traits of evolution, including convergent evolution 76. If indeed, evolution explains vocal communication then we propose that each implementation of this behavior represent a computational phenotype. Each computational phenotype vary by the presence of a computational allele, which could be a particular network implementation or coding strategy. In this context, we expect preservation and variation of computational strategies and their neuronal substrates across related species. Another area of study that should be taken into account is learning and memory of organisms in hybrid zones 77. Hybrids could have different learning strategies, possibly putting them in a disadvantage to the parental diverging populations; thus, contributing to the generation of species.\nIn the second scale, we look at computational phenotypes within a single species. Here, the diversity of computational alleles could result in adaptive radiation, where organisms express a given allele in higher frequencies. This adaptive radiation could take place in populations that are in the same (sympatric) or different (allopatric) environments. Computational alleles provide, just as in any other instances of alleles, flexibility to the survival of the population in case of\n"}, {"chunk": "environmental changes. In contrast to ideas that species in a stable environment develop a unique, engineering inspired, computational solution, we expect to have multiple computational strategies. Each computational allele could be optimal under different environmental conditions. Under an engineering framework, this would mean that some organisms are less optimal. However, under an evolutionary framework, this means that the population is retaining computational strategies for the survival of the species. Furthermore, we expect that the distribution of computational strategies have a stable distribution under similar environmental conditions, and for this distribution to change under environmental manipulation, as described by the Hardy-Weinberg principle of equilibrium. Thus, evolutionary principles suggest that we should find a distribution of computational strategies to solve particular problems or processes in genetically similar populations under similar environmental conditions.\nClearly, an open question is how to fit all the other frameworks under an evolutionary umbrella. In principle, under evolution, organisms could benefit from the presence of dynamical, statistical or machine learning strategies, all present and varying at population levels in order to maximize survival of the species.\nTraining the new generation and next steps\nThe primary current model to train engineers, mathematicians, or physicists that enter into a neuroscience doctoral program is through rotations in, hopefully, experimental laboratories, taking neuroscience classes, or participating in dedicated summer schools. For postdoctoral researchers the training is far less homogeneous, mostly consisting on participating in seminars and dynamics within the mentor\u2019s laboratory. Intrinsically, this training strategy assumes that it is only necessary to add some neuroscience topical training for students with these backgrounds to understand how the brain works. To some extent, the training of these new students is a closed-loop circuit, given that several of the most used textbooks to teach theoretical neuroscience are by physicists or mathematicians.\nWe tried to address this issue as part of a workshop we organized, supported by NSF 78. We mixed experimentalist and computational researchers, we purposely integrated the active participation of graduate students and postdocs 79,80, and we started the conversation well in advance of the meeting itself. Our aim was to integrate students and postdocs in the discussion rather than being passive listeners. There are other activities, such as the NIH supported Theories Modeling and Methods workgroup. Recent efforts within this group aimed to create synergies between theory and experimentally led groups 81. These activities centered in exchanging data and models. We envision a future where students and postdocs benefit from adding this type of training activities.\nIn fact, we advocate that training the next generation of theoretical neuroscientists should incorporate additional components that put the traditional training in the context of a more general form of \u201cbiological thinking\u201d. Training should include an understanding of theoretical\n"}, {"chunk": "biology in the forms of evolution and ecology in the context of the development and function of the nervous system. Complementary, it would be beneficial for theoretical neuroscientists to understand systems biology and, more generally, the subcellular processes of the brain. This objective could make use of already present training programs. However, it would also be useful to develop multidisciplinary textbooks that integrate the engineering/mathematical traditional side of theoretical neuroscience with theoretical biology, written in collaboration with experts in the field.\nSupport:\nF.S. NSF-IOS 1516648 and NIH NIMH-NIBIB R01EB026939\nH.G.R. NSF-DBI 1820631, NSF-CRCNS-1608077, NSF-IOS-2002863\nReferences\n1 Sejnowski, T. J., Koch, C. & Churchland, P. S. Computational Neuroscience. Science 241, 1299-1306, doi:doi:10.1126/science.3045969 (1988).\n2 Abbott, L. F. Theoretical Neuroscience Rising. Neuron 60, 489-495, doi:https://doi.org/10.1016/j.neuron.2008.10.019 (2008).\n3 Dayan, P. & Abbott, L. F. Theoretical neuroscience: computational and mathematical modeling of neural systems. Journal of Cognitive Neuroscience 15, 154-155 (2003).\n4 Douglas, R., Mahowald, M. & Mead, C. Neuromorphic analogue VLSI. Annual review of neuroscience 18, 255-281 (1995).\n5 Kriegeskorte, N. & Douglas, P. K. Cognitive computational neuroscience. Nature neuroscience 21, 1148-1160 (2018).\n6 Calabrese, R. L. Inconvenient truth to principle of neuroscience. Trends in neurosciences 41, 488-491 (2018).\n7 Gjorgjieva, J., Drion, G. & Marder, E. Computational implications of biophysical diversity and multiple timescales in neurons and synapses for circuit performance. Current opinion in neurobiology 37, 44-52 (2016).\n8 Gallistel, C. R. & Matzel, L. D. The neuroscience of learning: beyond the Hebbian synapse. Annual review of psychology 64, 169-200 (2013).\n9 Coward, L. A. in Towards a Theoretical Neuroscience: from Cell Chemistry to Cognition 389-393 (Springer, 2013).\n10 Curto, C. & Morrison, K. Relating network connectivity to dynamics: opportunities and challenges for theoretical neuroscience. Current opinion in neurobiology 58, 11-20 (2019).\n11 Bongard, J. & Levin, M. Living Things Are Not (20th Century) Machines: Updating Mechanism Metaphors in Light of the Modern Science of Machine Behavior. Frontiers in Ecology and Evolution 9, doi:10.3389/fevo.2021.650726 (2021).\n12 Bassett, D. S., Zurn, P. & Gold, J. I. On the nature and use of models in network neuroscience. Nature Reviews Neuroscience 19, 566-578 (2018).\n13 Brette, R. Is coding a relevant metaphor for the brain? Behavioral and Brain Sciences 42 (2019).\n "}, {"chunk": "14 Litvina, E. et al. BRAIN initiative: cutting-edge tools and resources for the community. Journal of Neuroscience 39, 8275-8284 (2019).\n15 Okasha, S. Evolution and the levels of selection. Evolution and the levels of selection / (2006).\n16 McShea, D. W. The hierarchical structure of organisms: a scale and documentation of a trend in the maximum. Paleobiology 27, 405-423 (2001).\n17 Turner, D. D. Evolutionary Theory: A Hierarchical Perspective. Edited by Niles Eldredge, Telmo Pievani, Emanuele Serrelli, and Ilya Te\u0308mkin. Chicago (Illinois): University of Chicago Press. $105.00 (hardcover); $35.00 (paper). vii + 385 p.; ill.; index. ISBN: 978- 0-226-42605-1 (hc); 978-0-226-42622-8 (pb); 978-0-226-42619-8 (eb). 2016. The Quarterly review of biology 92, 317-317, doi:10.1086/693596 (2017).\n18 Bechtel, W. & Richardson, R. C. Discovering complexity: Decomposition and localization as strategies in scientific research. (MIT press, 2010).\n19 Boyd, N. M. & Bogen, J. (ed N. Zalta Edward) (Metaphysics Research Lab Stanford University).\n20 Rotstein, H. G. & Santamaria, F. Present and future frameworks of theoretical neuroscience: outcomes of a community discussion. arXiv preprint arXiv:2004.01665 (2020).\n21 Levenstein, D. et al. On the role of theory and modeling in neuroscience. arXiv preprint arXiv:2003.13825 (2020).\n22 Varpio, L., Paradis, E., Uijtdehaage, S. & Young, M. The distinctions between theory, theoretical framework, and conceptual framework. Academic Medicine 95, 989-994 (2020).\n23 Wang, Y. The theoretical framework of cognitive informatics. International Journal of Cognitive Informatics and Natural Intelligence (IJCINI) 1, 1-27 (2007).\n24 Warren, C. E., Allen, M. & Haefner, J. W. Conceptual frameworks and the philosophical foundations of general living systems theory. Behavioral Science 24, 296-310 (1979).\n25 Camp, W. Formulating and evaluating theoretical frameworks for career and technical education research. Journal of Vocational Education Research 26, 4-25 (2001).\n26 Healey, M. P. & Hodgkinson, G. P. in Organizational neuroscience Vol. 7 51-81 (Emerald Group Publishing Limited, 2015).\n27 Bechtel, W. & Huang, L. T.-L. Elements in Philosophy of Mind (Cambridge University Press, Cambridge, 2022).\n28 Breakspear, M. Dynamic models of large-scale brain activity. Nature Neuroscience 20, 340-352, doi:10.1038/nn.4497 (2017).\n29 Schaal, S. in Adaptive Motion of Animals and Machines (eds Hiroshi Kimura, Kazuo Tsuchiya, Akio Ishiguro, & Hartmut Witte) 261-280 (Springer Tokyo, 2006).\n30 Sussillo, D. Neural circuits as computational dynamical systems. Current opinion in neurobiology 25, 156-163 (2014).\n31 Kass, R. E. et al. Computational Neuroscience: Mathematical and Statistical Perspectives. Annual Review of Statistics and Its Application 5, 183-214, doi:10.1146/annurev-statistics-041715-033733 (2018).\n32 Fox, J., Cooper, R. & Glasspool, D. A Canonical Theory of Dynamic Decision-Making. Frontiers in Psychology 4, doi:10.3389/fpsyg.2013.00150 (2013).\n33 Montague, P. R., Dolan, R. J., Friston, K. J. & Dayan, P. Computational psychiatry. Trends in cognitive sciences 16, 72-80 (2012).\n34 Anticevic, A. & Murray, J. D. Computational Psychiatry: Mathematical Modeling of Mental Illness. (Elsevier Science & Technology, 2017).\n35 Eliasmith, C. et al. A Large-Scale Model of the Functioning Brain. Science 338, 1202- 1205, doi:10.1126/science.1225266 (2012).\n"}, {"chunk": "36 Merolla Paul, A. et al. A million spiking-neuron integrated circuit with a scalable communication network and interface. Science 345, 668-673, doi:10.1126/science.1254642 (2014).\n37 Sanz Leon, P. et al. The Virtual Brain: a simulator of primate brain network dynamics. Frontiers in Neuroinformatics 7, doi:10.3389/fninf.2013.00010 (2013).\n38 Cox, David D. & Dean, T. Neural Networks and Neuroscience-Inspired Computer Vision. Current Biology 24, R921-R929, doi:https://doi.org/10.1016/j.cub.2014.08.026 (2014).\n39 Kuhn, T. S. The structure of scientific revolutions. Vol. 111 (Chicago University of Chicago Press, 1970).\n40 Frigg, R. & Harmann, S. (ed N. Zalta Edward) (Metaphysics Research Lab Stanford University, 2020).\n41 Gerstner, W., Sprekeler, H. & Deco, G. Theory and simulation in neuroscience. science 338, 60-65 (2012).\n42 Koch, C. Biophysics of computation: information processing in single neurons. (Oxford university press, 2004).\n43 Rieke, F., Warland, D., Van Steveninck, R. d. R. & Bialek, W. Spikes: exploring the neural code. (MIT press, 1999).\n44 Ashby, W. R. An introduction to cybernetics. (Chapman & Hall Ltd, 1961).\n45 Schiff, S. J. Neural control engineering: the emerging intersection between control theory\nand neuroscience. (MIT Press, 2011).\n46 Sherrington, C. The integrative action of the nervous system. (CUP Archive, 1952).\n47 Eccles, J. C. The cerebellum as a neuronal machine. (Springer Science & Business\nMedia, 2013).\n48 Wark, B., Fairhall, A. & Rieke, F. Timescales of Inference in Visual Adaptation. Neuron\n61, 750-761, doi:https://doi.org/10.1016/j.neuron.2009.01.019 (2009).\n49 Eronen, M. I. a. B., Daniel Stephen. in The Stanford Encyclopedia of Philosophy (ed\nEdward N. Zalta) (Metaphysics Research Lab, Stanford University, 2018).\n50 Alcocer-Cuaro\u0301n, C., Rivera, A. L. & Castan\u0303o, V. M. Hierarchical structure of biological\nsystems: a bioengineering approach. Bioengineered 5, 73-79, doi:10.4161/bioe.26570\n(2014).\n51 Cantor, M. et al. Nestedness across biological scales. PloS one 12, e0171691 (2017).\n52 Richards, B. A. et al. A deep learning framework for neuroscience. Nature neuroscience\n22, 1761-1770 (2019).\n53 Gramann, K., Jung, T.-P., Ferris, D. P., Lin, C.-T. & Makeig, S. Toward a new cognitive\nneuroscience: modeling natural brain dynamics. Frontiers in human neuroscience 8, 444\n(2014).\n54 Ashwin, P., Coombes, S. & Nicks, R. Mathematical frameworks for oscillatory network\ndynamics in neuroscience. The Journal of Mathematical Neuroscience 6, 1-92 (2016).\n55 Rabinovich, M. I., Varona, P., Selverston, A. I. & Abarbanel, H. D. Dynamical principles\nin neuroscience. Reviews of modern physics 78, 1213 (2006).\n56 Doya, K., Ishii, S., Pouget, A. & Rao, R. P. N. Bayesian Brain: Probabilistic Approaches\nto Neural Coding. (The MIT Press, 2006).\n57 Siettos, C. & Starke, J. Multiscale modeling of brain dynamics: from single neurons and\nnetworks to mathematical tools. Wiley Interdisciplinary Reviews: Systems Biology and\nMedicine 8, 438-458 (2016).\n58 Stepniewski, M., Breit, M., Hoffer, M. & Queisser, G. NeuroBox: computational\nmathematics in multiscale neuroscience. Computing and Visualization in Science 20,\n111-124 (2019).\n59 Dai, K. et al. Brain Modeling ToolKit: An open source software suite for multiscale\nmodeling of brain circuits. PLOS Computational Biology 16, e1008386 (2020).\n  "}, {"chunk": "60 Haueis, P. Multiscale modeling of cortical gradients: The role of mesoscale circuits for linking macro-and microscale gradients of cortical organization and hierarchical information processing. NeuroImage 232, 117846 (2021).\n61 Robinson, P. A., Rennie, C., Rowe, D. L., O'Connor, S. & Gordon. Multiscale brain modelling. Philosophical Transactions of the Royal Society B: Biological Sciences 360, 1043-1050 (2005).\n62 Kirov, R. Brain oscillations and predictive coding in the context of different conscious states and sleep-wake cycle: Implications for decision making and psychopathology. Frontiers in psychology 7, 1768 (2016).\n63 Knill, D. C. & Pouget, A. The Bayesian brain: the role of uncertainty in neural coding and computation. TRENDS in Neurosciences 27, 712-719 (2004).\n64 Huang, Y. & Rao, R. P. Predictive coding. Wiley Interdisciplinary Reviews: Cognitive Science 2, 580-593 (2011).\n65 Spanne, A. & Jo\u0308rntell, H. Questioning the role of sparse coding in the brain. Trends in neurosciences 38, 417-427 (2015).\n66 Buzsa\u0301ki, G., Llina\u0301s, R., Singer, W., Berthoz, A. & Christen, Y. Temporal coding in the brain. (Springer Science & Business Media, 2012).\n67 Branson, K. & Thiels, E. Machine Learning in Neuroscience: Fundamentals and Possibilities, <https://neuronline.sfn.org/scientific-research/machine-learning-in- neuroscience-fundamentals-and-possibilities> (2019).\n68 CRCNS. Machine Learning for Large-scale Neuroscience, <https://www.crcns2021nyc.org/workshop> (2021).\n69 Vogt, N. Machine learning in neuroscience. Nature Methods 15, 33-33, doi:10.1038/nmeth.4549 (2018).\n70 Vu, M.-A. T. et al. A Shared Vision for Machine Learning in Neuroscience. The Journal of Neuroscience 38, 1601-1607, doi:10.1523/jneurosci.0508-17.2018 (2018).\n71 Fellous, J.-M., Sapiro, G., Rossi, A., Mayberg, H. & Ferrante, M. Explainable artificial intelligence for neuroscience: behavioral neurostimulation. Frontiers in neuroscience, 1346 (2019).\n72 Arrieta, A. B. et al. Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information fusion 58, 82-115 (2020).\n73 Strickland, E. IBM Watson, heal thyself: How IBM overpromised and underdelivered on AI health care. IEEE Spectrum 56, 24-31 (2019).\n74 Losos, J. B. et al. The Princeton Guide to Evolution. (Princeton University Press, 2013).\n75 Clark, M. A., Choi, J. & Douglas, M. (OpenStax, 2018).\n76 Jarvis, E. D. Evolution of vocal learning and spoken language. Science 366, 50-54,\ndoi:doi:10.1126/science.aax0287 (2019).\n77 McQuillan, M. A., Roth II, T. C., Huynh, A. V. & Rice, A. M. Hybrid chickadees are\ndeficient in learning and memory. Evolution 72, 1155-1164,\ndoi:https://doi.org/10.1111/evo.13470 (2018).\n78 Roststein, H. Workshop: Present and Future Theoretical Frameworks in Neuroscience,\n<https://nsf.gov/awardsearch/showAward?AWD_ID=1820631&HistoricalAwards=false>\n(2018).\n79 Santamaria, F. Future Frameworks in Theoretical Neuroscience Workshop, Part 2,\n<https://snrp.utsa.edu/Podcast/Entries/2019/2/7_Future_Frameworks_in_Theoretical_Ne\nuroscience_Workshop%2C_Part_2.html> (2019).\n80 Quraishi, S. Future Frameworks in Theoretical Neuroscience Workshop, Part 1,\n<https://snrp.utsa.edu/Podcast/Entries/2019/2/4_Future_Frameworks_in_Theoretical_Ne uroscience_Workshop%2C_Part_I.html> (2019).\n         "}, {"chunk": "81 NIH. BRAIN Initiative -Theories, Models and Methods, <https://www.imagwiki.nibib.nih.gov/working-groups/brain-initiative-theories-models-and- methods> (2021).\n  "}, {"chunk": "ABSTRACT\nToward Deep Learning Based Access Control\nMohammad Nur Nobi Institute for Cyber Security (ICS) and Department of Computer Science University of Texas at San Antonio Texas, USA mohammadnur.nobi@utsa.edu\nRam Krishnan\nICS, NSF Center for Security and Privacy Enhanced Cloud Computing (C-SPECC), and Department of Electrical and Computer Engineering University of Texas at San Antonio Texas, USA ram.krishnan@utsa.edu\nYufei Huang Department of Medicine, University of Pittsburgh, and UPMC Hillman Cancer Center Pennsylvania, USA yuh119@pitt.edu\nMehrnoosh Shakarami ICS, C-SPECC, and Department of Computer Science University of Texas at San Antonio Texas, USA mehrnoosh.shakarami@my.utsa.edu\nRavi Sandhu\nICS, C-SPECC, and Department of Computer Science University of Texas at San Antonio Texas, USA ravi.sandhu@utsa.edu\nover forty years. Skilled security administrators needed to engineer and manage accesses as only humans could develop detailed policy insights about individuals\u2019 needs within the broader organization. Clearly, this leads to all types of errors and inefficiencies [4]: there remain plenty of users with accesses that should not have those ac- cesses (over-provisioned to ease administrative burden) and plenty of users that lack accesses that should indeed have those accesses (under-provisioned for the sake of tightened security) [22, 65]. Ad- ministrators tactfully perform a balancing act to maximize security and minimize costs. This complexity is further exacerbated with the proliferation of cloud-based applications that perform machine- to-machine access through APIs, IoT, BYOD, etc.\nIn this paper, we propose an automated and dynamic access control mechanism leveraging advances in deep learning technol- ogy [62] that could complement or potentially replace the human administrator. This approach, denoted as Deep Learning Based Ac- cess Control (DLBAC), addresses three major limitations of classical access control approaches such as RBAC and ABAC. Without loss of generality, we use the term attribute to refer to any form of tra- ditional access control information such as roles and relationships.\n1. Attribute Engineering. An organization typically holds a vast number of metadata about its users and resources. However, those metadata are often not meaningful access control attributes. As a first step, using organizational context often inferred from those metadata, administrators engineer access control specific attributes that could be used to express access control rules subse- quently. This is at best an art today involving semi-formal design and requirements engineering processes [58].\n2. Policy Engineering. After access control relevant attributes are engineered, administrators need to engineer access control rules. This is accomplished through either a manual engineering process akin to attribute engineering above or automated mining techniques that take as input a primitive form of access rules such as ACLs and generate approximate ABAC rules (or user-role assignments, in the case of RBAC) [19, 44]. We will show that, for complex situations, DLBAC generally captures the access control state of the system\nA common trait of current access control approaches is the challeng- ing need to engineer abstract and intuitive access control models. This entails designing access control information in the form of roles (RBAC), attributes (ABAC), or relationships (ReBAC) as the case may be, and subsequently, designing access control rules. This framework has its benefits but has significant limitations in the con- text of modern systems that are dynamic, complex, and large-scale, due to which it is difficult to maintain an accurate access control state in the system for a human administrator. This paper proposes Deep Learning Based Access Control (DLBAC) by leveraging signif- icant advances in deep learning technology as a potential solution to this problem. We envision that DLBAC could complement and, in the long-term, has the potential to even replace, classical access con- trol models with a neural network that reduces the burden of access control model engineering and updates. Without loss of generality, we conduct a thorough investigation of a candidate DLBAC model, called DLBAC\u03b1, using both real-world and synthetic datasets. We demonstrate the feasibility of the proposed approach by addressing issues related to accuracy, generalization, and explainability. We also discuss challenges and future research directions.\nCCS CONCEPTS\n\u2022 Security and privacy \u2192 Access control; \u2022 Computing method-\nologies \u2192 Machine learning. KEYWORDS\nAccess control; Deep learning; Automation\n1 INTRODUCTION AND MOTIVATION\nAccess Control Lists (ACLs) [28], Role-Based Access Control (RBAC) [60], and Attribute Based Access Control (ABAC) [32] are some of the mainstream approaches to determine users\u2019 access to resources. Commercial solutions [21] that cater to organizations employ one or more of these classical access control functionalities. While tremen- dous progress has been made in the realm of classical access control approaches [41], one fundamental issue has remained the same for\narXiv:2203.15124v1 [cs.CR] 28 Mar 2022\n"}, {"chunk": " with more precision than other approaches which are based on policy mining and classical machine learning.\n3. Generalization. Most prior approaches [11, 54] that mine access control rules from simpler forms of access control states such as ACLs focus on accurately capturing the access control state as given in those ACLs. Unfortunately, that leads to poor generalization [17, 73]\u2014that is, the ability to make better access control decisions on users and resources with attributes that were not explicitly seen during the mining process. However, this is something machine learning methods, especially deep learning, are better at. They have an innate ability to make quality predictions as long as the test sample at prediction time aligns with the training data distribution. We will show that the engineered rules typically make poor access control decisions for user-resource metadata that were not explicitly seen by the mining process.\nDLBAC addresses the above issues by exploring a fundamentally different approach to how access control is designed today. As illustrated in Figure 1, DLBAC differs from classical approaches by making decisions based on the metadata of users and resources and a trained neural network. (The key distinction between the notions of metadata and attributes albeit semantic has important practical benefits, which is explained in section 2.1.) It accomplishes this (see Figure 2) by first replacing access control policies with a neural network that instead makes access control decisions. Second, the neural network is trained using raw metadata from the organization instead of laboriously engineered access control attributes.\nTo summarize, we make the following contributions to the field of access control:\n\u2022 We propose DLBAC, a new approach of automated and dynamic next generation access control.\n\u2022 We develop a candidate DLBAC model, DLBAC\u03b1, which outper- forms classical policy mining and machine learning techniques in many aspects, including capturing the existing access control state of the system accurately and generalizing well to situations that were not seen during training time.\n\u2022 As DLBAC is a neural network, we address previously highlighted concerns on the explainability of the black-box nature of neural network-based systems for access control [12]. We apply deep learning interpretation methods to confirm that decision-making in DLBAC can indeed be understood to a large degree (albeit not with 100% accuracy).\n\u2022 We synthesize several large-scale access control datasets with a varying number of users and resources. We evaluate the per- formance of DLBAC on those synthetic datasets along with two real-world datasets.\nThe rest of the paper is organized as follows. Section 2 presents an overview of the DLBAC approach. We discuss related work in Section 3. Section 4 introduces some real-world datasets and presents the synthetic data generation method for DLBAC\u03b1, a can- didate DLBAC model. In the same section, we also explain the implementation of DLBAC\u03b1. We conduct performance evaluation of DLBAC\u03b1 in Section 5. We present approaches to understand DLBAC\u03b1 decisions in Section 6. In Section 7, we discuss future research directions, and conclude in Section 8.\nFigure 1: Decision Making in Classical Approaches vs. DL- BAC.\n2 DEEP LEARNING BASED ACCESS CONTROL\nIn this section, we provide a brief overview of DLBAC and explain how it differs from classical approaches.\n2.1 Decision Making in Classical Approaches vs. DLBAC\nFigure 1 illustrates how DLBAC makes a decision as compared to two classical access control approaches (the discussion applies to other forms of access control approaches such as relationship based access control or ReBAC [14]). In RBAC, an access control decision is simply a cross-reference between user-role and permission-role assignment relations. In the case of ABAC, an access control rule is evaluated for a given operation based on the attributes of the user and resource in question (sometimes attributes of other entities such as \u201cenvironment\u201d are used as well). In DLBAC, a deep neural network makes an access control decision based on the available metadata for the user and resource. For example, metadata could include logs of accesses, employee join date, access time, network access profile, etc. For simplicity, we assume metadata are repre- sented as name-value pairs. While syntactically they appear to be the same as attributes, which are often name-value pairs as well, semantically they are very different. Metadata are primarily differ- ent from attributes since they do not go through the access control design and engineering process. A typical organization could host multiple applications such as email, file storage, human resources, benefits, and other cloud services. Each of those applications hold metadata about users and resources in the organization. Metadata are designed inherently as part of the functionality engineering phase of the system instead of during the access control design phase of the system. Therefore, they are immediately available to DLBAC once the system is implemented. For example, \u2018join_date\u2019, \u2018spending_history\u2019 and \u2018credit_history\u2019 could be metadata of cus- tomer, whereas an engineered attribute could be \u2018status\u2019 (such as \u2018status = platinum\u2019), determined based on all of those metadata.\n2.2 Policy Engineering in Classical Approaches vs. DLBAC\nA conceptual representation of classical access control approaches versus DLBAC is depicted in Figure 2. For simplicity, we assume all methods obtain the current access control state of the system as authorization tuples (e.g., \u27e8user, resource, operations\u27e9), and the metadata of users (e.g., \u27e8designation, \u201cemployee\u201d\u27e9) and resources\n"}, {"chunk": " Figure 2: Design Process of Classical Approaches vs. DLBAC.\n(e.g., \u27e8size, \u201csmall\u201d\u27e9) as the input. In ABAC, the first step of attribute engineering involves designing users and resources attributes in the system that are selected and properly assigned based on available metadata. Common to ABAC and RBAC, the second stage is policy mining/engineering, through which proper policies are developed. Access control mining algorithms, including those using machine learning (ML), are summarized in Section 3. The last element in the conceptual representation of models is the output. For the RBAC approach, the mining process\u2019s output is a set of roles, permission assignment to roles (PA), and user assignment to roles (UA). For ABAC, the output includes a policy consisting of a set of access control rules. (Note that most ABAC mining works assume that attributes and attribute assignments are already available [54, 59]). In contrast, DLBAC is an end-to-end access control approach. It does not need attribute engineering since it works directly with the users and resources metadata. The DLBAC approach\u2019s output is a trained neural network, which takes user and resource metadata as input and makes access control decisions. We note that the DLBAC is agnostic to any deep neural network architecture.\n3 RELATED WORK\nThere is plenty of work on mining/engineering policies either by analyzing the current access control state in the forms of logs and ACLs or transforming one access control model to another. We review three classes of related work below.\nClassical Policy Mining Approaches. A rich body of research on mining classical access control models includes RBAC, ABAC, and ReBAC. Many algorithms were proposed to mine RBAC poli- cies [24, 72], following either top-down [19, 49, 51, 69] or bottom- up [61] methods, while hybrid methods [23] combine the advan- tages of both approaches. Researchers proposed different criteria to assess the quality of mined policy [51] or satisfy various constraints while mining [38]. Xu and Stoller proposed an ABAC mining al- gorithm [73], a variant of which was developed to mine ABAC policies from logs [74]. Many approaches have been proposed to mine ABAC policies\u2014for instance, multi-objective evolutionary op- timization framework [47], identifying functional dependencies in database tables to mine ABAC policies [67], and algorithms to find both positive and negative policy rules [34]. Bui et. al. [6] utilized XuStoller\u2019s algorithm for mining policies in the ReBAC [14] context. Extended versions of this research were presented in [7, 10]. They also proposed a greedy approach for mining ReBAC policy [11]. Iyer et al. [35] proposed a ReBAC mining algorithm in evolving systems for mining graph transitions. The authors later proposed a\nmethod for active learning [36] of ReBAC policies from a black-box access control decision engine using authorization and equivalence queries. A universal access control policy mining, called Unicorn, was proposed by Cotrini et al. [18], which builds policies in a class of access control models including RBAC, ABAC, and ReBAC.\nUsing Machine Learning (ML) for Mining Access Control.\nMany researchers applied ML algorithms for mining access control policies. A probabilistic model for the role mining problem driven from the logical structure of RBAC was proposed by Frank et al. [22]. Deep learning was used to identify relevant attributes [1] to mine ABAC policies from natural language. Other methods including classification trees [13], deep recurrent neural network (RNN) [53], K-Nearest Neighbor (KNN) [20], Decision Tree [8, 9, 71] and Re- stricted Boltzmann Machine (RBM) model [50] have also been used to mine ABAC policy. The first unsupervised learning-based ABAC mining method used k-modes clustering to mine rules from his- torical operation data [40]. Naroui et al. [54] proposed to improve an existing ABAC policy by mining a policy using ML. Cotrini et al. [17] proposed an ABAC policy mining algorithm, named Rhap- sody, built upon APRIORI-SD [42] which is an ML algorithm for subgroup discovery. Rhapsody mines a generalized policy based on sparse logs. Jabal et al. [37] proposed a novel framework for learning ABAC policies from data, named Polisma, combining data mining, statistical, and ML techniques. The Polisma mine a set of rules and applies ML techniques to include requests not covered by the mined rules. Karimi et al. [39] proposed an automatic ap- proach for learning ABAC policy by extracting rules containing both positive and negative attributes and relationship filters.\nClassical ML for Access Control Decision Making. Classi- cal ML approaches have been widely used for making access de- cisions. Sanders et al. [59] presented an approach to mine ABAC policies while satisfying the least privilege principle in a large-scale organization. Symbolic and non-symbolic ML algorithms to infer ABAC policies from access logs have been proposed by Cappelletti et al. [12]. Liu et al. [45] proposed a permission decision engine scheme for ABAC based on Random Forest [5]. The method, called EPDE-ML, decoupled the decision engine from the real access con- trol policy by moving policy updates into a separate phase.\nFollowing our discussion in Section 2, DLBAC is fundamentally different from current approaches. It aims to replace traditional rule- based methods with a neural network, leading to better decision accuracy, generalizability, and engineering ease. Comparing to the related works that uses classical machine learning, we will show that a deep learning based approach provides superior performance while being amenable to usable explainability in practice.\n4 DLBAC\u03b1 : A CANDIDATE DLBAC MODEL\nThis section presents a prototype of DLBAC, namely DLBAC\u03b1, which is an access control model built upon the proposed DLBAC approach in Section 2. As illustrated in Figure 2, DLBAC models e.g., DLBAC\u03b1 need to be fed with authorization tuples and user/resource metadata. We apply DLBAC\u03b1 to two real-world and eight synthetic datasets. First, we explain synthetic datasets construction and in- troduce real-world datasets. Then, we discuss how the DLBAC\u03b1 neural network is trained, and access decisions are made.\n"}, {"chunk": "4.1 Synthetic Dataset Generation\nAn approach to generate synthetic access control datasets was proposed in [73]. We adopt this approach with minor changes to generate multiple synthetic datasets and briefly discuss here. The algorithm first generates a set of attribute names for users and resources randomly. Next, it generates a set of rules based on those attributes and then uses these rules to inform user/resource cre- ation and attribute value assignments. Each rule is a tuple of the form \u27e8UAE;RAE;\ud835\udc42\ud835\udc43;\ud835\udc36\u27e9, where UAE is the set of user attribute expression, RAE is the set of resource attribute expression, \ud835\udc36 is the set of constraints, and \ud835\udc42\ud835\udc43 is a set of operations. For exam- ple, \u27e8title=student; type=document; read; department=department\u27e9 is a rule where title=student represents the UAE, type=document is the RAE, read is the operation, and department=department is the constraint. A user will be authorized to operate on a resource if the user satisfies the UAE, the resource satisfies the RAE, and both the user and resource satisfy the constraint. For each rule, the algorithm generates a set of users that satisfy the rule and then generates resources where for each resource, there is at least one user available to satisfy the rule. The following user and resource are created based on the above rule: user(student1, title=student, de- partment=cs), resource(document1, department=cs, type=document). Here, the student1 and document1 are the unique ids of a user and a resource, respectively. The user student1 has two attributes (title and department), and the resource document1 has two attributes (de- partment and type). Also, student1 satisfies UAE, as the user has the title student which is part of the title in UAE. Similarly, document1 satisfies RAE for the type attribute. Both student1 and document1 satisfy the constraint as they are from the same department. Thus, according to this rule, student1 has read access to document1.\nFinally, once the rules are generated, users and resources are created, and attributes are assigned, it is straight-forward to create the authorization tuples. For each user, resource and operation combination that satisfies a rule, an authorization tuple is created or updated with a new operation, as the case may be.\n4.1.1 Syntax of Synthetic Dataset. We adapt this data generation approach by creating many metadata instead of attributes. We main- tain four operations and various metadata (eight to thirteen) for each user/resource for different datasets. We define the syntax of DLBAC\u03b1\u2019s dataset to contain a set of authorization tuples. An autho- rization tuple could be illustrated of the form \u27e8\ud835\udc62\ud835\udc56\ud835\udc51|\ud835\udc5f\ud835\udc56\ud835\udc51|\ud835\udc5a\ud835\udc621 : \ud835\udc631,\ud835\udc5a\ud835\udc622 : \ud835\udc632, ...,\ud835\udc5a\ud835\udc62\ud835\udc56 : \ud835\udc63\ud835\udc56 |\ud835\udc5a\ud835\udc5f1 : \ud835\udc631,\ud835\udc5a\ud835\udc5f2 : \ud835\udc632, ...,\ud835\udc5a\ud835\udc5f\ud835\udc57 : \ud835\udc63\ud835\udc57 |\u27e8\ud835\udc5c\ud835\udc5d1,\ud835\udc5c\ud835\udc5d2,\ud835\udc5c\ud835\udc5d3,\ud835\udc5c\ud835\udc5d4\u27e9\u27e9. The uid and rid in the tuple indicates the unique id of a user and a re- source, respectively. The next part gives the metadata values of all \ud835\udc56 metadata of a user and \ud835\udc5a\ud835\udc621 indicates the first user metadata name (e.g. umeta0) whereas its value is indicated by \ud835\udc631. The subsequent part presents the metadata values of all \ud835\udc57 metadata of a resource, and first resource metadata name (e.g. rmeta0) and its value are represented by \ud835\udc5a\ud835\udc5f1 and \ud835\udc631, respectively. The last part is a binary se- quence with a \u20181\u2019 meaning \u2018grant\u2019 and a \u20180\u2019 meaning \u2018deny\u2019 for that operation. For example, \u27e81011|2021|30 49 5 26 63 129 3 42 | 43 49 5 16 63 108 3 3 |\u27e81 1 0 1\u27e9\u27e9 is a sample authorization tuple of our dataset where 1011 and 2021 are the user and resource\u2019s unique number. The next eight numbers indicate the metadata values of a user, the following eight numbers represent resource\u2019s metadata values, and the final four binary digits signify the user has \ud835\udc5c\ud835\udc5d1, \ud835\udc5c\ud835\udc5d2, \ud835\udc5c\ud835\udc5d4\naccess to the resource. (In the example above, we also skip naming the metadata with the assumption that it could be inferred from the position of the metadata value.) For simplicity, we assume the metadata values in our datasets are categorical, and each metadata value is an integer representation of a category. We anticipate that our results will hold even in cases of metadata with real numbers.\n4.1.2 Dataset Visualization. We use t-SNE plots [68] to visualize the samples in our datasets. A t-SNE plot discovers relationships in the data by identifying analogous clusters of data points with several features and projecting high dimensional features into a low dimensional feature space while retaining essential information. We project each of our samples to a 2-dimensional feature and plot them. (Note that our datasets have varying numbers of features/metadata ranging from 16 to 26 in total.) Each dot in the plot (Figure 3) represents an authorization tuple, where multiple tuples of the same color indicate that they have the same access permissions. For example, two tuples with only read and write access permissions will have the same color. Notably, a dataset with n operations will have tuples with 2\ud835\udc5b different access combinations and plotted with 2\ud835\udc5b distinct colors. For instance, the authorization tuples of a dataset with two operations (e.g., read and write) can be plotted with four different colors (tuples with the read access, write access, read and write access, and no access).\nThe position of a tuple in the plot is fixed according to the user and resource metadata values. For instance, two different users with the same metadata values may have access to a resource (or multiple resources with the same metadata values). Therefore, these tuples will have the same position regardless of their access permissions. Figure 3(a) depicts a dataset of 1650 users and 320 resources. The tuples (dots) take the position all over the plot according to their metadata values. This dataset has four different operations, and thereby, there are tuples with 16 distinct colors. However, we ob- serve different tuples with the same access permission (same color) are grouped, and groups are isolated from one another, as shown in the figure with blue circles. Thus, a simple classifier can easily distinguish them without much difficulty (e.g., making one rule for each circle). The access control states in real-world situations might be much more complicated [52]. Figure 3(e) shows the visualization of a dataset from Amazon. Even though this is not a complete ac- cess control scenario of the entire Amazon enterprise [17], samples with access (green dots) significantly overlap with other samples without access (red dots) which means tuples with very similar metadata values have entirely different accesses. A simple classifier would create too many rules to model such a dataset.\n4.1.3 Introducing Complexity into Synthetic Datasets. Informed by t-SNE visualization of the Amazon dataset, we seek to introduce complexity into our synthetic datatsets to closely reflect real-world situations. We observe that, in practice, the access privileges of users and resources with somewhat similar metadata could vary. It is also expected that not all the metadata of a user/resource would contribute equally to their permissions. To reflect such scenarios in some of our datasets, we determine accesses considering all the metadata values of user and resource but hide a portion of metadata values from the policy miner (when dealing with mining methods) and model training phase (when dealing with ML methods). How- ever, during rule generation, we ensure that the metadata that we\n"}, {"chunk": "   a\n b\n  c\n  d\n e\nFigure 3: Comparing Complexity of Datasets. (a) A dataset with 1650 users, 320 resources, eight user/resource metadata, (b) A dataset with 1000 users, 639 resources, 11 user/resource metadata, (c) A dataset with 800 users, 656 resources, 11 user/resource metadata, (d) 4500 users, 4500 resources, 11 user/resource metadata, (e) An Amazon dataset [2] (The dataset has more samples with \u2018grant\u2019 access. Therefore, for better visualization, we considered all the tuples with \u2018deny\u2019 access permission and randomly selected a similar number of tuples with \u2018grant\u2019 access permission).\n #\n1 2 3 4 5 6 7 8 9 10\nDataset \ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc67\ud835\udc5c\ud835\udc5b-\ud835\udc58\ud835\udc4e\ud835\udc54\ud835\udc54\ud835\udc59\ud835\udc52\n\ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc67\ud835\udc5c\ud835\udc5b-\ud835\udc62\ud835\udc50\ud835\udc56 \ud835\udc624\ud835\udc58-\ud835\udc5f4\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h11\ud835\udc58 \ud835\udc625\ud835\udc58-\ud835\udc5f5\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h12\ud835\udc58 \ud835\udc625\ud835\udc58-\ud835\udc5f5\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h19\ud835\udc58 \ud835\udc624\ud835\udc58-\ud835\udc5f4\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h21\ud835\udc58 \ud835\udc624\ud835\udc58-\ud835\udc5f7\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h20\ud835\udc58 \ud835\udc624\ud835\udc58-\ud835\udc5f4\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h22\ud835\udc58 \ud835\udc624\ud835\udc58-\ud835\udc5f6\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h28\ud835\udc58 \ud835\udc626\ud835\udc58-\ud835\udc5f6\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h32\ud835\udc58\nType\nReal-world Real-world Synthetic Synthetic Synthetic Synthetic Synthetic Synthetic Synthetic Synthetic\nUsers User Resources Metadata\nResource Authorization Metadata Tuples\nset of values (6 to 20 unique values) following the same distribu- tion used by Xu et al. [73]. We choose each metadata value from the corresponding list during user/resource creation and metadata value assignment. This strategy creates datasets with significantly overlapped samples as depicted in Figure 3(c). We also extended the number of users and resources to simulate a larger organization, which adds more overlaps among samples and higher complexity to the dataset, as shown in Figure 3(d).\nFinally, we synthesized eight different datasets (datasets #3-#10 in Table 1) used for DLBAC\u03b1 experimentation and evaluation, with varying numbers of users, resources, user and resource metadata, and authorization tuples, each reflecting a varying degree of com- plexity. We use the following naming convention for our synthetic datasets,aslistedinTable1:\ud835\udc62\u27e8approx.numberofusers\u27e9\u2212\ud835\udc5f\u27e8approx. number of resources\u27e9 \u2212 \ud835\udc4e\ud835\udc62\ud835\udc61h\u27e8approx. number of authorization tuples\u27e9. We use \u2018u\u2019, \u2018r\u2019, and \u2018auth\u2019 to indicate users, resources, and authorization tuples, respectively. We also visualize all the synthetic datasets in Figure 4(a-h) using t-SNE plots. As illustrated in the Figure, each plot has dots with one of 16 different colors (for four operations), and those dots mix extensively.\n4.2 Real-world Dataset\nAmazon published two datasets that contain access control infor- mation which is widely used in access control research [12, 17, 39]. We name these datasets as \ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc67\ud835\udc5c\ud835\udc5b-\ud835\udc58\ud835\udc4e\ud835\udc54\ud835\udc54\ud835\udc59\ud835\udc52 and \ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc67\ud835\udc5c\ud835\udc5b-\ud835\udc62\ud835\udc50\ud835\udc56, and list them in the Table 1 (1-2). The \ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc67\ud835\udc5c\ud835\udc5b-\ud835\udc58\ud835\udc4e\ud835\udc54\ud835\udc54\ud835\udc59\ud835\udc52 dataset was released in Kaggle [2] (a platform for predictive modeling competitions) as a challenge to the community to build a machine learning model to determine the employees\u2019 accesses. The dataset holds historical access data where employees were manually allowed or denied access to resources over time. The dataset has about nine thousand users and seven thousand resources with over 32K authorizations tuples. Each tuple specifies eight user metadata that depicts a user\u2019s properties, a resource id to identify the resource, and a binary flag to indicate whether the user has access to the resource or not. How- ever, the dataset is highly imbalanced, and about 93% of the tuples are with grant access. We visualize this dataset in Figure 4(i). As we see, there are dots from two colors where green and red correspond to tuples with grant and deny access, each. Notably, a significant number of dots are from grant accesses.\nThe \ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc67\ud835\udc5c\ud835\udc5b-\ud835\udc62\ud835\udc50\ud835\udc56 dataset was provided by Amazon in the UCI machine learning repository [3]. This dataset contains access in- formation of more than 36,000 users and 27,000 permissions. For\nTable 1: List of Datasets.\n 9560 8 7517 0 4224 11 7 0 4500 8 4500 8 5250 8 5250 8 5250 10 5250 10 4500 11 4500 11 4500 11 7194 11 4500 13 4500 13 4500 13 6738 13 6000 10 6000 10\n32769 4224 10964 12690 19535 20979 20033 22583 28751 32557\n will hide contributes to a lesser extent toward permission decisions by excluding them from being part of the constraint of the rules. In a nutshell, hiding metadata attempts to simulate a scenario, where access decisions are made based on access control attributes that are not fully informed by the entire metadata set. In a perfect world, access control attributes could succinctly capture the relevant meta- data distributed across an organization. However, it is reasonable to hypothesize that this is not a practical assumption.\nFigure 3(b) represents a dataset with 11 user and 11 resource metadata. The authorization tuples were created considering all the metadata. To simulate a similar situation while visualizing tuples and understand how it looks from a policy mining (or classification) perspective, we make only the first eight user and the first eight resource metadata values available for visualization. As shown, many dots of other colors now start to mix, indicating two tuples with similar user-resource metadata values may have very different accesses. Indeed, such proximity of the tuples is challenging for clustering or rule creation. The more metadata we hide, the more complicated the dataset for policy mining and ML approaches.\nWe still notice a few portions in the plot where the same colored dots are clustered together and separable, as shown with red circles in Figure 3(b). This is because the dataset generation algorithm [73] creates the metadata values based on a distribution, where the value range (i.e., number of values for each metadata) is sparse. For ex- ample, there are around one hundred different values for specific metadata (e.g., department) in a dataset with hundred users. One can easily cluster all the users into hundreds of groups based only on the department. However, there might be the case where meta- data values are required to be chosen from a set of a limited number of values (say, ten departments for hundred users). Evidently, it is harder to cluster one hundred users into ten groups than a hundred. To reflect this, for each metadata, we define a fixed and smaller\n"}, {"chunk": "       a\n b\n c\n d\n e\n f\n g\n h\n i\n j\n Figure 4: t-SNE Visualization of Synthetic and Real-world Datasets from Table 1. Figures a-h corresponds to synthetic datasets #3\u2212#10 and i-j corresponds to real-world datasets #1\u2212#2 in Table 1, respectively.\n Figure 5: Preparing Training Data for DLBAC\u03b1.\nany permission, less than 10% of all users have requested access. The dataset is widely used in access control researches, and in most of the cases, the experiments are confined to only 5 to 8 most re- quested permissions [12, 17, 39]. Likewise, we took the seven most requested permissions, and for each permission, we list users who have access to the selected permissions. However, this dataset is also imbalanced, around 75% tuples with the deny access. In addi- tion, the dataset is not ABAC in nature, and there are some tuples in the dataset where users with identical attribute values do not have the same access permissions. Because of this, policy mining or classification approaches may suffer while clustering the users for different permissions. We visualize this dataset in Figure 4(j).\n4.3 Neural Network Architecture and Training\nFor DLBAC\u03b1, the deep neural network takes user/resource metadata values as input. It includes a classification layer with the number of neurons equal to the number of operations, where each neuron outputs the probability of granting the permission for a related oper- ation, op. Given a feature vector \ud835\udc65 of the user and resource metadata, the neural network can be defined as a prediction function \ud835\udc53 such that \ud835\udc66\u02c6 = \ud835\udc53 (\ud835\udc65), where \ud835\udc66\u02c6 is the predicted label or permission (grant (1) or deny (0)) of \ud835\udc5c\ud835\udc5d, obtained from comparing the probability of granting the permission at the output of the network with a threshold. Note that for all DLBAC\u03b1 experimentation, we consider a threshold of 0.5. To train the neural network \ud835\udc53 (i.e. determine the network\u2019s weights), a set of training authorization tuples X\nof size \ud835\udc41 is collected, where (\ud835\udc65\ud835\udc56 , \ud835\udc66\ud835\udc56 ) denotes the \ud835\udc56 -th sample in X, where \ud835\udc65\ud835\udc56 is the feature vector of the user and resource metadata and \ud835\udc66\ud835\udc56 is the corresponding \ud835\udc5c\ud835\udc5d or the target label. As discussed in Section 4.1.3, for some synthetic datasets, we hide a portion of metadata from the policy mining algorithm to mimic some com- plex situations. We apply this for the datasets having more than eight user metadata and eight resource metadata. In such a case, \ud835\udc65\ud835\udc56 represents the feature vector of the first eight user metadata and the first eight resource metadata. So, for example, for a dataset with 13 user-resource metadata, we hide five metadata from the user metadata and five from the resource metadata.\nSince the metadata values in our dataset are categorical, we map them to binary values by utilizing encoding. We encode a tuple\u2019s user/resource metadata value using one-hot encoding [27] to trans- form the categorical values into a two-dimensional binary array. The row in the array represents metadata, and the column holds the encoded binary representation of the corresponding metadata value. (Amazon dataset\u2019s metadata values are too sparse, and we use binary encoding for them considering its memory efficiency in such cases [63]). As each operation is binary, we apply them directly as the target labels without any processing. Figure 5 illustrates the overall training data preparation for DLBAC\u03b1. As illustrated, we encode the metadata values of a user \ud835\udc34\ud835\udc59\ud835\udc56\ud835\udc50\ud835\udc52 and a resource \ud835\udc5d\ud835\udc5f\ud835\udc5c \ud835\udc57\ud835\udc52\ud835\udc50\ud835\udc61\ud835\udc34 and apply permissions to the associated operations without further processing. We train DLBAC\u03b1 based on the training data, and this trained DLBAC\u03b1 is used in Access Control Decision Engine (discussed below) to produce access decisions for test data.\n4.4 Decision Making Process in DLBAC\u03b1\nAccess Control Decision Engine (Decision Engine) is a DLBAC compo- nent responsible for receiving and authorizing any access request. In DLBAC\u03b1, the Decision Engine (Figure 6) takes three inputs (user, resource, and operation). The Decision Engine retrieves the user and resource metadata from the internal databases and then encodes them to obtain corresponding binary representation. The encoded input is fed into the neural network to predict the corresponding request\u2019s access permission. The network outputs access informa- tion for all the operations. The decision engine then determines the actual access authorization based on the requested access and the network\u2019s output. For the specific example in Figure 6, user Alice\n"}, {"chunk": " Figure 6: Decision Making Process in DLBAC\u03b1.\nwants op2 access on projectA resource. The output of the neural network for the op2 is 1, which indicates that Alice has op2 access on projectA. Thus, the Decision Engine authorizes this request.\n5 EVALUATION\nIn this section, we experimentally evaluate the performance of DLBAC\u03b1 using both synthetic and real-world datasets.\n5.1 Evaluation Methodology\nWe experiment and evaluate the performance for all the datasets listed in Table 1. We consider each dataset to represent an organiza- tion with its own unique characteristics. We split each dataset into training (80%) and testing (20%) sets. As the test dataset is entirely unseen during training, the evaluation shall adequately measure the generalization of any method.\nInstances of DLBAC\u03b1. DLBAC is agnostic to deep neural net- work architecture, and we will show that the deep learning-based model\u2019s performance is consistent across datasets. For demonstra- tion, we implement three instances of DLBAC\u03b1 using three dis- tinct deep neural network architectures including ResNet [29], DenseNet [33], and Xception [15], and name them as DLBAC\u03b1\u2212R, DLBAC\u03b1\u2212D, and DLBAC\u03b1\u2212X, respectively. For DLBAC\u03b1\u2212R, we use the ResNet network with depth 8 for the first four datasets in Table 1 whereas, for the rest of the datasets, we use a ResNet with depth 50. For DLBAC\u03b1\u2212D, we use the DenseNet architecture with [6,12,24,16] layers in the four dense blocks. We adopt the source code from the Keras application for all the model architectures implementation.1\nThe DLBAC\u03b1 instances were developed in Python using Keras library with a TensorFlow backend and trained on Google Colab (a 12GB NVIDIA Tesla K80 GPU). We apply Adam optimizer with an initial learning rate of 0.001, scheduled to reduce the learning rate by dividing by ten after every 10 epochs. The epoch and batch size was chosen as 60 and 16, respectively, with an early stop after 5 consecutive epochs without any performance improvement. As the DLBAC\u03b1 outputs an access probability between \u20180\u2019 and \u20181\u2019 for each operation, we use binary cross-entropy loss. We have created a repository in GitHub consisting of all the datasets, source code, and trained networks.2\n1 https://github.com/keras- team/keras- applications 2 https://github.com/dlbac/DlbacAlpha\nMachine learning (ML) algorithms. We compare the perfor- mance of DLBAC\u03b1 instances with classical machine learning ap- proaches such as Support Vector Machine (SVM) [16] and Random Forests (RF) [5]. We also compare with Multi-Layer Perceptron (MLP) [62] with four hidden layers (a shallow network) to evaluate how significant the performance difference is between a deep and a non-deep neural network. We use the SVC and RandomForestClas- sifier class of the Python scikit-learn library [57] for SVM and RF implementation, respectively, with their default configurations. We implement MLP using Keras library.\nPolicy mining algorithms. There is no other existing deep learning-based access control approach to the best of our knowl- edge, so a direct comparison of our work results is not currently possible. Therefore, we compare DLBAC\u03b1 with ABAC policy min- ing algorithms being one of the flexible and generalized access control approaches. We compare the performance of DLBAC\u03b1 in- stances with the following policy mining algorithms. While a few other works exist as discussed in our related work, a key decision factor in selecting these works was our ability to readily access their source codes and our ability to clearly understand, modify/tweak as needed and compile them.\n(1) The policy mining algorithm proposed by Xu and Stoller [73], which we refer to as XuStoller.\n(2) Rhapsody [17], a policy mining algorithm built upon an ML algo- rithm for subgroup discovery named APRIORI-SD [42]. Rhapsody performance has a direct correlation with multiple parameters. We trial with different parameter values and selected the policy with the highest F1 score while maintaining an FPR below 0.05.\n(3) EPDE-ML [45], a permission decision engine scheme based on ML where a trained RF model makes the access control decision.\nEvaluation metrics. For ML algorithms, we compute the F1 score and compare the performance with DLBAC\u03b1 instances and show that deep learning based algorithms generally perform better than traditional ML and MLP techniques. For an extensive compar- ison against policy mining algorithms, we compute the F1 score, False Positive Rate (FPR), True Positive Rate (TPR), and Precision. We consider the standard definitions [17, 45] of these evaluation metrics. Policies (or models) with a higher F1 score lead to better generalization. They can make more accurate access control de- cisions on users and resources with attributes not explicitly seen during the mining (or training) process. Also, the higher TPR and Precision are better as these scores indicate how accurately and efficiently the policies (or models) can grant access. On the contrary, the policies (or models) with a lower FPR are better as they are less likely to give access to requests, those which should be denied according to the ground truth access control policy.\n5.2 Results\n5.2.1 Performance comparison with ML algorithms. Figure 7 illus- trates the overall performance of all ML approaches and DLBAC\u03b1 instances for each dataset with respect to F1 score. The performance of all the algorithms is consistent and better for the \ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc67\ud835\udc5c\ud835\udc5b-\ud835\udc58\ud835\udc4e\ud835\udc54\ud835\udc54\ud835\udc59\ud835\udc52 dataset, but it is not the case for \ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc67\ud835\udc5c\ud835\udc5b-\ud835\udc62\ud835\udc50\ud835\udc56 dataset. In this case, SVM and MLP performed significantly lower, and other approaches including DLBAC\u03b1 instances could not achieve high performance.\n "}, {"chunk": "  Figure 7: F1 Score Comparison: ML Algorithms vs. DLBAC\u03b1 Instances.\nSuch a result is expected due to the inconsistency in the access per- missions in that dataset. The dataset contains tuples where users with identical attribute values do not have the same access permis- sions, as discussed in Section 4.2. The advantage of the DLBAC ap- proach is more evident if the dataset is processed correctly. We show this using our synthetic datasets. For synthetic datasets, DLBAC\u03b1 instances achieved the highest F1 score, while SVM and MLP per- formed the worst. Also, the instances of DLBAC\u03b1\u2019s improvements over RF are significant (for p-value < 0.05; paired T-test (not shown here))forallthesyntheticdatasetsexcept\ud835\udc625\ud835\udc58-\ud835\udc5f5\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h12\ud835\udc58 dataset. The performance advantage of DLBAC\u03b1 instances is particularly pronounced in synthetic datasets with a large number of authoriza- tion tuples, where DLBAC\u03b1 instances report 0.03 to 0.09 improve- ments over RF as shown in the figure. Notably, the performances of all algorithms vary with the complexity of the datasets. However, DLBAC\u03b1 instances show the lowest variation in its performance across the datasets, implying that DLBAC\u03b1 is most robust against changes in data characteristics such as number of hidden metadata, number of users, resources, and authorization tuples. Except for the \ud835\udc624\ud835\udc58-\ud835\udc5f6\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h28\ud835\udc58 dataset, all algorithms\u2019 performances drop with the increase of hidden metadata (e.g., the \ud835\udc624\ud835\udc58-\ud835\udc5f4\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h22\ud835\udc58 dataset with 13 metadata where we hide 5 of the metadata from the feature vector as discussed in Section 4.3), suggesting that an increase in data complexity generally impacts performance. Overall, the exper- imental results indicate that DLBAC\u03b1 is more effective and robust than classical ML approaches, including MLP, for making accurate access decisions.\nWhile the performance advantages of DLBAC\u03b1 are not apparent in the Amazon datasets, we emphasize that those datasets are not reflective of the access state complexity of the entire organization but that of a small portion of the company. This is one of the reasons why we synthesized additional datasets for our experimentation.\n5.2.2 Performance comparison with policy mining algorithms. Fig- ures 8, 9, 10, and 11 compare the F1 score, FPR, TPR, and Precision, respectively of policy mining algorithms and DLBAC\u03b1 instances. We could not experiment XuStoller algorithm for the largest syn- thetic dataset (\ud835\udc626\ud835\udc58-\ud835\udc5f6\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h32\ud835\udc58) as it took a very long runtime without any output. We can make the following observations based on all these experimental results.\nFigure 8: F1 Score Comparison: Policy Mining Algorithms vs. DLBAC\u03b1 Instances.\nFigure 9: FPR Comparison: Policy Mining Algorithms vs. DLBAC\u03b1 Instances.\nFigure 10: TPR Comparison: Policy Mining Algorithms vs. DLBAC\u03b1 Instances.\n\u2022 A deep learning based approach can make more accurate access control decisions and generalize better. The F1 score of EPDE-ML and DLBAC\u03b1 instances are significantly better than the rule-based approaches such as XuStoller and Rhapsody. That signifies, in general, machine learning-based approaches can make better gen- eralization and accurate access control decisions. As we see in Figure 8, the performance improvements of DLBAC\u03b1 instances over EPDE-ML, which is statistically significant for most datasets,\n  "}, {"chunk": " Figure 11: Precision Comparison: Policy Mining Algorithms vs. DLBAC\u03b1 Instances.\nsuggest that deep learning based algorithms make the more accu- rate decision and have even better generalization capability than classical ML-based policy mining approaches.\n\u2022 A deep learning based approach can properly balance both over- provision and under-provision. XuStoller and Rhapsody achieved the best FPR as shown in Figure 9, indicating they are unlikely to give access to requests that should be denied according to the actual access control policy. However, that is not the case for denying access. As we see in Figure 10, the TPR for Rhapsody is between 0.2 to 0.85, and for XuStoller, it is from 0 to 0.25. Such a lower TPR indicates that these algorithms are pretty inefficient while denying access (under-provisioned) even though the re- quests deserve grant access according to the actual access control policy. On the other hand, the EPDE-ML performed lowest in terms of FPR (over-provisioned) across synthetic datasets ranging from 0.06 to 0.23. Their average TPR and Precision are below 0.9. Such higher FPR and comparably lower TPR and Precision suggest that EPDE-ML could not achieve desirable performance in terms of over-provision and under-provision. The DLBAC\u03b1 instances obtained a much higher TPR and Precision as illustrated in Figure 10 and 11. Also, the DLBAC\u03b1 instances reached an FPR which is comparable to XuStoller and Rhapsody, as shown in Figure 9. This suggests that deep learning based approach can balance better between over- and under-provisioning.\n\u2022 An imbalanced dataset may affect some performance that could be calibrated. The FPR result of DLBAC\u03b1 instances for \ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc67\ud835\udc5c\ud835\udc5b- \ud835\udc58\ud835\udc4e\ud835\udc54\ud835\udc54\ud835\udc59\ud835\udc52 dataset is high, and the TPR for \ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc67\ud835\udc5c\ud835\udc5b-\ud835\udc62\ud835\udc50\ud835\udc56 dataset is relatively low, arising due to the characteristics of the dataset [70]. As discussed in Section 4.2, these datasets are imbalanced, one has unreasonably more samples from the grant class, and the other has more from the deny class. We argue that this is a typical machine learning problem, and EPDE-ML has a similar performance for these datasets. For balanced datasets, the FPR and TPR of DLBAC\u03b1 instances are consistent, and FPR is below 0.05 for most of the datasets while TPR is above 0.95, as demonstrated in Figure 9 and 10. Evidently, these metrics could be calibrated based on the tolerance to over vs. under-provisioning of an application context. Specifically, one could favor a particular metric in DLBAC\u03b1 by modifying the loss function to increase the weight of the minority class [31], adjusting the threshold for granting permissions as described in Section 4.3, etc. We note that an improvement in one\nof the metrics will likely negatively impact one or more of the others and that every work is prone to this issue.\nOverall, the DLBAC\u03b1 instances achieved better or comparable performance for all the metrics across datasets, suggesting that deep learning based approaches generalized better and made more accurate access control decisions than rule based and classical ML based approaches. These results demonstrate the effectiveness of using DLBAC as an access control system.\n6 UNDERSTANDING DLBAC DECISIONS\nAs the core of a DLBAC system is a neural network, a major chal- lenge is providing insights into why and how DLBAC makes certain decisions. That is, explainability is a key challenge for DLBAC. For instance, in Figure 6, the Decision Engine received a request that user Alice wishes op2 access on projectA resource. Based on the re- sult of the neural network, the decision engine approved the request. However, it is not quite obvious why the neural network made that prediction for this request. Such a justification is generally straight- forward in traditional access control systems as the decisions are made based on written policies. But, it is challenging for DLBAC due to the black-box nature of a neural network [64]. As the de- cisions are made based on provided user/resource metadata, it is essential to understand why a decision is made and which metadata influenced that decision. Many techniques have been introduced to help gain insights into a neural network\u2019s internal details. In this section, we investigate two state-of-the-art approaches for this pur- pose: Integrated Gradients [66] and Knowledge Transferring [25]. We experiment on DLBAC\u03b1\u2212R instance (as introduced in Section 5.1), and for brevity, we refer it to DLBAC\u03b1 in the following discussion. The related source code is uploaded to GitHub.3\n6.1 Integrated Gradients\nIntegrated Gradients is an effective interpretation technique that focuses on attributing the decisions of a neural network to the input features of the prediction samples. It attributes a network\u2019s decision to its input features in terms of gradient, which specifies the most effective elements for a decision. To understand the decision of DLBAC\u03b1 for a tuple, it is required to provide the user/resource metadata values, the decision, and the neural network as input to the Integrated Gradients. Then, Integrated Gradients outputs the attribution scores of the input metadata that we normalize in the scale of 0 to 1, denoting the degree of impact on the decision. Such an interpretation is known as local interpretation which helps to better understand each decision of a neural network. It is also helpful to have a global interpretation [26] of a network to understand the network\u2019s overall knowledge. Generally, it takes a set of decisions to generate a global interpretation of a network.\nFor DLBAC\u03b1, we investigate explainability for both specific ac- cess control decision and the overall knowledge learned by the net- work. For this purpose, we train DLBAC\u03b1 on our \ud835\udc624\ud835\udc58-\ud835\udc5f4\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h11\ud835\udc58 dataset. Then, we request op1 operation access to projectD resource for a user Dave and the Decision Engine grants the request. To learn the reason behind this decision, we perform local interpreta- tion with metadata values of Dave and projectD, the decision (grant access on op1 operation), and the DLBAC\u03b1 network. As depicted in\n3https://github.com/dlbac/DlbacAlpha/tree/main/understanding_dlbac_alpha\n "}, {"chunk": "   Figure 12: Local and Global Interpretation (blue: local inter- pretation of a decision in DLBAC\u03b1. orange: global interpre- tation of DLBAC\u03b1 for the grant access of an operation).\nFigure 12 (blue bars), for this particular request, user\u2019s umeta4 and resource\u2019s rmeta2 metadata are the most important and influential. To achieve global interpretation for the grant access to op1 oper-\nation, we take the op1 access information for a set of fifty random sampleswithgrantaccessfromthe\ud835\udc624\ud835\udc58-\ud835\udc5f4\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h11\ud835\udc58 dataset.(Note that the more samples we use, the more precise the result we get. However, Integrated Gradients is memory inefficient, so we could not test more samples using our workstation with 16 GB of mem- ory). We provide each user/resource metadata and their respective decisions for the op1 operation to Integrated Gradients to obtain the global interpretation. Figure 12 (orange bars) depicts the global interpretation of DLBAC\u03b1 for the \ud835\udc624\ud835\udc58-\ud835\udc5f4\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h11\ud835\udc58 dataset for the grant access to op1 operation. The result identifies resource\u2019s rmeta2 as the most influential metadata, user\u2019s umeta2 as second most in- fluential metadata, and the attribution scores of other metadata.\n6.1.1 Application of Integrated Gradients based Understanding. Im- proved explainability could be utilized to achieve other benefits. For instance, developers can utilize interpretation techniques to debug [55] incorrect decisions from the neural network in decision engine. We show that Integrated Gradients based interpretation can be used to grant/deny access permissions by modifying proper meta- data. As shown in Figure 13 (tuple2), the user Carol doesn\u2019t have op1 access on projectC resource. Applying local interpretation on other tuple with op1 access (e.g., Dave has the op1 access to projectD re- source as shown in Figure 13 (tuple1)) revealed the attribution scores of different metadata for op1 operation. As circled in tuple1, Dave\u2019s \u2018umeta1\u2019 and \u2018umeta4\u2019 are the most dominant metadata for this spe- cific access. To grant Carol\u2019s op1 access on projectC resource, we utilize attribution scores of tuple1. Our result shows that replacing Carol\u2019s \u2018umeta1\u2019 and \u2018umeta4\u2019 metadata value with Dave\u2019s metadata value enables Carol\u2019s op1 access to projectC resource. As reported, modifying one or two significant metadata changes corresponding access. The opposite holds for least-significant metadata where modifying multiple metadata could not alter related access.\nWe also experiment with such a metadata value modification across all the samples of a specific decision (e.g., tuples with \u2018deny\u2019 access on op1) in the same dataset to see the impact of a global interpretation. The idea is to alter the metadata values of influential metadata for a specific decision. For instance, according to Figure 12, the rmeta2 has the most influence on denying access. If we alter\nFigure 13: Applying Integrated Gradients to Grant Access.\nFigure 14: Modifying Metadata Value Based on Integrated Gradients Across Tuples (4581 tuples) with Deny Access.\nthe rmeta2 value of any tuple, say tupleA, with a rmeta2 value from a known tuple with grant access, say tupleB, the chance of denying access for tupleA might reduce and increases the chance of getting access. Also, altering the value of multiple influential metadata of the same tuple may eventually help to get access.\nTo investigate that we alter different metadata values, one by one, of all the tuples with deny access (4581 such tuples) on op1 in order of their significance level in the global interpretation. For example, we first change the value of rmeta2 metadata, next umeta2 metadata, and so on. We utilize the user/resource metadata values from tuple1 in Figure 13 as a known tuple with the \u2018grant\u2019 access for op1 operation. As described in Figure 14, initially, with no change, no tuple has been granted access. However, with the change of first metadata (rmeta2), around 5% of the tuples receive grant access. By changing the second metadata value, around one-third of the tuples get grant access. A similar surge continues to obtain grant access for over half of all the tuples before decreasing for sixth metadata (rmeta5) modification, reaching below 40%. It indicates that some tuples with such a big number of metadata modifications fall under a different distribution for which they have the \u2018deny\u2019 access. Overall, using this technique, a system admin can estimate the impact of metadata value vs. dependent accesses.\n6.2 Knowledge Transferring\nAlthough Integrated Gradients determines the attribution scores of each metadata for a decision, it does not establish the relationship among metadata or the network\u2019s logic [66]. Knowledge Transferring could help to identify such relationships. With Knowledge Transfer- ring, we can extract a decision tree to approximately understand the decision of DLBAC\u03b1 in the form of traditional rules. While accurate reconstruction of the representation details is infeasible, the generated decision tree will give an approximate explanation of the underlying logic of DLBAC\u03b1. Though the decision tree makes\n"}, {"chunk": " Figure 15: Knowledge Transferring Technique.\nclassification decisions understandable [57], it does not generalize as well as deep neural networks. Interestingly, a neural network\u2019s generalization ability is likely to be transferred to a decision tree through a method called distillation [30], which has been widely used in ML literature and we adopt in this paper. As explained in Section 4.3, DLBAC\u03b1 outputs whether a user has access to any re- source by giving the probability of granting the access instead of a direct yes/no answer. Therefore, we can determine those probability outputs for all the tuples in a dataset and train a decision tree, as shown in Figure 15. These probabilities represent the knowledge of the neural network, and we aim to transfer it to a decision tree.\nTo explore Knowledge Transferring technique, we train DLBAC\u03b1\nfor the\ud835\udc624\ud835\udc58-\ud835\udc5f4\ud835\udc58-\ud835\udc4e\ud835\udc62\ud835\udc61h11\ud835\udc58 dataset that we used for the Integrated Gra-\ndients experiment. We take op1 access probabilities for all the sam-\nples. Then, we train a decision tree (DT) on the same dataset. How-\never, instead of giving corresponding ground-truth permissions\nfrom the dataset, we provide the probability outputs of DLBAC\u03b1.\nEventually, we construct a DT with a maximum depth of eight\nthat facilitates retrieving underlying rules for any specific deci-\nsion. While the tree serves the global interpretation, a rule for any\nspecific decision represents the local interpretation. We apply the\nmetadata values of Dave and projectD that we described in previous\nsection, and retrieve the access rules from the DT for op1 operation.\nWe observe that Dave obtained grant access to projectD for op1\nD\nbased on following rule:\numeta2<20\u27e9\u2227\u27e8umeta6<50\u27e9 \u2227 \u27e8rmeta0<72\u27e9\u2227\u27e8rmeta2\nE\n< 18 \u27e9 \u2227 \u27e8 rmeta5 < 111 \u27e9\nsion tree should be generated with unlimited depth to obtain more precise rules. Note that the Integrated Gradients and Knowledge Transferring techniques are orthogonal in terms of insights they each provide into the neural network and do not substitute each other. For better insights, one could use both methods.\n7 FUTURE RESEARCH DIRECTIONS\nIn this section, we discuss some of the challenges for DLBAC and explore some ideas of how those could be addressed.\nAccess Control Administration. A major task in access con- trol is policy administration, i.e. updating the system\u2019s rules to affect a particular change. It is a significant challenge for DLBAC as a policy change amounts to adjusting the current neural network\u2019s weights. This can, of course, be obtained by retraining the network. However, that is neither ideal nor cost-effective. Fine-tuning is one of the common approaches that helps a neural network to learn\nnew changes by updating the current network\u2019s weight [43]. This allows one to implement policy changes by making minor changes to the network. However, the network should handle the issue of catastrophic forgetting, which is a common pitfall in fine-tuning. We believe these issues can be effectively mitigated by developing methods based on life-long learning [56] for DLBAC.\nAdversarial Attacks. Adversarial attacks are a common con- cern for any machine learning based system, deep learning net- works in particular. An adversary can obtain unauthorized access by fooling the network with modified samples that are indistin- guishable from natural ones by human [75]. However, such attacks could be mitigated by applying adversarial training [46]. In the context of DLBAC, an adversarial attack is to acquire access per- missions based on modified/perturbed user and resource metadata. In access control, the datasets and the adversarial attack profile are somewhat interesting and different from traditional image domains. One typically expects a mix of categorical and continuous metadata. Moreover, since some metadata are more trustworthy than others, an adversary does not have the complete flexibility to change an entire sample imperceptibly. These observations could be leveraged to develop better defenses against adversarial attacks in DLBAC. Another related aspect needs to investigate whether DLBAC can efficiently handle an access request if some of its user/resource metadata are deleted, a.k.a attribute hiding attack.\nBias and Fairness. As DLBAC learns based on metadata dis- tributed across various parts of an enterprise, there might be differ- ent types of human biases or errors in training data. As such, the DLBAC network trained based on such data can inadvertently be biased, favoring some decisions. For example, as observed in the \ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc67\ud835\udc5c\ud835\udc5b-\ud835\udc58\ud835\udc4e\ud835\udc54\ud835\udc54\ud835\udc59\ud835\udc52 dataset, most of the authorization tuples were with \u2018grant\u2019 decision, and DLBAC\u03b1 instances were biased towards the same decision. Certain metadata could be influenced by various factors including ethnographic. Therefore, to obtain a fair and trust- worthy DLBAC system, it is critical to audit training data, evaluate decisions for fairness, and establish a proper feedback loop [48].\nDLBAC in Tandem with Traditional Access Control. Evi- dently, in practice, we do not foresee (nor advocate) that DLBAC will simply substitute traditional forms of access control immedi- ately. One research challenge is how DLBAC could be effectively integrated to operate in tandem with traditional access controls such as RBAC or ABAC. One of the issues that will arise is con- flicting decisions between, say, RBAC and DLBAC. If that conflict were to be resolved in favor of RBAC, that decision could be used to fine-tune the DLBAC network. DLBAC could also be used in the background for monitoring or auditing purposes.\n8 CONCLUSION\nWe proposed DLBAC, a deep learning based access control ap- proach, to deal with issues in classical access control approaches. As DLBAC learns based on metadata, it obviates the need for at- tribute/role engineering, policy engineering, etc. We implemented DLBAC\u03b1, a prototype of DLBAC, using both real-world and syn- thetic datasets. We demonstrated DLBAC\u03b1\u2019s effectiveness as well as its generalizability. As the core of DLBAC is a neural network, we applied two different state-of-the-art techniques to understand DLBAC decisions in human terms. We also discussed some future\n\u27e8 umeta0 > 31 \u2227 umeta0 < 63 \u27e9 \u2227 \u27e8\n. It is worth mentioning that the deci-\n"}, {"chunk": "directions to build new models upon DLBAC and address current challenges, including access control administration issues.\nACKNOWLEDGMENTS\nWe would like to thank the CREST Center For Security And Pri- vacy Enhanced Cloud Computing (C-SPECC) through the National Science Foundation (NSF) (Grant Award #1736209) and the NSF Division of Computer and Network Systems (CNS) (Grant Award #1553696) for their support and contributions to this research.\nREFERENCES\n[1] Manar Alohaly, Hassan Takabi, and Eduardo Blanco. 2018. A deep learning approach for extracting attributes of ABAC policies. In SACMAT. ACM.\n[2] Kaggle Amazon. 2013. Amazon Employee Access Challenge in Kaggle. https: //www.kaggle.com/c/amazon-employee-access-challenge/\n[3] UCI Amazon. 2011. Amazon Access Samples Data Set. http://archive.ics.uci. edu/ml/datasets/Amazon+Access+Samples\n[4] L. Bauer, L. F Cranor, et al. 2009. Real life challenges in access-control manage- ment. In Conference on Human Factors in Computing Systems.\n[5] Leo Breiman. 2001. Random forests. Machine learning (2001).\n[6] T.Buietal.2017.Miningrelationship-basedaccesscontrolpolicies.InSACMAT.\n[7] T. Bui et al. 2018. Mining Relationship-Based Access Control Policies from\nIncomplete and Noisy Data. In Symposium on Foundations and Practice of Security.\n[8] ThangBuiandScottDStoller.2020.Adecisiontreelearningapproachformining\nrelationship-based access control policies. In SACMAT. ACM.\n[9] T. Bui and S. D Stoller. 2020. Learning Attribute-Based and Relationship-Based Access Control Policies with Unknown Values. In Information Systems Security.\n[10] Thang Bui, Scott D Stoller, and Hieu Le. 2019. Efficient and Extensible Policy\nMining for Relationship-Based Access Control. In SACMAT. ACM.\n[11] T.Bui,S.DStoller,andJ.Li.2019.Greedyandevolutionaryalgorithmsformining\nrelationship-based access control policies. Computers & Security (2019).\n[12] Luca Cappelletti et al. 2019. On the quality of classification models for inferring\nabac policies from access logs. In Big Data. IEEE.\n[13] Suresh N Chari and Ian M Molloy. 2016. Generation of attribute based access\ncontrolpolicyfromexistingauthorizationsystem. USPatent9,264,451.\n[14] Y.Cheng,K.Bijon,andR.Sandhu.2016.ExtendedReBACadministrativemodels\nwith cascading revocation and provenance support. In SACMAT. ACM.\n[15] Franc\u0327ois Chollet. 2017. Xception: Deep learning with depthwise separable con-\nvolutions. In IEEE CVPR.\n[16] C.CortesandV.Vapnik.1995.Support-vectornetworks.Machinelearning(1995).\n[17] C. Cotrini et al. 2018. Mining ABAC rules from sparse logs. In Euro S&P.\n[18] Carlos Cotrini, Luca Corinzia, Thilo Weghorn, and David Basin. 2019. The next\n700 policy miners: A universal method for building policy miners. In CCS. ACM.\n[19] S. Das, B. Mitra, V. Atluri, J. Vaidya, and S. Sural. 2018. Policy Engineering in\nRBAC and ABAC. In From Database to Cyber Security. Springer.\n[20] M. A El Hadj, Y. Benkaouz, B. Freisleben, and M. Erradi. 2017. ABAC rule reduction via similarity computation. In Intl. Conference on Networked Systems.\n[21] David F Ferraiolo, Dennis M Gilbert, and Nickilyn Lynch. 1995. An examination\nof federal and commercial access control policy needs. In NIST-NCSC.\n[22] M.Franketal.2008.Aclassofprobabilisticmodelsforroleengineering.InCCS.\n[23] M. Frank et al. 2009. A probabilistic approach to hybrid role mining. In CCS.\n[24] M. Frank et al. 2013. Role mining with probabilistic models. TISSEC (2013).\n[25] S. Fukui et al. 2019. Distilling Knowledge for Non-Neural Networks. In APSIPA.\n[26] Jindong Gu and Volker Tresp. 2019. Semantics for global and local interpretation\nof deep neural networks. arXiv:1910.09085 (2019).\n[27] J.Hancocketal.2020.Surveyoncategoricaldataforneuralnetworks.BigData.\n[28] M. A Harrison et al. 1976. Protection in operating systems. Commun. ACM.\n[29] Kaiming He et al. 2016. Deep residual learning for image recognition. In CVPR.\n[30] G. Hinton et al. 2015. Distilling the knowledge in a neural network. arXiv.\n[31] Yaoshiang Ho and Samuel Wookey. 2019. The real-world-weight cross-entropy\nloss function: Modeling the costs of mislabeling. IEEE Access 8 (2019), 4806\u20134813.\n[32] V. C Hu et al. 2013. Guide to attribute based access control (ABAC) definition\nand considerations (draft). NIST special publication (2013).\n[33] Gao Huang et al. 2017. Densely connected convolutional networks. In CVPR.\n[34] PadmavathiIyerandAmirrezaMasoumzadeh.2018.Miningpositiveandnegative\nattribute-based access control policy rules. In SACMAT. ACM.\n[35] Padmavathi Iyer and Amirreza Masoumzadeh. 2019. Generalized Mining of Relationship-Based Access Control Policies in Evolving Systems. In SACMAT.\n[36] Padmavathi Iyer and Amirreza Masoumzadeh. 2020. Active learning of relationship-based access control policies. In SACMAT.\n[37] Amani Abu Jabal, Elisa Bertino, et al. 2020. Polisma-a framework for learning attribute-based access control policies. In ESORICS.\n[38] J. H Jafarian, H. Takabi, et al. 2015. Towards a general framework for optimal role mining: A constraint satisfaction approach. In SACMAT.\n[39] L. Karimi, M. Aldairi, J. Joshi, and M. Abdelhakim. 2021. An automatic attribute based access control policy extraction from access logs. IEEE TDSC (2021).\n[40] Leila Karimi and James Joshi. 2018. An unsupervised learning based approach\nfor mining attribute based access control policies. In Big Data. IEEE.\n[41] Alan H Karp, Harry Haury, and Michael H Davis. 2010. From ABAC to ZBAC:\nthe evolution of access control models. Journal of Information Warfare (2010). [42] Branko Kavs\u030cek and Nada Lavrac\u030c. 2006. APRIORI-SD: Adapting association rule\nlearning to subgroup discovery. Applied Artificial Intelligence (2006).\n[43] A. Kaya et al. 2019. Analysis of transfer learning for deep neural network based\nplant classification models. Computers and electronics in agriculture (2019).\n[44] L. Krautsevich et al. 2013. Towards attribute-based access control policy engi-\nneering using risk. In Intl. Workshop on Risk Assessment and Risk-driven Testing. [45] A. Liu, X. Du, and N. Wang. 2021. Efficient Access Control Permission Decision Engine Based on Machine Learning. Security & Communication Networks (2021). [46] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu. 2017. Towards deep\nlearning models resistant to adversarial attacks. arXiv:1706.06083 (2017).\n[47] Eric Medvet, Alberto Bartoli, Barbara Carminati, and Elena Ferrari. 2015. Evolu-\ntionary inference of attribute-based access control policies. In EMO. Springer. [48] N.Mehrabietal.2019.Asurveyonbiasandfairnessinmachinelearning.arXiv. [49] B. Mitra et al. 2016. A survey of role mining. Computing Surveys (CSUR) (2016). [50] D. Mocanu, F. Turkmen, and A. Liotta. 2015. Towards ABAC policy mining from\nlogs with deep learning. In International Multiconference (Intelligent Systems). [51] Ian Molloy et al. 2009. Evaluating role mining algorithms. In SACMAT. ACM. [52] I.Molloyetal.2011.Adversaries\u2019holygrail:accesscontrolanalytics.InWorkshop\non Building Analysis Datasets and Gathering Experience Returns for Security. [53] M. Narouei, H. Khanpour, H. Takabi, et al. 2017. Towards a top-down policy\nengineering framework for attribute-based access control. In SACMAT. ACM. [54] Masoud Narouei and Hassan Takabi. 2019. A Nature-Inspired Framework for Optimal Mining of Attribute-Based Access Control Policies. In ICSPCS. Springer. [55] A.Nguyen,J.Yosinski,andJ.Clune.2015.Deepneuralnetworksareeasilyfooled:\nHigh confidence predictions for unrecognizable images. In CVPR. IEEE.\n[56] G.IParisi,R.Kemker,J.LPart,C.Kanan,andS.Wermter.2019.Continuallifelong\nlearning with neural networks: A review. Neural Networks (2019).\n[57] F. Pedregosa et al. 2011. Scikit-learn: Machine Learning in Python. JMLR.\n[58] ZhangSainanandZhengChangyou.2019.ResearchandApplicationofRigorous\nAccess Control Mechanism in Distributed Objects System. In ITNEC. IEEE. [59] Matthew W Sanders and Chuan Yue. 2019. Mining least privilege attribute based\naccess control policies. In ACSAC.\n[60] Ravi Sandhu et al. 1996. Role-based access control models. Computer (1996). [61] Gerhard Schimpf. 2000. Role-engineering critical success factors for enterprise\nsecurity administration. In ACSAC. ACM.\n[62] Ju\u0308rgen Schmidhuber. 2015. Deep learning in neural networks: An overview.\nNeural networks 61 (2015).\n[63] Cedric Seger. 2018. An investigation of categorical variable encoding techniques\nin machine learning: binary versus one-hot and feature hashing.\n[64] Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje. 2017. Learning im-\nportant features through propagating activation differences. In ICML. PMLR. [65] Sara Sinclair and Sean W Smith. 2008. Preventative directions for insider threat\nmitigation via access control. In Insider Attack and Cyber Security. Springer. [66] M. Sundararajan et al. 2017. Axiomatic attribution for deep networks. In ICML. [67] Tanay Talukdar et al. 2017. Efficient bottom-up mining of attribute based access\ncontrol policies. In Intl. Conference on Collaboration and Internet Computing. IEEE. [68] L. V d Maaten and G. Hinton. 2008. Visualizing data using t-SNE. JMLR (2008). [69] J. Vaidya et al. 2010. The role mining problem: A formal perspective. TISSEC. [70] ChengGWengandJosiahPoon.2008.Anewevaluationmeasureforimbalanced\ndatasets. In 7th Australasian Data Mining Conference-Volume 87.\n[71] ChengchengXiang,YudongWu,etal.2019.TowardsContinuousAccessControl\nValidation and Forensics. In CCS. ACM.\n[72] Z.XuandS.DStoller.2012.Algorithmsforminingmeaningfulroles.InSACMAT. [73] Zhongyuan Xu and Scott D Stoller. 2014. Mining attribute-based access control\npolicies. TDSC (2014).\n[74] Zhongyuan Xu and Scott D Stoller. 2014. Mining attribute-based access control\npolicies from logs. In DBSec. Springer.\n[75] T. Zheng et al. 2019. Distributionally adversarial attack. In AAAI Conf. on AI.\n"}]